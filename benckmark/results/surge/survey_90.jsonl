{"id": "8a473653-5cf6-4f3e-941b-06c5873beaf5", "title": "Introduction", "level": "section", "subsections": ["74284b44-a1b2-476d-b3b5-489a51838419", "e5555e5b-acf2-4c85-9ee1-4bf47dcf2ae1"], "parent_id": "4c23e240-6b38-42a9-a3ad-77c4f677661a", "prefix_titles": [["title", "Learning from Noisy Labels with Deep Neural Networks: A Survey"], ["section", "Introduction"]], "content": "\\label{sec:introduction}\n\\IEEEPARstart{W}ith the recent emergence of large-scale datasets, deep neural networks (DNNs) have exhibited impressive performance in numerous machine learning tasks, such as computer vision , information retrieval , and language processing . Their success is dependent on the availability of massive but carefully labeled data, which are expensive and time-consuming to obtain. Some non-expert sources, such as Amazon's Mechanical Turk and the surrounding text of collected data, have been widely used to mitigate the high labeling cost; however, the use of these source often results in unreliable labels . \nIn addition, data labels can be extremely complex even for experienced domain experts ; \nthey can also be adversarially manipulated by a label-flipping attack . Such unreliable labels are called \\emph{noisy labels} because they may be \\emph{corrupted} from ground-truth labels. The ratio of corrupted labels in real-world datasets is reported to range from $8.0\\%$ to $38.5\\%$ . \\looseness=-1\nIn the presence of noisy labels, training DNNs is known to be susceptible to noisy labels because of the significant number of model parameters that render DNNs overfit to even corrupted labels with the capability of learning any complex function . Zhang et al.  demonstrated that DNNs can easily fit an entire training dataset with any ratio of corrupted labels, which eventually resulted in poor generalizability on a test dataset. Unfortunately, popular regularization techniques, such as data augmentation , weight decay , dropout , and batch normalization  {have been applied extensively, but they do \\emph{not} completely overcome the overfitting issue by themselves.} As shown in Figure \\ref{fig:convergence_analysis}, the gap in test accuracy between models trained on clean and noisy data remains significant even though all of the aforementioned regularization techniques are activated. Additionally, the accuracy drop with label noise is considered to be more harmful than with other noises, such as input noise . Hence, achieving a good generalization capability in the presence of noisy labels is a key challenge.\n\\begin{figure}[t!]\n\\begin{center}\n\\includegraphics[width=8.8cm]{figures/introduction/convergence.pdf}\n\\end{center}\n\\vspace*{-0.55cm}\n\\caption{Convergence curves of training and test accuracy when training WideResNet-16-8 using a standard training method on the CIFAR-100 dataset with the symmetric noise of $40\\%$: \\enquote{Noisy w/o. Reg.} and \\enquote{Noisy w. Reg.} are the models trained on noisy data without and with regularization, respectively, and \\enquote{Clean w. Reg.} is the model trained on clean data with regularization.}\n\\label{fig:convergence_analysis}\n\\vspace*{-0.4cm}\n\\end{figure}\nSeveral studies have been conducted to investigate supervised learning under noisy labels. Beyond conventional machine learning techniques , deep learning techniques have recently gained significant attention in the machine learning community. In this survey, we present the advances in recent deep learning techniques for overcoming noisy labels. We surveyed {recent studies by recursively tracking relevant bibliographies in papers published at premier research conferences, such as CVPR, ICCV, NeurIPS, ICML, and ICLR. Although we attempted to comprehensively include all recent studies at the time of submission, some of them may not be included because of the quadratic increase in deep learning papers. The studies included were grouped into \\emph{five} categories, as shown in Figure \\ref{fig:categorization} (see Section \\ref{sec:methodology} for details).\n\\begin{figure*}[t!]\n\\begin{center}\n\\includegraphics[width=16.5cm]{figures/introduction/catorization_revise.pdf}\n\\end{center}\n\\vspace*{-0.55cm}\n\\caption{Categorization of recent deep learning methods for overcomming noisy labels.}\n\\label{fig:categorization}\n\\vspace*{-0.4cm}\n\\end{figure*}", "cites": [7, 206, 7210, 4238, 7770, 71, 3630, 8734, 4116, 4115, 7769], "cite_extract_rate": 0.39285714285714285, "origin_cites_number": 28, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.5, "critical": 3.0, "abstraction": 3.0}, "insight_level": "medium", "analysis": "The introduction section synthesizes key points from multiple cited papers to establish the context of noisy labels in deep learning, connecting issues like overfitting, regularization limitations, and the impact of label noise on generalization. It includes critical observations, such as the ineffectiveness of standard regularization techniques in overcoming noisy label challenges. While it identifies some broader patterns (e.g., the scalability vs. effectiveness trade-off in label cleaning), the abstraction remains limited to general trends without deeper meta-level insights into the field."}}
{"id": "74284b44-a1b2-476d-b3b5-489a51838419", "title": "Related Surveys", "level": "subsection", "subsections": [], "parent_id": "8a473653-5cf6-4f3e-941b-06c5873beaf5", "prefix_titles": [["title", "Learning from Noisy Labels with Deep Neural Networks: A Survey"], ["section", "Introduction"], ["subsection", "Related Surveys"]], "content": "\\label{sec:related_surveys}\nFr{\\'e}nay and Verleysen  discussed the potential negative consequence of learning from noisy labels and provided a comprehensive survey on noise-robust classification methods, focusing on conventional supervised approaches such as na\\\"ive Bayes and support vector machines. Furthermore, their survey included the definitions and sources of label noise as well as the taxonomy of label noise. Zhang et al.  discussed another aspect of label noise in crowdsourced data annotated by non-experts and provided a thorough review of expectation-maximization (EM) algorithms that were proposed to improve the quality of crowdsourced labels. Meanwhile, Nigam et al.  provided a brief introduction to deep learning algorithms that were proposed to manage noisy labels; however, the scope of these algorithms was limited to only two categories, i.e., the loss function and sample selection in Figure \\ref{fig:categorization}. Recently, Han et al.  summarized the essential components of robust learning with noisy labels, but their categorization is totally different from ours in philosophy; {we mainly focus on systematic methodological difference, whereas they rather focused on more general views, such as input data, objective functions, and optimization policies. Furthermore, this survey is the first to present a comprehensive methodological comparison of existing robust training approaches (see Tables \\ref{table:all_comparision} and \\ref{table:direction_comparison}}).", "cites": [7771], "cite_extract_rate": 0.25, "origin_cites_number": 4, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.5, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section effectively synthesizes multiple related surveys, highlighting their focus areas and methodological perspectives. It offers a critical comparison of these works by pointing out their limitations, such as limited scope or differing categorization philosophies. The section abstracts from individual contributions to establish a broader understanding of the landscape, positioning this survey as more systematic and comprehensive in its methodological approach."}}
{"id": "e5555e5b-acf2-4c85-9ee1-4bf47dcf2ae1", "title": "Survey Scope", "level": "subsection", "subsections": [], "parent_id": "8a473653-5cf6-4f3e-941b-06c5873beaf5", "prefix_titles": [["title", "Learning from Noisy Labels with Deep Neural Networks: A Survey"], ["section", "Introduction"], ["subsection", "Survey Scope"]], "content": "\\label{sec:survey_scope}\n{\nRobust training with DNNs becomes critical to guarantee the reliability of machine learning algorithms. In addition to label noise, two types of flawed training data have been actively studied by different communities . \\emph{Adversarial learning} is designed for small, worst-case perturbations of the inputs, so-called adversarial examples, which are maliciously constructed to deceive an already trained model into making errors . Meanwhile, \\emph{data imputation} primarily deals with missing inputs in training data, where missing values are estimated from the observed ones . Adversarial learning and data imputation are closely related to robust learning, but handling \\emph{feature} noise is beyond the scope of this survey---i.e., learning from noisy \\emph{labels}. \n}", "cites": [8696, 4118, 313, 4117], "cite_extract_rate": 0.5714285714285714, "origin_cites_number": 7, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.5, "critical": 2.0, "abstraction": 2.0}, "insight_level": "medium", "analysis": "The section provides a basic synthesis by mentioning related fields like adversarial learning and data imputation, and it connects them to the broader theme of robust learning. However, it does not integrate the cited papers deeply or develop a novel perspective. The analysis is minimal, focusing more on description than evaluation or critique. Abstraction is limited to identifying that these problems are related, without generalizing to higher-level principles."}}
{"id": "5a2e6abe-21d0-4935-ab73-f9bf0caf9ca6", "title": "Instance-independent Label Noise", "level": "subsubsection", "subsections": [], "parent_id": "53f5fc74-56fd-44a0-ad89-6075838d51dd", "prefix_titles": [["title", "Learning from Noisy Labels with Deep Neural Networks: A Survey"], ["section", "Preliminaries"], ["subsection", "Taxonomy of Label Noise"], ["subsubsection", "Instance-independent Label Noise"]], "content": "}\nA typical approach for modeling label noise assumes that the corruption process is conditionally \\emph{independent} of data features when the true label is given . That is, the true label is corrupted by a \\emph{noise transition matrix} $\\text{T} \\in [0, 1]^{c\\times c}$, where $ \\text{T}_{ij} \\coloneqq p(\\tilde{y}=j|y=i)$ is the probability of the true label $i$ being flipped into a corrupted label $j$. \nIn this approach, the noise is called a \\emph{symmetric}\\,(or \\emph{uniform}) noise with a noise rate $\\tau \\in [0,1]$ if $\\forall_{i=j} \\text{T}_{ij} \\!=\\! 1-\\tau \\wedge \\forall_{i \\neq j} \\text{T}_{ij} = \\frac{\\tau}{c-1}$, where a true label is flipped into other labels with equal probability. In contrast to symmetric noise, the noise is called an \\emph{asymmetric}\\,(or \\emph{label-dependent}) noise if $\\forall_{i=j} \\text{T}_{ij} \\!=\\! 1-\\tau \\wedge \\exists_{i \\neq j, i\\neq k, j\\neq k} \\text{T}_{ij} > \\text{T}_{ik} $, where a true label is more likely to be mislabeled into a particular label. For example, a \\enquote{dog} is more likely to be confused with a \\enquote{cat} than with a \\enquote{fish.} In a stricter case when $\\forall_{i=j} \\text{T}_{ij} \\!=\\! 1-\\tau \\wedge \\exists_{i \\neq j} \\text{T}_{ij} = \\tau$, the noise is called a \\emph{pair noise}, where a true label is flipped into only a certain label.  \n\\smallskip", "cites": [3630], "cite_extract_rate": 0.5, "origin_cites_number": 2, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 2.0, "abstraction": 2.5}, "insight_level": "medium", "analysis": "The section provides a factual description of instance-independent label noise, introducing symmetric, asymmetric, and pair noise with definitions and examples. It cites one paper primarily to ground the concept in the broader context of deep learning generalization. While it organizes the noise types clearly, it lacks critical evaluation of methods or limitations and offers only basic abstraction by classifying noise patterns without deeper insights into their implications or interactions."}}
{"id": "587ccbe7-447b-402d-9bec-671027007ca9", "title": "Non-deep Learning Approaches", "level": "subsection", "subsections": [], "parent_id": "345d7d1c-66a9-4d03-80b2-cee975c6db53", "prefix_titles": [["title", "Learning from Noisy Labels with Deep Neural Networks: A Survey"], ["section", "Preliminaries"], ["subsection", "Non-deep Learning Approaches"]], "content": "\\label{sec:non_deep_learning}\nFor decades, numerous methods have been proposed to manage noisy labels using conventional machine learning techniques. These methods can be categorized into \\emph{four} groups , as follows:\n\\begin{itemize}[leftmargin=9pt]\n\\item \\textbf{Data Cleaning:} Training data are cleaned by excluding examples whose labels are likely to be corrupted. Bagging and boosting are used to filter out false-labeled examples to remove examples with higher weights because false-labeled examples tend to exhibit much higher weights than true-labeled examples . In addition, various methods, such as $k$-nearest neighbor, outlier detection, and anomaly detection, have been widely exploited to exclude false-labeled examples from noisy training data . Nevertheless, this family of methods suffers from over-cleaning issue that overly removes even the true-labeled examples. \n\\vspace*{0.12cm}\n\\item \\textbf{Surrogate Loss:} Motivated by the noise-tolerance of the 0-1 loss function , many researchers have attempted to resolve its inherent limitations, such as computational hardness and non-convexity  that render gradient methods unusable. Hence, several convex surrogate loss functions, which approximate the 0-1 loss function, have been proposed to train a specified classifier under the binary classification setting . However, these loss functions cannot support the multi-class classification task.\n\\vspace*{0.12cm}\n\\item \\textbf{Probabilistic Method:} Under the assumption that the distribution of features is helpful in solving the problem of learning from noisy labels , the confidence of each label is estimated by clustering and then used for a weighted training scheme . This confidence is also used to convert hard labels into soft labels to reflect the uncertainty of labels . In addition to these clustering approaches, several Bayesian methods have been proposed for graphical models such that they can benefit from using any type of prior information in the learning process . However, this family of methods may exacerbate the overfitting issue owing to the increased number of model parameters.  \n\\vspace*{0.12cm}\n\\item \\textbf{Model-based Method:} As conventional models, such as the SVM and decision tree, are not robust to noisy labels, significant effort has been expended to improve the robustness of them. To develop a robust SVM model, misclassified examples during learning are penalized in the objective . In addition, several decision tree models are extended using new split criteria to solve the overfitting issue when the training data are not fully reliable . However, it is infeasible to apply their design principles to deep learning.\n\\end{itemize}\n\\smallskip\n{\nMeanwhile, deep learning is more susceptible to label noises than traditional machine learning owing to its high expressive power, as proven by many researchers . \nThere has been significant effort to understand why noisy labels negatively affect the performance of DNNs . This theoretical understanding has led to the algorithmic design which achieves higher robustness than non-deep learning methods. A detailed analysis of theoretical understanding for robust deep learning was provided by Han et al. . \n}\n\\begin{comment}\n\\vspace*{-0.2cm}", "cites": [3454, 7771, 4121, 8735, 4120, 4122, 3630, 4119, 4115, 8736], "cite_extract_rate": 0.3448275862068966, "origin_cites_number": 29, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.5, "critical": 2.0, "abstraction": 2.5}, "insight_level": "medium", "analysis": "The section provides a descriptive overview of non-deep learning approaches to label noise, categorizing them into four groups and briefly summarizing their mechanisms and limitations. It makes minimal effort to synthesize ideas across the cited papers, instead listing methods and their outcomes. Some abstract patterns (e.g., over-cleaning, overfitting) are noted, but the section lacks deeper critical evaluation or meta-level insights."}}
{"id": "f4b49791-795c-49a1-9ee2-043cc9fa43e4", "title": "Theoretical Foundations", "level": "subsection", "subsections": [], "parent_id": "345d7d1c-66a9-4d03-80b2-cee975c6db53", "prefix_titles": [["title", "Learning from Noisy Labels with Deep Neural Networks: A Survey"], ["section", "Preliminaries"], ["subsection", "Theoretical Foundations"]], "content": "\\label{sec:theoretical}\n{\nDeep learning is more susceptible to label noises than traditional machine learning owing to its high expressive power, as proven by many researchers . \nThere has been significant effort to understand why noisy labels negatively affect the performance of DNNs . This theoretical understanding has led to the architectural or algorithmic design which is more robust than the non-deep learning methods. A detailed analysis of theoretical understanding for robust deep learning was provided by Han et al. ; \\emph{three} high-level perspectives have been widely leveraged to design robust approaches, as follows:\n\\vspace*{0.05cm}\n\\newcommand{\\norm}[1]{\\left\\lVert#1\\right\\rVert}\n\\begin{itemize}[leftmargin=9pt]\n\\item \\textbf{Memorization Effect}: The \\emph{memorization nature} of DNNs was explored theoretically in recent literature . Assuming clusterable data where the clusters are located on the unit Euclidean ball, Li et al.  proved the distance from the initial weight ${W}_{0}$ to the weight ${W}_t$ after $t$ iterations,\n\\begin{equation}\n\\label{eq:memorization_effect_foundation}\n\\norm{{W}_t - {W}_0}_{F} \\lesssim \\big( \\sqrt{K} + (K^{2}\\epsilon_{0}/\\norm{{C}}^{2})t \\big),\n\\end{equation}\nwhere $\\norm{\\cdot}_{F}$ is the Frobenius norm, $K$ is the number of clusters, and ${C}$ is the set of cluster centers reaching all input examples within their $\\epsilon_0$ neighborhood.\nEq.\\ \\eqref{eq:memorization_effect_foundation} demonstrates that the weights of DNNs start to stray far from the initial weights when overfitting to corrupted labels, while they are still in the vicinity of the initial weights at the beginning of training . In the empirical studies , this result is also known as the \\emph{memorization effect} that DNNs tend to first learn simple and generalized patterns and then gradually overfit to all the noisy patterns. Thus, to achieve better generalization, early stopping  and favoring small-loss training examples  are commonly employed to design robust training methods.\n\\end{itemize}\n}\n\\end{comment}\n\\vspace*{-0.2cm}", "cites": [7771, 3340, 4126, 3630, 4253, 8735, 4120, 4124, 4125, 4115, 4123], "cite_extract_rate": 0.6470588235294118, "origin_cites_number": 17, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 2.5, "abstraction": 3.5}, "insight_level": "medium", "analysis": "The section synthesizes multiple papers to explain the 'memorization effect' in DNNs and its implications for robust training. It integrates theoretical and empirical perspectives to build a coherent narrative. However, it mainly summarizes the key findings without deep critical evaluation or contrasting different viewpoints. The abstraction level is moderate, as it generalizes the memorization effect and links it to broader robust training strategies."}}
{"id": "7dbbb1a5-6e79-42e1-a3b6-1ed894715ef6", "title": "Regression with Noisy Labels", "level": "subsection", "subsections": [], "parent_id": "345d7d1c-66a9-4d03-80b2-cee975c6db53", "prefix_titles": [["title", "Learning from Noisy Labels with Deep Neural Networks: A Survey"], ["section", "Preliminaries"], ["subsection", "Regression with Noisy Labels"]], "content": "\\label{sec:regression}\n{\nIn addition to classification, regression is another main topic of supervised machine learning, which aims to model the relationship between a number of features and a continuous target variable. Unlike the classification task with a \\emph{discrete} label space, the regression task considers the continuous variable as its target label , and thus it learns the mapping function $f(~\\cdot~; \\Theta): \\mathcal{X} \\rightarrow \\mathcal{Y}$, where $\\mathcal{Y} \\in \\mathbb{R}$ is a \\emph{continuous} label space. \nGiven the input feature $x$ and its ground-truth label $y$, two types of label noise are considered in the regression task. An \\emph{additive noise}  is formulated by $\\tilde{y} := y + \\epsilon$ where $\\epsilon$ is drawn from a random distribution  independent from the input feature; an \\emph{instance-dependent noise}  is formulated by $\\tilde{y} := \\rho(x)$ where $\\rho: \\mathcal{X} \\rightarrow \\mathcal{Y}$ is a noise function dependent on the input feature.  \nAlthough regression predicts continuous values, regression and classification share the same concept of learning the mapping function from the input feature $x$ to the output label $y$. Thus, many robust approaches for classification are easily extended to the regression problem with simple modification . Thus, in this survey, we focus on the classification setting for which most robust methods are defined.\n}\n\\vspace*{-0.1cm}", "cites": [4127], "cite_extract_rate": 0.25, "origin_cites_number": 4, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 1.5, "abstraction": 2.5}, "insight_level": "low", "analysis": "The section provides a basic description of regression with noisy labels, differentiating it from classification and introducing two types of label noise. It mentions that robust classification approaches can be adapted to regression with minor modifications but does not synthesize or connect ideas from multiple papers. There is minimal critical evaluation or abstraction beyond the specific context of the cited work."}}
{"id": "60bd8c81-37fb-4934-ab18-bb9a24e80724", "title": "Deep Learning Approaches", "level": "section", "subsections": ["f16bcc10-a9fa-4749-b206-8aa388990240", "25e15182-1991-4f1a-83d9-017fe1a40d14", "59ab6098-f130-49dc-b87f-123eaa6be482", "3d40345d-b6d6-4b98-943c-ec552f10d7fb", "54d73157-e47b-4943-9b30-b518e1806946"], "parent_id": "4c23e240-6b38-42a9-a3ad-77c4f677661a", "prefix_titles": [["title", "Learning from Noisy Labels with Deep Neural Networks: A Survey"], ["section", "Deep Learning Approaches"]], "content": "\\label{sec:methodology}\n\\vspace*{-0.0cm}\nAccording to our comprehensive survey, the robustness of deep learning can be enhanced in numerous approaches . Figure \\ref{fig:tree_categorization} shows an overview of recent research directions conducted by the machine learning community. {All of them\\,(i.e., \\textsection \\ref{sec:robust_architecture}~--~\\textsection \\ref{sec:sample_selection}) focused on making a supervised learning process more robust to label noise: \\looseness=-1\n\\begin{itemize}[leftmargin=9pt]\n\\item\n(\\textsection \\ref{sec:robust_architecture}) Robust architecture: adding a noise adaptation layer at the top of an underlying DNN to learn label transition process or developing a dedicated architecture to reliably support more diverse types of label noise;\n\\vspace*{0.12cm}\n\\item (\\textsection \\ref{sec:robust_regularization}) Robust regularization: enforcing a DNN to overfit less to false-labeled examples explicitly or implicitly;\n\\vspace*{0.12cm}\n\\item (\\textsection \\ref{sec:robust_loss_function}) Robust loss function: improving the loss function;\n\\vspace*{0.12cm}\n\\item (\\textsection \\ref{sec:loss_adjustment}) Loss adjustment: adjusting the loss value according to the confidence of a given loss (or label) by loss correction, loss reweighting, or label refurbishment; \n\\vspace*{0.12cm}\n\\item (\\textsection \\ref{sec:sample_selection}) Sample selection: identifying true-labeled examples from noisy training data via multi-network or multi-round learning. \n\\end{itemize}\nOverall, we categorize all recent deep learning methods into \\emph{five} groups corresponding to popular research directions, as shown in Figure \\ref{fig:tree_categorization}. In \\textsection \\ref{sec:loss_adjustment}, meta learning is also discussed because it finds the optimal hyperparameters for loss reweighting. In \\textsection \\ref{sec:sample_selection}, we discuss the recent efforts for combining sample selection with other orthogonal directions or semi-supervised learning toward the state-of-the-art performance.}\nFigure \\ref{fig:categorization} illustrates the categorization of robust training methods using these five groups. \n\\begin{comment}\n{\n\\newcolumntype{L}[1]{>{\\centering\\let\\newline\\\\\\arraybackslash\\hspace{0pt}}m{#1}}\n\\newcolumntype{X}[1]{>{\\centering\\let\\newline\\\\\\arraybackslash\\hspace{0pt}}p{#1}}\n\\begin{table}[t!]\n\\caption{Summary of existing deep learning methods according to the seven categories in Figure \\ref{fig:categorization}.}\n\\vspace*{-0.3cm}\n\\begin{center}\n\\begin{tabular}{L{1.75cm} |X{6.23cm}}\\toprule\n\\!\\!\\textbf{Category} & \\textbf{Deep Learning Method}  \\\\\\midrule \nRobust Loss Function & \\makecell[l]{\\!\\!\\emph{Robust MAE}\\,\\!, \\emph{Generalized Cross Entropy}\\,\\!,\\!\\!\\!\\\\ \\!\\!\\emph{Symmetric Cross Entropy}\\,\\!, \\emph{Curriculum Loss}\\,\\!}\\!\\!\\! \\\\\\hline\nRobust Architecture & \\makecell[l]{ \\!\\!\\emph{Webly Learning}\\,\\!, \\emph{Noise Model}\\,\\!, \\emph{Dropout Noise} \\!\\!\\!\\!\\!\\\\ \\!\\!\\emph{Model}\\,\\!, \\emph{S--model}\\,\\!, \\emph{C--model}\\,\\!, \\emph{NLNN}\\,\\!, \\!\\!\\!\\!\\!\\\\ \\!\\!\\emph{Probabilistic Noise Model}\\,\\!, \\emph{Masking}\\,\\!,\\!\\!\\!\\\\ \\!\\!\\emph{Contrastive-additive Noise Network}\\,\\!}\\!\\!\\! \\\\\\hline\nRobust Regularization & \\makecell[l]{ \\!\\!\\!\\! \\emph{Adversarial Training}\\,\\!, \\emph{Label Smoothing}\\,\\!,\\!\\!\\!\\\\ \\!\\!\\emph{Mixup}\\,\\!, \\emph{Bilevel Learning}\\,\\!, \\emph{Annotator}\\!\\!\\!\\\\ \\!\\!\\!\\! \\emph{Confusion}\\,\\!, \\emph{Pre-training}\\,\\!\\!\\!} \\!\\!\\!\\\\\\hline\n\\!\\!Loss Adjustment\\!\\!\\! & \\makecell[l]{ \\!\\!\\emph{Backward Correction}\\,\\!}, \\emph{Forward Correction}\\,\\!}, \\!\\!\\!\\\\ \\!\\!\\emph{Gold}\\! \\emph{Loss}\\! \\emph{Correction}\\,\\!\\!,  \\emph{Importance}\\! \\emph{Reweighting}\\,\\!\\!, \\!\\!\\!\\!\\!\\!\\\\ \\!\\!\\emph{Active Bias}\\! ,  \\emph{Bootstrapping}\\! , \\emph{Dynamic} \\!\\!\\\\ \\!\\!\\!\\! \\emph{Bootstrapping}\\,\\!, \\emph{D2L}\\,\\!, \\emph{SELFIE}\\,\\! }\\!\\!\\!\\\\\\hline\n\\!\\!\\!Sample Selection\\!\\!\\! & \\makecell[l]{\\!\\!\\emph{Decouple}\\,\\!, \\emph{MentorNet}\\,\\!, \\emph{Co-teaching}\\,\\!,\\!\\!\\!\\\\ \\!\\!\\emph{Co-teaching+}\\,\\!, \\emph{Iterative Detection}\\,\\!,\\!\\!\\!\\\\ \\!\\!\\emph{ITLM}\\,\\!, \\emph{INCV}\\,\\!, \\emph{SELFIE}\\,\\!, \\emph{SELF}\\,\\!,\\!\\!\\!\\\\ \\!\\!\\emph{Curriculum Loss}\\,\\!}\\!\\!\\!\\\\\\hline\n\\!\\!\\!Meta Learning\\!\\!\\! & \\makecell[l]{ \\!\\!\\emph{Meta-Regressor}\\,\\!, \\emph{Knowledge Distillation}\\,\\!,\\!\\!\\!\\\\ \\!\\!\\emph{L2LWS}\\,\\!, \\emph{CWS}\\,\\!, \\emph{Automatic Reweighting}\\,\\!,\\!\\!\\!\\\\ \\!\\!\\emph{MLNT}\\,\\!, \\emph{Meta-weight-net}\\,\\!} \\!\\!\\!\\\\\\hline\n\\!\\!Semi-supervised\\!\\! \\!Learning\\! & \\makecell[l]{ \\!\\!\\emph{Label Aggregation}\\,\\!, \\emph{Two-Stage Framework}\\,\\!,\\!\\!\\!\\\\ \\!\\!\\emph{SELF} , \\emph{DivideMix}\\,\\!}\\!\\!\\! \\\\\\bottomrule\n\\end{tabular}\n\\end{center}\n\\label{table:summary_methods}\n\\vspace*{-0.5cm}\n\\end{table}\n}\n\\end{comment}", "cites": [3340, 4129, 4143, 7133, 4137, 7773, 3345, 4134, 4132, 4140, 4141, 7775, 4126, 3342, 4142, 7772, 8737, 4130, 4138, 7191, 7162, 4135, 4144, 4145, 7774, 4139, 4125, 892, 4128, 4253, 4131, 8630, 4133, 2277, 4136], "cite_extract_rate": 0.7777777777777778, "origin_cites_number": 45, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.5, "critical": 2.0, "abstraction": 2.5}, "insight_level": "medium", "analysis": "The section provides a descriptive overview of various deep learning approaches to robust training with noisy labels, listing methods and grouping them into five categories. While it references several papers and aligns them with these categories, it lacks deeper synthesis of their underlying ideas and does not critically evaluate their strengths or limitations. Some abstraction is present in the form of categorization, but the overall insight remains at a medium level due to limited comparative or evaluative analysis."}}
{"id": "f16bcc10-a9fa-4749-b206-8aa388990240", "title": "Robust Architecture", "level": "subsection", "subsections": ["439a17f4-972c-4739-b63c-f2fd25ca8426", "81044d2e-5255-4dbd-8274-7c1d26bb1d92"], "parent_id": "60bd8c81-37fb-4934-ab18-bb9a24e80724", "prefix_titles": [["title", "Learning from Noisy Labels with Deep Neural Networks: A Survey"], ["section", "Deep Learning Approaches"], ["subsection", "Robust Architecture"]], "content": "\\label{sec:robust_architecture}\nIn numerous studies, architectural changes have been made to model the noise transition matrix of a noisy dataset . These changes include adding a noise adaptation layer at the top of the softmax layer and designing a new dedicated architecture. The resulting architectures yield improved generalization through the modification of the DNN output based on the estimated label transition probability.\n\\vspace*{0.15cm}", "cites": [4138, 4133, 4146, 7773, 2277, 4136], "cite_extract_rate": 0.6666666666666666, "origin_cites_number": 9, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 1.5, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section provides a brief, factual description of the idea of modifying DNN architectures for robust training with noisy labels but lacks deeper synthesis or comparison of the cited works. It mentions architectural changes and their purpose without critically analyzing their strengths, weaknesses, or differences. There is minimal abstraction beyond specific implementations, resulting in a low-level descriptive overview."}}
{"id": "439a17f4-972c-4739-b63c-f2fd25ca8426", "title": "Noise Adaptation Layer", "level": "subsubsection", "subsections": [], "parent_id": "f16bcc10-a9fa-4749-b206-8aa388990240", "prefix_titles": [["title", "Learning from Noisy Labels with Deep Neural Networks: A Survey"], ["section", "Deep Learning Approaches"], ["subsection", "Robust Architecture"], ["subsubsection", "Noise Adaptation Layer"]], "content": "}\n\\label{sec:adaptation_layer}\n{\nFrom the view of training data, the noise process is modeled by discovering the underlying label transition pattern (i.e., the {noise transition matrix} T). Given an example $x$, the noisy class posterior probability for an example $x$ is expressed by\n\\begin{equation}\n\\label{eq:label_transition_matrix}\n\\begin{gathered}\n\\!\\!\\!\\!\\!p(\\tilde{y}=j|x) \\!=\\!\\sum_{i=1}^{c}p(\\tilde{y}=j, y=i|x)\\! = \\!\\sum_{i=1}^{c}\\text{T}_{ij}p(y=i|x),\\\\\n\\text{where} ~~ \\text{T}_{ij} = p(\\tilde{y}=j|y=i,x).\n\\end{gathered}\n\\end{equation} \nIn light of this, the noise adaptation layer is intended to mimic the label transition behavior in learning a DNN. Let $p(y|x;\\Theta)$ be the output of the base DNN with a softmax output layer.\nThen, following  Eq.\\,\\eqref{eq:label_transition_matrix}, the probability of an example $x$ being predicted as its noisy label $\\tilde{y}$ is parameterized by }\n\\begin{equation}\n\\label{eq:noise_adaption_process}\n\\begin{split}\n\\!\\!\\!p(\\tilde{y}=j|x;\\Theta, \\mathcal{W})&= \\sum_{i=1}^{c}p(\\tilde{y}=j, y\\!=\\!i|x; \\Theta, \\mathcal{W})\\\\\n&= \\sum_{i=1}^{c}\\underbrace{p(\\tilde{y}=j|y\\!=\\!i;\\mathcal{W})}_{\\text{Noise Adaptation Layer}}\\underbrace{p(y\\!=\\!i|x;\\Theta)}_{\\text{Base Model}}.\n\\end{split}\n\\end{equation}\nHere, the noisy label $\\tilde{y}$ is assumed to be \\emph{conditionally independent} of the input $x$ in general. \nAccordingly, as shown in Figure \\ref{fig:noise_adaption_process}, the noisy adaptation layer is added at the top of the base DNN to model the noise transition matrix parameterized by $\\mathcal{W}$. This layer should be removed when test data is to be predicted. \\looseness=-1\n\\begin{figure}[t!]\n\\begin{center}\n\\includegraphics[width=8.5cm]{figures/methodology/noise_adaption_layer.pdf}\n\\end{center}\n\\vspace*{-0.4cm}\n\\caption{Noise modeling process using the noise adaptation layer.}\n\\label{fig:noise_adaption_process}\n\\vspace*{-0.3cm}\n\\end{figure}\n\\smallskip\n\\noindent \\underline{Technical Detail}: \\emph{Webly learning}  first trains the base DNN only for easy examples retrieved by search engines; subsequently, the confusion matrix for all training examples is used as the initial weight $\\mathcal{W}$ of the noise adaptation layer. It fine-tunes the entire model in an end-to-end manner for hard training examples. In contrast, the \\emph{noise model}  initializes $\\mathcal{W}$ to an identity matrix and adds a regularizer to force $\\mathcal{W}$ to diffuse during DNN training. The \\emph{dropout noise model}  applies dropout regularization to the adaptation layer, whose output is normalized by the softmax function to implicitly diffuse $\\mathcal{W}$. The \\emph{s-model}  is similar to the \\emph{dropout noise model} but dropout is not applied. The \\emph{c-model}  is an extension of the s-model that models the instance-dependent noise, which is more realistic than the symmetric and asymmetric noises. Meanwhile, \\emph{NLNN}  adopts the EM algorithm to iterate the E-step to estimate the noise transition matrix and the M-step to back-propagate the DNN. \\looseness=-1\n\\smallskip\n\\noindent {\\underline{Remark}: A common drawback of this family is their inability to identify false-labeled examples, treating all the examples equally. Thus, the estimation error for the transition matrix is generally large when only noisy training data is used or when the noise rate is high .}\nMeanwhile, for the EM-based method, becoming stuck in local optima is inevitable, and high computational costs are incurred .\n\\vspace*{0.15cm}", "cites": [7776, 2277, 4136], "cite_extract_rate": 0.5, "origin_cites_number": 6, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.0, "abstraction": 3.5}, "insight_level": "medium", "analysis": "The section synthesizes the concept of the noise adaptation layer by integrating and generalizing the mathematical formulation from the cited papers, providing a clear and unified explanation. It includes a critical remark about the limitations of the approach, particularly its inability to distinguish false-labeled examples and issues with estimation error and EM-based methods. The abstraction level is moderate, as it identifies a general framework (noise transition matrix modeling) but does not elevate the discussion to a more meta-level or broader theoretical insight."}}
{"id": "81044d2e-5255-4dbd-8274-7c1d26bb1d92", "title": "Dedicated Architecture", "level": "subsubsection", "subsections": [], "parent_id": "f16bcc10-a9fa-4749-b206-8aa388990240", "prefix_titles": [["title", "Learning from Noisy Labels with Deep Neural Networks: A Survey"], ["section", "Deep Learning Approaches"], ["subsection", "Robust Architecture"], ["subsubsection", "Dedicated Architecture"]], "content": "} \n{Beyond the label-dependent label noise, several studies have been conducted to support more complex noise, leading to the design of dedicated architectures .} They typically aimed at increasing the reliability of estimating the label transition probability to handle more complex and realistic label noise. \n\\smallskip\n\\noindent \\underline{Technical Detail}: \\emph{Probabilistic noise modeling}  manages two independent networks, each of which is specialized to predict the noise type and label transition probability.\nBecause an EM-based approach with random initialization is impractical for training the entire network, both networks are trained with massive noisy labeled data after the pre-training step with a small amount of clean data.\nMeanwhile, \\emph{masking}  is a human-assisted approach to convey the human cognition of invalid label transitions.\nConsidering that noisy labels are mainly from the interaction between humans and tasks, the invalid transition investigated by humans was leveraged to constrain the noise modeling process. Owing to the difficulty in specifying the explicit constraint, a variant of generative adversarial networks\\,(GANs)  was employed in this study. Recently, the \\emph{contrastive-additive noise network}  was proposed to adjust incorrectly estimated label transition probabilities by introducing a new concept of quality embedding, which models the trustworthiness of noisy labels. {\\emph{RoG}  builds a simple yet robust generative classifier on top of any discriminative DNN pre-trained on noisy data.}\n\\smallskip\n\\noindent \\underline{Remark}: Compared with the noise adaptation layer, this family of methods significantly improves the robustness to more diverse types of label noise, but it cannot be easily extended to other architectures in general.", "cites": [4138, 7773, 8738], "cite_extract_rate": 0.6, "origin_cites_number": 5, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.0, "critical": 2.5, "abstraction": 3.0}, "insight_level": "medium", "analysis": "The section provides a focused analytical overview of dedicated architectures for handling label noise, connecting key techniques like probabilistic noise modeling, masking, and contrastive-additive networks. It synthesizes the cited papers by highlighting their methodological contributions and how they aim to improve label transition probability estimation. While it offers some critical remarks on the limitations of these methods (e.g., difficulty in extending to other architectures), the critique is not deeply nuanced. The section identifies general patterns in architectural robustness but does not elevate the discussion to a meta-level or propose new conceptual frameworks."}}
{"id": "25e15182-1991-4f1a-83d9-017fe1a40d14", "title": "Robust Regularization", "level": "subsection", "subsections": ["84774a8d-19b4-4ef8-ba90-419f51709a46", "50da4bbd-f1a0-49f9-b327-8d43650a94c6"], "parent_id": "60bd8c81-37fb-4934-ab18-bb9a24e80724", "prefix_titles": [["title", "Learning from Noisy Labels with Deep Neural Networks: A Survey"], ["section", "Deep Learning Approaches"], ["subsection", "Robust Regularization"]], "content": "\\label{sec:robust_regularization}\nRegularization methods have been widely studied to improve the generalizability of a learned model in the machine learning community . \nBy avoiding overfitting in model training, the robustness to label noise improves with widely-used regularization techniques such as \\emph{data augmentation} , \\emph{weight decay} , \\emph{dropout} , and \\emph{batch normalization} . {These canonical regularization methods operate well on moderately noisy data, but they alone do \\emph{not sufficiently} improve the test accuracy}; poor generalization could be obtained when the noise is heavy . Thus, more advanced regularization techniques have been recently proposed, which further improved robustness to label noise when used along with the canonical methods. The main advantage of this family is its \\emph{flexibility} in collaborating with other directions because it only requires simple modifications. \n\\smallskip", "cites": [4142, 71], "cite_extract_rate": 0.4, "origin_cites_number": 5, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.0, "critical": 2.5, "abstraction": 3.0}, "insight_level": "medium", "analysis": "The section integrates the concept of regularization in the context of noisy labels, linking general methods like dropout and batch normalization with more specific works such as regularized estimation of annotator confusion. It provides a basic synthesis by highlighting how canonical techniques work on moderate noise but fail under heavy noise. While there is some critical analysis (e.g., noting that standard methods are insufficient for heavy noise), it lacks deeper comparative or evaluative discussion of the cited papers. The abstraction level is moderate, as it identifies patterns in the effectiveness of regularization for robust training but stops short of providing a meta-level framework."}}
{"id": "84774a8d-19b4-4ef8-ba90-419f51709a46", "title": "Explicit Regularization", "level": "subsubsection", "subsections": [], "parent_id": "25e15182-1991-4f1a-83d9-017fe1a40d14", "prefix_titles": [["title", "Learning from Noisy Labels with Deep Neural Networks: A Survey"], ["section", "Deep Learning Approaches"], ["subsection", "Robust Regularization"], ["subsubsection", "Explicit Regularization"]], "content": "}\n{\nThe regularization can be an {explicit} form that modifies the expected training loss, e.g., weight decay and dropout. \n}\n\\smallskip\n\\noindent \\underline{Technical Detail}:\n\\emph{Bilevel learning}  uses a clean validation dataset to regularize the overfitting of a model by introducing a bilevel optimization approach, which differs from the conventional one in that its regularization constraint is also an optimization problem. Overfitting is controlled by adjusting the weights on each mini-batch and selecting their values such that they minimize the error on the validation dataset. Meanwhile, \\emph{annotator confusion}  assumes the existence of multiple annotators and introduces a regularized EM-based approach to model the label transition probability; its regularizer enables the estimated transition probability to converge to the true confusion matrix of the annotators. \nIn contrast, \\emph{pre-training}  empirically proves that fine-tuning on a pre-trained model provides a significant improvement in robustness compared with models trained from scratch; the universal representations of pre-training prevent the model parameters from being updated in the wrong direction by noisy labels. { \\emph{PHuber}  proposes a composite loss-based gradient clipping, which is a variation of standard gradient clipping for label noise robustness. \\emph{Robust early-learning}  classifies critical parameters and non-critical parameters for fitting clean and noise labels, respectively. Then, it penalizes only the non-critical ones with a different update rule.} \n{\\emph{ODLN}  leverages open-set auxiliary data and prevents the overfitting to noisy labels by assigning random labels to the open-set examples, which are uniformly sampled from the label set.}\n\\smallskip\n\\noindent {\\underline{Remark}: The explicit regularization often introduces sensitive model-dependent hyperparameters or requires deeper architectures to compensate for the reduced capacity, yet it can lead to significant performance gain if they are optimally tuned. \\looseness=-1}\n\\smallskip", "cites": [4147, 4131, 7133, 4142], "cite_extract_rate": 0.6666666666666666, "origin_cites_number": 6, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.5, "critical": 2.0, "abstraction": 2.0}, "insight_level": "medium", "analysis": "The section provides a descriptive overview of explicit regularization methods for learning from noisy labels, listing several approaches with brief explanations. While it mentions different techniques and links each to a paper, the synthesis is limited to basic grouping without deeper conceptual integration. There is minimal critical analysis or abstraction to broader principles, and the 'Remark' only briefly touches on a limitation (hyperparameter sensitivity) without substantial evaluation or comparison."}}
{"id": "50da4bbd-f1a0-49f9-b327-8d43650a94c6", "title": "Implicit Regularization", "level": "subsubsection", "subsections": [], "parent_id": "25e15182-1991-4f1a-83d9-017fe1a40d14", "prefix_titles": [["title", "Learning from Noisy Labels with Deep Neural Networks: A Survey"], ["section", "Deep Learning Approaches"], ["subsection", "Robust Regularization"], ["subsubsection", "Implicit Regularization"]], "content": "}\nThe regularization can also be an {implicit} form that gives the effect of stochasticity, e.g., data augmentation and mini-batch stochastic gradient descent.\n\\smallskip\n\\noindent \\underline{Technical Detail}: \\emph{Adversarial training}  enhances the noise tolerance by encouraging the DNN to correctly classify both original inputs and hostilely perturbed ones. {\\emph{Label smoothing}  estimates the marginalized effect of label noise during training, thereby reducing overfitting by preventing the DNN from assigning a full probability to noisy training examples. Instead of the one-hot label, the noisy label is mixed with a uniform mixture over all possible labels,\n\\begin{equation}\n\\begin{gathered}\n\\bar{y} = \\big\\langle \\bar{y}(1), \\bar{y}(2), \\dots, \\bar{y}(c) \\big\\rangle,\\\\ \n\\text{where} ~ \\bar{y}(i) = (1-\\alpha) \\cdot [\\tilde{y} = i] + \\alpha / c ~\\text{and}~ \\alpha \\in [0, 1].\n\\end{gathered}\n\\end{equation}\nHere, $[\\cdot]$ is the Iverson bracket and $\\alpha$ is the smoothing degree.} In contrast, \\emph{mixup}  regularizes the DNN to favor simple linear behaviors in between training examples. \nFirst, the mini-batch is constructed using virtual training examples, each of which is formed by the linear interpolation of two noisy training examples $(x_i, \\tilde{y}_i)$ and $(x_j, \\tilde{y}_j)$ obtained at random from noisy training data $\\tilde{\\mathcal{D}}$,\n\\begin{equation}\n\\label{eq:mixup_construction}\n{x}_{mix} = \\lambda x_i + (1-\\lambda) x_j~~ \\text{and} ~~{y}_{mix} = \\lambda \\tilde{y}_i + (1-\\lambda) \\tilde{y}_j,\n\\end{equation}\nwhere $\\lambda \\in [0,1]$ is the balance parameter between two examples. Thus, \\emph{mixup} extends the training distribution by updating the DNN for the constructed mini-batch. \n\\smallskip\n\\noindent {\\underline{Remark}: The implicit regularization improves the generalization capability of the DNN without reducing the representational capacity. It also does not introduce sensitive model-dependent hyperparameters because it is applied to the training data. However, the extended feature or label space slows down the convergence of training.}", "cites": [7191, 4141, 4148, 892], "cite_extract_rate": 1.0, "origin_cites_number": 4, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.0, "abstraction": 3.5}, "insight_level": "medium", "analysis": "The section synthesizes key implicit regularization techniques (adversarial training, label smoothing, mixup) and integrates them with references to the cited papers, showing how they encourage robustness in the presence of label noise. It includes some critical evaluation by noting the trade-off between improved generalization and slower convergence. While it abstracts the concept of implicit regularization and its goals, it does not fully generalize to a meta-level framework or provide deeper comparative or evaluative analysis across these methods."}}
{"id": "59ab6098-f130-49dc-b87f-123eaa6be482", "title": "Robust Loss Function", "level": "subsection", "subsections": [], "parent_id": "60bd8c81-37fb-4934-ab18-bb9a24e80724", "prefix_titles": [["title", "Learning from Noisy Labels with Deep Neural Networks: A Survey"], ["section", "Deep Learning Approaches"], ["subsection", "Robust Loss Function"]], "content": "\\label{sec:robust_loss_function}\n{\nIt was proven that a learned DNN with a \\emph{suitably modified} loss function $\\ell^{\\prime}$ for noisy data $\\tilde{\\mathcal{D}}$ can approach the Bayes optimal classifier $f^{*}$, which achieves the optimal Bayes risk $\\mathcal{R}^{*} = \\mathcal{R}_{\\mathcal{D}}(f^{*})$ for clean data $\\mathcal{D}$. Let $\\hat{f} = \\text{argmin}_{f \\in \\mathcal{F}} \\hat{\\mathcal{R}}_{\\ell^{\\prime}, \\tilde{\\mathcal{D}}}(f)$ be the learned classifier with the modified loss $\\ell^{\\prime}$ for the noisy data, where $\\hat{\\mathcal{R}}_{\\ell^{\\prime}, \\tilde{\\mathcal{D}}}(f) = \\mathbb{E}_{\\tilde{\\mathcal{D}}}[\\ell(f(x;\\Theta), \\tilde{y})]$. If $\\ell$ is $L$-Lipschitz and classification-calibrated , with probability at least $1\\!-\\!\\delta$, there exists a non-decreasing function $\\zeta_{\\ell}$ with $\\zeta_{\\ell}(0)=0$  such that \\looseness=-1\n\\vspace*{-0.6cm}\n\\begin{equation}\n\\begin{split}\n\\mathcal{R}_{\\mathcal{D}}(\\hat{f}) - \\mathcal{R}^{*} \\leq &~\\overbrace{\\zeta_{\\ell} \\Big( \\text{min}_{f\\in \\mathcal{F}}\\mathcal{R}_{\\ell,\\mathcal{D}}(f) - \\text{min}_{f}\\mathcal{R}_{\\ell, \\mathcal{D}}(f)}^{\\text{Approximation and Estimation Errors}}\\\\\n&~~+ 4L_{p}\\text{RC}(\\mathcal{F}) + 2\\sqrt{{\\text{log}(1/\\delta)}\\big/{2|\\mathcal{D}|}} \\Big),\\!\\!\\!\\!\\!\n\\end{split}\n\\end{equation}\n$L_{p}$ is the Lipschitz constant of $\\ell^{\\prime}$ and RC is the Rademacher complexity of the hypothesis class $\\mathcal{F}$. Then, by the universal approximation theorem , the Bayes optimal classifier $f^*$ is guaranteed to be in the hypothesis class $\\mathcal{F}$ with DNNs. \nBased on this theoretical foundation, researchers have attempted to design robust loss functions such that they achieve a small risk for unseen clean data even when noisy labels exist in the training data . \n}\n\\smallskip\n\\noindent \\underline{Technical Detail}: \nInitially, Manwani and Sastry  theoretically proved a sufficient condition for the loss function such that risk minimization with that function becomes noise-tolerant for binary classification. Subsequently, the sufficient condition was extended for multi-class classification using deep learning . Specifically, a loss function is defined to be \\emph{noise-tolerant} for a $c$-class classification under \\emph{symmetric} noise if the function satisfies the noise rate $\\tau<\\frac{c-1}{c}$ and\n\\begin{equation}\n\\label{eq:symmetric_function}\n\\sum_{j=1}^{c}\\ell\\big(f(x;\\Theta),y=j\\big)=C, ~\\forall x\\in\\mathcal{X}, ~\\forall f,\n\\end{equation}\nwhere $C$ is a constant. This condition guarantees that the classifier trained on noisy data has the same misclassification probability as that trained on noise-free data under the specified assumption. {An extension for \\emph{multi-label} classification was provided by Kumar et al. .} Moreover, if $\\mathcal{R}_{\\mathcal{D}}(f^{*})=0$, then the function is also noise-tolerant under an \\emph{asymmetric} noise, where $f^{*}$ is a global risk minimizer of $\\mathcal{R}_{\\mathcal{D}}$. \\looseness=-1\nFor the classification task, the categorical cross entropy\\,(CCE) loss is the most widely used loss function owing to its fast convergence and high generalization capability. However, in the presence of noisy labels, the \\emph{robust MAE}  showed that the mean absolute error\\,(MAE) loss achieves better generalization than the CCE loss because only the MAE loss satisfies the aforementioned condition. A limitation of the MAE loss is that its generalization performance degrades significantly when complicated data are involved. Hence, the \\emph{generalized cross entropy}\\,(GCE)  was proposed to achieve the advantages of both MAE and CCE losses; the GCE loss is a more general class of noise-robust loss that encompasses both of them. \n{\nAmid et al.  extended the GCE loss by introducing two temperatures based on the Tsallis divergence. \\emph{Bi-tempered loss}  introduces a proper unbiased generalization of the CE loss based on the Bregman divergence.}\nIn addition, inspired by the symmetricity of the Kullback-Leibler divergence, the symmetric cross entropy\\,(SCE)  was proposed by combining a noise tolerance term, namely reverse cross entropy loss, with the standard CCE loss. \nMeanwhile, the \\emph{curriculum loss}\\,(CL)  is a surrogate loss of the 0-1 loss function; it provides a tight upper bound and can easily be extended to multi-class classification.  {The \\emph{active passive loss}\\,(APL)  is a combination of two types of robust loss functions, an active loss that maximizes the probability of belonging to the given class and a passive loss that minimizes the probability of belonging to other classes.}\n\\smallskip\n\\noindent \\underline{Remark}: The robustness of these methods is theoretically supported well. However, they perform well only in simple cases, when learning is easy or the number of classes is small . Moreover, the modification of the loss function increases the training time for convergence .\n\\vspace*{-0.2cm}", "cites": [4130, 3454, 4132, 4151, 4150, 4128, 4149, 8736, 4134], "cite_extract_rate": 0.6, "origin_cites_number": 15, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.5, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section synthesizes key theoretical and practical contributions from multiple papers to build a coherent narrative on robust loss functions. It identifies conditions for noise tolerance, traces the evolution from MAE to GCE and beyond, and highlights trade-offs and limitations, such as performance degradation with complexity. The abstraction is strong, as it generalizes principles like noise rate constraints and loss function calibration."}}
{"id": "3d40345d-b6d6-4b98-943c-ec552f10d7fb", "title": "Loss Adjustment", "level": "subsection", "subsections": ["26fbf349-d8eb-41b0-9964-18115fa4704c", "67aed536-256b-4b94-954e-fe79fe9aa42b", "6322f675-ca49-4162-8e1c-216bde9693b8", "5cc6d843-bb17-416b-bbf4-7e089941b605"], "parent_id": "60bd8c81-37fb-4934-ab18-bb9a24e80724", "prefix_titles": [["title", "Learning from Noisy Labels with Deep Neural Networks: A Survey"], ["section", "Deep Learning Approaches"], ["subsection", "Loss Adjustment"]], "content": "\\label{sec:loss_adjustment}\n\\vspace*{-0.0cm}\nLoss adjustment is effective for reducing the negative impact of noisy labels by adjusting the loss of all training examples before updating the DNN . The methods associated with it can be categorized into three groups depending on their adjustment philosophy: \\emph{1)} {\\emph{loss correction}} that estimates the noise transition matrix to correct the forward or backward loss, \\emph{2)} {\\emph{loss reweighting}} that imposes different importance to each example for a weighted training scheme, \\emph{3)} {\\emph{label refurbishment}} that adjusts the loss using the refurbished label obtained from a convex combination of noisy and predicted labels, and \\emph{4)} {\\emph{meta learning}} that automatically infers the optimal rule for loss adjustment. {Unlike the robust loss function newly designed for robustness, this family of methods aims to make the traditional optimization process robust to label noise. Hence, in the middle of training, the {update rule} is adjusted such that the negative impact of label noise is minimized.}\nIn general, loss adjustment allows for a \\emph{full exploration} of the training data by adjusting the loss of every example. However, the error incurred by \\emph{false} correction is accumulated, especially when the number of classes or the number of mislabeled examples is large . \n\\vspace*{0.15cm}", "cites": [7162, 3340, 7775, 4135, 4145, 4139], "cite_extract_rate": 0.6666666666666666, "origin_cites_number": 9, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.5, "critical": 3.0, "abstraction": 3.5}, "insight_level": "medium", "analysis": "The section provides a clear analytical framework by categorizing loss adjustment methods into four distinct groups and explaining their underlying philosophies. It connects ideas from multiple papers to form a structured overview, though the integration is not entirely novel. The critical evaluation is moderate, noting the accumulation of errors from false corrections, but does not deeply critique individual papers or their assumptions. The abstraction is reasonable, highlighting broader principles such as the adjustment of the optimization process for robustness."}}
{"id": "26fbf349-d8eb-41b0-9964-18115fa4704c", "title": "Loss Correction", "level": "subsubsection", "subsections": [], "parent_id": "3d40345d-b6d6-4b98-943c-ec552f10d7fb", "prefix_titles": [["title", "Learning from Noisy Labels with Deep Neural Networks: A Survey"], ["section", "Deep Learning Approaches"], ["subsection", "Loss Adjustment"], ["subsubsection", "Loss Correction"]], "content": "}\n\\label{sec:loss_correction}\nSimilar to the noise adaptation layer presented in Section \\ref{sec:robust_architecture}, this approach modifies the loss of each example by multiplying the estimated label transition probability by the output of a specified DNN. The main difference is that the learning of the transition probability is decoupled from that of the model. \n\\smallskip\n\\noindent \\underline{Technical Detail}:\n\\emph{Backward correction}  initially approximates the noise transition matrix using the softmax output of the DNN trained without loss correction. Subsequently, it retrains the DNN while correcting the original loss based on the estimated matrix. The corrected loss of a example $(x,\\tilde{y})$ is computed by a linear combination of its loss values for observable labels, whose coefficient is the inverse transition matrix $\\text{T}^{-1}$ to the observable label $y\\in\\{1,\\dots, c\\}$, given its target label $\\tilde{y}$.\nTherefore, the backward correction $\\cev{\\ell}$ is performed by multiplying the inverse transition matrix to the prediction for all the observable labels, \n{\n\\begin{equation}\n\\small\n\\label{eq:backward_correction}\n\\begin{split}\n\\cev{\\ell}\\big(f(x;&\\Theta),\\tilde{y}\\big) = \\hat{\\text{T}}^{-1}\\Big\\langle\\ell\\big(f(x;\\Theta), 1\\big), \\dots, \\ell\\big(f(x;\\Theta), c\\big)\\Big\\rangle^{\\!\\top}\\!\\!,\n\\end{split}\n\\end{equation}\n}\n\\noindent where $\\hat{\\text{T}}$ is the estimated noise transition matrix. \nConversely, \\emph{forward correction}  uses a linear combination of a DNN's softmax outputs before applying the loss function. Hence, the forward correction $\\vec{\\ell}$ is performed by multiplying the estimated transition probability with the softmax outputs during the forward propagation step,\n{\n\\begin{equation}\n\\small\n\\label{eq:forward_correction}\n\\begin{split}\n\\vec{\\ell}\\big(f(x;\\Theta),\\tilde{y}\\big)& = \\ell\\Big(\\Big\\langle\\hat{p}(\\tilde{y}|1),\\dots,\\hat{p}(\\tilde{y}|c)\\Big\\rangle f(x;\\Theta)^{\\top},\\tilde{y}\\Big)\\\\\n&=\\ell\\big(\\hat{\\text{T}}^{\\top}f(x;\\Theta)^{\\top},\\tilde{y}\\big).\n\\end{split}\n\\end{equation}\n}\n\\vspace*{-0.2cm}\nFurthermore, \\emph{gold loss correction}  assumes the availability of clean validation data or anchor points for loss correction. Thus, a more accurate transition matrix is obtained by using them as additional information, which further improves the robustness of the loss correction. {Recently, \\emph{T-Revision}  provides a solution that can infer the transition matrix without anchor points, and \\emph{Dual T}  factorizes the matrix into the product of two easy-to-estimate matrices to avoid directly estimating the noisy class posterior.}\n{\nBeyond the instance-independent noise assumption, Zhang et al.  introduced the instance-confidence embedding to model instance-dependent noise in estimating the transition matrix. On the other hand, Yang et al.  proposed to use the Bayes optimal transition matrix estimated from the distilled examples for the instance-dependent noise transition matrix.}\n\\smallskip\n\\noindent {\\underline{Remark}: The robustness of these approaches is highly dependent on how precisely the transition matrix is estimated. To acquire such a transition matrix, they require prior knowledge in general, such as anchor points or clean validation data.}\n\\vspace*{0.15cm}", "cites": [7777, 4145, 4153, 4152], "cite_extract_rate": 0.6666666666666666, "origin_cites_number": 6, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.5, "critical": 3.0, "abstraction": 3.0}, "insight_level": "medium", "analysis": "The section integrates information from multiple cited papers to explain different loss correction strategies (backward, forward, and gold loss correction), connecting methodological ideas to form a coherent overview. It highlights the role of the transition matrix and different assumptions (e.g., instance-dependent noise) across approaches. While it offers some analytical depth, it does not extensively compare or evaluate the methods, nor does it identify overarching theoretical principles."}}
{"id": "67aed536-256b-4b94-954e-fe79fe9aa42b", "title": "Loss Reweighting", "level": "subsubsection", "subsections": [], "parent_id": "3d40345d-b6d6-4b98-943c-ec552f10d7fb", "prefix_titles": [["title", "Learning from Noisy Labels with Deep Neural Networks: A Survey"], ["section", "Deep Learning Approaches"], ["subsection", "Loss Adjustment"], ["subsubsection", "Loss Reweighting"]], "content": "} Inspired by the concept of importance reweighting , loss reweighting aims to assign smaller weights to the examples with false labels and greater weights to those with true labels. Accordingly, the reweighted loss on the mini-batch $\\mathcal{B}_t$ is used to update the DNN, \n{\n\\begin{equation}\n\\label{eq:loss_reweighting}\n\\Theta_{t+1} = \\Theta_{t} - \\eta\\nabla \\Big( \\frac{1}{|\\mathcal{B}_{t}|}\\!\\sum_{(x,\\tilde{y})\\in\\mathcal{B}_t}\\!\\!\\!\\!\\overbrace{w(x,\\tilde{y})\\ell\\big(f(x;\\Theta_t), \\tilde{y}\\big)}^{\\text{Reweighted Loss}}\\Big),\n\\end{equation}}\nwhere $w(x,\\tilde{y})$ is the weight of an example $x$ with its noisy label $\\tilde{y}$. Hence, the examples with smaller weights do not significantly affect the DNN learning.\n\\smallskip\n\\noindent \\underline{Technical Detail}:\nIn \\emph{importance reweighting} , the ratio of two joint data distributions {$w(x,\\tilde{y})=P_{\\mathcal{D}}(x,\\tilde{y})/P_{\\tilde{\\mathcal{D}}}(x,\\tilde{y})$} determines the contribution of the loss of each noisy example. An approximate solution to estimate the ratio was developed because the two distributions are difficult to determine from noisy data. Meanwhile, \\emph{active bias}  emphasizes uncertain examples with inconsistent label predictions by assigning their prediction variances as the weights for training. \n{\n\\emph{DualGraph}  employs graph neural networks and reweights the examples according to the structural relations among labels, eliminating the abnormal noise examples.}\n\\smallskip\n\\noindent {\\underline{Remark}: These approaches need to manually pre-specify the weighting function as well as there additional hyper-parameters, which is fairly hard to be applied in practice due to the significant variation of appropriate weighting schemes that rely on the noise type and training data.}\n\\vspace*{0.15cm}", "cites": [3453, 7775], "cite_extract_rate": 0.5, "origin_cites_number": 4, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.0, "critical": 3.0, "abstraction": 3.0}, "insight_level": "medium", "analysis": "The section synthesizes the core idea of loss reweighting by integrating concepts from two cited papers, showing how each method assigns weights to noisy examples. It includes a critical remark on the practical limitations of these approaches, such as the need for manual specification and hyperparameter tuning. The section abstracts the concept beyond specific implementations, highlighting common challenges in applying weighting schemes across different noise types and datasets."}}
{"id": "6322f675-ca49-4162-8e1c-216bde9693b8", "title": "Label Refurbishment", "level": "subsubsection", "subsections": [], "parent_id": "3d40345d-b6d6-4b98-943c-ec552f10d7fb", "prefix_titles": [["title", "Learning from Noisy Labels with Deep Neural Networks: A Survey"], ["section", "Deep Learning Approaches"], ["subsection", "Loss Adjustment"], ["subsubsection", "Label Refurbishment"]], "content": "} Refurbishing a noisy label $\\tilde{y}$ effectively prevents overfitting to false labels. Let $\\hat{y}$ be the current prediction of the DNN $f(x;\\Theta)$. Therefore, the refurbished label $y^{refurb}$ can be obtained by a convex combination of the noisy label $\\tilde{y}$ and the DNN prediction $\\hat{y}$,\n\\begin{equation}\n\\label{eq:label_correction}\ny^{refurb} = \\alpha \\tilde{y} + (1-\\alpha) \\hat{y},\n\\end{equation}\nwhere $\\alpha \\in [0,1]$ is the label confidence of $\\tilde{y}$. To mitigate the damage of incorrect labeling, this approach backpropagates the loss for the refurbished label instead of the noisy one, thereby yielding substantial robustness to noisy labels. \n\\smallskip\n\\noindent \\underline{Technical Detail}:\n\\emph{Bootstrapping}  is the first method that proposes the concept of label refurbishment to update the target label of training examples. It develops a more coherent network that improves its ability to evaluate the consistency of noisy labels, with the label confidence $\\alpha$ obtained via cross-validation.\n\\emph{Dynamic bootstrapping}  dynamically adjusts the confidence $\\alpha$ of individual training examples. The confidence $\\alpha$ is obtained by fitting a two-component and one-dimensional beta mixture model to the loss distribution of all training examples. {\\emph{Self-adaptive training}  applies the exponential moving average to alleviate the instability issue of using instantaneous prediction of the current DNN, \n\\begin{equation}\n\\!\\!y_{t+1}^{refurb} = \\alpha y_t^{refurb} + (1-\\alpha)\\hat{y}, ~\\text{where}~ y_0^{refurb} = \\tilde{y}\\!\\!\n\\end{equation}\n}\n\\emph{D2L}  trains a DNN using a dimensionality-driven learning strategy to avoid overfitting to false labels. A simple measure called \\emph{local intrinsic dimensionality}  is adopted to evaluate the confidence $\\alpha$ in considering that the overfitting is exacerbated by dimensional expansion. Hence, refurbished labels are generated to prevent the dimensionality of the representation subspace from expanding at a later stage of training. \nRecently, \\emph{SELFIE}  introduces a novel concept of \\emph{refurbishable examples} that can be corrected with high precision. The key idea is to consider the example with consistent label predictions as refurbishable because such consistent predictions correspond to its true label with a high probability owing to the learner's perceptual consistency. Accordingly, the labels of only refurbishable examples are corrected to minimize the number of falsely corrected cases. {Similarly, \\emph{AdaCorr}  selectively refurbishes the label of noisy examples, but a theoretical error-bound is provided. Alternatively, \\emph{SEAL}  averages the softmax output of a DNN on each example over the whole training process, then re-trains the DNN using the averaged soft labels.}\n\\smallskip\n\\noindent {\\underline{Remark}: Differently from loss correction and reweighting, all the noisy labels are explicitly replaced with other expected clean labels (or their combination). If there are not many confusing classes in data, these methods work well by refurbishing the noisy labels with high precision. In the opposite case, the DNN could overfit to wrongly refurbished labels.}\n\\vspace*{0.15cm}", "cites": [7162, 4135, 4156, 4154, 4155, 4139], "cite_extract_rate": 0.75, "origin_cites_number": 8, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.0, "abstraction": 3.5}, "insight_level": "medium", "analysis": "The section synthesizes multiple label refurbishment methods by connecting their technical details and showing how they relate through the common goal of mitigating overfitting to noisy labels. It provides a critical note at the end by highlighting potential limitations (e.g., overfitting to wrongly refurbished labels when classes are confusing). The abstraction is moderate, as it generalizes the idea of label refurbishment but does not fully articulate overarching theoretical principles or unify the methods under a novel framework."}}
{"id": "5cc6d843-bb17-416b-bbf4-7e089941b605", "title": "Meta Learning", "level": "subsubsection", "subsections": [], "parent_id": "3d40345d-b6d6-4b98-943c-ec552f10d7fb", "prefix_titles": [["title", "Learning from Noisy Labels with Deep Neural Networks: A Survey"], ["section", "Deep Learning Approaches"], ["subsection", "Loss Adjustment"], ["subsubsection", "Meta Learning"]], "content": "}\n{In recent years, meta learning becomes an important topic in the machine learning community and is applied to improve noise robustness . The key concept is \\emph{learning to learn} that performs learning at a level higher than conventional learning, thus achieving data-agnostic and noise type-agnostic rules for better practical use. It is similar to loss reweighting and label refurbishment, but the adjustment is automated in a meta learning manner.\n\\smallskip\n\\noindent \\underline{Technical Detail}:\nFor the loss reweighting in Eq.~\\eqref{eq:loss_reweighting}, the goal is to learn the weight function $w(x,\\tilde{y})$. Specifically, \\emph{L2LWS}  and \\emph{CWS}  are unified neural architectures composed of a target DNN and a meta-DNN. The meta-DNN is trained on a small clean validation dataset; it then provides guidance to evaluate the weight score for the target DNN. Here, part of the two DNNs are shared and jointly trained to benefit from each other. \\emph{Automatic reweighting}  is a meta learning algorithm that learns the weights of training examples based on their gradient directions. It includes a small clean validation dataset into the training dataset and reweights the backward loss of the mini-batch examples such that the updated gradient minimizes the loss of this validation dataset.  \\emph{Meta-weight-net}  parameterizes the weighting function as a multi-layer perceptron network with only one hidden layer. A meta-objective is defined to update its parameters such that they minimize the empirical risk of a small clean dataset. At each iteration, the parameter of the target network is guided by the weight function updated via the meta-objective. \n{Likewise, \\emph{data coefficients}\\,(i.e., exemplar weights and true labels)  are estimated by meta-optimization with a small clean set, which is only $0.2$\\% of the entire training set, while refurbishing the examples probably mislabeled.}\nFor the label refurbishment in Eq.~\\eqref{eq:label_correction}, \\emph{knowledge distillation}  adopts the technique of transferring knowledge from one expert model to a target model. The prediction from the expert DNN trained on small clean validation data is used instead of the prediction $\\hat{y}$ from the target DNN. \n{\\emph{MLC}  updates the target model with corrected labels provided by a meta model trained on clean validation data. The two models are trained concurrently via a bi-level optimization.} \n\\smallskip\n\\noindent \\underline{Remark}:\nBy learning the update rule via meta learning, the trained network easily adapts to various types of data and label noise. Nevertheless, unbiased clean validation data is essential to minimize the auxiliary objective, although it may not be available in real-world data.}\n\\vspace*{-0.1cm}", "cites": [4157, 4158, 4128, 3345, 1695, 7774, 7772, 8737], "cite_extract_rate": 0.8888888888888888, "origin_cites_number": 9, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.0, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section synthesizes multiple meta-learning approaches for handling noisy labels, integrating key ideas from L2LWS, CWS, Automatic Reweighting, Meta-weight-net, and MLC into a coherent narrative. It abstracts these methods under the broader theme of using a meta-learning framework to guide robust training, particularly by reweighting or correcting labels. While it offers a clear analytical perspective, the critical evaluation is moderate, as it mainly points out the general limitation of requiring clean validation data rather than engaging in deeper critique or comparison of specific methods."}}
{"id": "54d73157-e47b-4943-9b30-b518e1806946", "title": "Sample Selection", "level": "subsection", "subsections": ["a00439ee-902b-4911-93a8-2198ddea3d64", "3f9409b8-29c2-4f75-91a3-9614418f8bb4", "3b9e7951-da54-4090-b74a-113ced54d832"], "parent_id": "60bd8c81-37fb-4934-ab18-bb9a24e80724", "prefix_titles": [["title", "Learning from Noisy Labels with Deep Neural Networks: A Survey"], ["section", "Deep Learning Approaches"], ["subsection", "Sample Selection"]], "content": "\\label{sec:sample_selection}\nTo avoid any false corrections, many recent studies  have adopted sample selection that involves selecting true-labeled examples from a noisy training dataset. In this case, the update equation in Eq.\\ \\eqref{eq:corrupted_update} is modified to render a DNN more robust for noisy labels. Let $\\mathcal{C}_t \\subseteq \\mathcal{B}_t$ be the identified \\emph{clean} examples at time $t$. Then, the DNN is updated only for the selected clean examples $\\mathcal{C}_t$, \n\\begin{equation}\n\\label{eq:clean_update}\n\\Theta_{t+1} = \\Theta_{t} - \\eta\\nabla\\Big(\\frac{1}{|\\mathcal{C}_t|} \\!\\sum_{(x,\\tilde{y}) \\in \\mathcal{C}_t} \\!\\!\\!\\!\\ell\\big(f(x;\\Theta_{t}), \\tilde{y}\\big)\\Big),\n\\end{equation}\nwhere the rest mini-batch examples, which are likely to be false-labeled, are excluded to pursue robust learning. \n\\newcommand{\\norm}[1]{\\left\\lVert#1\\right\\rVert}\n{The {memorization nature} of DNNs has been explored theoretically and empirically to identify clean examples from noisy training data .\nSpecifically, assuming clusterable data where the clusters are located on the unit Euclidean ball, Li et al.  proved the distance from the initial weight ${W}_{0}$ to the weight ${W}_t$ after $t$ iterations,\n\\begin{equation}\n\\label{eq:memorization_effect_foundation}\n\\norm{{W}_t - {W}_0}_{F} \\lesssim \\big( \\sqrt{K} + (K^{2}\\epsilon_{0}/\\norm{{C}}^{2})t \\big),\n\\end{equation}\nwhere $\\norm{\\cdot}_{F}$ is the Frobenius norm, $K$ is the number of clusters, and ${C}$ is the set of cluster centers reaching all input examples within their $\\epsilon_0$ neighborhood.\nEq.\\ \\eqref{eq:memorization_effect_foundation} demonstrates that the weights of DNNs start to stray far from the initial weights when overfitting to corrupted labels, while they are still in the vicinity of the initial weights at an early stage of training . In the empirical studies , the \\emph{memorization effect} is also observed since DNNs tend to first learn simple and generalized patterns and then gradually overfit to all noisy patterns. As such, favoring small-loss training examples as the clean ones are commonly employed to design robust training methods .\nLearning with sample selection is well motivated and works well in general, but this approach suffers from accumulated error caused by incorrect selection, especially when there are many ambiguous classes in training data.} \nHence, recent approaches often leverage multiple DNNs to cooperate with one another  or run multiple training rounds .\nMoreover, to benefit from even false-labeled examples, loss correction or semi-supervised learning have been recently combined with the sample selection strategy .\n\\begin{figure}\n\\vspace*{+0.08cm}\n\\begin{center}\n\\includegraphics[width=8.7cm]{figures/methodology/loss_distribution.pdf}\n\\end{center}\n\\vspace*{-0.2cm}\n\\hspace*{0.80cm} {\\small (a) Symmetric Noise $40\\%$.} \\hspace*{0.525cm} {\\small (b) Asymmetric Noise $40\\%$.}\n\\vspace*{-0.15cm}\n\\caption{Loss distribution of training examples at the training accuracy of $50\\%$ on noisy CIFAR-100. (This figure is adapted from Song et al. .)}\n\\label{fig:loss_distribution}\n\\vspace*{-0.4cm}\n\\end{figure}\n\\smallskip\\smallskip", "cites": [3340, 4137, 7771, 4140, 4126, 3342, 4125, 4124, 4123, 4253, 8630, 4115], "cite_extract_rate": 0.631578947368421, "origin_cites_number": 19, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.2, "critical": 3.5, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section effectively synthesizes multiple works on sample selection by connecting the concept of the memorization effect to practical robust training methods like Co-teaching and SELF. It provides an analytical perspective by explaining the theoretical and empirical motivations for sample selection and addressing its limitations, such as accumulated error. The section abstracts the idea that DNNs first learn generalized patterns and later overfit, which underpins broader strategies like early stopping and iterative trimming."}}
{"id": "a00439ee-902b-4911-93a8-2198ddea3d64", "title": "Multi-network Learning", "level": "subsubsection", "subsections": [], "parent_id": "54d73157-e47b-4943-9b30-b518e1806946", "prefix_titles": [["title", "Learning from Noisy Labels with Deep Neural Networks: A Survey"], ["section", "Deep Learning Approaches"], ["subsection", "Sample Selection"], ["subsubsection", "Multi-network Learning"]], "content": "}\n{\nCollaborative learning and co-training are widely used for the multi-network training. Consequently, the sample selection process is guided by the mentor network in the case of collaborative learning or the peer network in the case of co-training.\n}\n\\smallskip\n\\noindent \\underline{Technical Detail}:\nInitially, \\emph{Decouple}  proposes the decoupling of when to update from how to update. Hence, two DNNs are maintained simultaneously and updated only the examples selected based on a disagreement between the two DNNs.\nNext, due to the memorization effect of DNNs, many researchers have adopted another selection criterion, called a \\emph{small-loss} trick, which treats a certain number of small-loss training examples as true-labeled examples; many true-labeled examples tend to exhibit smaller losses than false-labeled examples, as illustrated in Figure \\ref{fig:loss_distribution}(a). In \\emph{MentorNet} , a pre-trained mentor network guides the training of a student network in a collaborative learning manner. Based on the small-loss trick, the mentor network provides the student network with examples whose labels are likely to be correct. \\emph{Co-teaching}  and \\emph{Co-teaching+}  also maintain two DNNs, but each DNN selects a certain number of small-loss examples and feeds them to its peer DNN for further training. \\emph{Co-teaching+} further employs the disagreement strategy of \\emph{Decouple} compared with \\emph{Co-teaching}. {In contrast, \\emph{JoCoR}  reduces the diversity of two networks via co-regularization, making predictions of the two networks closer.}\n\\smallskip\n\\noindent {\\underline{Remark}: The co-training methods help reduce the confirmation bias , which is a hazard of favoring the examples selected at the beginning of training, while the increase in the number of learnable parameters makes their learning pipeline inefficient. In addition, the small-loss trick does not work well when the loss distribution of true-labeled and false-labeled examples largely overlap, as in the asymmetric noise in Figure \\ref{fig:loss_distribution}(b).}\n\\smallskip\\smallskip", "cites": [3340, 4140, 4137, 4159], "cite_extract_rate": 0.8, "origin_cites_number": 5, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.5, "abstraction": 3.5}, "insight_level": "high", "analysis": "The section effectively synthesizes multiple methods (Decouple, MentorNet, Co-teaching, Co-teaching+, JoCoR) by highlighting common themes such as the small-loss trick and disagreement strategy. It offers critical insights, like the inefficiency caused by increased parameters and the limitations of the small-loss trick under asymmetric noise. While not reaching a meta-level abstraction, it identifies broader patterns such as the role of collaboration and diversity in robust training."}}
{"id": "3f9409b8-29c2-4f75-91a3-9614418f8bb4", "title": "Multi-round Learning", "level": "subsubsection", "subsections": [], "parent_id": "54d73157-e47b-4943-9b30-b518e1806946", "prefix_titles": [["title", "Learning from Noisy Labels with Deep Neural Networks: A Survey"], ["section", "Deep Learning Approaches"], ["subsection", "Sample Selection"], ["subsubsection", "Multi-round Learning"]], "content": "}\nWithout maintaining additional DNNs, multi-round learning iteratively refines the selected set of clean examples by repeating the training round. Thus, the selected set keeps improved as the number of rounds increases. \n\\smallskip\n\\noindent \\underline{Technical Detail}:\n\\emph{ITLM}  iteratively minimizes the trimmed loss by alternating between selecting true-labeled examples at the current moment and retraining the DNN using them. At each training round, only a fraction of small-loss examples obtained in the current round are used to retrain the DNN in the next round. \\emph{INCV}  randomly divides noisy training data and then employs cross-validation to classify true-labeled examples while removing large-loss examples at each training round. Here, \\emph{Co-teaching} is adopted to train the DNN on the identified examples in the final round of training. {Similarly, \\emph{O2U-Net}  repeats the whole training process with the cyclical learning rate until enough loss statistics of every examples are gathered. Next, the DNN is re-trained from scratch only for the clean data where false-labeled examples have been detected and removed based on statistics.} \\looseness=-1\nA number of variations have been proposed to achieve high performance using iterative refinement only in a single training round.\nBeyond the small-loss trick, \\emph{iterative detection}  detects false-labeled examples by employing the local outlier factor algorithm . With a Siamese network, it gradually pulls away false-labeled examples from true-labeled samples in the deep feature space. \\emph{MORPH}  introduces the concept of memorized examples which is used to iteratively expand an initial safe set into a maximal safe set via self-transitional learning. \\emph{TopoFilter}  utilizes the spatial topological pattern of learned representations to detect true-labeled examples, not relying on the prediction of the noisy classifier.\n{\n\\emph{NGC}  iteratively constructs the nearest neighbor graph using latent representations and performs geometry-based sample selection by aggregating information from neighborhoods. Soft pesudo-labels are assigned to the examples not selected.\n}\n\\smallskip\n\\noindent {\\underline{Remark}: The selected clean set keeps expanded and purified with iterative refinement, mainly through multi-round learning. As a side effect, the computational cost for training increases linearly for the number of training rounds.}\n\\smallskip", "cites": [4126, 3343, 8630, 4125, 7163, 4123], "cite_extract_rate": 0.75, "origin_cites_number": 8, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.0, "abstraction": 3.5}, "insight_level": "medium", "analysis": "The section effectively synthesizes several multi-round learning approaches (ITLM, INCV, Co-teaching, O2U-Net, NGC, MORPH, TopoFilter) into a unified narrative, highlighting their shared goal of iteratively refining clean sample sets. It demonstrates analytical depth by noting a common side effect—increased computational cost—and by showing how different methods leverage diverse mechanisms (e.g., loss statistics, outlier detection, topological patterns). However, while it connects the methods conceptually, it lacks deeper comparative analysis or explicit evaluation of their strengths and weaknesses."}}
{"id": "3b9e7951-da54-4090-b74a-113ced54d832", "title": "Hybrid Approach", "level": "subsubsection", "subsections": [], "parent_id": "54d73157-e47b-4943-9b30-b518e1806946", "prefix_titles": [["title", "Learning from Noisy Labels with Deep Neural Networks: A Survey"], ["section", "Deep Learning Approaches"], ["subsection", "Sample Selection"], ["subsubsection", "Hybrid Approach"]], "content": "} {An inherent limitation of sample selection is to discard all the \\emph{unselected} training examples, thus resulting in a \\emph{partial} exploration of training data. To exploit all the noisy examples, researchers have attempted to combine sample selection with other orthogonal ideas.\n\\begin{figure}[t!]\n\\begin{center}\n\\includegraphics[width=8.45cm]{figures/methodology/semi_supervised.pdf}\n\\end{center}\n\\vspace*{-0.1cm}\n\\hspace*{0.2cm} \\small{(a) Noisy Data.} \\hspace*{0.4cm} \\small{(b) Transformed Data.} \\hspace*{0.8cm} \\small{(c) SSL.}\n\\vspace*{-0.2cm}\n\\caption{{Procedures for semi-supervised learning under label noise.}}\n\\label{fig:noise_semi_supervised}\n\\vspace*{-0.45cm}\n\\end{figure}\n\\smallskip\n\\noindent \\underline{Technical Detail}:\nThe most prominent method in this direction is combining a specific sample selection strategy with a specific semi-supervised learning model. As illustrated in Figure \\ref{fig:noise_semi_supervised}, selected examples are treated as labeled clean data, whereas the remaining examples are treated as unlabeled. Subsequently, semi-supervised learning is performed using the transformed data. \\emph{SELF}  is combined with a semi-supervised learning approach to progressively filter out false-labeled examples from noisy data. By maintaining the running average model called the {mean-teacher}  as the backbone, it obtains the self-ensemble predictions of all training examples and then progressively removes examples whose ensemble predictions do not agree with their annotated labels. This method further leverages unsupervised loss from the examples not included in the selected clean set. \\emph{DivideMix}  uses two-component and one-dimensional Gaussian mixture models to transform noisy data into labeled (clean) and unlabeled (noisy) sets. Then, it applies a semi-supervised technique \\emph{MixMatch} . Recently, \\emph{RoCL}  employs two-phase learning strategies: supervised training on selected clean examples and then semi-supervised learning on relabeled noisy examples with self-supervision. For selection and relabeling, it computes the exponential moving average of the loss over training iterations. \n}\n\\clearpage\n{\n\\newcolumntype{L}[1]{>{\\centering\\let\\newline\\\\\\arraybackslash\\hspace{0pt}}m{#1}}\n\\newcolumntype{X}[1]{>{\\centering\\let\\newline\\\\\\arraybackslash\\hspace{0pt}}p{#1}}\n\\newcolumntype{Y}[1]{>{\\let\\newline\\\\\\arraybackslash\\hspace{1pt}}m{#1}}\n\\begin{table*}[h]\n\\vspace*{-3.9cm}\n\\caption{{Comparison of proposed robust deep learning methods with respect to the following six properties: (P1)\\,Flexibility, (P2)\\,No Pre-training, (P3)\\,Full Exploration, (P4)\\,No Supervision, (P5)\\,Heavy Noise, and (P6)\\,Complex Noise.}}\n\\vspace*{-0.2cm}\n\\begin{tabular}{L{0.7cm}|L{2.5cm}|Y{4.7cm}|X{0.5cm}|X{0.5cm}|X{0.5cm}|X{0.5cm}|X{0.5cm}|X{0.5cm}|Y{2.9cm}}\n\\toprule\n\\multicolumn{2}{c|}{\\textbf{Category}} & \\hspace*{2.0cm}\\textbf{Method} & \\textbf{P1} & \\textbf{P2} & \\textbf{P3} & \\textbf{P4} & \\textbf{P5} & \\textbf{P6} & \\,\\,\\,\\,\\,\\,\\,\\,\\,\\textbf{Implementation}\\!\\! \\\\ \\hline\n\\multirow{9}{*}{\\vspace*{-0.35cm}\\hspace*{0.13cm}\\!\\!\\!\\!\\!\\!\\rotatebox[origin=c]{90}{\\makecell[l]{Robust Architecture\\\\\\hspace*{0.66cm}(\\textsection \\ref{sec:robust_architecture})}}\\!\\!\\!\\!\\!} \n& \\multirow{6}{*}{\\vspace*{-0.2cm}\\makecell[l]{Noisy Adaptation\\\\\\hspace*{0.67cm}Layer}}  \n& \\emph{Webly Learning} & \\cellcolor{gray!10}$\\bigtriangleup$ & \\cellcolor{red!10}\\xmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{red!10}\\xmark & \\cellcolor{red!10}\\xmark & Official\\,(Caffe)\\protect\\footnotemark[1] \\\\\\cline{3-10} \n& & \\emph{Noise Model} & \\cellcolor{gray!10}$ \\bigtriangleup$ & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{red!10}\\xmark & \\cellcolor{red!10}\\xmark & Unofficial\\,(Keras)\\protect\\footnotemark[2] \\\\\\cline{3-10}\n& & \\emph{Dropout Noise Model} & \\cellcolor{gray!10}$ \\bigtriangleup$ & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{red!10}\\xmark & \\cellcolor{red!10}\\xmark & Official\\,(MATLAB)\\protect\\footnotemark[3] \\\\\\cline{3-10}\n& & \\emph{S-model} & \\cellcolor{gray!10}$ \\bigtriangleup$ & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{red!10}\\xmark & \\cellcolor{red!10}\\xmark & Official\\,(Keras)\\protect\\footnotemark[4]\\\\\\cline{3-10}\n& & \\emph{C-model} & \\cellcolor{gray!10}$ \\bigtriangleup$ & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{red!10}\\xmark & \\cellcolor{blue!10}\\cmark & Official\\,(Keras)\\protect\\footnotemark[4] \\\\\\cline{3-10}\n& & \\emph{NLNN} & \\cellcolor{gray!10}$ \\bigtriangleup$ & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{red!10}\\xmark & \\cellcolor{red!10}\\xmark & Unofficial\\,(Chainer)\\protect\\footnotemark[5] \\\\\\cmidrule{2-10}\n& \\multirow{4}{*}{\\makecell[l]{\\hspace*{0.12cm}Dedicated\\\\Architecture}} \n& \\emph{Probablistic Noise Model} & \\cellcolor{red!10}\\xmark & \\cellcolor{red!10}\\xmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{red!10}\\xmark & $ \\cellcolor{gray!10}\\bigtriangleup$ & \\cellcolor{blue!10}\\cmark & Official\\,(Caffe)\\protect\\footnotemark[6] \\\\\\cline{3-10}\n& & \\emph{Masking} & \\cellcolor{red!10}\\xmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{red!10}\\xmark & $ \\cellcolor{gray!10}\\bigtriangleup$ & \\cellcolor{blue!10}\\cmark & Official\\,(TensorFlow)\\protect\\footnotemark[7] \\\\\\cline{3-10}\n& & \\emph{Contrastive-Additive Noise Network} & \\cellcolor{red!10}\\xmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark &\\cellcolor{blue!10}\\cmark & $ \\cellcolor{gray!10}\\bigtriangleup$ &\\cellcolor{blue!10}\\cmark & N/A \\\\\\cline{3-10}\n& & {\\emph{RoG}} & \\cellcolor{blue!10}\\cmark & \\cellcolor{red!10}\\xmark & \\cellcolor{blue!10}\\cmark &\\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark &$ \\cellcolor{gray!10}\\bigtriangleup$ & Official\\,(PyTorch)\\protect\\footnotemark[8] \\\\\\midrule\n\\multirow{9}{*}{\\vspace*{-0.25cm}\\hspace*{0.13cm}\\!\\!\\!\\!\\!\\!\\rotatebox[origin=c]{90}{\\makecell[l]{Robust Regularization\\\\\\hspace*{0.8cm}(\\textsection \\ref{sec:robust_regularization})}}\\!\\!\\!\\!\\!} \n& \\multirow{6}{*}{\\makecell[l]{\\hspace*{0.35cm}Explicit\\\\Regularization}}  \n& \\emph{Bilevel Learning} & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{red!10}\\xmark & \\cellcolor{gray!10}$ \\bigtriangleup$ & \\cellcolor{gray!10}$ \\bigtriangleup$ & Official\\,(TensorFlow)\\protect\\footnotemark[9] \\\\\\cline{3-10}\n& & \\emph{Annotator Confusion} & \\cellcolor{blue!10}\\cmark & \\cellcolor{red!10}\\xmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{gray!10}$ \\bigtriangleup$ & \\cellcolor{gray!10}$ \\bigtriangleup$ & Official\\,(TensorFlow)\\protect\\footnotemark[10] \\\\\\cline{3-10}\n& & \\emph{Pre-training} & \\cellcolor{blue!10}\\cmark & \\cellcolor{red!10}\\xmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{gray!10}$ \\bigtriangleup$ & \\cellcolor{gray!10}$ \\bigtriangleup$ & Official\\,(PyTorch)\\protect\\footnotemark[11] \\\\\\cline{3-10}\n& & {\\emph{PHuber}} & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark  & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{gray!10}$ \\bigtriangleup$ & \\cellcolor{gray!10}$ \\bigtriangleup$ & Unofficial\\,(PyTorch)\\protect\\footnotemark[12] \\\\\\cline{3-10}\n& & {\\emph{Robust Early-learning}} & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{gray!10}$ \\bigtriangleup$ & \\cellcolor{gray!10}$ \\bigtriangleup$ & Official\\,(PyTorch)\\protect\\footnotemark[13] \\\\\\cline{3-10}\n& & {\\emph{ODLN}} & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{gray!10}$ \\bigtriangleup$ & \\cellcolor{gray!10}$ \\bigtriangleup$ & Official\\,(PyTorch)\\protect\\footnotemark[14] \\\\\\cmidrule{2-10}\n& \\multirow{3}{*}{\\makecell[l]{\\hspace*{0.35cm}Implicit\\\\Regularization}} \n& \\emph{Adversarial Training} & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{red!10}\\xmark  & \\cellcolor{gray!10}$ \\bigtriangleup$ & Unofficial\\,(PyTorch)\\protect\\footnotemark[15] \\\\\\cline{3-10}\n& & \\emph{Label Smoothing} & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{red!10}\\xmark  & \\cellcolor{gray!10}$ \\bigtriangleup$ & Unofficial\\,(PyTorch)\\protect\\footnotemark[16] \\\\\\cline{3-10}\n& & \\emph{Mixup} & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{red!10}\\xmark  & \\cellcolor{gray!10}$ \\bigtriangleup$ & Official\\,(PyTorch)\\protect\\footnotemark[17] \\\\\\midrule\n\\multicolumn{2}{c|}{\\multirow{7}{*}{{\\makecell[l]{Robust Loss Function\\\\\\hspace*{0.75cm}(\\textsection \\ref{sec:robust_loss_function})}}}}  \n& \\emph{Robust MAE} & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{red!10}\\xmark & \\cellcolor{red!10}\\xmark & N/A \\\\\\cline{3-10}\n\\multicolumn{2}{c|}{} & \\emph{Generalized Cross Entropy} & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{red!10}\\xmark & \\cellcolor{red!10}\\xmark & Unofficial\\,(PyTorch)\\protect\\footnotemark[18] \\\\\\cline{3-10}\n\\multicolumn{2}{c|}{} & \\emph{Symmetric Cross Entropy} & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{red!10}\\xmark & \\cellcolor{red!10}\\xmark & Official\\,(Keras)\\protect\\footnotemark[19] \\\\\\cline{3-10}\n\\multicolumn{2}{c|}{} & {\\emph{Bi-tempered Loss}} & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{gray!10}$\\bigtriangleup$  & \\cellcolor{gray!10}$\\bigtriangleup$ & Official\\,(TensorFlow)\\protect\\footnotemark[20] \\\\\\cline{3-10}\n\\multicolumn{2}{c|}{} & \\emph{Curriculum Learning} & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{red!10}\\xmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{gray!10}$\\bigtriangleup$ & N/A \\\\\\cline{3-10}\n\\multicolumn{2}{c|}{} & {\\emph{Active Passive Loss}} & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{gray!10}$\\bigtriangleup$ & Official\\,(PyTorch)\\protect\\footnotemark[21] \\\\\\midrule\n\\multirow{21}{*}{\\vspace*{-0.7cm}\\hspace*{0.13cm}\\!\\!\\!\\!\\!\\!\\rotatebox[origin=c]{90}{\\makecell[l]{Loss Adjustment\\\\\\hspace*{0.5cm}(\\textsection \\ref{sec:loss_adjustment})}}\\!\\!\\!\\!\\!} \n& \\multirow{5}{*}{\\makecell[l]{Loss Correction}}  \n& \\emph{Backward Correction} & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark &  \\cellcolor{red!10}\\xmark &  \\cellcolor{red!10}\\xmark &  \\cellcolor{red!10}\\xmark & Official\\,(Keras)\\protect\\footnotemark[22] \\\\\\cline{3-10}\n& & \\emph{Forward Correction} & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark &  \\cellcolor{red!10}\\xmark &  \\cellcolor{red!10}\\xmark &  \\cellcolor{red!10}\\xmark & Official\\,(Keras)\\protect\\footnotemark[22] \\\\\\cline{3-10}\n& & \\emph{Gold Loss Correction} & \\cellcolor{blue!10}\\cmark & \\cellcolor{red!10}\\xmark & \\cellcolor{blue!10}\\cmark &  \\cellcolor{red!10}\\xmark &  \\cellcolor{red!10}\\xmark &  \\cellcolor{red!10}\\xmark & Official\\,(PyTorch)\\protect\\footnotemark[23] \\\\\\cline{3-10}\n& & {\\emph{T-revision}} & \\cellcolor{blue!10}\\cmark &  \\cellcolor{red!10}\\xmark  & \\cellcolor{blue!10}\\cmark &  \\cellcolor{blue!10}\\cmark &  \\cellcolor{red!10}\\xmark  &  \\cellcolor{red!10}\\xmark & Official\\,(PyTorch)\\protect\\footnotemark[24] \\\\\\cline{3-10}\n& & {\\emph{Dual T}} & \\cellcolor{blue!10}\\cmark & \\cellcolor{red!10}\\xmark & \\cellcolor{blue!10}\\cmark &  \\cellcolor{blue!10}\\cmark &  \\cellcolor{gray!10}$ \\bigtriangleup$ &  \\cellcolor{red!10}\\xmark & N/A \\\\\\cmidrule{2-10}\n& \\multirow{3}{*}{\\makecell[l]{Loss Reweigting}} \n& \\emph{Importance Reweighting} & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{red!10}\\xmark & \\cellcolor{gray!10}$ \\bigtriangleup$ & Unofficial\\,(PyTorch)\\protect\\footnotemark[25] \\\\\\cline{3-10}\n& & \\emph{Active Bias} & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{red!10}\\xmark & \\cellcolor{gray!10}$ \\bigtriangleup$ & Unofficial\\,(TensorFlow)\\protect\\footnotemark[26]\\!\\! \\\\\\cline{3-10}\n& & {\\emph{DualGraph}} & \\cellcolor{red!10}\\xmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{gray!10}$ \\bigtriangleup$ & N/A \\\\\\cmidrule{2-10}\n& \\multirow{6}{*}{\\makecell[l]{Label Refurbishment}} \n& \\emph{Bootstrapping} & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{red!10}\\xmark & \\cellcolor{red!10}\\xmark & \\cellcolor{gray!10}$ \\bigtriangleup$ & Unofficial\\,(Keras)\\protect\\footnotemark[27] \\\\\\cline{3-10}\n& & \\emph{Dynamic Bootstrapping} & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{red!10}\\xmark & \\cellcolor{gray!10}$ \\bigtriangleup$ & Official\\,(PyTorch)\\protect\\footnotemark[28] \\\\\\cline{3-10}\n& & {\\emph{Self-adaptive Training}} & \\cellcolor{blue!10}\\cmark & \\cellcolor{red!10}\\xmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark  & \\cellcolor{gray!10}$ \\bigtriangleup$ & Official\\,(PyTorch)\\protect\\footnotemark[29] \\\\\\cline{3-10}\n& & \\emph{D2L} & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{red!10}\\xmark & \\cellcolor{gray!10}$ \\bigtriangleup$ & Official\\,(Keras)\\protect\\footnotemark[30] \\\\\\cline{3-10}\n& & {\\emph{AdaCorr}} & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{gray!10}$ \\bigtriangleup$ & Official\\,(PyTorch)\\protect\\footnotemark[31] \\\\\\cline{3-10}\n& & {\\emph{SEAL}} & \\cellcolor{blue!10}\\cmark & \\cellcolor{red!10}\\xmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & Official\\,(PyTorch)\\protect\\footnotemark[32] \\\\\\cmidrule{2-10}\n& \\multirow{7}{*}{\\makecell[l]{Meta Learning}} \n& \\emph{L2LWS} & \\cellcolor{red!10}\\xmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark &  \\cellcolor{red!10}\\xmark & \\cellcolor{gray!10}$ \\bigtriangleup$ & \\cellcolor{gray!10}$ \\bigtriangleup$ & Unofficial\\,(TensorFlow)\\protect\\footnotemark[33]\\!\\! \\\\\\cline{3-10}\n& & \\emph{CWS} & \\cellcolor{red!10}\\xmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark &  \\cellcolor{red!10}\\xmark & \\cellcolor{gray!10}$ \\bigtriangleup$ & \\cellcolor{gray!10}$ \\bigtriangleup$ & N/A \\\\\\cline{3-10}\n& & \\emph{Automatic Reweighting} & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark &  \\cellcolor{red!10}\\xmark & \\cellcolor{gray!10}$ \\bigtriangleup$ & \\cellcolor{gray!10}$ \\bigtriangleup$ & Official\\,(TensorFlow)\\protect\\footnotemark[34] \\\\\\cline{3-10}\n& & \\emph{Meta-weight-net} & \\cellcolor{gray!10}$ \\bigtriangleup$ & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{red!10}\\xmark &  \\cellcolor{gray!10}$ \\bigtriangleup$ & \\cellcolor{gray!10}$ \\bigtriangleup$ & Official\\,(PyTorch)\\protect\\footnotemark[35] \\\\\\cline{3-10}\n& & {\\emph{Data Coefficients}} &  \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{red!10}\\xmark & \\cellcolor{gray!10}$ \\bigtriangleup$ & \\cellcolor{gray!10}$ \\bigtriangleup$ & Official\\,(TensorFlow)\\protect\\footnotemark[36] \\\\\\cline{3-10}\n& & \\emph{Knowledge Distillation} & \\cellcolor{blue!10}\\cmark & \\cellcolor{red!10}\\xmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{red!10}\\xmark &  \\cellcolor{gray!10}$ \\bigtriangleup$ & \\cellcolor{gray!10}$ \\bigtriangleup$ & N/A \\\\\\cline{3-10}\n& & {\\emph{MLC}} & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{red!10}\\xmark &  \\cellcolor{gray!10}$ \\bigtriangleup$ & \\cellcolor{blue!10}\\cmark & Official\\,(PyTorch)\\protect\\footnotemark[37] \\\\\\midrule\n\\multirow{13}{*}{\\vspace*{-0.45cm}\\hspace*{0.13cm}\\!\\!\\!\\!\\!\\!\\rotatebox[origin=c]{90}{\\makecell[l]{Sample Selection\\\\\\hspace*{0.5cm}(\\textsection \\ref{sec:sample_selection})}}\\!\\!\\!\\!\\!} \n& \\multirow{4}{*}{\\makecell[l]{Multi-Network\\\\\\hspace*{0.33cm}Learning}}  \n& \\emph{Decouple} & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{red!10}\\xmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{red!10}\\xmark & \\cellcolor{gray!10}$ \\bigtriangleup$ & Official\\,(TensorFlow)\\protect\\footnotemark[38] \\\\\\cline{3-10}\n& & \\emph{MentorNet} & \\cellcolor{red!10}\\xmark & \\cellcolor{red!10}\\xmark & \\cellcolor{red!10}\\xmark & \\cellcolor{red!10}\\xmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{gray!10}$ \\bigtriangleup$ & Official\\,(TensorFlow)\\protect\\footnotemark[39] \\\\\\cline{3-10}\n& & \\emph{Co-teaching} & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{red!10}\\xmark & \\cellcolor{red!10}\\xmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{gray!10}$ \\bigtriangleup$ & Official\\,(PyTorch)\\protect\\footnotemark[40] \\\\\\cline{3-10}\n& &  \\emph{Co-teaching+} & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{red!10}\\xmark & \\cellcolor{red!10}\\xmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{gray!10}$ \\bigtriangleup$ & Official\\,(PyTorch)\\protect\\footnotemark[41] \\\\\\cline{3-10}\n& &  {\\emph{JoCoR}} & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{red!10}\\xmark & \\cellcolor{red!10}\\xmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{gray!10}$ \\bigtriangleup$ & Official\\,(PyTorch)\\protect\\footnotemark[42] \\\\\\cmidrule{2-10}\n& \\multirow{6}{*}{\\makecell[l]{Multi-Round\\\\\\hspace*{0.23cm}Learning}}  \n& \\emph{ITLM} & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{red!10}\\xmark & \\cellcolor{red!10}\\xmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{gray!10}$ \\bigtriangleup$ & Official\\,(GluonCV)\\protect\\footnotemark[43] \\\\\\cline{3-10}\n& & \\emph{INCV} & \\cellcolor{blue!10}\\cmark &\\cellcolor{blue!10}\\cmark & \\cellcolor{red!10}\\xmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{gray!10}$ \\bigtriangleup$ & Official\\,(Keras)\\protect\\footnotemark[44] \\\\\\cline{3-10}\n& & {\\emph{O2U-Net}} & \\cellcolor{blue!10}\\cmark &\\cellcolor{blue!10}\\cmark & \\cellcolor{red!10}\\xmark & \\cellcolor{red!10}\\xmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{gray!10}$ \\bigtriangleup$ & Unofficial\\,(PyTorch)\\protect\\footnotemark[45] \\\\\\cline{3-10}\n& &  \\emph{Iterative Detection} & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{red!10}\\xmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{gray!10}$ \\bigtriangleup$ & Official\\,(Keras)\\protect\\footnotemark[46] \\\\\\cline{3-10}\n& &  {\\emph{MORPH}} & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{red!10}\\xmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{gray!10}$ \\bigtriangleup$ & N/A \\\\\\cline{3-10}\n& &  {\\emph{TopoFilter}} & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{red!10}\\xmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{gray!10}$ \\bigtriangleup$ & Official\\,(PyTorch)\\protect\\footnotemark[47] \\\\\\cline{3-10}\n& &  {\\emph{NGC}} & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{gray!10}$ \\bigtriangleup$ & N/A\\\\\\cmidrule{2-10}\n& \\multirow{3}{*}{\\vspace*{-0.24cm}\\makecell[l]{Hybrid Approach}}  \n& \\emph{SELFIE} & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{red!10}\\xmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{gray!10}$ \\bigtriangleup$ & Official\\,(TensorFlow)\\protect\\footnotemark[48] \\\\\\cline{3-10}\n& & \\emph{SELF} & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{gray!10}$ \\bigtriangleup$ & N/A \\\\\\cline{3-10}\n& & \\emph{DivideMix} & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{gray!10}$ \\bigtriangleup$ & Official\\,(PyTorch)\\protect\\footnotemark[49] \\\\\\cline{3-10}\n& & {\\emph{RoCL}} & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{gray!10}$ \\bigtriangleup$ & N/A \\\\\\bottomrule\n\\end{tabular}\n\\label{table:all_comparision}\n\\vspace*{-4cm}\n\\end{table*}\n}\n\\clearpage\n{\n\\footnotetext[1]{\\url{https://github.com/endernewton/webly-supervised}}\n\\footnotetext[2]{\\url{https://github.com/delchiaro/training-cnn-noisy-labels-keras}}\n\\footnotetext[3]{\\url{https://github.com/ijindal/Noisy_Dropout_regularization}}\n\\footnotetext[4]{\\url{https://github.com/udibr/noisy_labels}}\n\\footnotetext[5]{\\url{https://github.com/Ryo-Ito/Noisy-Labels-Neural-Network}}\n\\footnotetext[6]{\\url{https://github.com/Cysu/noisy_label}}\n\\footnotetext[7]{\\url{https://github.com/bhanML/Masking}}\n\\footnotetext[8]{\\url{https://github.com/pokaxpoka/RoGNoisyLabel}}\n\\footnotetext[9]{\\url{https://github.com/sjenni/DeepBilevel}}\n\\footnotetext[10]{\\url{https://rt416.github.io/pdf/trace_codes.pdf}}\n\\footnotetext[11]{\\url{github.com/hendrycks/pre-training}}\n\\footnotetext[12]{\\url{https://github.com/dmizr/phuber}}\n\\footnotetext[13]{\\url{https://github.com/xiaoboxia/CDR}}\n\\footnotetext[14]{\\url{https://github.com/hongxin001/ODNL?ref=pythonrepo.com}}\n\\footnotetext[15]{\\url{https://https://github.com/sarathknv/adversarial-examples-pytorch}}\n\\footnotetext[16]{\\url{https://github.com/CoinCheung/pytorch-loss}}\n\\footnotetext[17]{\\url{https://github.com/facebookresearch/mixup-cifar10}}\n\\footnotetext[18]{\\url{https://github.com/AlanChou/Truncated-Loss}}\n\\footnotetext[19]{\\href{https://github.com/YisenWang/symmetric\\_cross\\_entropy\\_for\\_noisy_label}{https://github.com/YisenWang/symmetric\\_cross\\_entropy}}\n\\footnotetext[20]{\\url{https://github.com/google/bi-tempered-loss}}\n\\footnotetext[21]{\\url{https://github.com/HanxunH/Active-Passive-Losses}}\n\\footnotetext[22]{\\url{https://github.com/giorgiop/loss-correction}}\n\\footnotetext[23]{\\url{https://github.com/mmazeika/glc}}\n\\footnotetext[24]{\\url{https://github.com/xiaoboxia/T-Revision}}\n\\footnotetext[25]{\\href{https://github.com/xiaoboxia/Classification-with-noisy-labels-by-importance-reweighting}{https://github.com/xiaoboxia/Classification-with-noisy-labels}}\n\\newcolumntype{L}[1]{>{\\centering\\let\\newline\\\\\\arraybackslash\\hspace{0pt}}m{#1}}\n\\newcolumntype{X}[1]{>{\\centering\\let\\newline\\\\\\arraybackslash\\hspace{0pt}}p{#1}}\n\\begin{table*}[!htb]\n\\centering\n\\vspace*{-0.1cm}\n\\caption{Comparison of robust deep learning categories for overcoming noisy labels.}\n\\vspace*{-0.2cm}\n\\begin{tabular}{L{2.2cm} | L{2.85cm}|X{1.5cm}|X{1.55cm}|X{1.8cm}|X{1.65cm}|X{1.5cm}|X{1.6cm}}\n\\toprule\n\\multicolumn{2}{>{}c|}{\\multirow{2}{*}{\\textbf{Category}}} & \\textbf{P1} & \\textbf{P2} & \\textbf{P3} & \\textbf{P4} & \\textbf{P5} & \\textbf{P6} \\\\\n\\multicolumn{2}{>{}c|}{} & \\!\\!\\!{Flexibility}\\!\\!\\! & \\!\\!\\!{No Pre-train}\\!\\!\\! & \\!\\!\\!{Full Exploration}\\!\\!\\! & \\!\\!\\!{No Supervision}\\!\\!\\!  & \\!\\!\\!{Heavy Noise}\\!\\!\\! & \\!\\!\\!{Complex Noise}\\!\\!\\! \\\\\\midrule\n\\multirow{2}{*}\n{\\makecell[l]{\\!\\!\\!Robust Architecture\\!\\!\\! \\\\\\hspace*{0.5cm}(\\textsection \\ref{sec:robust_architecture})}}\n& \\!\\!Noise Adaptation Layer & \\cellcolor{gray!10}$ \\bigtriangleup$ & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark  & \\cellcolor{red!10}\\xmark & \\cellcolor{red!10}\\xmark \\\\\n\\cline{2-8}\n& \\!\\!Dedicated Architecture & \\cellcolor{red!10}\\xmark & \\cellcolor{gray!10}$ \\bigtriangleup$ & \\cellcolor{blue!10}\\cmark & \\cellcolor{gray!10}$ \\bigtriangleup$  & \\cellcolor{gray!10}$ \\bigtriangleup$ & \\cellcolor{blue!10}\\cmark\\\\ \\midrule\n\\multirow{2}{*}\n{\\makecell[l]{\\!\\!\\!\\!\\!\\!Robust Regularization\\!\\!\\!\\!\\!\\! \\\\\\hspace*{0.5cm}(\\textsection \\ref{sec:robust_regularization})}}\n& \\!\\!Implicit Regularization & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark  & \\cellcolor{gray!10}$ \\bigtriangleup$ & \\cellcolor{gray!10}$ \\bigtriangleup$ \\\\\n\\cline{2-8}\n& \\!\\!Explicit Regularization & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark  & \\cellcolor{red!10}\\xmark & \\cellcolor{gray!10}$ \\bigtriangleup$ \\\\ \\midrule\n\\multicolumn{2}{>{}c|}{\\hspace*{0cm}Robust Loss Function (\\textsection \\ref{sec:robust_loss_function}) }& \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark  & \\cellcolor{red!10}\\xmark & \\cellcolor{red!10}\\xmark \\\\\\midrule\n\\multirow{2}{*}\n{\\vspace*{-0.58cm}\\!\\makecell[l]{Loss Adjustment \\\\\\hspace*{0.52cm}(\\textsection \\ref{sec:loss_adjustment})}}\n& \\!\\!Loss Correction &\\cellcolor{blue!10}\\cmark & \\cellcolor{red!10}\\xmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{red!10}\\xmark  & \\cellcolor{red!10}\\xmark &\\cellcolor{red!10}\\xmark \\\\\n\\cline{2-8}\n& \\!\\!Loss Reweighting & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark  & \\cellcolor{red!10}\\xmark & \\cellcolor{gray!10}$ \\bigtriangleup$\\\\\n\\cline{2-8}\n& \\!\\!Label Refurbishment & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{gray!10}$ \\bigtriangleup$ & \\cellcolor{gray!10}$ \\bigtriangleup$\\\\\\cline{2-8}\n& \\!\\!Meta Learning & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark &  \\cellcolor{red!10}\\xmark & \\cellcolor{gray!10}$ \\bigtriangleup$  & \\cellcolor{gray!10}$ \\bigtriangleup$ \\\\ \\midrule\n{\\vspace*{-0.55cm}\\hspace*{0.075cm}\\makecell[l]{Sample Selection\\\\\\hspace*{0.55cm}(\\textsection \\ref{sec:sample_selection})}}\n& \\!\\!Multi-Network Learning &\\cellcolor{blue!10}\\cmark &\\cellcolor{blue!10}\\cmark &  \\cellcolor{red!10}\\xmark & \\cellcolor{red!10}\\xmark  & \\cellcolor{blue!10}\\cmark  & \\cellcolor{gray!10}$ \\bigtriangleup$ \\\\\n\\cline{2-8}\n& \\!\\!Multi-Round Learning & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{red!10}\\xmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{gray!10}$ \\bigtriangleup$\\\\\\cline{2-8}\n& \\!\\!Hybrid Approach & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark & \\cellcolor{blue!10}\\cmark  & \\cellcolor{gray!10}$ \\bigtriangleup$\\\\\\bottomrule\n\\end{tabular}\n\\label{table:direction_comparison}\n\\vspace*{-0.4cm}\n\\end{table*}\n}\nMeanwhile, \\emph{SELFIE}  is a hybrid approach of sample selection and loss correction. The loss of refurbishable examples is corrected (i.e., loss correction) and then used together with that of small-loss examples (i.e., sample selection). Consequently, more training examples are considered for updating the DNN.\nThe \\emph{curriculum loss\\,(CL)}  is combined with the robust loss function approach and used to extract the true-labeled examples from noisy data.\n\\smallskip\n\\noindent \\underline{Remark}:\nNoise robustness is significantly improved by combining with other techniques. However, the hyperparameters introduced by these techniques render a DNN more susceptible to changes in data and noise types, and an increase in computational cost is inevitable", "cites": [3340, 3343, 7133, 4137, 7773, 3345, 8738, 4159, 4134, 4132, 4140, 4141, 7775, 7778, 4126, 3342, 4156, 4142, 7772, 4150, 8737, 4155, 4138, 4130, 7191, 4151, 4147, 4135, 7162, 4157, 4145, 7774, 4139, 4125, 4123, 892, 4128, 4152, 4253, 4158, 7777, 4131, 8630, 7163, 4133, 4154, 2277, 4136], "cite_extract_rate": 0.7741935483870968, "origin_cites_number": 62, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.0, "abstraction": 3.5}, "insight_level": "medium", "analysis": "The section effectively synthesizes multiple methods by connecting sample selection with semi-supervised learning, creating a coherent narrative around hybrid approaches. It critically discusses the limitations of discarding unselected data and highlights how methods like SELF, DivideMix, and RoCL address this. While some general patterns are identified (e.g., the role of model averaging and loss-based filtering), the abstraction remains grounded in specific methods rather than rising to a meta-level theoretical framework."}}
{"id": "3b9c1099-a2f2-417d-a753-e663d7ce62fa", "title": "Methodological Comparison", "level": "section", "subsections": [], "parent_id": "4c23e240-6b38-42a9-a3ad-77c4f677661a", "prefix_titles": [["title", "Learning from Noisy Labels with Deep Neural Networks: A Survey"], ["section", "Methodological Comparison"]], "content": "\\label{sec:comparison}\nIn this section, we compare the {$62$} deep learning methods for overcoming noisy labels introduced in Section \\ref{sec:methodology} with respect to the following \\emph{six} properties. When selecting the properties, we refer to the properties that are typically used to compare the performance of robust deep learning methods . To the best of our knowledge, this survey is the first to provide a systematic comparison of robust training methods. \nThis comprehensive comparison will provide useful insights that can enlighten new future directions.\n\\vspace*{0.1cm}\n\\begin{itemize}[leftmargin=9pt]\n\\item \\textbf{(P1)\\,Flexibility:} With the rapid evolution of deep learning research, a number of new network architectures are constantly emerging and becoming available. Hence, the ability to support any type of architecture is important. \\enquote{Flexibility} ensures that the proposed method can quickly adapt to the state-of-the-art architecture.\n\\vspace*{0.1cm}\n\\item \\textbf{(P2)\\,No Pre-training:} A typical approach to improve noise robustness is to use a pre-trained network; however, this incurs an additional computational cost to the learning process. \\enquote{No Pre-training} ensures that the proposed method can be trained from scratch without any pre-training.\n\\vspace*{0.1cm}\n\\item \\textbf{(P3)\\,Full Exploration:} Excluding unreliable examples from the update is an effective method for robust deep learning; however, it eliminates hard but useful training examples as well. \\enquote{Full Exploration} ensures that the proposed methods can use \\emph{all} training examples without severe overfitting to false-labeled examples by adjusting their training losses or applying semi-supervised learning.\n\\vspace*{0.1cm}\n\\item \\textbf{(P4)\\,No Supervision:} Learning with supervision, such as a clean validation set or a known noise rate, is often impractical because they are difficult to obtain. Hence, such supervision had better be avoided to increase practicality in real-world scenarios. \\enquote{No Supervision} ensures that the proposed methods can be trained without any supervision.\n\\vspace*{0.1cm}\n\\item \\textbf{(P5)\\,Heavy Noise:} In real-world noisy data, the noise rate can vary from light to heavy. Hence, learning methods should achieve consistent noise robustness with respect to the noise rate. \\enquote{Heavy Noise} ensures that the proposed methods can combat even the heavy noise.\n\\end{itemize}\n{\n\\footnotetext[26]{\\url{https://github.com/songhwanjun/ActiveBias}}\n\\footnotetext[27]{\\url{https://github.com/dr-darryl-wright/Noisy-Labels-with-Bootstrapping}}\n\\footnotetext[28]{\\url{https://github.com/PaulAlbert31/LabelNoiseCorrection}}\n\\footnotetext[29]{\\url{https://github.com/LayneH/self-adaptive-training}}\n\\footnotetext[30]{\\url{https://github.com/xingjunm/dimensionality-driven-learning}}\n\\footnotetext[31]{\\url{https://github.com/pingqingsheng/LRT}}\n\\footnotetext[32]{\\url{https://github.com/chenpf1025/IDN}}\n\\footnotetext[33]{\\url{https://github.com/krayush07/learn-by-weak-supervision}}\n\\footnotetext[34]{\\url{https://github.com/uber-research/learning-to-reweight-examples}}\n\\footnotetext[35]{\\url{https://github.com/xjtushujun/meta-weight-net}}\n\\footnotetext[36]{\\url{https://github.com/google-research/google-research/tree/master/ieg}}\n\\footnotetext[37]{\\url{https://aka.ms/MLC}}\n\\footnotetext[38]{\\url{https://github.com/emalach/UpdateByDisagreement}}\n\\footnotetext[39]{\\url{https://github.com/google/mentornet}}\n\\footnotetext[40]{\\url{https://github.com/bhanML/Co-teaching}}\n\\footnotetext[41]{\\url{https://github.com/bhanML/coteaching_plus}}\n\\footnotetext[42]{\\url{https://github.com/hongxin001/JoCoR}}\n\\footnotetext[43]{\\url{https://github.com/yanyao-shen/ITLM-simplecode}}\n\\footnotetext[44]{\\url{https://github.com/chenpf1025/noisy_label_understanding_utilizing}}\n\\footnotetext[45]{\\url{https://github.com/hjimce/O2U-Net}}\n\\footnotetext[46]{\\url{https://github.com/YisenWang/Iterative_learning}}\n\\footnotetext[47]{\\url{https://github.com/pxiangwu/TopoFilter}}\n\\footnotetext[48]{\\url{https://github.com/kaist-dmlab/SELFIE}}\n\\footnotetext[49]{\\url{https://github.com/LiJunnan1992/DivideMix}}\n}\n\\begin{itemize}[leftmargin=9pt]\n\\item \\textbf{(P6)\\,Complex Noise:} The type of label noise significantly affects the performance of a learning method. To manage real-world noisy data, diverse types of label noise should be considered when designing a robust training method. \\enquote{Complex Noise} ensures that the proposed method can combat even the complex label noise.\n\\end{itemize}\n\\vspace*{0.05cm}\nTable \\ref{table:all_comparision} shows a comparison of all robust deep learning methods, which are grouped according to the most appropriate category. In the first row, the aforementioned six properties are labeled as P1--P6, and the availability of open-source implementation is added in the last column. For each property, we assign \\enquote{\\cmark} if it is completely supported, \\enquote{\\xmark} if it is not supported, and \\enquote{$\\bigtriangleup$} if it is supported but not completely. \nMore specifically, \\enquote{$\\bigtriangleup$} is assigned to P1 if the method can be flexible but requires additional effort, to P5 if the method can combat only moderate label noise, {and to P6 if the method does not make a strict assumption about the noise type but without explicitly modeling instance-dependent noise. Thus, for P6, the method marked with \\enquote{\\xmark} only deals with the instance-independent noise, while the method marked with \\enquote{\\cmark} deals with both instance-independent and -dependent noises.} The remaining properties\\,(i.e., P2, P3, and P4) are only assigned \\enquote{\\cmark} or \\enquote{\\xmark}. Regarding the implementation, we assign \\enquote{N/A} if a publicly available source code is not available.\nNo existing method supports all the properties. Each method achieves noise robustness by supporting a different combination of the properties. The supported properties are similar among the methods of the same (sub-)category because those methods share the same methodological philosophy; however, they differ significantly depending on the (sub-)category. Therefore, we investigate the properties generally supported in each (sub-)category and summarize them in Table \\ref{table:direction_comparison}. Here, the property of a (sub-)category is marked as the majority  of the belonging methods. If no clear trend is observed among those methods, then the property is marked \\enquote{$\\bigtriangleup$}.", "cites": [3340], "cite_extract_rate": 0.5, "origin_cites_number": 2, "insight_result": {"type": "comparative", "scores": {"synthesis": 4.0, "critical": 3.5, "abstraction": 4.2}, "insight_level": "high", "analysis": "The section demonstrates strong synthesis by organizing 62 methods into a coherent comparison framework based on six key properties. It also includes critical analysis by identifying trade-offs and limitations, such as the need for pre-training or the inability to handle complex noise. The abstraction level is high as it generalizes the methodological strengths and weaknesses within and across categories, offering a systematic view of trends in robust training approaches."}}
{"id": "8d7ed0bf-5e07-45ed-a147-190ba1a209fb", "title": "Noise Rate Estimation", "level": "section", "subsections": ["841668d4-4892-46d7-ae08-7e210e7c2add", "39b0234a-04ab-44e2-98d0-fa20ed4e0f74", "8516d834-e901-490a-aa9d-864c2f267139", "685f1250-3a8b-48b6-b510-042be23d64f6"], "parent_id": "4c23e240-6b38-42a9-a3ad-77c4f677661a", "prefix_titles": [["title", "Learning from Noisy Labels with Deep Neural Networks: A Survey"], ["section", "Noise Rate Estimation"]], "content": "\\label{sec:noise_rate}\n{\nThe estimation of a noise rate is an imperative part of utilizing robust methods for better practical use, especially with the approaches belonging to the loss adjustment and sample selection. The estimated noise rate is widely used to reweight examples for a robust classifier  or to determine how many examples should be selected as clean ones . However, detailed analysis has yet to be performed properly, though many robust approaches highly rely on the accuracy of noise rate estimation. The noise rate can be estimated by exploiting the inferred noise transition matrix , the Gaussian mixture model , or the cross-validation .\n}\n\\begin{comment}\n1. Yao, Y., Liu, T., Han, B., Gong, M., Deng, J., Niu, G., & Sugiyama, M.\nDual T: Reducing estimation error for transition matrix in label-noise learning. Advances in Neural Information Processing Systems 33, pp. 7260-7271, 2020. \n-> noise transition matrix\n2. Xia, X., Liu, T., Wang, N., Han, B., Gong, C., Niu, G., & Sugiyama, M.\nAre anchor points really indispensable in label-noise learning? Advances in Neural Information Processing Systems 32, pp. 6835-6846, 2019.\n-> noise transition matrix\n3. Li, X., Liu, T., Han, B., Niu, G., & Sugiyama, M.\nProvably end-to-end label-noise learning without anchor points.\n-> noise transition matrix\nProceedings of 38th International Conference on Machine Learning (ICML2021), pp. 6403-6413, 2021.\n4. Patrini, Giorgio et al. “Making Deep Neural Networks Robust to Label Noise: A Loss Correction Approach.” 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2017): 2233-2241.\n-> noise transition matrix\n5. Liu, Tongliang, and Dacheng Tao. \"Classification with noisy labels by importance reweighting.\" IEEE Transactions on pattern analysis and machine intelligence 38.3 (2015): 447-461.\n6. Scott, Clayton, Gilles Blanchard, and Gregory Handy. \"Classification with asymmetric label noise: Consistency and maximal denoising.\" Conference on learning theory. PMLR, 2013.\n\\end{comment}\n\\vspace*{-0.15cm}", "cites": [4130, 3340, 4126, 4135, 7777, 3453, 4123, 4160, 4152], "cite_extract_rate": 0.9, "origin_cites_number": 10, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.5, "critical": 2.0, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section provides a basic description of noise rate estimation methods, citing relevant papers, but lacks a deeper synthesis of their contributions. It does not compare or contrast the approaches meaningfully, nor does it offer critical evaluation or identify broader trends in the field. As a result, the insights remain at a surface level."}}
{"id": "841668d4-4892-46d7-ae08-7e210e7c2add", "title": "Noise Transition Matrix", "level": "subsection", "subsections": [], "parent_id": "8d7ed0bf-5e07-45ed-a147-190ba1a209fb", "prefix_titles": [["title", "Learning from Noisy Labels with Deep Neural Networks: A Survey"], ["section", "Noise Rate Estimation"], ["subsection", "Noise Transition Matrix"]], "content": "{\nThe noise transition matrix has been used to build a statistically consistent robust classifier because it represents the class posterior probabilities for noisy and clean data, as in Eq.\\,\\eqref{eq:label_transition_matrix}. The first method to estimate the noise rate is exploiting this noise transition matrix, which can be inferred or trained accurately by using perfectly clean examples, i.e., \\emph{anchor points} ; an example $x$ with its label $i$ is defined as an anchor point if $p(y=i|x)=1$ and $p(y=k|x)=0$ for $k \\neq i$. Thus, let $\\mathcal{A}_i$ be the set of anchor points with label $i$, then the element of the noise transition matrix $T_{ij}$ is estimated by \\looseness=-1\n\\begin{equation}\n\\begin{split}\n\\hat{T}_{ij} &= \\frac{1}{|\\mathcal{A}_{i}|}\\sum_{x\\in\\mathcal{A}_{i}} \\sum_{k=1}^{c} p(\\tilde{y}=j|y=k)p(y=k|x) \\\\\n&= \\frac{1}{|\\mathcal{A}_{i}|}\\sum_{x\\in\\mathcal{A}_{i}} p(\\tilde{y}=j|x; \\Theta),  \n\\end{split}\n\\end{equation}\nwhere $p(\\tilde{y}=j|x; \\Theta)$ is the noisy class posterior probability of the classifier trained on noisy training data for the anchor point $x$ (see the detailed proof in ). Next, based on the inferred noise transition matrix, the noise rate of a balanced training data is obtained by averaging the label transition probabilities between classes,\n\\begin{equation}\n\\hat{\\tau} = \\frac{1}{c} \\sum_{i=1}^{c} \\sum_{j\\neq i}^{c} p(\\tilde{y}=j | {y}=i) = \\frac{1}{c} \\sum_{i=1}^{c} \\sum_{j\\neq i}^{c} \\hat{T}_{ij}.\n\\end{equation}\nHowever, since the anchor points are typically unknown in real-world data, they are identified from noisy training data by either theoretical derivations  or heuristics . \nIn addition, there have been recent efforts to learn the noise transition matrix without anchor points. \\emph{T-Revision}  initializes a transition matrix by exploiting the examples with high noisy class posterior probabilities and then refines the matrix by adding a slack variable. \\emph{Dual-T}  introduces an intermediate class that factorizes the transition matrix into  two easy-to-estimate matrices for better accuracy. \\emph{VolMinNet}  realizes an end-to-end framework and relaxes the need for anchor points under the sufficiently scattered assumption.\n}\n{\n\\newcolumntype{L}[1]{>{\\centering\\let\\newline\\\\\\arraybackslash\\hspace{0pt}}m{#1}}\n\\newcolumntype{X}[1]{>{\\centering\\let\\newline\\\\\\arraybackslash\\hspace{0pt}}p{#1}}\n\\newcolumntype{Y}[1]{>{\\let\\newline\\\\\\arraybackslash\\hspace{1pt}}m{#1}}\n\\begin{table*}[t!]\n\\small\n\\caption{Summary of publicly available datasets used for studying label noise.}\n\\vspace*{-0.7cm}\n\\begin{center}\n\\begin{tabular}{L{2.0cm} | Y{3.4cm} |X{1.9cm}| X{1.9cm} |X{1.9cm} |X{1.9cm} |Y{2.1cm}}\\toprule \n\\multicolumn{2}{c|}{\\textbf{Dataset}} & \\textbf{\\# Training} & \\textbf{\\# Validation} & \\textbf{\\# Testing} & \\textbf{\\# Classes} & \\textbf{Noise Rate\\,(\\%)} \\\\\\hline\n\\multirow{7}{*}{\\hspace*{0.13cm}\\!\\!\\!\\!\\!\\!{\\makecell[l]{Clean Data}}\\!\\!\\!\\!\\!} \n& {MNIST} \\footnote[50] & {60K}& N/A  & {10K} & $10$ & $\\approx0.0$ \\\\\\cline{2-7}\n& {Fashion-MNIST} \\footnote[51]\\!\\!\\!\\!\\! & {60K}& N/A & {10K} & $10$ & $\\approx0.0$ \\\\\\cline{2-7}\n& {CIFAR-10} \\footnote[52] & {50K}& N/A & {10K} & $10$ & $\\approx0.0$ \\\\\\cline{2-7}\n& {CIFAR-100} \\footnote[52] & {50K}& N/A & {10K} & $100$ & $\\approx0.0$ \\\\\\cline{2-7}\n& {SVHN} \\footnote[53] & {73K}& N/A  & {26K} & $10$ & $\\approx0.0$ \\\\\\cline{2-7}\n& {Tiny-ImageNet} \\footnote[55] & {100K}& {10K} & {10K} & $200$ & $\\approx0.0$ \\\\\\cline{2-7}\n& {ImageNet} \\footnote[54] & {1.3M}& {50K}  & {50K} & $1000$ & $\\approx0.0$ \\\\\\midrule\n\\multirow{6}{*}{\\hspace*{0.13cm}\\!\\!\\!\\!\\!\\!{\\makecell[l]{Real-world\\\\\\hspace*{-0.02cm}Noisy Data}}\\!\\!\\!\\!\\!} \n& {ANIMAL-10N} \\footnote[56] & {50K}& N/A  & {5K} & $10$ & $\\approx8.0$ \\\\\\cline{2-7}\n& {CIFAR-10N }\\footnote[57]  & {50K}& N/A  & {10K} & $10$ & $\\approx9.0/18.0/40.2$\\!\\!\\!\\!\\!\\!\\!  \\\\\\cline{2-7}\n& {CIFAR-100N }\\footnote[57]  & {50K}& N/A  & {10K} & $100$ & $\\approx 25.6/40.2$ \\\\\\cline{2-7}\n& {Food-101N} \\footnote[58] & {310K}& {5K} & {25K} & $101$ & $\\approx18.4$ \\\\\\cline{2-7}\n& {Clothing1M} \\footnote[59] & {1M}& {14K} & {10K} & $14$ & $\\approx38.5$ \\\\\\cline{2-7}\n& {WebVision} \\footnote[60] & {2.4M}& {50K} & {50K} & $1000$ & $\\approx20.0$ \\\\\\bottomrule\n\\end{tabular}\n\\end{center}\n\\label{table:summary_dataset}\n\\vspace*{-0.6cm}\n\\end{table*}\n}\n\\vspace*{-0.15cm}", "cites": [7777, 4238, 4145, 4161, 652, 3453, 7769, 4160, 4152], "cite_extract_rate": 0.5, "origin_cites_number": 18, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.0, "abstraction": 3.5}, "insight_level": "medium", "analysis": "The section synthesizes methods from multiple papers to explain the role of the noise transition matrix in robust training. It abstracts the general idea of anchor points and discusses alternative approaches like T-Revision, Dual-T, and VolMinNet. While it provides some critical evaluation of the limitations of anchor points, the critique is not deeply nuanced and primarily focuses on method descriptions and assumptions."}}
{"id": "39b0234a-04ab-44e2-98d0-fa20ed4e0f74", "title": "Gaussian Mixture Model\\,(GMM)", "level": "subsection", "subsections": [], "parent_id": "8d7ed0bf-5e07-45ed-a147-190ba1a209fb", "prefix_titles": [["title", "Learning from Noisy Labels with Deep Neural Networks: A Survey"], ["section", "Noise Rate Estimation"], ["subsection", "Gaussian Mixture Model\\,(GMM)"]], "content": "\\label{sec:gmm}\n\\begin{figure}[t!]\n\\begin{center}\n\\vspace*{0.1cm}\n\\includegraphics[width=8.8cm]{figures/evaluation/gmm_analysis.pdf}\n\\end{center}\n\\vspace*{-0.15cm}\n\\hspace*{1.3cm} \\small{(a) Symmetric Noise.} \\hspace*{1.2cm} \\small{(b) Asymmetric Noise.} \n\\vspace*{-0.15cm}\n\\caption{Training loss distributions of true-labeled and false-labeled examples using the ground-truth label and the GMM on CIFAR-100 data with two synthetic noises of $40\\%$.}\n\\label{fig:loss_gmm}\n\\vspace*{-0.4cm}\n\\end{figure}\nThe second method is exploiting a one-dimensional and two-component GMM to model the loss distribution of true-labeled and false-labeled examples . As shown in Figure \\ref{fig:loss_gmm}, since the loss distribution tends to be \\emph{bi-modal}, the two Gaussian components are fitted to the training loss by using the EM algorithm; the probability of an example being a false-labeled one is obtained through its posterior probability. Hence, the noise rate is estimated at each epoch $t$ by computing the expectation of the posterior probability for all training examples, \\looseness=-1\n\\begin{equation}\n\\label{eq:naive_gmm}\n\\begin{gathered}\n\\hat{\\tau} = \\mathbb{E}_{(x,\\tilde{y})\\in\\tilde{\\mathcal{D}}}\\Big[\\,p\\big(g\\,|\\,\\ell\\big(f(x;\\Theta_{t}), \\tilde{y}\\big)\\big)\\,\\Big],\\\\ \n\\end{gathered}\n\\end{equation}\nwhere $g$ is the Gaussian component with a larger loss. However, Pleiss et al.  recently pointed out that the training loss becomes less separable by the GMM as the training progresses, and thus proposed the \\emph{area under the loss}\\,(AUL) curve, which is the sum of the example's training losses obtained from all previous training epochs. Even after the loss signal decays in later epochs, the distributions remain separable. Therefore, the noise rate is finally estimated by\n\\begin{equation}\n\\label{eq:aul_gmm}\n\\begin{gathered}\n\\hat{\\tau} = \\mathbb{E}_{(x,\\tilde{y})\\in\\tilde{\\mathcal{D}}}\\Big[\\,p\\big(g\\,|\\,{\\rm AUL}_{t}(x,\\tilde{y})\\big)\\,\\Big],\\\\ \n\\text{where}~ \\text{AUL}_{t}(x,\\tilde{y})= \\sum_{i=1}^{t}\\ell\\big(f(x;\\Theta_t),\\tilde{y}\\big).\n\\end{gathered}\n\\end{equation}\n\\vspace*{-0.4cm}", "cites": [4135], "cite_extract_rate": 1.0, "origin_cites_number": 1, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.5, "critical": 3.0, "abstraction": 3.0}, "insight_level": "medium", "analysis": "The section provides a clear explanation of how GMM is used to model loss distributions for noise rate estimation, integrating the methodological approach from the cited paper. It also introduces the AUL improvement and explains its advantage over the naive GMM approach. However, while it connects the two ideas, it does not critically evaluate their broader implications or limitations in the context of other methods, nor does it abstract the concept to a higher level framework."}}
{"id": "8516d834-e901-490a-aa9d-864c2f267139", "title": "Cross Validation", "level": "subsection", "subsections": [], "parent_id": "8d7ed0bf-5e07-45ed-a147-190ba1a209fb", "prefix_titles": [["title", "Learning from Noisy Labels with Deep Neural Networks: A Survey"], ["section", "Noise Rate Estimation"], ["subsection", "Cross Validation"]], "content": "\\label{sec:cross_val}\nThe third method is estimating the noise rate by applying cross validation, which typically requires clean validation data . However, such clean validation data is hard to acquire in real-world applications. Thus, Chen et al.  leveraged two randomly divided noisy training datasets for cross validation. Under the assumption that the two datasets share exactly the same noise transition matrix, the noise rate quantifies the test accuracy of DNNs that are respectively trained and tested on the two divided sets,\n\\begin{equation}\n\\label{eq:cross_val}\n\\!\\!\\!{\\rm Test\\,Accuracy} \\!= \\!\\!\\!\\\n\\begin{cases}\n(1 - \\hat{\\tau})^{2} +  \\hat{\\tau}^{2} / (c - 1) \\!\\!&\\!\\! \\text{if symmetric}\\!\\!\\!\\!\\\\\n(1 - \\hat{\\tau})^{2} + \\hat{\\tau}^{2}  \\!\\!& \\!\\!\\text{if asymmetric}.\\!\\!\\!\\!\n\\end{cases}\n\\end{equation}\nTherefore, the noise rate is estimated from the test accuracy obtained by cross validation.\n\\begin{comment}", "cites": [3340, 4140, 4126], "cite_extract_rate": 0.75, "origin_cites_number": 4, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.0, "critical": 2.5, "abstraction": 3.0}, "insight_level": "medium", "analysis": "The section synthesizes key ideas from the cited papers, particularly connecting the use of cross validation and the behavior of deep networks under label noise. It provides a formula and explains how test accuracy can be used to estimate noise rates, showing some analytical depth. However, it lacks deeper critical evaluation of the methods' limitations and offers limited broader abstraction or generalization beyond the specific technique."}}
{"id": "0c8efb50-e5a7-4707-a3b7-dcff2ec802f5", "title": "Clean Datasets", "level": "subsubsection", "subsections": [], "parent_id": "b05d418b-8b51-4e39-b585-58d8b1bcd7ff", "prefix_titles": [["title", "Learning from Noisy Labels with Deep Neural Networks: A Survey"], ["section", "Experimental Design"], ["subsection", "Publicly Available Datasets"], ["subsubsection", "Clean Datasets"]], "content": "According to the literature , \\emph{seven} clean datasets are widely used: MNIST\\footnote[50]{\\url{http://yann.lecun.com/exdb/mnist}}, classification of handwritten digits ; Fashion-MNIST\\footnote[51]{\\url{https://github.com/zalandoresearch/fashion-mnist}}, classification of various clothing ; CIFAR-10\\footnote[52]{\\url{https://www.cs.toronto.edu/~kriz/cifar.html}} and CIFAR-100\\footnotemark[52], classification of a subset of $80$ million categorical images ; SVHN\\footnote[53]{\\url{http://ufldl.stanford.edu/housenumbers}}, classification of house numbers in Google Street view images ;  ImageNet\\footnote[54]{\\url{http://www.image-net.org}} and Tiny-ImageNet\\footnote[55]{\\url{https://www.kaggle.com/c/tiny-imagenet}}, image database organized according to the WordNet hierarchy and its small subset . Because the labels in these datasets are almost all true-labeled, their labels in the training data should be artificially corrupted for the evaluation of synthetic noises, namely \\emph{symmetric} noise and \\emph{asymmetric} noise. \n\\vspace*{0.15cm}", "cites": [4253, 8630, 652], "cite_extract_rate": 0.3333333333333333, "origin_cites_number": 9, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 1.5, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section primarily lists commonly used clean datasets for benchmarking noisy label methods, with minimal synthesis of the cited papers. It provides basic factual information and integrates only superficially by mentioning that these datasets are used for synthetic noise evaluation. There is no critical analysis or abstraction beyond the datasets themselves."}}
{"id": "2e98f74b-5745-4f37-aea0-711f64e9e6c5", "title": "Real-world Noisy Datasets", "level": "subsubsection", "subsections": [], "parent_id": "b05d418b-8b51-4e39-b585-58d8b1bcd7ff", "prefix_titles": [["title", "Learning from Noisy Labels with Deep Neural Networks: A Survey"], ["section", "Experimental Design"], ["subsection", "Publicly Available Datasets"], ["subsubsection", "Real-world Noisy Datasets"]], "content": "Unlike the clean datasets, real-world noisy datasets inherently contain many mislabeled examples annotated by non-experts. According to the literature , \\emph{six} real-world noisy datasets are widely used: ANIMAL-10N\\footnote[56]{\\url{https://dm.kaist.ac.kr/datasets/animal-10n}}, real-world noisy data of human-labeled online images for 10 confusing animals ;\n{CIFAR-10N\\footnote[57]{\\url{http://noisylabels.com/}} and CIFAR-100N\\footnotemark[57], variations of CIFAR-10 and CIFAR-100 with human-annotated real-world noisy labels collected from Amazon’s Mechanical Turk . They provide human labels with different noise rates, as shown in Table \\ref{table:summary_dataset};}\nFood-101N\\footnote[58]{\\url{https://kuanghuei.github.io/Food-101N}}, real-world noisy data of crawled food images annotated by their search keywords in the Food-101 taxonomy ; Clothing1M\\footnote[59]{\\url{https://www.floydhub.com/lukasmyth/datasets/clothing1m}}, real-world noisy data of large-scale crawled clothing images from several online shopping websites ; WebVision\\footnote[60]{\\url{https://data.vision.ee.ethz.ch/cvl/webvision/download.html}}, real-world noisy data of large-scale web images crawled from  Flickr  and Google Images search . To support sophisticated evaluation, most real-world noisy datasets contain their own clean validation set and provide the estimated noise rate of their training set. \\looseness=-1", "cites": [4238, 4161, 7769], "cite_extract_rate": 0.5, "origin_cites_number": 6, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.5, "critical": 2.0, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section provides a factual description of real-world noisy datasets, listing them and their sources, but offers minimal synthesis of the cited papers. It does not connect their contributions or insights into a broader narrative. There is no critical evaluation of the datasets or the methods introduced in the papers, and no abstraction to highlight overarching trends or principles in the field."}}
{"id": "6b4a1fff-c3c1-412a-b6f0-eeaa7d3721a4", "title": "Evaluation Metrics", "level": "subsection", "subsections": [], "parent_id": "0788ae52-30c4-4156-89f9-6be2e443db83", "prefix_titles": [["title", "Learning from Noisy Labels with Deep Neural Networks: A Survey"], ["section", "Experimental Design"], ["subsection", "Evaluation Metrics"]], "content": "A typical metric to assess the robustness of a particular method is the prediction accuracy for unbiased and clean examples that are not used in training. The prediction accuracy degrades significantly if the DNN overfits to false-labeled examples . Hence, \\emph{test accuracy} has generally been adopted for evaluation . For a test set $\\mathcal{T}=\\{(x_i,y_i)\\}_{i=1}^{|\\mathcal{T}|}$, let $\\hat{y}_i$ be the predicted label of the $i$-th example in $\\mathcal{T}$. Subsequently, the test accuracy is formalized by\n\\begin{equation}\n\\label{eq:test_accuracy}\n\\text{Test Accuracy} = \\frac{|\\{(x_i,y_i)\\in\\mathcal{T}:\\hat{y}_i=y_i\\}|}{|\\mathcal{T}|}.\n\\end{equation}\nIf the test data are not available, \\emph{validation accuracy} can be used by replacing $\\mathcal{T}$ in Eq.\\,\\eqref{eq:test_accuracy} with validation data $\\mathcal{V}=\\{(x_i,y_i)\\}_{i=1}^{|\\mathcal{V}|}$ as an alternative,\n\\begin{equation}\n\\label{eq:validation_accuracy}\n\\text{Validation Accuracy} = \\frac{|\\{(x_i,y_i)\\in\\mathcal{V}:\\hat{y}_i=y_i\\}|}{|\\mathcal{V}|}.\n\\end{equation}\nFurthermore, if the specified method belongs to the \\enquote{sample selection} category, \\emph{label precision} and \\emph{label recall}  can be used as the metrics,\n\\noindent\n\\begin{equation}\n\\label{eq:label_precision}\n\\begin{gathered}\n\\text{Label Precision} = \\frac{|\\{(x_i,\\tilde{y}_i)\\in\\mathcal{S}_t: \\tilde{y}_i = y_i\\}|}{|\\mathcal{S}_t|},\\\\\n\\text{Label Recall} = \\frac{|\\{(x_i,\\tilde{y}_i)\\in\\mathcal{S}_t: \\tilde{y}_i = y_i\\}|}{|\\{(x_i,\\tilde{y}_i)\\in\\mathcal{B}_t: \\tilde{y}_i = y_i\\}|},\n\\end{gathered}\n\\end{equation}\nwhere $\\mathcal{S}_t$ is the set of selected clean examples in a mini-batch $\\mathcal{B}_t$. The two metrics are performance indicators for the examples selected from the mini-batch as true-labeled ones . \\looseness=-1\nMeanwhile, if the specified method belongs to the \\enquote{label refurbishment} category, \\emph{correction error}  can be used as an indicator of how many examples are incorrectly refurbished,\n\\begin{equation}\n\\label{eq:correction_error}\n\\!\\text{Correction Error} = \\frac{|\\{x_i\\!\\in\\!\\mathcal{R}: \\text{argmax}(y_{i}^{refurb}) \\neq y_i\\}|}{|\\mathcal{R}|},\n\\end{equation}\nwhere $\\mathcal{R}$ is the set of examples whose labels are refurbished by Eq.\\,(\\ref{eq:label_correction}) and $y_i^{refurb}$ is the refurbished label of the $i$-th examples in $\\mathcal{R}$. \n\\vspace*{-0.12cm}", "cites": [3340, 4126, 3630], "cite_extract_rate": 0.6, "origin_cites_number": 5, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 2.0, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section provides a straightforward description of common evaluation metrics used in learning from noisy labels. It integrates concepts from cited papers by mentioning their relevance to test accuracy and label refurbishment but does not critically analyze or synthesize these ideas into a broader framework. The presentation is factual and lacks deeper comparative or analytical insights."}}
{"id": "4ad866ea-f321-4ab2-be85-14135292873f", "title": "{Instance-dependent Label Noise", "level": "subsection", "subsections": [], "parent_id": "01d4e82b-d227-4b85-bfa5-6db6af2b743d", "prefix_titles": [["title", "Learning from Noisy Labels with Deep Neural Networks: A Survey"], ["section", "Future Research Directions"], ["subsection", "{Instance-dependent Label Noise"]], "content": "}\n{\nExisting theoretical and empirical studies for \\emph{robust loss function} and \\emph{loss correction} are largely built upon the instance-independent noise assumption that the label noise is independent of input features . However, this assumption may not be a good approximation of the real-world label noise. In particular, Chen et al.  conducted a theoretical hypothesis testing\\footnote[61]{In Clothing1M, the result showed that the instance-independent noise happens with probability lower than $10^{-21250}$, which is statistically impossible.} using a popular real-world dataset, Clothing1M, and proved that its label noise is statistically different from the instance-independent noise. This testing confirms that the label noise should depend on the instance. \\looseness=-1\nConversely, most methods for the other direction (especially, \\emph{sample selection}) work well even under the instance-dependent label noise in general since they do not rely on the assumption. Nevertheless, Song et al.  pointed out that their performance could considerably worsen in the instance-dependent\\,(or real-world) noise compared to symmetric noise due to the confusion between true-labeled and false-labeled examples. The loss distribution of true-labeled examples heavily overlaps that of false-labeled samples in the asymmetric noise, which is similar to the real-world noise, in Figure \\ref{fig:loss_distribution}(b). Thus, identifying clean examples becomes more challenging when dealing with the instance-dependent label noise.\nBeyond the instance-independent label noise, there have been a few recent studies for the instance-dependent label noise. Mostly, they only focus on a binary classification task  or a restricted small-scale machine learning model such as logistic regression . Therefore, learning with the instance-dependent label noise is an important topic that deserves more research attention.} \n\\vspace*{-0.32cm}", "cites": [7777, 4120, 4124, 4155, 4136, 4152], "cite_extract_rate": 0.6666666666666666, "origin_cites_number": 9, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.5, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section synthesizes several cited papers to build a coherent narrative around the limitations of instance-independent noise assumptions and the challenges of instance-dependent label noise. It critically evaluates the implications of these assumptions on different methodological approaches and highlights key limitations, such as the difficulty in distinguishing true and false labels in asymmetric noise. Furthermore, it abstracts the problem by identifying broader research gaps and the need for more generalized methods beyond binary or small-scale models."}}
{"id": "e53153d2-a39d-4573-9711-598781d00529", "title": "{Multi-label Data with Label Noise", "level": "subsection", "subsections": [], "parent_id": "01d4e82b-d227-4b85-bfa5-6db6af2b743d", "prefix_titles": [["title", "Learning from Noisy Labels with Deep Neural Networks: A Survey"], ["section", "Future Research Directions"], ["subsection", "{Multi-label Data with Label Noise"]], "content": "}\n{\nMost of the existing methods are applicable only for a \\emph{single-label} multi-class classification problem, where each data example is assumed to have only one true label. However, in the case of \\emph{multi-label} learning, each data example can be associated with a set of multiple true class labels. In music categorization, each music can belong to multiple categories . In semantic scene classification, each scene may belong to multiple scene classes . Thus, contrary to the single-label setup, the multi-label classifier aims to predict a set of target objects simultaneously. \nIn this setup, a multi-label dataset of millions of examples are reported to contain over $26.6\\%$ false-positive labels as well as a significant number of omitted labels . \nEven worse, the difference in occurrence between classes makes this problem more challenging; some minor class labels occur less in training data than other major class labels. Considering such aspects that can arise in multi-label classification, the simple extension of existing methods may not learn the proper correlations among multiple labels. Therefore, learning from noisy labels with multi-label data is another important topic for future research. We refer the readers to a recent study  that discusses the evaluation of multi-label classifiers trained with noisy labels.\n}\n\\vspace*{-0.12cm}", "cites": [4162], "cite_extract_rate": 0.25, "origin_cites_number": 4, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.0, "critical": 3.0, "abstraction": 3.0}, "insight_level": "medium", "analysis": "The section provides a coherent discussion on the challenges of multi-label data with label noise by integrating the context from the cited paper, highlighting the distinction between single-label and multi-label classification. It identifies key issues such as false-positive labels and class imbalance, and notes the limitations of extending single-label methods to multi-label settings. While it points to a need for future research, it does not offer a comprehensive critique or a novel synthesis of multiple ideas."}}
{"id": "cfbd0ac1-5575-43b8-9a59-26d13838ff8e", "title": "{Class Imbalance Data with Label Noise", "level": "subsection", "subsections": [], "parent_id": "01d4e82b-d227-4b85-bfa5-6db6af2b743d", "prefix_titles": [["title", "Learning from Noisy Labels with Deep Neural Networks: A Survey"], ["section", "Future Research Directions"], ["subsection", "{Class Imbalance Data with Label Noise"]], "content": "}\n{\nThe \\emph{class imbalance} in training data is commonly observed, where a few classes account for most of the data. Especially when working with large data in many real-world applications, this problem becomes more severe and is often associated with the problem of noisy labels .\nNevertheless, to ease the label noise problem, it is commonly assumed that training examples are equally distributed over all class labels in the training data. This assumption is quite strong when collecting large-scale data, and thus we need to consider a more realistic scenario in which the two problems coexist. \\looseness=-1\nMost of the existing robust methods may not work well with the class imbalance, especially when they rely on the learning dynamics of DNNs, e.g., the small-loss trick or memorization effect. Under the existence of the class imbalance, the training model converges to major classes faster than minor classes such that most examples in the major class exhibit small losses\\,(i.e., early memorization). That is, there is a risk of discarding most examples in the minor class. Furthermore, in terms of example importance, high-loss examples are commonly favored for the class imbalance problem , while small-loss examples are favored for the label noise problem. This conceptual contradiction hinders the applicability of the existing methods that neglect the class imbalance. Therefore, these two problems should be considered simultaneously to deal with more general situations.}\n\\vspace*{-0.12cm}", "cites": [7774], "cite_extract_rate": 0.5, "origin_cites_number": 2, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.5, "critical": 3.0, "abstraction": 3.5}, "insight_level": "medium", "analysis": "The section provides an analytical discussion on the intersection of class imbalance and label noise, highlighting conceptual contradictions and limitations in existing robust training methods. It integrates the idea of example importance from the cited paper to build a narrative about the challenges in real-world data scenarios. While it identifies a critical issue and points to a need for more realistic approaches, it does not compare multiple works in detail or offer a novel framework, limiting the depth of synthesis and critique."}}
{"id": "23870233-7f5b-4ef1-9d38-e6f3adb0fa48", "title": "{Robust and Fair Training", "level": "subsection", "subsections": [], "parent_id": "01d4e82b-d227-4b85-bfa5-6db6af2b743d", "prefix_titles": [["title", "Learning from Noisy Labels with Deep Neural Networks: A Survey"], ["section", "Future Research Directions"], ["subsection", "{Robust and Fair Training"]], "content": "}\n{\nMachine learning classifiers can perpetuate and amplify the existing systemic injustices in society . Hence, fairness is becoming another important topic. Traditionally, robust training and fair training have been studied by separate communities; robust training with noisy labels has mostly focused on combating label noise without regarding data bias , whereas fair training has focused on dealing with data bias, not necessarily noise . However, noisy labels and data bias, in fact, coexist in real-world data. Satisfying both robustness and fairness is more realistic but challenging because the bias in data is pertinent to label noise. \nIn general, many fairness criteria are group-based, where a target metric is equalized or enforced over subpopulations in the data, also known as \\emph{protected groups} such as race or gender . Accordingly, the goal of fair training is building a model that satisfies such fairness criteria for the \\emph{true} protected groups. However, if the \\emph {noisy} protection group is involved, such fairness criteria cannot be directly applied. Recently, mostly after 2020, a few pioneering studies have emerged to consider both robustness and fairness objectives at the same time under the binary classification setting . Therefore, more research attention is needed for the convergence of robust training and fair training.\n}\n\\vspace*{-0.12cm}", "cites": [7771, 4163, 3899, 8740, 8739], "cite_extract_rate": 0.8333333333333334, "origin_cites_number": 6, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.5, "critical": 3.0, "abstraction": 3.5}, "insight_level": "medium", "analysis": "The section effectively synthesizes key ideas from the cited papers by highlighting the intersection between robust training and fair training, particularly in the context of noisy protected groups and label corruption. It abstracts from specific studies to present a broader perspective on the coexistence of label noise and data bias, but the critical analysis is limited to identifying gaps rather than evaluating the strengths and weaknesses of individual approaches in depth."}}
{"id": "bf2c4a41-a623-4acf-b905-fe345054727a", "title": "{Connection with Input Perturbation", "level": "subsection", "subsections": [], "parent_id": "01d4e82b-d227-4b85-bfa5-6db6af2b743d", "prefix_titles": [["title", "Learning from Noisy Labels with Deep Neural Networks: A Survey"], ["section", "Future Research Directions"], ["subsection", "{Connection with Input Perturbation"]], "content": "}\n{\nThere has been a lot of research on the robustness of deep learning under input perturbation, mainly in the field of adversarial training where the  {input feature} is maliciously perturbed to distort the output of the DNN . Although learning with noisy labels and learning with noisy inputs have been regarded as separate research fields, their goals are similar in that they learn noise-robust representations from noisy data. Based on this common point of view, a few recent studies have investigated the interaction of adversarial training with noisy labels .\nInterestingly, it was turned out that adversarial training makes DNNs robust to label noise . Based on this finding, Damodaran et al.  proposed a new regularization term, called Wasserstein adversarial regularization, to address the problem of learning with noisy labels. Zhu et al.  proposed to use the number of projected gradient descent steps as a new criterion for sample selection such that clean examples are filtered out from noisy data. These approaches are regarded as a new perspective on label noise compared to traditional work. Therefore, understanding the connection between input perturbation and label noise could be another future topic for better representation learning toward robustness. \n}\n\\vspace*{-0.12cm}", "cites": [9127, 4164], "cite_extract_rate": 0.4, "origin_cites_number": 5, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.5, "critical": 2.5, "abstraction": 3.0}, "insight_level": "medium", "analysis": "The section synthesizes two key papers on adversarial training and label noise, highlighting a conceptual bridge between input perturbation and noisy label robustness. It abstracts the common goal of learning robust representations and introduces new approaches like Wasserstein adversarial regularization and PGD-based sample selection. However, the critical analysis is limited—there is no evaluation of the limitations or trade-offs of these approaches, nor a deeper discussion of the implications of their findings."}}
