{"id": "da501b52-1d05-4879-b017-45bbd44a3f17", "title": "Introduction", "level": "section", "subsections": [], "parent_id": "bdd5e762-3e68-4db2-9bc5-bf9a0a58e168", "prefix_titles": [["title", "Survey of Machine Learning Accelerators"], ["section", "Introduction"]], "content": "It has become apparent that researching, developing and deploying Artificial Intelligence (AI) and machine learning (ML) solutions has become a promising path to addressing the challenges of evolving events, data deluge, and rapid courses of action faced by many industries, militaries, and other organizations. Advances in the past decade in computations, data sets, and algorithms have driven many advances for machine learning and its application to many different areas. \n\\begin{figure}[th]\n    \\centering\n    \\includegraphics[width=3in]{AIarchitecture.png}\n    \\caption{Canonical AI architecture consists of sensors, data conditioning, algorithms, modern computing, robust AI, human-machine teaming, and users (missions). Each step is critical in developing end-to-end AI applications and systems.}\n    \\label{fig:architecture}\n  \\end{figure}\nAI systems bring together a number of components that must work together to effectively provide capabilities for use by decision makers, warfighters, and analysts~. \nFigure~\\ref{fig:architecture} captures this system and its components of an end-to-end AI solution. \nOn the left side of Figure~\\ref{fig:architecture}, structured and unstructured data sources provide different views of entities and/or phenomenology. \nThese raw data products are fed into a data conditioning step in which they are fused, aggregated, structured, accumulated, and converted to information. The information generated by the data conditioning step feeds into a host of supervised and unsupervised algorithms such as neural networks, which extract patterns, predict new events, fill in missing data, or look for similarities across datasets, thereby converting the input information to actionable knowledge. This actionable knowledge is then passed to human beings for decision-making processes in the human-machine teaming phase. The phase of human-machine teaming provides the users with useful and relevant insight turning knowledge into actionable intelligence or insight. \nUnderpinning this system are modern computing systems, for which Moore's law trends have ended~, as have a number of related laws and trends including Denard's scaling (power density), clock frequency, core counts, instructions per clock cycle, and instructions per Joule (Koomey's law)~. However, advancements and innovations are still progressing in the form of specialized circuits and chips that accelerate often-used operational kernels, methods, or functions.  These accelerators are designed with a different balance between performance and functional flexibility. This includes an explosion of innovation in ML processors and accelerators~. Understanding the relative benefits of these technologies is of particular importance to applying AI to domains under significant constraints such as size, weight, and power, both in embedded applications and in data centers. \nThis paper is an update to last year's IEEE-HPEC paper~. Quite a number more accelerator chips have been announced and released, and other technologies like neuromorphic architectures, memory-based analog acceleration, and computing with light are gaining attention. There are also some technology categories that were included in last year's paper that will not be included this year, namely most FPGA-based inference instances~ and smartphone accelerators. Only FPGA-based offerings that have some dynamic programmability are considered in this paper (e.g., Intel Arria, AImotive, and Microsoft Brainwave). Smartphone accelerators are not being considered this year because they cannot be used in a different platform without significant re-engineering. \nBefore getting to the accelerators, we will review a few topics pertinent to understanding the capabilities of the accelerators. We must discuss the types of neural networks for which these ML accelerators are being designed; the distinction between neural network training and inference; the numerical precision with which the neural networks are being used for training and inference, and how neuromorphic accelerators fit into the mix: \n\\begin{itemize}\n\\item Types of Neural Networks -- While AI and machine learning encompass a wide set of statistics-based technologies~, this paper continues with last year's focus on processors that are geared toward deep neural networks (DNNs) and convolutional neural networks (CNNs).  Overall, the most emphasis of computational capability for machine learning is on DNN and CNNs because they are quite computationally intensive~, and because most of the computations are dense matrix-matrix and matrix-vector multiplies, they are primed to take advantage of computational architectures that exploit data reuse, data locality, and data density. \n\\item Neural Network Training versus Inference -- As was explained in last year's survey, neural network training uses libraries of input data to converge model weight parameters by applying the labeled input data (forward projection), measuring the output predictions and then adjusting the model weight parameters to better predict output predictions (back projection).  Neural network inference is using a trained model of weight parameters and applying it to input data to receive output predictions. Processors designed for training may also perform well at inference, but the converse is not always true. \n\\item Numerical Precision -- The numerical precision with which the model weight parameters and model input data are stored and computed has an impact on the accuracy and efficiency with which networks are trained and used for inference. Generally higher numerical precision representations, particularly floating point representations, are used for training, while lower numerical precision representations, (in particular, integer representations) have been shown to be reasonably effective for inference~. However, it is still an open research question whether very limited numerical precisions like int4, int2, and int1 adequately represent model weight parameters and significantly affect model output predictions. Over the past year, more training accelerators have been released that support 16-bit floating point numbers (fp16 and bfloat16), and most inference accelerators now release performance results for 8-bit integer (int8) operands, particularly the inference accelerators geared at edge and embedded processing applications.  \n\\item Neuromorphic Computing -- The field of neuromophic computing emerged from the neuroscience field, in which researchers and engineers design circuits to model biological and physiological mechanisms in brains. Schuman's survey~ provides a rich background of all of the significant efforts in the field over the past several decades. Some of the most prominent features of neuromorphic circuits are synthetic neurons and synapses along with spiking synapse signaling, and many agree that the spiking synapse signal is the most prominent feature, especially when implemented in neural network accelerators. \nIn recent accelerators, these spiking signals are usually encoded as digital signals, e.g., IBM TrueNorth chip~, University of Manchester SpiNNaker~, and Intel's Loihi~. Another recent notable research accelerator is the Tianjic research chip~, developed by a team at Tsinghua University, which demonstrated the capability of choosing either a spiking neural network (SNN) layer or non-spiking artificial neural network (ANN) layer to instantiate each layer of a DNN model for inference. The team showed that for certain models for audio and video processing a hybrid layer-by-layer approach was most effective, both in accuracy and power consumption. Finally, a startup called Knowm is developing a new neuromorphic computational framework called AHaH Computing (Anti-Hebbian and Hebbian) based on memristor technology~. Their goal is to use this technology to dramatically reduce SWaP for machine learning applications. \n\\end{itemize}\nThere are many surveys~ and other papers that cover various aspects of AI accelerators; this paper focuses on gathering a comprehensive list of AI accelerators with their computational capability, power efficiency, and ultimately the computational effectiveness of utilizing accelerators in embedded and data center applications, as did last year's paper. Along with this focus, this paper mainly compares neural network accelerators that are useful for government and industrial sensor and data processing applications. Therefore, it will make a distinction between research accelerators and commercially available accelerators, and it will focus comparisons on the latter. Research accelerators are developed by university and industry researchers to demonstrate the art of the possible, often with the intent of influencing commercial attention to technology developments or to attract venture funding to commercialize their developed technology. But before either of these intents are realized, the demonstration of the art of the possible show us opportunities in which commercial products may pursue for improved capabilities and features.", "cites": [7633, 7632, 7629, 7630, 7631], "cite_extract_rate": 0.17857142857142858, "origin_cites_number": 28, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.0, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section synthesizes multiple cited papers to provide a coherent overview of machine learning accelerators, particularly focusing on DNNs and CNNs. It abstracts key concepts such as training vs. inference, numerical precision, and neuromorphic computing, placing them in a broader context of modern computing limitations and innovations. While it offers some critical remarks, such as noting the open research question around low numerical precision, the analysis is more focused on explanation than deep critique."}}
{"id": "98bfa4d1-0dae-4237-b04f-67a312fa4d18", "title": "Survey of Processors", "level": "section", "subsections": ["76bb1123-ef5f-4172-8763-1159521e75fc", "119cadbf-0fd5-4c79-839e-2a9a574aee6e", "d1fce379-9b26-4715-b65b-aeb8d67c41f0", "dc851290-d627-43d2-96aa-eb3b66407447", "1a0bfe4c-ec20-46c3-9d84-ac6b4ebdf80a", "774764f9-5ef7-4467-83c6-1ddc41074169"], "parent_id": "bdd5e762-3e68-4db2-9bc5-bf9a0a58e168", "prefix_titles": [["title", "Survey of Machine Learning Accelerators"], ["section", "Survey of Processors"]], "content": "Many recent advances in AI can be at least partly credited to advances in computing hardware~, enabling computationally heavy machine-learning algorithms such as neural networks. This survey gathers performance and power information from publicly available materials including research papers, technical trade press, company benchmarks, etc. While there are ways to access information from companies and startups (including those in their silent period), this information is intentionally left out of this survey; such data will be included in this survey when it becomes publicly available. The key metrics of this public data are plotted in Figure~\\ref{fig:PeakPerformancePower}, which graphs recent processor capabilities (as of June 2020) mapping peak performance vs. power consumption. \nThe x-axis indicates peak power, and the y-axis indicate peak giga-operations per second (GOps/s). Note the legend on the right, which indicates various parameters used to differentiate computing techniques and technologies. The computational precision of the processing capability is depicted by the geometric shape used; the computational precision spans from analog and single-bit int1 to four-byte int32 and two-byte fp16 to eight-byte fp64. The precisions that show two types denotes the precision of the multiplication operations on the left and the precision of the accumulate/addition operations on the right (for example, fp16.32 corresponds to fp16 for multiplication and fp32 for accumulate/add). The form factor is depicted by  color; this is important for showing how much power is consumed, but also how much computation can be packed onto a single chip, a single PCI card, and a full system. Blue corresponds to a single chip; orange corresponds to a card (note that they all are in the 200-300 Watt zone); and green corresponds to entire systems (single node desktop and server systems). This survey is limited to single motherboard, single memory-space systems. Finally, the hollow geometric objects are peak performance for inference-only accelerators, while the solid geometric figures are performance for accelerators that are designed to perform both training and inference. \n\\begin{figure*}[htb]\n    \\includegraphics[width=\\textwidth]{2020-08-31_AI_Accelerators-AReuther-r3-ellipses.pdf}\n    \\caption{Peak performance vs. power scatter plot of publicly announced AI accelerators and processors.}\n    \\label{fig:PeakPerformancePower}\n  \\end{figure*}\nWe can make some general observations from Figure~\\ref{fig:PeakPerformancePower}. First, quite a number of new accelerator chips, cards, and systems have been announced and released in the past year. Each of the five categories have a higher density of entries from last year, and there is a greater diversity of underlying architectures and technologies with which these accelerators have been developed as you will notice in the descriptions below. Also, many more recent accelerators have broken through the 1 TeraOps/W boundary for peak performance. \nAn observation that has not changed from last year is that at least 100W must be employed to perform training; almost all of the points on the scatter plot below 100W are inference-only processors/accelerators. (Cornami is the one exception, but their plot point is based on simulation estimates.) It is generally understood that training requires floating point precision which requires more capable and power-consuming ALUs, datapaths, memories, etc.  \nWhen it comes to precision, there is an even wider variety of numerical precisions for which peak performance numbers have been released. There continues to be exploration about how much precision is necessary for neural networks to perform well even when using limited or mixed precision representation of activation functions, weights, and biases~. \nFinally, a reasonable categorization of accelerators follows their intended application, and the five categories are shown as ellipses on the graph, which roughly correspond to performance and power consumption: Very Low Power for speech processing, very small sensors, etc.; Embedded for cameras, small UAVs and robots, etc.; Autonomous for driver assist services, autonomous driving, and autonomous robots; Data Center Chips and Cards; and Data Center Systems. In the following listings, the angle-bracketed string is the label of the item on the scatter plot, and the square bracket after the angle bracket is the literature reference from which the performance and power values came. A few of the performance values are reported in frames per second (fps) with a given machine learning model. For translating fps values to performance values, Samuel Albanie's Matlab code and a web site of all of the major machine learning models with their operations per epoch/inference, parameter memory, feature memory, and input size~ were used.", "cites": [7198], "cite_extract_rate": 0.2, "origin_cites_number": 5, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.0, "critical": 2.5, "abstraction": 3.5}, "insight_level": "medium", "analysis": "The section synthesizes information from cited papers and public sources to provide a structured overview of AI accelerators, particularly linking the discussion of numerical precision to its impact on training and inference. It abstracts key trends, such as the 1 TeraOps/W performance threshold and the relationship between power consumption and training capability. However, critical analysis is limitedâ€”while it mentions observations, it does not deeply evaluate the strengths or limitations of the cited works or their claims."}}
{"id": "76bb1123-ef5f-4172-8763-1159521e75fc", "title": "Research Chips", "level": "subsection", "subsections": [], "parent_id": "98bfa4d1-0dae-4237-b04f-67a312fa4d18", "prefix_titles": [["title", "Survey of Machine Learning Accelerators"], ["section", "Survey of Processors"], ["subsection", "Research Chips"]], "content": "Many research papers have been published that have introduced, evaluated, and compared various architectural elements, organizations, and technologies. The following list contains just a fraction of the research chips, but most of these have been highly cited. And, they have performance and power numbers. \n\\begin{itemize}\n\\item The NeuFlow chip $\\langle$NeuFlow$\\rangle$~ was a project between IBM, New York University and Yale University to explore architectures for efficient edge inference. It was designed with dataflow processing tiles comprised of a matrix multiplier and convolver in a 2-dimensional grid. \n\\item The Stanford-designed energy efficient inference engine (EIE) $\\langle$EIE$\\rangle$~ demonstrated the use of sparsity in DNN with compressed neural network models, weight sharing, and on-chip SRAM utilization to design an extremely efficent inference chip. \n\\item Another Stanford chip, the TETRIS $\\langle$TETRIS$\\rangle$~, demonstrated highly efficient inference by using 3-dimensional memory and a partitioning scheme that placed weights and data close to their processing elements. This allowed the team to use more chip area for computation than local SRAM memory. \n\\item MIT Eyeriss chip $\\langle$Eyeriss$\\rangle$~ is a research chip from Vivienne Sze's group in MIT CSAIL. Their goal was to develop the most energy efficient inference chip possible by experimenting with different circuit computation trade-offs. The reported result was acquired running AlexNet with no mention of batch size. \n\\item The DianNao series of dataflow research chips came from a university research team primarily at the Institute of Computing Technology of the Chinese Academy of Sciences (IST-CAS); this team overlaps with the Cambricon company, which has released several chips as well as the Kirin accelerator that is included in the Huawei smartphone system-on-chip (SoC). They published four different designs aimed at different types of ML processing~. The DianNao $\\langle$DianNao$\\rangle$~ is a neural network inference accelerator, and the DaDianNao $\\langle$DaDianNao$\\rangle$~ is a many-tile version of the DianNao for larger NN model inference. The ShiDianNao $\\langle$ShiDianNao$\\rangle$~ is designed specifically for convolutional neural network inference. Finally, the PuDianNao $\\langle$PuDianNao$\\rangle$~ is designed for seven representative machine learning techniques: k-means, k-NN, na\\\"ive Bayes, support vector machines, linear regression, classification tree, and deep neural networks. \n\\item The TrueNorth $\\langle$TrueNorth$\\rangle$~ is a digital neuromorphic research chip from the IBM Almaden research lab. It was developed under DARPA funding in the Synapse program to demonstrate the efficacy of digital spiking neural network (neuromorphic) chips. Note that there are points on the graph for both the system, which draws the 44 W power, and the chip, which itself only draws up to 275 mW. The TrueNorth has inspired several companies to develop and release neuromorphic chips. \n\\end{itemize}", "cites": [7631, 7634, 7633], "cite_extract_rate": 0.23076923076923078, "origin_cites_number": 13, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 1.5, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section provides a factual list of research chips with brief descriptions and mentions their goals and techniques, but it does not meaningfully synthesize or integrate the ideas across cited works. There is minimal critical analysis or comparison, and no broader abstraction or meta-level insights are drawn about trends or principles in ML accelerator research."}}
{"id": "7b79321c-4291-4026-8ea5-8b2b4a78d637", "title": "FPGA-based Accelerators", "level": "subsubsection", "subsections": [], "parent_id": "1a0bfe4c-ec20-46c3-9d84-ac6b4ebdf80a", "prefix_titles": [["title", "Survey of Machine Learning Accelerators"], ["section", "Survey of Processors"], ["subsection", "Data Center Chips and Cards"], ["subsubsection", "FPGA-based Accelerators"]], "content": "\\begin{itemize}\n\\item The Intel Arria solution pairs an Intel Xeon CPU with an Altera Arria FPGA $\\langle$Arria$\\rangle$~. The CPU is used to rapidly download FPGA hardware configurations to the Arria, and then farms out the operations to the Arria for processing certain key kernels. Since inference models do not change, this technique is well geared toward this CPU-FPGA processing paradigm. However, it would be more challenging to farm ML model training out to the FPGAs. Since it is an FPGA, the peak performance is equal to the performance the DNN model, the performance peak is reported for using GoogLeNet which ran at 900 fps. \n\\item The Bittware/Achronix VectorPath S7t-VG6 accelerator $\\langle$Achronix$\\rangle$~ is a FPGA-based processor on a PCI Express card. The FPGA includes eight banks of GDDR6 memory, a 2000GbE and a 4000GbE network interfaces, and 40,000 int8 multiply-accumulate units. \n\\item Cornami has been developing a reconfigurable AI chip based on FPGA technology. Their FPGA-based prototype posted impressive performance in fp16 precision~, but their ASIC has not yet taped out. \n\\item The Flex Logix InferX X1 eFPGA/DSP accelerator card $\\langle$FlexLogix$\\rangle$~ targets both signal processing and machine learning markets and supports int8, int16, Bfloat16 and fp16 precisions. It has 4,000 multiply-accumulate units and is programmable by TensorFlow Lite and ONNX.\n\\item The Microsoft Brainwave project $\\langle$Brainwave$\\rangle$~ is a programmable Intel Stratix 10 280 FPGA that was deployed as part of the Catapult project~. It is intended for re-programmable inference processing. \n\\end{itemize}", "cites": [7635], "cite_extract_rate": 0.14285714285714285, "origin_cites_number": 7, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 1.5, "abstraction": 1.5}, "insight_level": "low", "analysis": "The section provides a descriptive overview of various FPGA-based accelerators, listing their features and use cases without substantial synthesis across cited works. It includes only minimal integration of the cited paper, and lacks critical evaluation or abstraction to identify broader trends or principles in FPGA-based machine learning acceleration."}}
