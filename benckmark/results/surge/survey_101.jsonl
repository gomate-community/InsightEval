{"id": "c3d164ea-0fac-49d9-820a-43318a641edc", "title": "Introduction", "level": "section", "subsections": [], "parent_id": "59d19c15-d2fe-4919-9357-dccad053bdfa", "prefix_titles": [["title", "DL-Traff: Survey and Benchmark of Deep Learning Models for Urban Traffic Prediction"], ["section", "Introduction"]], "content": "Nowadays, with the rapid development of IoT (Internet of Things) and CPS (Cyber-Physical Systems) technologies, big spatiotemporal data are being generated from mobile phones, car navigation systems, and traffic sensors. Based on such data, urban traffic prediction has been taken as a significant research problem and a key technique for building smart city, especially intelligent transportation system. From 2014 to 2017, encouraged by the huge success of deep learning technologies in the Computer Vision and Natural Language Processing field, researchers in the Intelligent Transportation System community, started to apply Long-Term Short Memory (LSTM) and Convolution Neural Network (CNN) to the well-established traffic prediction task, and also achieved an unprecedented success. Following these pioneers, researchers have leveraged the state-of-the-art deep learning technologies to develop various prediction models and publish a big amount of studies on the major AI and transportation venues as listed in Table \\ref{tab:modelsummary}. Although the prediction tasks may slightly differ from each other, they can all be categorized as deep traffic models.\n\\begin{figure}[h]\n\t\\centering\t\n\t\\includegraphics[width=0.45\\textwidth]{./figure/problem.png}\n\t\\caption{Grid-Based Traffic and Graph-Based Traffic.}\n\t\\label{fig:intro}\n\\end{figure}\nNo matter based on grid or graph, the traffic data illustrated in Fig.\\ref{fig:intro} can be uniformly represented with a 3D tensor $\\mathbb{R}^{T\\times N \\times C}$, where T denotes the size of the temporal domain (i.e., timeslots with constant sampling rate), N denotes the size of the spatial domain (i.e., mesh-grids or graph-nodes), and C denotes the number of information channels. For instance, assuming 300 traffic sensors are deployed to record traffic speed (channel1) and volume (channel2) every 30 minutes for 100 consecutive days, then the total data can be represented by tensor $\\mathbb{R}^{4800\\times 300 \\times 2}$. Besides traffic volume and speed, channels can also be used to store crowd density, taxi demand, traffic accident, car/ride-hailing order, and crowd/taxi/bike inflow and outflow. More specifically, grid-based model meshes the entire spatial domain into $H\\times W$ fine-grained mesh-grids and converts the 3D representation into 4D tensor $\\mathbb{R}^{T\\times H\\times W\\times C}$ format. Graph-based model introduces directed or undirected graph $G$ = $(V,E)$ to utilize the topological structure of the urban road network for modeling, where $v\\in V$ is a node, $|V|$ = $N$, and $e\\in E$ is an edge. Multivariate time-series model naturally takes the N spatial units as N time-series variates and shares the same representation, i.e., $\\mathbb{R}^{T\\times N \\times C}$ with graph-based model. Thus, the deep learning models listed in Table \\ref{tab:modelsummary} can be divided into three groups according to the specific modeling strategy along the spatial axis.\nThrough the citation number in Table \\ref{tab:modelsummary}, we can know how much attention these studies have drawn in our AI and data science community. But due to the huge amount of the related works, researchers are often too exhausted to follow up with the specific details of each model. More importantly, the evaluations on this family of models are still confusing and not well organized. For instance, some models demonstrated superior performances to the existing ones by using different datasets or metrics as shown in Table \\ref{tab:modelsummary}, while some models utilized a self-designed objective function or employed extra data sources such as Point-of-Interest (POI) data  or navigation app data  to achieve better prediction accuracy. To address the problems above, a concise but precise survey will be a great help for researchers involved in this emerging topic. But only a survey is not enough. It is also significant to conduct standard performance evaluations to examine the true function of each spatial and temporal component by using the same datasets, metrics, and other experimental settings. This paper fills these needs by providing a concise survey followed by a comprehensive benchmark evaluation on the recent deep traffic models. \nWe first define two benchmark tasks in Section 2, one is single-step prediction for inflow and outflow based on grid-based traffic data, another is multi-step prediction for traffic speed based on graph-based data. Second, in Section 3, we investigate both of the grid-based and graph-based datasets and pick up some open and widely used ones as our benchmark data including TaxiBJ, BikeNYC, TaxiNYC, METR-LA, PeMS-BAY, and PeMSD7M. Next, in Section 4, we decompose the models into spatial and temporal units and give the roadmap that how the models evolve along the spatial and temporal axis. Further, we draw the architectures for a bunch of representative models (e.g., ST-ResNet, DMVST-Net, STDN, DeepSTN+, STGCN, DCRNN, Graph WaveNet) in an intuitive and comparative manner. Then, in Section 5, we do a comprehensive evaluation on both the grid-based and graph-based models by using the benchmark tasks and datasets under the same settings and metrics (RMSE, MAE, MAPE). In Section 6, we briefly introduce the implementation details, the availability, and the usability of our benchmark. Finally, we give our conclusion in Section 7. \nThe contributions of our work are summarized as follows:\n\\begin{itemize}\n\\item We give a concise but concrete survey on the recent deep traffic models. The technique detail and the evolution are clearly summarized along spatial and temporal axes.\n\\item We carefully select two traffic flow prediction tasks, four grid-based traffic datasets, and three graph-based traffic datasets, and implement plenty of grid/graph-based state-of-the-arts to form a complete benchmark called \\textbf{DL-Traff}.\n\\item On this benchmark, we conduct a comprehensive evaluation of the effectiveness and efficiency performances of the-state-of-the-arts.\n\\item Our benchmark is implemented with the two most popular deep learning frameworks, i.e., TensorFlow and PyTorch. \\textbf{DL-Traff} is already publicly available as two GitHub repositories \\url{https://github.com/deepkashiwa20/DL-Traff-Grid} and \\url{https://github.com/deepkashiwa20/DL-Traff-Graph}.\n\\end{itemize}\nWith DL-Traff, (1) users can quickly grasp the technical details about the state-of-the-art deep spatiotemporal models; (2) users can smoothly reproduce the prediction results reported in this paper and use them as the baselines; (3) users can easily launch a new deep solution with either TensorFlow or PyTorch for not only traffic flow prediction tasks, but also for other spatiotemporal problems such as anomaly/accident, electricity consumption, air quality, etc.", "cites": [22, 24, 23, 21, 8312, 25], "cite_extract_rate": 0.5, "origin_cites_number": 12, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.0, "critical": 2.5, "abstraction": 3.5}, "insight_level": "medium", "analysis": "The introduction synthesizes key ideas from the cited papers by identifying common modeling strategies (grid, graph, multivariate time-series) and unifying them under a 3D tensor representation. It abstracts these works into broader categories and highlights their evolution. However, the critical analysis is limited to pointing out methodological inconsistencies in evaluations, rather than deeply evaluating the strengths and weaknesses of individual approaches or their theoretical foundations."}}
{"id": "db39650d-72d6-4e23-b522-8eaf2152ba44", "title": "Problem", "level": "section", "subsections": [], "parent_id": "59d19c15-d2fe-4919-9357-dccad053bdfa", "prefix_titles": [["title", "DL-Traff: Survey and Benchmark of Deep Learning Models for Urban Traffic Prediction"], ["section", "Problem"]], "content": "In this paper, we employ the following two prediction tasks into our benchmark. \n\\begin{enumerate}\n    \\item Grid-based inflow and outflow prediction proposed by. The problem is to predict how many taxis/bikes will flow into or out from each mesh-grid in the next time interval. It takes $\\alpha$ steps of historical observations as input and gives the next step prediction as follows: [$X_{t-(\\alpha-1)}$,...,$X_{t-1}$,$X_{t}$] $\\rightarrow$ $X_{t+1}$, where $X_i$ $\\in$ $\\mathbb{R}^{H\\times W\\times C}$, $H,W$ are the indexes for the mesh, and C is equal to 2, respectively used for inflow and outflow.\n    \\item Graph-based traffic speed prediction as defined in . In order to make a variation to the first task, we define this task as multi-step-to-multi-step one as follows: [$X_{t-(\\alpha-1)}$,...,$X_{t-1}$,$X_{t}$] $\\rightarrow$ [$X_{t+1}$,$X_{t+2}$,...,$X_{t+\\beta}$], where $X_i$ $\\in$ $\\mathbb{R}^{N\\times C}$, $\\alpha$/$\\beta$ is the number of steps of observations/predictions, $N$ is the number of traffic sensors (i.e., nodes), and $C$ is equal to 1 that only stores the traffic speed.\n\\end{enumerate}\n\\begin{table*}[t]\n    \\small\n\t\\centering\n\t\\caption{Summary of The Public Traffic Datasets}\n\t\\label{tab:datasummary}\n\t\\begin{tabular*}{17.7cm}{@{\\extracolsep{\\fill}}l|l|l|l|l|l}\n\t\t\\hline\n\t\t\\textbf{Grid-Based} & \\textbf{Reference} & \\textbf{Data Description / Data Source} & \\textbf{Spatial Domain} & \\textbf{Time Period} & \\textbf{Time Interval}\\\\\n\t\t\\hline\n\t\t\\multirow{2}{*}{TaxiBJ*}&  & \\multirow{2}{*}{Taxi In-Out Flow / Taxi GPS Data of Beijing} & \\multirow{2}{*}{32$\\times$32 grids} & 2013/7/1$\\sim$2016/4/10 & \\multirow{2}{*}{30 minutes}\\\\\n\t\t&  & & & *Four Time Periods & \\\\\n\t\t\\hline\n\t\tTaxiBJ-I* & & Taxi In-Out Flow / Taxi GPS Data of Beijing (TDrive) & 32$\\times$32 grids & 2015/2/1$\\sim$2015/6/2 & 60 minutes\\\\\n\t\t\\hline\n\t\t\\multirow{2}{*}{BikeNYC*} & \\multirow{2}{*}{} & Bike In-Out Flow / Bike Trip Data of New York City  & \\multirow{2}{*}{16$\\times$8 grids} & \\multirow{2}{*}{2014/4/1$\\sim$2014/9/30} & \\multirow{2}{*}{60 minutes}\\\\\n\t\t& & Citi Bike: \\url{https://www.citibikenyc.com/system-data} && \\\\\n\t\t\\hline\n\t\tBikeNYC-I* &  & Bike In-Out Flow / Bike Trip Data of New York City & 21$\\times$12 grids & 2014/4/1$\\sim$2014/9/30 & 60 minutes \\\\\n\t\t\\hline\n\t\tBikeNYC-II* &  & Bike In-Out Flow / Bike Trip Data of New York City & 10$\\times$20 grids & 2016/7/1$\\sim$2016/8/29 & 30 minutes\\\\\n\t\t\\hline\n\t\t\\multirow{3}{*}{TaxiNYC*} & \\multirow{3}{*}{} & Taxi In-Out Flow / Taxi Trip Data of New York City & \\multirow{3}{*}{10$\\times$20 grids} & \\multirow{3}{*}{2015/1/1$\\sim$2015/3/1} & \\multirow{3}{*}{30 minutes}\\\\\n\t\t&& The New York City Taxi\\&Limousine Commission && \\\\\n\t\t&& (TLC) \\url{https://www1.nyc.gov/site/tlc/about/data.page} && \\\\\n\t\t\\toprule\n\t\t\\hline\n\t\t\\textbf{Graph-Based} & \\textbf{Reference} & \\textbf{Data Description / Data Source} & \\textbf{Spatial Domain} & \\textbf{Time Period} & \\textbf{Time Interval}\\\\\n\t\t\\hline\n\t\t\\multirow{4}{*}{METR-LA*}\n\t\t& &\n\t\tTraffic Speed Sensors in Los Angeles County & \\multirow{4}{*}{207 sensors} & \\multirow{4}{*}{2012/3/1$\\sim$2012/6/30} & \\multirow{4}{*}{5 minutes}\\\\\n\t\t&& Los Angeles Metropolitan Transportation Authority& & &\\\\\n\t\t&& *Collaborated with University of Southern California& & &\\\\\n\t\t&& \\url{https://imsc.usc.edu/platforms/transdec/} & & &\\\\\n\t\t\\hline\n\t\t\\multirow{3}{*}{PeMS-BAY*} &  & Traffic Speed Sensors in California & \\multirow{3}{*}{325 sensors} & \\multirow{3}{*}{2017/1/1$\\sim$2017/5/31} & \\multirow{3}{*}{5 minutes}\\\\\n\t\t&& Caltrans Performance Measurement System (PeMS) & &\\\\\n\t\t&& PeMS: \\url{http://pems.dot.ca.gov/} & & &\\\\\n\t\t\\hline\n\t\tPeMSD7(M)* &  & Traffic Speed Sensors in California (PeMS) & 228 sensors& 2012/5/1$\\sim$2012/6/30 & 5 minutes\\\\\n\t\tPeMS03* & & Traffic Speed Sensors in California (PeMS) & 358 sensors & 2018/9/1$\\sim$2018/11/30& 5 minutes\\\\\n\t\tPeMSD4(PeMS04)* & & Traffic Speed Sensors in California (PeMS) & 307 sensors & 2018/1/1$\\sim$2018/2/28& 5 minutes\\\\\n\t\tPeMS07* & & Traffic Speed Sensors in California (PeMS) & 883 sensors & 2017/5/1$\\sim$2017/8/31& 5 minutes\\\\\n\t\tPeMSD8(PeMS08)* & & Traffic Speed Sensors in California (PeMS) & 170 sensors & 2016/7/1$\\sim$2016/8/31& 5 minutes\\\\\n\t\tPeMSD4-I* & & Traffic Speed Sensors in California (PeMS) & 3848 sensors & 2018/1/1$\\sim$2018/2/28 & 5 minutes\\\\\n\t\tPeMSD8-I* & & Traffic Speed Sensors in California (PeMS) & 1979 sensors & 2016/7/1$\\sim$2016/8/31& 5  minutes\\\\\n\t\tPeMSD10* & & Traffic Speed Sensors in California (PeMS) &  608 sensors &2018/1/1$\\sim$2018/3/31& 15 minutes\\\\\n\t\tTraffic(PeMS)* & & Traffic Speed Sensors in California (PeMS) & 862 sensors & 2015/1/1$\\sim$2016/12/31& 60 minutes\\\\\n\t\t\\hline\n\t\tLOOP-SEATTLE* & & Traffic Speed Sensors in Greater Seattle Area & 323 sensors & 2015/1/1$\\sim$2015/12/31& 5 minutes\\\\\n\t\t\\hline\n\t\tTaxiSZ* & & Taxi Speed on Roads / Taxi GPS Data of Shenzhen & 156 roads & 2015/1/1$\\sim$2015/1/31 & 15 minutes \\\\\n\t\t\\hline\n\t\t\\multirow{2}{*}{HZJTD*} & \\multirow{2}{*}{} & Traffic Speed Sensors in Hangzhou & \\multirow{2}{*}{202 sensors} & \\multirow{2}{*}{2013/10/16$\\sim$2014/10/3} & \\multirow{2}{*}{15 minutes}\\\\\n\t\t& & Hangzhou Integrated Transportation Research Center & &\\\\\n\t\t\\toprule\n\t\\end{tabular*}\n\\end{table*}", "cites": [24, 31, 27, 30, 33, 29, 28, 21, 26, 8312, 25, 23, 34, 32], "cite_extract_rate": 0.5833333333333334, "origin_cites_number": 24, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 1.5, "abstraction": 1.5}, "insight_level": "low", "analysis": "The section primarily describes two traffic prediction tasks and provides a detailed table of datasets without synthesizing insights from the cited papers. It lacks critical evaluation or comparison of the methods and does not abstract broader patterns or principles from the literature."}}
{"id": "1e1d840c-dfcc-4de8-b328-03ffae66ed07", "title": "Grid-Based Traffic Dataset", "level": "subsection", "subsections": [], "parent_id": "86e2ba0d-2f46-4b09-9dfc-24ff62f7ac9c", "prefix_titles": [["title", "DL-Traff: Survey and Benchmark of Deep Learning Models for Urban Traffic Prediction"], ["section", "Dataset"], ["subsection", "Grid-Based Traffic Dataset"]], "content": "\\noindent\\textbf{TaxiBJ.} This is taxi in-out flow data published by , created from the taxicab GPS data in Beijing from four separate time periods: 2013/7/1-2013/10/30, 2014/3/1-2014/6/30, 2015/3/1-2015/6/30, and 2015/11/1-2016/4/10. Based on the same underlying taxi GPS data (T-Drive), a similar dataset denoted as TaxiBJ-I is created by .\n\\noindent\\textbf{BikeNYC.} This is bike in-out flow data of New York City from 2014/4/1 to 2014/9/30 used by . The original bike trip data is published by Citi Bike, NYC's official bike-sharing system, which includes: trip duration, starting and ending station IDs, and start and end times. Similar datasets \\textbf{BikeNYC-I}, \\textbf{BikeNYC-II} were used by  and  respectively. These two will be used in our experiment due to the larger spatial domain.\n\\noindent\\textbf{TaxiNYC.} This is taxi in-out flow data of New York City from 2015/1/1~2015/3/1 used by . The original taxi trip data is published by the New York City Taxi and Limousine Commission (TLC), that includes pick-up and drop-off dates/times, pick-up and drop-off locations, trip distances, itemized fares, driver-reported passenger counts, etc.", "cites": [21, 24], "cite_extract_rate": 0.5, "origin_cites_number": 4, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 1.5, "abstraction": 1.5}, "insight_level": "low", "analysis": "The section provides a factual description of grid-based traffic datasets without substantial synthesis of concepts or integration with the cited papers' contributions. It lacks critical evaluation of the papers and does not abstract broader trends or principles from the datasets or the associated works. The content is primarily a listing of datasets and their sources."}}
{"id": "1c054657-e289-43fb-bf15-a3497000fd76", "title": "Graph-Based Traffic Dataset", "level": "subsection", "subsections": [], "parent_id": "86e2ba0d-2f46-4b09-9dfc-24ff62f7ac9c", "prefix_titles": [["title", "DL-Traff: Survey and Benchmark of Deep Learning Models for Urban Traffic Prediction"], ["section", "Dataset"], ["subsection", "Graph-Based Traffic Dataset"]], "content": "\\noindent\\textbf{METR-LA.} This is a Los Angeles traffic data published by . The data are collected from 207 highway sensors within 4 months from 2012/3/1 to 2012/6/30. A quite number of studies used this dataset as shown in Table \\ref{tab:datasummary}. To be intuitive, a data visualization has been made as Fig.\\ref{fig:dataset_one}.\n\\noindent\\textbf{PeMS-BAY.} This is a traffic flow dataset collected from California Transportation Agencies Performance Measurement System (PeMS). It contains 325 traffic sensors in the Bay Area from 2017/1/1 to 2017/5/31. Massive studies also generate a variety of PeMS datasets by using the same source. \n\\noindent\\textbf{PeMSD7M.} This traffic dataset is created and published by , also collected from PeMS. It covers 228 traffic sensors lasting from 2012/5/1 to 2012/6/30 with a 5-minute sampling rate on weekdays.\n\\noindent\\textbf{Summary.} The taxi and bike trip data published by Citi Bike and TLC of New York City and the traffic sensor data from PeMS of California are taken as three trustworthy and wildly-used data sources for traffic prediction. Researchers can easily access the data through the URLs listed in Table \\ref{tab:datasummary}. \n\\begin{table*}[t]\n    \\small\n\t\\centering\n\t\\caption{Base Technologies Employed for Spatial and Temporal Modeling}\n\t\\label{tab:basetechnology}\n\t\\begin{tabular*}{17.8cm}{@{\\extracolsep{\\fill}}l|lll|llll|l|lll|llll}\n\t\t\\hline\n\t\t& \\multicolumn{3}{c|}{Spatial Axis} & \\multicolumn{4}{c|}{Temporal Axis} & & \\multicolumn{3}{c|}{Spatial Axis} & \\multicolumn{4}{c}{Temporal Axis}\\\\\n\t\t\\hline\n\t\tmodels & CNN & GCN & Attn. & LSTM & GRU & TCN & Attn. & models & CNN & GCN & Attn. & LSTM & GRU & TCN & Attn. \\\\\n\t\t\\hline\n\t\tST-ResNet & \\checkmark &&&&&&& STGCN & & \\checkmark & & & & \\checkmark & \\\\ \n\t\tDMVST-Net & \\checkmark &&& \\checkmark &&&& GaAN(GGRU) & & \\checkmark&\\checkmark &&\\checkmark &&\\\\\n\t\tSTDN & \\checkmark &&& \\checkmark &&& \\checkmark & DCRNN(GCGRU) & &\\checkmark &&& \\checkmark && \\\\\n\t\tDeepSTN+ & \\checkmark &&&&&& & Multi-graph &&\\checkmark&&\\checkmark&&&\\\\\n\t\tLSTNet & \\checkmark & & & & \\checkmark & \\checkmark& \\checkmark & ASTGCN && \\checkmark &\\checkmark &&&&\\checkmark \\\\\n\t\tGeoMAN & & &\\checkmark &\\checkmark & & &\\checkmark & TGCN && \\checkmark &&&\\checkmark&&\\\\\n\t\tTPA-LSTM &&& & \\checkmark & & \\checkmark &\\checkmark & Graph WaveNet && \\checkmark &&&& \\checkmark &\\\\\n\t\tTransformer &&& & & & &\\checkmark & MTGNN && \\checkmark &&&& \\checkmark &\\\\\n\t\tST-MetaNet &&&\\checkmark &&\\checkmark&&& STGNN &&\\checkmark &\\checkmark &&\\checkmark&&\\checkmark\\\\\n\t\tGMAN &&&\\checkmark &&&&\\checkmark &AGCRN & &\\checkmark &&& \\checkmark & &\\\\\n\t\t\\hline\n\t\\end{tabular*}\n\\end{table*}", "cites": [24, 31, 35, 27, 22, 29, 33, 28, 21, 8312, 25, 23, 34, 36, 32], "cite_extract_rate": 0.75, "origin_cites_number": 20, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 1.5, "abstraction": 1.5}, "insight_level": "low", "analysis": "The section primarily describes various graph-based traffic datasets without synthesizing insights from the cited papers. It lacks critical evaluation of their strengths, weaknesses, or comparative performance. Additionally, it fails to generalize or abstract broader trends in graph-based data modeling for traffic prediction."}}
{"id": "23050b21-5fab-45c0-9c6c-dd4a43d7184b", "title": "Model", "level": "section", "subsections": ["f9c25975-edd8-4784-bcd1-0b0a149168bc", "f509b7e2-496e-42c4-8c44-c0803a49aa44"], "parent_id": "59d19c15-d2fe-4919-9357-dccad053bdfa", "prefix_titles": [["title", "DL-Traff: Survey and Benchmark of Deep Learning Models for Urban Traffic Prediction"], ["section", "Model"]], "content": "Complex spatial and temporal dependencies are the key challenges in urban traffic prediction tasks.\nTemporally, future prediction depends on the recent observations as well as the past periodical patterns; Spatially, the traffic states in certain mesh-grid or graph-node are affected by the nearby ones as well as distant ones. To capture the temporal dependency, LSTM and its simplified variant GRU are respectively utilized by the models as shown in Table \\ref{tab:basetechnology}. In parallel with the RNNs, 1D CNN and its enhanced version TCN  are also employed as the core technology for temporal modeling, and demonstrate the superior time efficiency and matchable effectiveness to LSTM and GRU. \nOn the other hand, to capture the spatial dependency, grid-based models simply use the normal convolution operation thanks to the natural euclidean property of grid spacing; graph-based models leverage the graph convolution in non-euclidean space  by involving the adjacency relation $A\\in$ $\\mathbb{R}^{N*N}$ between each pair of spatial units. Meanwhile, attention mechanism also known as Transformer has rapidly taken over the AI community from natural language (GPT-3) to vision since 2020. Thus, attention is also introduced as base technology for modeling both spatial and temporal dependencies. \nWe select the most representative models in Table \\ref{tab:modelsummary} and summarize the base technologies employed by each model for spatial and temporal modeling as Table \\ref{tab:basetechnology}. On the other hand, for better understanding, we simplify and plot the network architectures in a unified manner for five grid-based models including\nST-ResNet, DMVST-Net, Periodic-CRN(PCRN), STDN, and DeepSTN+ as Fig.\\ref{fig:architectures}, and five graph-based models, namely STGCN, DCRNN, Graph WaveNet, ASTGCN, and GMAN as Fig.\\ref{fig:architectures1}. Through Fig.\\ref{fig:architectures}$\\sim$\\ref{fig:architectures1}, we can easily understand how the spatial and temporal modules listed in Table \\ref{tab:basetechnology} are assembled to form an integrated model. \nMoreover, we describe how the employed technologies are evolving along the spatial and temporal axis for both grid-based and graph-based models in the next two subsections. Note that the multivariate time-series (MTS) models such as LSTNet, TPA-LSTM, GeoMAN, and Transformer are also gradually evolving along the spatial and temporal axis. From the spatial perspective, they focus on correlation/dependence between variates; from the temporal perspective, they aim to utilize the periodic patterns occurred in time series. But due to space limitations, we don't expand the details of those MTS models in this paper.", "cites": [24, 8313, 31, 35, 37, 38, 22, 21, 8312, 25, 23, 39, 34, 32], "cite_extract_rate": 0.6666666666666666, "origin_cites_number": 21, "insight_result": {"type": "descriptive", "scores": {"synthesis": 3.0, "critical": 2.0, "abstraction": 2.5}, "insight_level": "medium", "analysis": "The section provides a descriptive overview of how different deep learning models approach spatial and temporal modeling in urban traffic prediction. It synthesizes information by grouping models into categories (grid-based, graph-based, MTS) and describing the technologies they use (e.g., LSTM, GRU, CNN, attention). However, it lacks in-depth critical evaluation of the cited papers and does not offer a nuanced critique or comparison of their strengths and weaknesses. The abstraction level is limited to identifying basic modeling strategies without presenting overarching principles or meta-level insights."}}
{"id": "f9c25975-edd8-4784-bcd1-0b0a149168bc", "title": "Roadmap for Grid-Based Model", "level": "subsection", "subsections": [], "parent_id": "23050b21-5fab-45c0-9c6c-dd4a43d7184b", "prefix_titles": [["title", "DL-Traff: Survey and Benchmark of Deep Learning Models for Urban Traffic Prediction"], ["section", "Model"], ["subsection", "Roadmap for Grid-Based Model"]], "content": "ST-ResNet is the earliest and the most representative grid-based deep learning method for traffic in-out flow prediction. It converts 4D tensor ($T$,$H$,$W$,$C$) into 3D tensor ($H$,$W$,$T$*$C$) by concatenating the channels at each time step so that CNN can be used to capture spatial dependency similarly to an image. Then, it creatively proposes a set of temporal features called $Closeness$, $Period$, and $Trend$, which correspond to \\emph{the most recent observations}, \\emph{daily periodicity}, and \\emph{weekly trend} respectively. Intuitively, the three parts of the features can be represented by:\n$X^{Closeness}$ = [$X_{t-l_c}$, $X_{t-(l_c-1)}$, ..., $X_{t-1}$]\n$X^{Period}$ = [$X_{t-l_p \\times s_p}$, $X_{t-(l_p-1) \\times s_p}$, ..., $X_{t-s_p}$]\n$X^{Trend}$ = [$X_{t-l_q \\times s_q}$, $X_{t-(l_q-1) \\times s_q}$, ..., $X_{t-s_q}$]\n\\noindent where $l_c$, $l_p$, $l_q$ are the sequence length of \\{$Closeness$, $Period$, $Trend$\\}, $s_p$ and $s_q$ are the time span of $Period$ and $Trend$, the $Closeness$ span $s_c$ is equal to 1 by default. This feature is not only inherited by the later grid-based models including STDN and DeepSTN+, but also some graph-based models like ASTGCN, which is still \nregarded as the state-of-the-art temporal feature by now. To capture the long-range spatial dependency between mesh-grids, it employs Residual Learning to construct deep enough CNN networks.  Additionally, it further utilizes external information including weather, event, and metadata(i.e. DayOfWeek, WeekdayOrWeekend) to auxiliarily enhance spatiotemporal modeling. \n\\begin{figure*}[h]\n\t\\centering\n\t\\includegraphics[width=0.97\\textwidth]{./figure/architectures.png}\n\t\\caption{Architectures of Representative Grid-Based Models.}\n\t\\label{fig:architectures}\n\\end{figure*}\n\\begin{figure*}[h]\n\t\\centering\n\t\\includegraphics[width=0.97\\textwidth]{./figure/architectures1.png}\n\t\\caption{Architectures of Representative Graph-Based Models.}\n\t\\label{fig:architectures1}\n\\end{figure*}\n\\noindent\\textbf{Improvement along Spatial Axis.} Different from ST-ResNet that takes the entire mesh-grids as input, DMVST-Net and STDN take one grid and its surrounding grids (i.e. $S$$\\times$$S$ region) as input, thus a local CNN is enough to capture spatial dependency only among nearby grids. For the global spatial dependency, DMVST-Net introduces a weighted graph as an extra input, where nodes are the grids, and each edge represents the similarity of two time-series values (i.e. historical taxi demand) between any two grids. The graph will be manually embedded into a feature vector so that it can be concatenated with the other part. Through this, DMVST-Net gains the ability to capture long-range spatial dependency. Furthermore, STDN and  consider the local flow information (i.e. flow from one central grid to its surrounding $S$$\\times$$S$ grids) to facilitate predicting the traffic volume in the central grid, which is implemented with a flow gating mechanism in STDN and multitask learning in . DeepSTN+  uses Point-Of-Interest (POI) data as external information (e.g., office/residential/shopping area) to take the influence of location function on the crowd/traffic flow into consideration.\n\\noindent\\textbf{Improvement along Temporal Axis.}\nOne major drawback of ST-ResNet is it does not explicitly handle the temporal axis, because it forces the video-like tensor ($T$,$H$,$W$,$C$) to be converted into an image-like tensor ($H$,$W$,$T$*$C$). To address this, DMVST-Net and STDN employ LSTM to connect with a separate and unshared CNN for each timestamp. STDN further considers the temporal shifting problem about periodicity (i.e. traffic data is not strictly periodic) and designs a \\emph{Periodically Shifted Attention Mechanism} to solve the issue. Specifically, it sets a small time window to collect $Q$ time intervals right before and after the currently-predicting one. And the attention is used to obtain a weighted average representation $h$ from the $Q$ representations \\{$h_1$, $h_2$, $...$, $h_Q$\\} generated by LSTM. To this end, LSTM, and CNN work together to separately and sequentially model the spatial and temporal dependency. Convolutional LSTM  extends the fully connected LSTM (FC-LSTM) to have convolutional structures in both the input-to-state and state-to-state transitions and achieves a lot of successes on video modeling tasks. Motivated by this, ConvLSTM and its variant ConvGRU are utilized by  to simultaneously capture the spatial and temporal dependency.\n\\begin{table*}[h]\n    \\small\n\t\\centering\n\t\\caption{Performance Evaluation for Single-Step Prediction on Grid-Based Traffic Datasets}\n\t\\label{tab:performance_grid}\n\t\\begin{tabular*}{17.0cm}{@{\\extracolsep{\\fill}}l|ccc|ccc|ccc|ccc}\n\t\t\\hline\n\t\t\\multicolumn{1}{l|}{} &\n\t\t\\multicolumn{3}{c|}{TaxiBJ} &\n\t\t\\multicolumn{3}{c|}{BikeNYC-I} &\n\t\t\\multicolumn{3}{c|}{BikeNYC-II} &\n\t\t\\multicolumn{3}{c}{TaxiNYC} \n\t\t\\\\\n\t\t\\hline\n\t\t\\multicolumn{1}{l|}{Model} & \n\t\t\\multicolumn{1}{c}{RMSE} & \n\t\t\\multicolumn{1}{c}{MAE} &\n\t\t\\multicolumn{1}{c|}{MAPE} &\n\t\t\\multicolumn{1}{c}{RMSE} & \n\t\t\\multicolumn{1}{c}{MAE} &\n\t\t\\multicolumn{1}{c|}{MAPE} &\n\t\t\\multicolumn{1}{c}{RMSE} & \n\t\t\\multicolumn{1}{c}{MAE} &\n\t\t\\multicolumn{1}{c|}{MAPE} &\n\t\t\\multicolumn{1}{c}{RMSE} & \n\t\t\\multicolumn{1}{c}{MAE} &\n\t\t\\multicolumn{1}{c}{MAPE}\n\t\t\\\\\n\t\t\\hline\n\t\tHistoricalAverage & 45.004 & 24.475 & 8.04\\% & 15.676 & 4.882 & 5.45\\% & 4.874 & 1.500 & 3.30\\% & 21.535 & 7.121 & 4.56\\%\\\\\n\t\tCopyLastStep & 23.609 & 13.372 & 6.20\\% & 14.152 & 4.344 & 5.01\\% & 4.999 & 1.606 & 3.50\\% & 18.660 & 6.497 & 4.91\\%\\\\\n\t\tCNN & 23.550 & 13.797 & 8.46\\% & 12.064 & 4.088 & 5.82\\% & 4.511 & 1.574 & 3.98\\% & 16.741 & 6.884 & 8.08\\%\\\\\n\t\tConvLSTM & 19.247 & 10.816 & 5.61\\% & 6.616 & 2.412 & 3.90\\% & 3.174 & 1.133 & 2.90\\% & 12.143 & 4.811 & 5.16\\%\\\\\n\t\tST-ResNet & 18.702 & 10.493 & 5.19\\% & 6.106 & 2.360 & 3.72\\% & 3.191 & 1.169 & 2.86\\% & 11.553 & 4.535 & 4.32\\%\\\\\n\t\tDMVST-Net & 20.389 & 11.832 & 5.99\\% & 7.990 & 2.833 & 3.93\\% & 3.521 & 1.287 & 2.97\\% & 13.605 & 4.928 & 4.49\\%\\\\\n\t\tPCRN & 18.629 & 10.432 & 5.45\\% & 6.680 & \\textbf{2.351} & 3.63\\% & 3.149 & \\textbf{1.107} & 2.78\\% & 12.027 & 4.606 & 4.62\\%\\\\\n\t\tDeepSTN+ & 18.141 & 10.126 & 5.14\\% & 6.205 & 2.489 & 3.48\\% & 3.205 & 1.245 & 2.80\\% & 11.420 & \\textbf{4.441} & 4.45\\%\\\\\n\t\tSTDN & \\textbf{17.826} & \\textbf{9.901} & \\textbf{4.81\\%} & \\textbf{5.783} & 2.410 & \\textbf{3.35\\%} & \\textbf{3.004} & 1.167 & \\textbf{2.67\\%} & \\textbf{11.252} & 4.474 & \\textbf{4.09\\%}\\\\\n\t\t\\hline\n\t\\end{tabular*}\n\\end{table*}\n\\begin{table*}[h]\n    \\small\n\t\\centering\n\t\\caption{Performance Evaluation for Multi-Step Prediction on Graph-Based Traffic Datasets}\n\t\\label{tab:trafficvolumn}\n\t\\begin{tabular*}{17.0cm}{@{\\extracolsep{\\fill}}l|l|ccc|ccc|ccc}\n\t\t\\hline\n\t\t\\multicolumn{1}{l|}{} & \\multicolumn{1}{l|}{} & \\multicolumn{3}{c|}{3 Steps / 15 Minutes Ahead} &\n\t\t\\multicolumn{3}{c|}{6 Steps / 30 Minutes Ahead} &\n\t\t\\multicolumn{3}{c}{12 Steps / 60 Minutes Ahead}\n\t\t\\\\\n\t\t\\hline\n\t\t\\multicolumn{1}{l|}{Dataset} & \\multicolumn{1}{l|}{Model} & \n\t\t\\multicolumn{1}{c}{RMSE} & \n\t\t\\multicolumn{1}{c}{MAE} &\n\t\t\\multicolumn{1}{c|}{MAPE} & \n\t\t\\multicolumn{1}{c}{RMSE} & \n\t\t\\multicolumn{1}{c}{MAE} & \n\t\t\\multicolumn{1}{c|}{MAPE} & \n\t\t\\multicolumn{1}{c}{RMSE} & \n\t\t\\multicolumn{1}{c}{MAE} & \n\t\t\\multicolumn{1}{c}{MAPE} \n\t\t\\\\\n\t\t\\hline\n\t    \\multirow{8}{*}{METR-LA} &  \n\t\tHistoricalAverage & 14.737 & 11.013 & 23.34\\% & 14.737 & 11.010 & 23.34\\% & 14.736 & 11.005 & 23.33\\% \\\\\n\t\t& CopyLastSteps & 14.215 & 6.799 & 16.73\\% & 14.214 & 6.799 & 16.73\\% & 14.214 & 6.798 & 16.72\\% \\\\\n\t\t& LSTNet & 8.067 & 3.914 & 9.27\\% & 10.181 & 5.219 & 12.22\\% & 11.890 & 6.335 & 15.38\\% \\\\\n\t\t& STGCN & 7.918 & 3.469 & 8.57\\% & 9.948 & 4.263 & 10.70\\% & 11.813 & 5.079 & 13.09\\% \\\\\n\t\t& DCRNN & \\textbf{7.509} & 3.261 & 8.00\\% & 9.543 & 4.021 & 10.12\\% & 11.854 & 5.080 & 13.08\\% \\\\\n\t\t& Graph WaveNet & 7.512 & \\textbf{3.204} & \\textbf{7.62\\%} &\\textbf{9.445}  & \\textbf{3.922} & \\textbf{9.52\\%} & \\textbf{11.485} & \\textbf{4.848} & \\textbf{11.93\\%} \\\\\n\t\t& ASTGCN & 7.977 & 3.624 & 9.13\\% & 10.042 & 4.514 & 11.57\\% & 12.092 & 5.776 & 14.85\\% \\\\\n\t\t& GMAN & 8.869 & 4.139 & 10.88\\% & 9.917 & 4.517 & 11.77\\% & 11.910 & 5.475 & 14.10\\% \\\\\n\t\t& MTGNN & 7.707 & 3.277 & 8.02\\% & 9.625 & 3.999 & 10.00\\% & 11.624 & 4.867 & 12.17\\% \\\\\n\t\t& AGCRN & 7.558 & 3.292 & 8.17\\% & 9.499 & 4.016 & 10.16\\% & 11.502 & 4.901 & 12.43\\% \\\\\n\t\t\\hline\n\t\t\\multirow{8}{*}{PeMS-BAY} &\n\t\tHistoricalAverage & 6.687 & 3.333 & 8.10\\% & 6.686 & 3.333 & 8.10\\% & 6.685 & 3.332 & 8.10\\% \\\\\n\t\t& CopyLastSteps & 7.022 & 3.052 & 6.84\\% & 7.016 & 3.049 & 6.84\\% & 7.05 & 3.044 & 6.83\\% \\\\\n\t\t& LSTNet & 3.224 & 1.643 & 3.47\\% & 4.375 & 2.383 & 5.04\\% & 5.515 & 2.974 & 6.86\\% \\\\\n\t\t& STGCN & 2.827 & 1.327 & 2.79\\% & 3.887 & 1.698 & 3.81\\% & 4.748 & 2.055 & 5.02\\% \\\\\n\t\t& DCRNN & 2.867 & 1.377 & 2.96\\% & 3.905 & 1.726 & 3.97\\% & 4.798 & 2.091 & 4.99\\% \\\\\n\t\t& Graph WaveNet & \\textbf{2.759} & \\textbf{1.322} & \\textbf{2.78\\%} & \\textbf{3.737} & 1.660 & \\textbf{3.75\\%} & 4.562 & 1.991 & 4.75\\% \\\\\n\t\t& ASTGCN & 3.057 & 1.435 & 3.25\\% & 4.066 & 1.795 & 4.40\\% & 4.770 & 2.103 & 5.30\\% \\\\\n\t\t& GMAN & 4.219 & 1.802 & 4.47\\% & 4.143 & 1.794 & 4.40\\% & 5.034 & 2.186 & 5.29\\% \\\\\n\t\t& MTGNN & 2.849 & 1.334 & 2.84\\% & 3.800 & \\textbf{1.658} & 3.77\\% & \\textbf{4.491} & \\textbf{1.950} & \\textbf{4.59\\%} \\\\\n\t\t& AGCRN & 2.856 & 1.354 & 2.94\\% & 3.818 & 1.670 & 3.84\\% & 4.570 & 1.964 & 4.69\\% \\\\\n\t\t\\hline\n\t\t\\multirow{8}{*}{PEMSD7M} &   \n\t\tHistoricalAverage & 7.077 & 3.917 & 9.90\\% & 7.083 & 3.920 & 9.92\\% & 7.095 & 3.925 & 9.95\\% \\\\\n\t\t& CopyLastSteps & 9.591 & 5.021 & 12.33\\% & 9.594 & 5.022 & 12.33\\% & 9.597 & 5.024 & 12.34\\% \\\\\n\t\t& LSTNet & 4.308 & 2.423 & 5.73\\% & 8.951 & 5.132 & 12.22\\% & 10.881 & 6.624 & 16.72\\% \\\\\n\t\t& STGCN  & 4.051 & 2.124 & 5.02\\% & 5.532 & 2.783 & 6.96\\% & 6.695 & 3.374 & 8.74\\% \\\\\n\t\t& DCRNN & 4.143 & 2.213 & 5.33\\% & 5.679 & 2.907 & 7.41\\% & 7.138 & 3.670 & 9.81\\%  \\\\\n\t\t& Graph WaveNet & \\textbf{3.992} & 2.130 & \\textbf{5.00\\%} & \\textbf{5.332} & 2.715 & 6.75\\% & \\textbf{6.431} & 3.266 & 8.47\\% \\\\\n\t\t& ASTGCN & 4.257 & 2.340 & 5.83\\% & 5.506 & 2.992 & 7.69\\% & 6.587 & 3.572 & 9.48\\% \\\\\n\t\t& GMAN & 5.711 & 2.877 & 7.25\\% & 6.171 & 3.084 & 7.77\\% & 7.897 & 3.988 & 10.02\\% \\\\\n\t\t& MTGNN & 4.032 & \\textbf{2.120} & 5.02\\% & 5.373 & \\textbf{2.687} & \\textbf{6.70\\%} & 6.496 & \\textbf{3.204} & \\textbf{8.24\\%} \\\\\n\t\t& AGCRN & 4.073 & 2.167 & 5.19\\% & 5.479 & 2.769 & 6.89\\% & 6.733 & 3.358 & 8.55\\% \\\\\n\t\t\\hline\n\t\\end{tabular*}\n\\end{table*}", "cites": [22, 24, 40, 23, 32, 29, 33, 25, 21, 8312, 34], "cite_extract_rate": 0.6111111111111112, "origin_cites_number": 18, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.5, "abstraction": 3.5}, "insight_level": "medium", "analysis": "The section synthesizes key ideas from multiple grid-based traffic prediction models, highlighting the evolution of spatial and temporal modeling strategies. It critically evaluates limitations, such as the lack of explicit temporal handling in ST-ResNet, and contrasts improvements in later models like DMVST-Net and STDN. While it identifies some patterns in design choices, the abstraction remains grounded in the specific modeling axes (spatial and temporal), limiting broader theoretical generalization."}}
{"id": "f509b7e2-496e-42c4-8c44-c0803a49aa44", "title": "Roadmap for Graph-Based Model", "level": "subsection", "subsections": [], "parent_id": "23050b21-5fab-45c0-9c6c-dd4a43d7184b", "prefix_titles": [["title", "DL-Traff: Survey and Benchmark of Deep Learning Models for Urban Traffic Prediction"], ["section", "Model"], ["subsection", "Roadmap for Graph-Based Model"]], "content": "STGCN is one of the earliest models that use graph neural networks to predict traffic flow. Temporally, instead of RNN, it uses TCN  with a gated mechanism as shown in Fig.\\ref{fig:architectures1} to capture the dependency only from $Closeness$ features. Spatially, it applies two spectral graph convolution, ChebyNet and 1st-order approximation of ChebyNet . TCN and GCN are stacked together as an ST-Conv block to sequentially do the spatial and temporal modeling. One major limitation of STGCN is that it uses a symmetrical adjacency matrix (i.e., undirected graph) that considers the euclidean distance between two road sensors. Thus it is difficult to model the difference of the two-way traffic flow in one road. DCRNN  is another pioneer to utilize graph convolution for traffic flow prediction. In contrast to the spectral convolution in STGCN, DCRNN applies a spatial graph convolution called Diffusion Convolution implemented with bidirectional random walks on a directed graph (i.e., non-symmetric adjacent matrix), so that it can capture the spatial influence from both the upstream and the downstream traffic flows. For the temporal axis, similar to ConvLSTM, it replaces the normal matrix multiplication in GRU with the proposed diffusion convolution, then a Diffusion Convolution Gated Recurrent Unit (DCGRU) is assembled that can simultaneously do the spatial and temporal modeling. With this DCGRU, it further implements an encoder-decoder structure to enable the multi-step-to-multi-step prediction. Inspired by STGCN and DCRNN, massive graph-based traffic models have been proposed as summarized in Table \\ref{tab:modelsummary}.\n\\noindent\\textbf{Improvement along Temporal Axis.} For the temporal feature, ASTGCN inherits $Closeness$, $Period$, and $Trend$ from ST-ResNet, and improves STGCN that only takes $Closeness$. Besides, STSGCN constructs a localized temporal graph by connecting all nodes with themselves at the previous and the next steps, updating the adjacency matrix from $A$$\\in$$\\mathbb{R}^{N*N}$ to $A'$$\\in$$\\mathbb{R}^{3N*3N}$, then only uses GCN to simultaneously do the spatial and temporal modeling. On the other hand, to get better ability of temporal modeling, T-GCN and TGC-LSTM respectively use GRU and LSTM instead of TCN to improve STGCN; GCGA combines Generative Adversarial Network(GAN) and Autoencoder with GCN; STGNN adopts transformer (attention) for  better global/long-term temporal modeling; STG2Seq utilized GCN for temporal modeling, which is an interesting attempt.\n\\noindent\\textbf{Improvement along Spatial Axis.} A lot of effort has been put on the spatial axis, that is the graph. (1) From single-graph to multi-graph. STGCN and DCRNN only use a single graph, directed or non-directed, to describe the spatial relationship. However, multimodal correlations and compound spatial dependencies exist among regions. Therefore, a series of researches elevate single-graph to multi-graph.\nFor instance,  and ST-MGCN consider spatial proximity, functional similarity, and road connectivity as mutli-graph, and so as T-MGCN; H-STGCN takes travel time correlation matrix and shortest-path distance matrix as compound matrix; MRA-BGCN builds the node-wise graph according to the road network distance, and the edge-wise graph according to the connectivity and competition. (2) From static graph to adaptive graph. Graph WaveNet, TGC-LSTM, and AGCRN adopt adaptive/learnable graph rather than a static one used in STGCN and DCRNN; DGCNN proposes dynamic Laplacian matrix learning through tensor decomposition; SLCNN designs Structure Learning Convolution (SLC) to dynamically learn the global/local graph structure. \nIn addition to the above, attention-augmented GCN also demonstrated better performance in terms of spatial modeling in GaAN, ASTGCN, and GMAN.", "cites": [8313, 27, 30, 37, 33, 28, 26, 8312, 25, 23, 36, 32], "cite_extract_rate": 0.5217391304347826, "origin_cites_number": 23, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.5, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section effectively synthesizes the cited graph-based models by organizing them into temporal and spatial improvement categories, highlighting the evolution of techniques. It critically evaluates limitations (e.g., STGCN’s symmetric adjacency matrix) and contrasts them with alternative approaches (e.g., DCRNN’s directed graph modeling). The abstraction level is strong as it identifies broader trends such as moving from static to adaptive graphs and from single to multi-graph models."}}
{"id": "c0ce4579-96dc-48f8-84c3-543a96d159da", "title": "Availability and Usability", "level": "section", "subsections": [], "parent_id": "59d19c15-d2fe-4919-9357-dccad053bdfa", "prefix_titles": [["title", "DL-Traff: Survey and Benchmark of Deep Learning Models for Urban Traffic Prediction"], ["section", "Availability and Usability"]], "content": "DL-Traff is already available at GitHub as the following two repositories under the MIT License: one is for grid-based datasets/models \\url{https://github.com/deepkashiwa20/DL-Traff-Grid}, and another is for graph-based datasets/models \\url{https://github.com/deepkashiwa20/DL-Traff-Graph}. It is implemented with Python and the most popular deep learning frameworks: Keras on TensorFlow and PyTorch. Fig.\\ref{fig:usecase} shows a use case by taking DCRNN model on METR-LA dataset as an example. To run the benchmark, the repository should be cloned locally and a conda environment with the necessary dependencies should be created. The directory is structured in a flat style and only with two levels. The traffic datasets are stored in DATA directories (e.g., METRLA), and the python files are put in workDATA directories (e.g., workMETRLA). Entering the work directory for a certain dataset, we can find MODEL class file (e.g., DCRNN.py) and its corresponding running program named pred\\_MODEL.py (e.g., pred\\_DCRNN.py). We can run ``python MODEL.py'' to simply check the model architecture without feeding the training data and run ``python pred\\_MODEL.py'' to train and test the model. Additionally, Param.py file contains a variety of hyper-parameters as described in Section 5.1 that allow the experiment to be customized in a unified way. Metrics.py file contains the metric functions listed in Section 5.1. Utils.py file integrates a set of supporting functions such as pickle file reader and self-defined loss function. More details about the usability and implementation can be found at GitHub.\n\\begin{figure}[h]\n\t\\centering\n\t\\includegraphics[width=0.49\\textwidth]{./figure/usecase.png}\n\t\\caption{Illustration of The Use Case for DL-Traff.}\n\t\\label{fig:usecase}\n\\end{figure}", "cites": [41], "cite_extract_rate": 0.3333333333333333, "origin_cites_number": 3, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 1.5, "abstraction": 1.0}, "insight_level": "low", "analysis": "The section provides a factual description of the DL-Traff repository's availability, structure, and implementation, mentioning the use of PyTorch as a deep learning framework. However, it does not synthesize or integrate insights from the cited paper in a meaningful way, nor does it offer critical analysis or abstract patterns. The content is primarily instructional and descriptive."}}
