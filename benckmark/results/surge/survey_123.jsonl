{"id": "41d0c2e5-0bc9-4e11-bba7-da658b523704", "title": "Introduction", "level": "section", "subsections": [], "parent_id": "81d577c7-6481-41cd-8b79-48e73c6a5850", "prefix_titles": [["title", "Neuron-level Interpretation of Deep NLP Models: A Survey"], ["section", "Introduction"]], "content": "Models trained using Deep Neural Networks (DNNs) have constantly pushed the state-of-the-art in \nvarious Natural Language Processing (NLP) problems, for example Language Modeling  and Machine Translation  to name a few. Despite this remarkable revolution, the black-box nature of deep neural networks \nhas remained major bottleneck in their large scale adaptability -- especially in the applications where fairness, trust, accountability, reliability and ethical decision-making are considered critically important metrics or at least as important as model's performance . \nThis opaqueness of Deep Neural Networks has spurred a new area of research to analyze and understand these models. A plethora of papers have been written in the past five years on interpreting deep NLP models and to answer one question in particular: \\textit{\\textbf{What knowledge is learned within representations?}} We term \nthis \nwork as the \n\\emph{Representation Analysis}. \nRepresentation Analysis thrives on post-hoc decomposability, where we analyze \nthe embeddings to uncover linguistic (and non-linguistic) concepts\\footnote{Please refer to Section~\\ref{sec:definitions} for a formal definition.} that are captured as the network is trained towards an NLP task .\nA majority of the work on \\emph{Representation Analysis} has focused on a holistic view of the representations i.e. how much knowledge of a certain concept is learned within representations as a whole (See \\newcite{belinkov-etal-2020-analysis} for a survey done on this line of work). Recently, a more fine-grained neuron interpretation has started to gain attention. In addition to \nthe holistic view of the representation, \\emph{Neuron Analysis} provides insight into a fundamental question: \\textbf{\\textit{How is knowledge structured within these representations?}} In particular, it targets \nquestions such as:\n\\begin{itemize}\n\\item What \nconcepts are learned within neurons of the network?\n\\item Are there neurons \nthat specialize in learning particular concepts?\n\\item How localized/distributed and redundantly is the knowledge preserved within neurons of the network?\n\\end{itemize}\nAnswers to these questions entail potential benefits beyond understanding the inner workings of models, \nfor example: i) controlling bias and manipulating system’s behaviour by identifying relevant neurons with respect to a prediction, ii) model distillation by removing less useful neurons, iii) efficient feature selection by selecting the most salient neurons and removing the redundant ones, iv) neural architecture search by guiding the search with important neurons. \nThe work on neuron analysis has explored various \ndirections such as: proposing novel methods to \ndiscover concept neurons \n, analyzing and comparing \narchitectures \nusing neuron distributions , and \nenabling applications of neuron analysis~.\nIn this survey, we aim to provide a broad perspective of the field with an in-depth coverage of each of these directions. We propose a matrix of seven attributes to compare various neuron analysis methods. Moreover, \nwe discuss the open issues and promising future directions in this area.\nThe survey is organized as follows: \nSection~\\ref{sec:definitions} defines the terminologies and formally introduces neuron analysis. Section~\\ref{sec:methods} covers various neuron analysis methods and compares them \nusing seven attributes.\nSection~\\ref{sec:evaluation} presents the \ntechniques that have been used to evaluate the effectiveness of neuron analysis methods. \nSection~\\ref{sec:findings} discusses the findings of neuron analysis methods. \nLastly \nSection~\\ref{sec:applications} showcases various applications of the presented methods and Section~\\ref{sec:conclude} \ntouches upon the open issues and future research directions. \n\\begin{figure*}[]\n    \\centering\n\t\\includegraphics[width=0.98\\linewidth]{figures/overview.png}\n\t\\caption{Overview of neuron analysis summarizing the three objectives as discussed in Section~\\ref{sec:definitions}}\n\t\\label{fig:overview}\n\\end{figure*}\n\\begin{table*}[t]\n\t\\centering\n\t\\footnotesize\n\t\\begin{tabular}{c|cccccccc}\n\t\\toprule\n\t\tWords & Obama  & receives & Netanyahu  & in  & the & capital & of  & USA \\\\ \n\t\t\\midrule\n\t\tSuffix & -- & s & -- & -- & -- & -- & -- & -- \\\\\n\t\tPOS  & NNP & VBZ & NNP & IN & DT & NN & IN & NP \\\\ \n\t\tSEM  & PER & ENS & PER & REL & DEF & REL & REL & GEO \\\\ \n\t\tChunk & B-NP & B-VP & B-NP & B-PP & B-NP & I-NP & B-PP & B-NP \\\\\n\t\tCCG & NP & ((S[dcl]$\\backslash$NP)/PP)/NP & NP  & PP/NP  & NP/N  & N  & (NP$\\backslash$NP)/NP  & NP\n        \\\\\n       \t\\bottomrule\n\t\\end{tabular}\n    \\caption{Example sentences with different word-level concepts. POS: Parts of Speech tags, SEM: Semantic tags, Chunk: Chunking tags, CCG: Combinatory Categorial Grammar tags}\n\t\\label{tab:example-annotation}\n\\end{table*}", "cites": [2401, 7622, 8598, 7623, 7165, 7, 7621, 8599, 168, 2909], "cite_extract_rate": 0.7692307692307693, "origin_cites_number": 13, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.5, "critical": 2.5, "abstraction": 3.0}, "insight_level": "medium", "analysis": "The section integrates key concepts from cited papers to frame neuron-level interpretation as a distinct and valuable approach compared to representation analysis. It provides a coherent narrative around the motivations and goals of neuron analysis, such as understanding how knowledge is structured and enabling applications like bias control and model distillation. While it offers some abstraction by introducing high-level questions and potential benefits, the critical analysis is limited and mostly descriptive in nature."}}
{"id": "e12954b7-fc6e-4c95-ba61-28fbdef9e14b", "title": "Neuron Analysis Methods", "level": "section", "subsections": ["01454814-cf97-4f62-adb2-09d747c8cf8b", "5176e758-71b9-4fce-87a1-c46ce47d1a3e", "2ae46c4c-2724-42b1-ad00-d1ffeade8ae0", "d96870c8-fadd-42d3-a191-1b8ead129436", "b6dbcfb8-3c71-4e58-962e-8dce2aa7597a"], "parent_id": "81d577c7-6481-41cd-8b79-48e73c6a5850", "prefix_titles": [["title", "Neuron-level Interpretation of Deep NLP Models: A Survey"], ["section", "Neuron Analysis Methods"]], "content": "\\label{sec:methods}\nWe have classified the work done on neuron analysis into 5 broader categories of methods, namely: i) visualizations, ii) corpus-based, iii) probing-based, iv) causation-based and v) miscellaneous methods, based on a set of attributes we describe below: \n\\begin{itemize}\n    \\item Scope: Does the method provide global \n    or local \n    interpretation? \n    Global methods accumulate statistics across a set of examples to discover the role of a neuron. \n    Local methods provide interpretation of a neuron in a particular example and may not necessarily reflect its role over a large corpus.\n    \\item Input and Output: What is the input (e.g. a set of neurons or concepts) to the method and what does it output? \n    \\item Scalability: Can the method be scaled to a larger set of neurons?\n    \\item HITL: Does the method require a human-in-the-loop for interpretation?\n    \\item Supervision: Does the method depend on labeled data to provide interpretation?\n    \\item Causation: Is the interpretation connected with the model's prediction? \n\\end{itemize}\nTable~\\ref{tab:neuronmethods} summarizes and compares each method in the light of these attributes. We discuss them in detail below.\\footnote{Table \\ref{tab:appendix:neuronmethods} in Appendix gives a more comprehensive list.}\n\\begin{table*}[t]\n\\centering\n\\footnotesize\n\\begin{tabular}{p{0.19\\textwidth}p{0.08\\textwidth}p{0.1\\textwidth}p{0.1\\textwidth}p{0.1\\textwidth}p{0.06\\textwidth}p{0.1\\textwidth}p{0.06\\textwidth}}\n\\toprule\n   & Scope & Input & Output  & Scalability & HITL & Supervision & Causation \\\\\n\\midrule\n\\rowcolor[HTML]{D9EAD3} \n\\multicolumn{8}{l}{\\cellcolor[HTML]{D9EAD3}\\textbf{Visualization}}                                                                                                                        \\\\\n\\rowcolor[HTML]{D9EAD3} \n  & local        & neuron                 & concept              & low         & yes  & no              & no            \\\\\n\\rowcolor[HTML]{A4C2F4} \n\\multicolumn{8}{l}{\\cellcolor[HTML]{A4C2F4}\\textbf{Corpus-based methods}}                                                              \n                                     \\\\\n\\multicolumn{8}{l}{\\cellcolor[HTML]{A4C2F4}{Concept Search}}                                                                                                                  \\\\\n\\rowcolor[HTML]{A4C2F4} \n\\cellcolor[HTML]{A4C2F4}     & global       & neuron                 & concept              & low         & yes  & no              & no            \\\\\n\\rowcolor[HTML]{A4C2F4}  \n  & global       & neuron                 & concept              & high        & no   & no              & no            \\\\\n\\rowcolor[HTML]{A4C2F4} \n\\multicolumn{8}{l}{\\cellcolor[HTML]{A4C2F4}{Neuron Search}}                                                                                                                  \\\\\n\\rowcolor[HTML]{A4C2F4} \n\\cellcolor[HTML]{A4C2F4}      & global       & concept                & neurons              & high        & no   & yes             & no            \\\\\n\\rowcolor[HTML]{EA9999} \n\\multicolumn{8}{l}{\\cellcolor[HTML]{EA9999}\\textbf{Probing-based methods}}                                                                                                            \\\\\n\\rowcolor[HTML]{EA9999} Linear      & global       & concept                & neurons              & high        & no   & yes             & no            \\\\\n\\rowcolor[HTML]{EA9999} \nGaussian      & global       & concept                & neurons              & high        & no   & yes             & no            \\\\\n\\rowcolor[HTML]{D9D9D9} \n\\multicolumn{8}{l}{\\cellcolor[HTML]{D9D9D9}\\textbf{Causation-based methods}}                                                                                                              \\\\\n\\rowcolor[HTML]{D9D9D9} \nAblation       & both         & concept/ class         & neurons              & medium      & no   & no              & yes           \\\\\n\\rowcolor[HTML]{D9D9D9} \nKnowledge attribution     & local        & concept/ class         & neurons              & high        & no   & no              & yes           \\\\\n\\rowcolor[HTML]{FFE599} \n\\multicolumn{8}{l}{\\cellcolor[HTML]{FFE599}\\textbf{Miscellaneous methods}}                                                                                                                \\\\\n\\rowcolor[HTML]{FFE599} \nCorpus generation    & global       & neuron                 & concept              & low         & yes  & no              & no            \\\\\n\\rowcolor[HTML]{FFE599} \nMatrix factorization    & local        & neurons                      & neurons      & low         & yes  & no              & no            \\\\\n\\rowcolor[HTML]{FFE599} \nClustering       & global        & neurons                      & neurons      & high         & yes  & no    & no            \\\\\n\\rowcolor[HTML]{FFE599} \nMulti model search   & global       & neurons                & neurons              & high        & yes  & no              & no     \\\\ \n\\bottomrule\n\\end{tabular}\n\\caption{Comparison of neuron analysis methods based on various attributes. The exhaustive list of citations for each method are provided in the text.} \n\\label{tab:neuronmethods}\n\\end{table*}", "cites": [8598, 2911, 2910, 8599, 2909], "cite_extract_rate": 0.7142857142857143, "origin_cites_number": 7, "insight_result": {"type": "comparative", "scores": {"synthesis": 3.5, "critical": 2.5, "abstraction": 3.0}, "insight_level": "medium", "analysis": "The section organizes neuron analysis methods into five categories and compares them using a set of attributes like scope, scalability, and causation. This provides a structured synthesis of the cited works. However, the critical evaluation is limited, as the section does not deeply analyze the limitations or trade-offs of the methods. The abstraction level is moderate, with some generalization in the classification but without deeper meta-level insights."}}
{"id": "01454814-cf97-4f62-adb2-09d747c8cf8b", "title": "Visualization", "level": "subsection", "subsections": ["acce36b1-fbcb-4699-a007-45b0a0f27eec"], "parent_id": "e12954b7-fc6e-4c95-ba61-28fbdef9e14b", "prefix_titles": [["title", "Neuron-level Interpretation of Deep NLP Models: A Survey"], ["section", "Neuron Analysis Methods"], ["subsection", "Visualization"]], "content": "\\label{sec:method:visualization}\nA simple way to discover the role of a neuron is \nby visualizing its activations and manually identifying \nthe underlying concept over a set of sentences~.\nGiven that deep NLP models are trained using billions of neurons, it is \nimpossible to visualize all \nthe neurons. A number of clues have been used to shortlist the \nneurons for visualization, \nfor example, selecting saturated neurons, high/low variance neurons, or ignoring dead neurons~ when using ReLU activation function.\\footnote{Saturated neurons have a gradient value of zero. Dead neurons have an activation value of zero.}", "cites": [2911], "cite_extract_rate": 0.5, "origin_cites_number": 2, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 2.0, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section provides a basic description of visualization as a method for neuron analysis but offers little synthesis of the cited work. It mentions common strategies for selecting neurons (e.g., saturated, high/low variance, dead neurons) without elaborating on how these relate to broader interpretability goals or contrasting with other methods. There is minimal critical analysis or abstraction beyond the specific techniques described."}}
{"id": "9c7f994b-e743-49b7-a00e-12debba70995", "title": "Limitation", "level": "paragraph", "subsections": [], "parent_id": "0b2f96c4-b1e2-449a-904b-792f6e29e584", "prefix_titles": [["title", "Neuron-level Interpretation of Deep NLP Models: A Survey"], ["section", "Neuron Analysis Methods"], ["subsection", "Probing-based Methods"], ["paragraph", "Linear Classifiers"], ["paragraph", "Limitation"]], "content": "A pitfall to \nprobing classifiers is whether a probe \nfaithfully reflects the concept \nlearned within the representation or just \nmemorizes the task~. Researchers have mitigated this pitfall for some analyses by using random initialization of neurons~ and control tasks~ to demonstrate that the knowledge is possessed within the neurons and not due to the probe's capacity for memorization. Another discrepancy in the neuron probing framework, that especially affects the linear classifiers, is that variance patterns in neurons differ strikingly across the layers. \\newcite{sajjad2021:znorm} suggested to apply z-normalization as a pre-processing step to any neuron probing method to alleviate this issue.", "cites": [2910], "cite_extract_rate": 0.3333333333333333, "origin_cites_number": 3, "insight_result": {"type": "analytical", "scores": {"synthesis": 2.5, "critical": 3.5, "abstraction": 2.5}, "insight_level": "medium", "analysis": "The section provides an analytical overview of the limitations of probing classifiers, particularly linear ones, in neuron-level analysis. It integrates the cited work by pointing out how researchers have addressed the issue of memorization and highlights a specific preprocessing technique from Sajjad et al. (2021). While it offers some critical evaluation of the framework’s shortcomings, the synthesis and abstraction remain limited, as it does not explore deeper connections or broader implications across multiple studies."}}
{"id": "e4822c95-8f3c-456f-a54e-e63911b8a8eb", "title": "Limitation", "level": "paragraph", "subsections": [], "parent_id": "13b0a245-e39d-453e-a3fc-6924bc8e4535", "prefix_titles": [["title", "Neuron-level Interpretation of Deep NLP Models: A Survey"], ["section", "Neuron Analysis Methods"], ["subsection", "Causation-based methods"], ["paragraph", "Ablation"], ["paragraph", "Limitation"]], "content": "Identifying \n\\emph{group neurons} require ablating all possible combinations of neurons which is an NP-hard problem~. Several researchers have tried to circumvent this by using \nleave-one-out estimates~, beam search~, by learning end-to-end differentiable prediction model~ and by using correlation clustering to group similar neurons before ablation~. Nevertheless all these approaches are approximations and may incur search errors.", "cites": [8600], "cite_extract_rate": 0.3333333333333333, "origin_cites_number": 3, "insight_result": {"type": "analytical", "scores": {"synthesis": 2.5, "critical": 3.0, "abstraction": 2.5}, "insight_level": "medium", "analysis": "The section provides a brief analytical overview of the limitations of group neuron identification through ablation, citing various methods. While it mentions a single paper in relation to the broader topic, the synthesis is limited and the critical discussion remains at a high-level without deep comparative or conceptual analysis. It identifies a computational challenge and some approximation-based workarounds, which contributes some level of insight, but lacks broader abstraction or a novel integrative framework."}}
{"id": "6b1c7149-f2cf-4421-9201-478661544d82", "title": "Summary of Findings", "level": "subsection", "subsections": [], "parent_id": "bafcff9d-1ddd-433e-9988-8693300da7f1", "prefix_titles": [["title", "Neuron-level Interpretation of Deep NLP Models: A Survey"], ["section", "Findings"], ["subsection", "Summary of Findings"]], "content": "\\label{sec:findingSummary}\nBelow is a summary of the key findings that emerged from the work we covered in this survey. Neurons learned within Deep NLP models capture\nnon-trivial linguistic knowledge ranging from \nlexical phenomenon such as morphemes, words and multi-word expressions to highly complex global phenomenon such as  semantic roles and syntactic dependencies. Neuron analysis resonates with the findings of representation analysis  in demonstrating that the networks follow linguistic hierarchy. Linguistic neurons are distributed across the network based on their complexity, with lower layers focused on the lexical concepts and middle and higher layers learning global phenomenon based on long-range contextual dependencies. While the networks preserve linguistic hierarchy, many authors showed that information is not discretely preserved, but is rather distributed and redundantly present in the network. It was also shown that a small optimal subset of neurons w.r.t any concept can be extracted from a network. On another dimension, a few works showed that some concepts are localized to fewer neurons while others are distributed to a large group. Finally, some interesting cross architectural analyses were drawn based on how the neurons are distributed within their layers.", "cites": [7623], "cite_extract_rate": 0.5, "origin_cites_number": 2, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 2.5, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section effectively synthesizes findings across neuron-level studies, particularly highlighting the hierarchical distribution of linguistic knowledge and the balance between distributed and localized representation. While it offers some abstraction by identifying general patterns in how neurons encode linguistic concepts, it lacks deeper critical evaluation of the methodologies or limitations of the cited works. The narrative is insightful and organized around overarching themes, which contributes to its high insight level."}}
{"id": "a2492ee2-c312-4c75-b088-6f29f214f5e9", "title": "Open Issues and Future Directions", "level": "section", "subsections": [], "parent_id": "81d577c7-6481-41cd-8b79-48e73c6a5850", "prefix_titles": [["title", "Neuron-level Interpretation of Deep NLP Models: A Survey"], ["section", "Open Issues and Future Directions"]], "content": "\\label{sec:conclude}\nIn the following section, we discuss several open issues and limitations related to methods, evaluation and datasets. Moreover, we provide potential future directions vital to the progress of neuron and model interpretation.\n\\begin{itemize}\n    \\item DNNs are distributed in nature which encourages groups of neurons to work together to learn a concept. The current analysis methods, at large, ignore interaction between neurons while discovering neurons with respect to a concept. Trying all possible combination of neurons is a computationally intractable problem. A linear classifier using ElasticNet regularization~ considers grouping of features during training -- however, it's effectiveness in handling grouped neurons has not been empirically validated. Evolutionary algorithms\\footnote{\\url{https://en.wikipedia.org/wiki/Evolutionary_algorithm}} do not make any assumption of the underline distribution of the features and they have been effectively used for feature selection of multivariate features. Exploring them for neuron selection is a promising research direction to probe towards latent concepts in these models.\n    \\item A large number of interpretation studies rely on human-defined linguistic concepts to probe a model. It is possible that the models do not strictly adhere to the human-defined concepts and learn novel concepts about the language. \n    This results in an incorrect or incomplete analysis. \n    Several researchers  made strides in this direction by analyzing hidden structures in the input representations in an unsupervised manner. They discovered existence of novel structures not captured in the human defined categories. \n    \\newcite{dalvi2022discovering} also proposed\n    BERT ConceptNet, \n    a manual annotation of the latent concepts in BERT. Introducing similar datasets across other models \n    enables model-centric interpretation, and is a promising research direction. \n    \\item While a lot of work has been done on analyzing how knowledge is encoded within the learned representations, the question whether it is used by the model during prediction is a less explored area . \n    Ablation and knowledge attribution methods are two neuron interpretation methods that intrinsically use causal relation to select concept neurons. A few other studies evaluated the causal relation of the selected concept neurons via ablation or by clamping their activation values~ and observed the change in model's prediction. However, most of the studies do not take into account the causal relation as part of the method or the evaluation of their method. The causal relation with respect to concept neurons is important to understand their importance to overall prediction and it leads way towards practical applications such as debiasing, model distillation and domain adaptation. \n    \\item The work on neuron interpretation lacks standard evaluation benchmarks, and therefore studies conducted on identical models are not comparable. For example, there exists no gold annotation of neurons with respect to a certain dataset or a class. \n    The curation of standard evaluation benchmarks \n    is an essential step towards improving methods of interpretation of deep neural network models.\n    \\item The neuron analysis methods vary in their theoretical foundations as well as the perspective they aim to capture with respect to a given concept. This results in a selection of neurons that may not strictly align across all methods.\n    For example, \\emph{Visualization}, \\emph{Neuron Search} and \\emph{Corpus Search} discover neurons that are highly focused on a specific task (like \"less\" suffix or POS \"TO\" concepts), while \\emph{Probing-based} methods discover ranking of neurons that highlight grouping behavior within the neurons targeting broad concepts like POS \"Nouns\". \n    Therefore, the choice of which neuron interpretation method to use is not straightforward and depends on various factors such as the nature of the concept to investigate, the availability of supervised data for the concept of interest etc. Apart from these high-level guiding principles, a thorough comparison of methods with respect to the nature of the concept of interest is needed to fully understand the strengths and weaknesses of each approach. \\newcite{antverg2022on} is one such effort in this direction that compares three neuron interpretation methods. \n    \\item Neuron-level interpretation opens door for a number of applications useful for the successful deployment of DNN systems (Section \\ref{sec:applications}). However, most of the research conducted in this direction is preliminary. For example, there are many open research questions in \\textbf{controlling system's behaviour} using neurons such as: i) are all concepts manipulatable? ii) how to identify neurons that can be controlled to change the output? iii) is high distributiveness a hindrance for controlling model's behavior? iv) and whether disentangled ~ and sparse models~ may serve as a better alternate on this front? Addressing these questions will enable a more reliable control of the deep NLP models and entail numerous applications such as removing bias and adapting the system to novel domains.\n\\end{itemize}\n\\bibliography{acl2020,anthology}\n\\bibliographystyle{acl_natbib}\n\\appendix\n\\newpage\n\\begin{table*}[t]\n\\centering\n\\footnotesize\n\\begin{tabular}{p{0.19\\textwidth}p{0.08\\textwidth}p{0.1\\textwidth}p{0.1\\textwidth}p{0.1\\textwidth}p{0.06\\textwidth}p{0.1\\textwidth}p{0.06\\textwidth}}\n\\toprule\n   & Scope & Input & Output  & Scalability & HITL & Supervision & Causation \\\\\n\\midrule\n\\rowcolor[HTML]{D9EAD3} \n\\multicolumn{8}{l}{\\cellcolor[HTML]{D9EAD3}\\textbf{Visualization}}                                                                                                                        \\\\\n\\rowcolor[HTML]{D9EAD3} \n  & local        & neuron                 & concept              & low         & yes  & no              & no            \\\\\n\\rowcolor[HTML]{D9EAD3} \n  &         &                  &               &           &    &                &             \\\\\n\\rowcolor[HTML]{A4C2F4} \n\\multicolumn{8}{l}{\\cellcolor[HTML]{A4C2F4}\\textbf{Corpus-based methods}}                                                              \n                                     \\\\\n\\multicolumn{8}{l}{\\cellcolor[HTML]{A4C2F4}{Concept Search}}                                                                                                                  \\\\\n\\rowcolor[HTML]{A4C2F4} \n\\cellcolor[HTML]{A4C2F4}     & global       & neuron                 & concept              & low         & yes  & no              & no            \\\\\n\\rowcolor[HTML]{A4C2F4}  \n  & global       & neuron                 & concept              & high        & no   & no              & no            \\\\\n\\rowcolor[HTML]{A4C2F4} \n\\multicolumn{8}{l}{\\cellcolor[HTML]{A4C2F4}{Neuron Search}}                                                                                                                  \\\\\n\\rowcolor[HTML]{A4C2F4} \n\\cellcolor[HTML]{A4C2F4}      & global       & concept                & neurons              & high        & no   & yes             & no            \\\\\n\\rowcolor[HTML]{EA9999} \n\\multicolumn{8}{l}{\\cellcolor[HTML]{EA9999}\\textbf{Probing-based methods}}                                                                                                            \\\\\n\\rowcolor[HTML]{EA9999} Linear      & global       & concept                & neurons              & high        & no   & yes             & no\n\\\\\n\\rowcolor[HTML]{EA9999} \nRandom Forest      & global       & concept                & neurons              & high        & no   & yes             & no            \\\\\n\\rowcolor[HTML]{EA9999} \nGaussian      & global       & concept                & neurons              & high        & no   & yes             & no            \\\\\n\\rowcolor[HTML]{D9D9D9} \n\\multicolumn{8}{l}{\\cellcolor[HTML]{D9D9D9}\\textbf{Causation-based methods}}                                                                                                              \\\\\n\\rowcolor[HTML]{D9D9D9} \nAblation       & both         & concept/ class         & neurons              & medium      & no   & no              & yes           \\\\\n\\rowcolor[HTML]{D9D9D9} \nKnowledge attribution     & local        & concept/ class         & neurons              & high        & no   & no              & yes           \\\\\n\\rowcolor[HTML]{FFE599} \n\\multicolumn{8}{l}{\\cellcolor[HTML]{FFE599}\\textbf{Miscellaneous methods}}                                                                                                                \\\\\n\\rowcolor[HTML]{FFE599} \nCorpus generation    & global       & neuron                 & concept              & low         & yes  & no              & no            \\\\\n\\rowcolor[HTML]{FFE599} \nMatrix factorization    & local        & neurons                      & neurons      & low         & yes  & no              & no            \\\\\n\\rowcolor[HTML]{FFE599} \nClustering       & global        & neurons                      & neurons      & high         & yes  & no    & no            \\\\\n\\rowcolor[HTML]{FFE599} \nMulti model search   & global       & neurons                & neurons              & high        & yes  & no              & no \\\\\n\\bottomrule\n\\end{tabular}\n\\caption{Comparison of neuron analysis methods based on various attributes. The exhaustive list of citations for each method are provided in the text.} \n\\label{tab:appendix:neuronmethods}\n\\end{table*}\n\\end{document}", "cites": [8598, 2911, 8599, 2912, 2910, 2913, 2914, 2909], "cite_extract_rate": 0.55, "origin_cites_number": 20, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 4.0, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section demonstrates strong synthesis by connecting multiple cited works to highlight limitations and opportunities in neuron-level interpretation. It critically evaluates the state of research, pointing out methodological gaps and suggesting alternative approaches like evolutionary algorithms. The section abstracts these findings into broader themes such as causal relations, model controllability, and the need for standardized benchmarks."}}
