{"id": "3f1ed082-d802-4718-be34-b43d0539bbf2", "title": "INTRODUCTION", "level": "section", "subsections": [], "parent_id": "c3fa99ba-0455-4503-afd1-855fc00c9941", "prefix_titles": [["title", "Deep Fake Detection : Survey of Facial Manipulation Detection Solutions"], ["section", "INTRODUCTION"]], "content": "}\nForgery and manipulation of multimedia like images and videos including facial information generated by digital manipulation, in particular with DeepFake methods, have become a great public concern recently ,  especially for public figures. The famous term “DeepFake” is referred to a deep learning-based technique able to create fake videos by manipulating features or swapping the face of a person by the face of another person. This term originated after a Reddit user named “deepfakes” claimed in late 2017 to have developed an algorithm that helped him to transpose celebrity faces into adult videos . Additionally, to fake pornography, some of the more harmful usages of such fake content include fake news, hoaxes, financial fraud, and defamation of the victim. Resulting in revitalizing general media forensics which is now dedicated to advance in detecting facial manipulation in image and video   .\\\\\nThe efforts in fake face detection are built on the foundation of the past research in biometric anti-spoofing and modern supervised deep learning  . The growing interest in manipulation detection is demonstrated through the increasing number of workshops in various top conferences. International projects such as MediFor funded by the DARPA, and competitions such as the Media Forensics Challenge and the Deepfake Detection Challenge launched by the National Institute of Standards and Technology (NIST) and Facebook, respectively. In the old days, the number and realism of the manipulations have been limited by the lack of advanced tools, domain expertise, and the complex and time-consuming process. For example, the early work in this domain  was able to modify the motion of the lip using a different audio track, by making connections between the soundtrack and the shape of the subject’s face. However, many things have evolved now since those experiments. Nowadays, it is becoming really easy to synthesize/generate non-existent faces or manipulate an existing face in an image/video, All of this is possible because of accessibility to large-scale public data, and the advancement in deep learning techniques that eliminate many manual steps such as Autoencoders (AE) and Generative Adversarial Networks (GAN) , . As a result, Much public software and mobile application (e.g FaceApp, etc) have been released giving access to everyone to create fake images and videos, without any experience in this domain. Therefore, to counter those advanced and realistic manipulated content, large efforts are being carried out by the research community to design improved methods for face manipulation detection. \\\\\nOver the past couple of years, huge steps forward in the field of automatic video editing techniques have been made and great interest has been shown towards methods for facial manipulation. For Instance, it is nowadays possible to easily perform facial reenactment, i.e. transferring the facial expressions between people. This enables to change of the identity of a speaker with almost no effort. Advancement in these Systems and tools for facial manipulations enables even users without any previous experience in digital arts to use them. Indeed, code and libraries that work in an almost automatic fashion are more and more often open sources. On one hand, this technological advancement opens the door to uncharted territories. And On the other hand, people are using these gifts in the worst possible ways for their reasons. \\\\\nIn this paper, We consider MesoNet, ResNet-50, VGG-19, Xception and comparing their characteristics to know which of these networks is the most efficient and accurate one on basis of different parameters like operation time, accuracy rate, loss rate, and ability to perform on random data. Training and Evaluation are performed on three datasets: Celeb-DF and Celeb-DF-v2, which has been proposed as a public benchmark; DFDC, which has been released as part of the DFDC Kaggle competition. Results show that the attention-based neural network modification helps the system in outperforming the baseline reported in the domain on all three datasets. Our paper makes contributions by Comparing the state-of-the-art neural networks like MesoNet, VGG-19, ResNet-50, and Xception performances in this domain and drawing the conclusion from the results to advance in media manipulation detection. Detailed evaluation of complex forgery detectors in various scenarios.\\\\", "cites": [7217, 329, 1600, 5680, 327], "cite_extract_rate": 0.45454545454545453, "origin_cites_number": 11, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 2.0, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section provides a general background on deep fake technologies and their societal implications, and mentions several cited works without deeply integrating or synthesizing their content. While it introduces key concepts from the cited papers (e.g., GANs, Autoencoders, and detection challenges), it does so in a largely descriptive manner without offering critical evaluation or abstraction into broader principles or trends."}}
{"id": "95839902-27a5-4270-b4d6-cee1448eaade", "title": "RELATED WORK", "level": "section", "subsections": [], "parent_id": "c3fa99ba-0455-4503-afd1-855fc00c9941", "prefix_titles": [["title", "Deep Fake Detection : Survey of Facial Manipulation Detection Solutions"], ["section", "RELATED WORK"]], "content": "}\nIn the last couple of years, several techniques for facial manipulation in media like images, video, etc have been successfully developed and are available to the public (i.e., FaceSwap, Face2Face, deepfake, etc.). This enables anyone to easily edit faces in video sequences with incredibly realistic results and very little effort. Moreover, the free access to large-scale public databases, together with the fast progress of deep learning techniques, in particular Generative Adversarial Networks, have led to the generation of very realistic fake content with its corresponding implications towards society in this era of fake news. Likewise, deepfake detection is also an important application of deep learning and machine learning which helps detect forgeries in media like images, and videos and a wide range of research has already been done that encompasses a comprehensive study and implementation of various popular algorithms.  where They tackle the problem of face manipulation detection in video sequences targeting modern facial manipulation techniques. In particular, the ensembling of different trained Convolutional Neural Network (CNN) models. In the proposed solution, different models are obtained starting from a base network making use of two different concepts, attention layers, and siamese training. They showed the community that combining these networks leads to promising face manipulation detection results on two publicly available datasets with more than 119000 videos. In  the authors survey the other popular techniques for manipulating face images including DeepFake methods, and methods to detect such manipulations. In particular, they reviewed four types of facial manipulation, entire face synthesis, identity swap (DeepFakes), attribute manipulation, and expression swap. For each of them, they provided details regarding manipulation techniques on existing open-source databases, including a summary of results from those evaluations. \\\\", "cites": [1602, 1601], "cite_extract_rate": 1.0, "origin_cites_number": 2, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.5, "critical": 2.0, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section provides a basic description of two papers, mentioning their approaches and contributions to deepfake detection and facial manipulation. It lists techniques and results but does not integrate them into a broader framework or compare them critically. There is minimal abstraction or synthesis beyond summarizing individual works."}}
{"id": "62eec432-4fd1-4bc6-925d-8801ee607789", "title": "METHODOLOGY", "level": "section", "subsections": [], "parent_id": "c3fa99ba-0455-4503-afd1-855fc00c9941", "prefix_titles": [["title", "Deep Fake Detection : Survey of Facial Manipulation Detection Solutions"], ["section", "METHODOLOGY"]], "content": "}\nThe comparison of the neural networks (MesoNet, ResNet-50, VGG-19, and Xception) is based on the characteristic chart of each network on common grounds like dataset, the number of epochs, complexity of the network, accuracy of each network, specification of the device (Ubuntu 20.04 LTS, 8 GB RAM, intel core i7 8th gen processor, NVIDIA GTX 1050Ti GPU) used to execute the program and runtime of the algorithm, under ideal condition. \\\\\n\\begin{flushleft}\n\\textbf{\\textit{A. \t\tDATASET}}\n\\end{flushleft}\nDeep Fake Detection is an expansive research area that already contains detailed ways of implementation which include major learning datasets, popular algorithms, features scaling, and feature extraction methods. Celeb-DF, Celeb-DF-v2, and DFDC datasets are datasets containing the real and manipulated videos of common people and public figures. Due to hardware limitations, we had to take only a small part of the datasets mentioned above. Celeb-DF \\& Celeb-DF-v2 are high-quality, large-scale challenging datasets for deepfake forensics. They contain DeepFake videos of celebrities generated using an improved synthesis process. The DFDC dataset was created by the companies to solve the deepfake detection problem and it is by far the largest currently and publicly available face swap video dataset, with over 100,000 total clips sourced from 3,426 paid actors, produced with several Deepfake, GAN-based, and non-learned methods. Celeb-DF contains a total of 1,171 videos out of which 376 are real and 795 are fake. whereas Celeb-DF-v2, DFDC contains 2,172 videos(890 real \\& 1,282 fake), and 910 videos(362 real \\& 548 fake) respectively. \\\\\n\\begin{flushleft}\n\\includegraphics[scale=0.30]{./datasetBar.pdf}\n\\end{flushleft}\n\\footnotesize Figure 1. Category wise number of videos in each dataset that we have used. \\\\\n\\begin{center}\n\\includegraphics[scale=0.30]{./dataset.pdf}\n\\footnotesize Figure 2. Some random snapshots of videos from each datasets (Celeb-DF, Celeb-DF-v2, and DFDC). \\\\\n\\end{center}\n\\begin{flushleft}\n\\textbf{\\textit{B.\t\tMESO NETWORK (MesoNet)}}\n\\end{flushleft}\nThis network is a derivation from well-performing networks for classification that alternate layers of convolutions, pooling, and a dense network for classification. This neural network comprises a sequence of four convolution layers and pooling and is followed by a fully connected dense layer with one hidden layer in between. The convolutional layers use ReLU as its activation functions that introduce non-linearities and Batch Normalization  to regularize their output which prevent the vanishing gradient problem, and the fully-connected layers use Dropout  to regularize which improve its robustness and taking generalization on another level .\n\\begin{center}\n\\includegraphics[scale=0.37]{./mesoNetArchitecture.pdf}\n\\end{center}\n\\footnotesize Figure 3. The network architecture of Meso-4. Layers and parameters. \\\\\n\\begin{flushleft}\n\\begin{normalsize}\n\\textbf{\\textit{C.\t\tRESIDUAL NETWORK (ResNet)}}\n\\end{normalsize}\n\\end{flushleft}\nResidual Network a.k.a ResNet50 is a variant of the ResNet model which consists of 48 Convolution layers along with 1 MaxPool and 1 Average Pool layer. It is capable of 3.8 billion Floating-point operations. Out of all other variants of residual network with different capabilities, this one widely used ResNet model and we have shown ResNet50 architecture in detail in Figure 4. Because of this framework, it is possible to train ultra DNN (deep neural networks) i.e. Now, the network can contain thousands of layers and still achieve great performance. The ResNets were initially applied to the image recognition task but as is mentioned in the paper that the framework can be used for non-computer vision tasks also to achieve better accuracy. Many people argued that simply stacking more layers also gives us better accuracy why was there a need for Residual learning for training ultra-deep neural networks but stacking more layer arises a serious problem of vanishing/exploding gradients, that is why ResNet is used in this paper so that we can assess it's effectiveness in deepfake detection problem .\n\\begin{center}\n\\includegraphics[scale=0.31]{./resnetArchitecture.pdf}\n\\end{center}\n\\footnotesize Figure 4. The architecture of the ResNet-50 with variable specification of the network.\\\\\n\\begin{flushleft}\n\\begin{normalsize}\n\\textbf{\\textit{D.\t\tVISUAL GEOMETRY GROUP NETWORK (VGG-19)}}\n\\end{normalsize}\n\\end{flushleft}\nVisual Geometry group network a.k.a VGG-19 is a variant of the VGG model which consists of 19 layers that include 16 convolution layers, 3 fully connected layers, 5 MaxPool layers, and 1 SoftMax layer. There are other variants of VGG like VGG-11, VGG-16, etc. VGG-19 has 19.6 billion Floating Operations. VGG is a deep CNN used to classify images . \\\\\n\\begin{center}\n\\includegraphics[scale=0.29]{./vggArchitecture.pdf}\n\\end{center}\n\\footnotesize Figure 5. The architectural design of VGG-19 Network. \\\\\n~ \\\\\n\\begin{flushleft}\n\\begin{normalsize}\n\\textbf{\\textit{E.\t\tXCEPTION NETWORK}}\n\\end{normalsize}\n\\end{flushleft}\nXception neural network was created by Google. It stands for Extreme Inception. It consists of a modified depth-wise separable convolution, it has shown even better results than Inception-v3. The original depthwise separable convolution is the depthwise convolution followed by a pointwise convolution but In Xception, modified depthwise separable convolution is the pointwise convolution followed by a depthwise convolution. This modification is motivated by the inception module in Inception-v3. The 14 modules are grouped into three groups viz. the entry flow, the middle flow, and the exit flow. And each of the groups has four, eight, and two modules respectively. The final group, i.e the exit flow, can optionally have fully connected layers at the end. This modification is the reason for the order of operation \\& the presence/absence of non-linearity. Due to this modified depthwise separable convolution, there is NO intermediate ReLU non-linearity. Moreover, Xception without any intermediate activation has the highest accuracy. \\\\\n\\begin{center}\n\\includegraphics[scale=0.30]{./xceptionArchitecture.pdf}\n\\end{center}\n\\footnotesize Figure 6. The architectural design of Xception Network.\n\\begin{flushleft}\n\\begin{normalsize}\n\\textbf{\\textit{F.\t\tOPTIMIZATION}}\n\\end{normalsize}\n\\end{flushleft}\nTensorRT is an SDK for deep learning which provides significantly low inference time, developed by NVIDIA. It contains an inference optimizer and a runtime that is capable of delivers significantly low latency and high throughput for deep learning inference applications. TensorRT-based applications are capable of performing up to a whopping 40 times faster than CPU-only platforms during inference. With TensorRT, you can optimize neural network models trained in all major frameworks, calibrate for lower precision with high accuracy, and deploy to hyper-scale data centers. TensorRT is built on CUDA®, NVIDIA’s parallel programming model which enables the model to efficiently utilize GPU resources, while also enables you to optimize inference leveraging libraries and development tools for artificial intelligence-related tasks. TensorRT provides INT8 and FP16 optimizations for production deployments of deep learning inference applications such as video streaming, speech recognition, recommendation, fraud detection, and natural language processing, to provide the models in class floating point precision. TensorRT achieves this by reducing precision inference significantly which in turn reduces application latency, which is a requirement for many real-time services, as well as autonomous and embedded applications.\n\\begin{flushleft}\n\\begin{normalsize}\n\\textbf{\\textit{G.\t\tVISUALIZATION}}\n\\end{normalsize}\n\\end{flushleft}\nIn this research, we have used multiple datasets (i.e. Celeb-DF, Celeb-DF-v2, and a part of DFDC dataset due to hardware limitations) to compare different neural networks (i.e. MesoNet, ResNet-50, VGG-19, and Xception) based on training \\& testing accuracy, training \\& testing loss, training time, inference time on CPU, GPU \\& after TRT optimization. To visualize the information obtained by the detailed analysis of algorithms we have used Line graphs and Tabular format charts using module matplotlib, which gives us the most precise visuals of the advances of the algorithms in classifying. The graphs are given at each vital part of the programs to give visuals of each part to bolster the outcome. \\\\", "cites": [1603, 71], "cite_extract_rate": 0.3333333333333333, "origin_cites_number": 6, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 2.0, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section primarily describes the neural networks (MesoNet, ResNet-50, VGG-19, and Xception) and datasets used in the study, with minimal synthesis of ideas across the cited works. It lacks critical evaluation or comparison of the methods in terms of strengths, weaknesses, or suitability for deepfake detection. The content remains concrete and system-specific, without abstracting broader patterns or principles in deepfake detection research."}}
{"id": "ca5a1cde-1df0-4136-a39a-59042dd7b68c", "title": "IMPLEMENTATION", "level": "section", "subsections": [], "parent_id": "c3fa99ba-0455-4503-afd1-855fc00c9941", "prefix_titles": [["title", "Deep Fake Detection : Survey of Facial Manipulation Detection Solutions"], ["section", "IMPLEMENTATION"]], "content": "}\nTo compare the networks based on working accuracy rate, loss, training time, complexity, and inference time, we have used four different classifiers: \\\\\n\\begin{itemize}\n\t\\item MesoNet Classifier \n\t\\item ResNet-50 : Residual Neural Network\n\t\\item VGG-19 : Visual Geometry Group Network\n\t\\item Xception\n\\end{itemize}\nAfter training the neural networks, we have optimized the models using TensorRT, to get the minimum inference time and maximum accuracy. We have encapsulated every information in Table 1. \\\\\n\\begin{table*}\n\\centering\n\\caption{Comparison Analysis of Different network.}\n\\begin{tabular}{|c|c|c|c|c|c|c|c|} \n\\hline\n\\multirow{2}{*}{Network Name} & \\multicolumn{2}{c|}{Training} & \\multicolumn{2}{c|}{Testing} & \\multicolumn{3}{c|}{Inference Time}   \\\\ \n\\cline{2-8}\n                              & ~~~ Accuracy ~~~ & ~~~ Loss ~~~   & ~~~ Accuracy ~~~  & ~~~ Loss ~~~   & ~~~ CPU ~~~  & ~~~ GPU ~~~  & ~~~ TRT Op ~~~   \\\\ \n\\hline\nMesoNet                       & 73.189\\%           & 25.83       & 72.39\\%          & 23.92       & 194 ms       & 180.7 ms    & 64.6 ms             \\\\ \n\\hline\nResNet-50                     & 75.26\\%            & 6.55        & 74.12\\%          & 15.05       & 1978 ms     & 1142.2 ms   & 789 ms             \\\\ \n\\hline\nVGG - 19                      & 74.92\\%           & 1.06        & 73.28\\%          & 3.39        & 302.2 ms    & 254.3 ms    & 113.9 ms             \\\\ \n\\hline\nXception                      & 77.83\\%           & 11.69       & 75.99\\%          & 16.11       & 1080 ms     & 1002.1 ms   & 976.2 ms             \\\\\n\\hline\n\\end{tabular}\n\\\\\n\\end{table*}\nWe have discussed in detail the implementation of each algorithm explicitly below to create a flow of this analysis for a fluent and accurate comparison.\\\\\n\\begin{flushleft}\n\\textbf{\\textit{I. \t\tDATASET HANDLING \\& PRE-PROCESSING}}\n\\end{flushleft}\nThe datasets we used in this paper (i.e. Celeb-DF, Celeb-DF-v2, and DFDC) are quite large and due to hardware limitations, we were unable to utilize the complete dataset. So, we took small chunks of the datasets. Now the challenge is to train the neural network on these video datasets. Now, we converted the videos into face images (we used the dlib library to extract images from frames). Overall, We have 51,036 images divided into two categories: Real (19,536 images) and Fake (31,500 images). Since we cannot store all this data for training into the memory, we used the ImageDataGenerator by TensorFlow to create batches of our dataset while training the network. Pre-processing is a crucial step in machine learning which focuses on improving the input data by reducing unwanted impurities and redundancy. To simplify and break down the input data we reshaped all the images present in the dataset in 2-dimensional images i.e (128,128,1). Each pixel value of the images lies between 0 to 255 so, we Normalized these pixel values by dividing them by 255.0 so that the input features will range between 0.0 to 1.0. \\\\\n\\begin{flushleft}\n\\textbf{\\textit{II. \tMESO NETWORK}}\n\\end{flushleft}\nThe MesoNet-4 used in this paper is a shallow convolutional neural network that was made for the sole purpose of detecting video forgery. In , Meso-4 and MesoInception-4 are classes capable of performing binary classification on a dataset. In this paper, we have used MesoNet-4 for the classification of deepfakes datasets. Various libraries and sub-modules of libraries like TensorFlow, TensorFlow.Keras.preprocessing, and matplotlib have been used for the implementation purpose. Firstly, we will download the datasets, followed by loading them using TensorFlow ImageDataGenerator and pre-processing the images while loading them in the network in batches to reduce the memory usage. After this, plotting of some samples of the dataset followed by normalization and scaling of features have been done. Finally, we have created our experimental model. \\\\\n\\begin{flushleft}\n\\textbf{\\textit{III. \tRESIDUAL NETWORK - 50}}\n\\end{flushleft}\nThe implementation of deepfake detection by ResNet-50 is done with the help of the TensorFlow module to create an MLP model of Sequential class and add the respective inbuilt model of resnet in TensorFlow to take an image of 128x128 pixel size as input. After creating a sequential model, we added a Global average pooling layer followed by a Dense layer. Once you have the training and test data, you can follow these steps to train a neural network in Tensorflow. We used a neural network with 50 hidden layers with multiple max-pooling layers and an output layer with 1 unit (i.e. total number of labels). The number of units in the hidden layers is standard. The input to the network is the 16,384-dimensional array converted from the 128×128 image. We used the Sequential model for building the network. In the Sequential model, we can just stack up layers by adding the desired layer one by one. We used the Dense layer, also called a fully connected layer. Apart from the Dense layer, we added the sigmoid activation function which is a common preference for the binary classification model.\n\\begin{flushleft}\n\\textbf{\\textit{IV. \tVISUAL GEOMETRY GROUP NETWORK - 19 }}\n\\end{flushleft}\nThe model implementation is done using Tensorflow as well. From it, we have used a Sequential class which allowed us to create a model layer-by-layer. The dimension of the input image is set to 128(Height), 128(Width), 3(Number of channels). Next, we added the standard vgg-19 model to this sequential model. The VGG-19 model consists of 19 layers with multiple pooling layers followed by 2 fully connected layers. The pooling layer  is used which reduces the dimensionality of the image and computation in the network. We have employed MAX-pooling which keeps only the maximum value from a pool. The convolution layer uses a matrix to convolve around the input data across its height and width and extract features from it. This matrix is called a Filter or Kernel. The values in the filter matrix are weights. We have used the standard filter of VGG-19. Stride determines the number of pixels shifts. Convolution of filter over the input data gives us activation maps whose dimension is given by the formula: ((N + 2P - F)/S) + 1 where N= dimension of input image, P= padding, F= filter dimension and S=stride. This model returns probability distribution over all the classes. The class with the maximum probability is the output.\n\\begin{flushleft}\n\\textbf{\\textit{V. \tXCEPTION NETWORK}}\n\\end{flushleft}\nThe xception network consists of 36 convolutional layers and its implementation is done using Tensorflow. From Tensorflow, we have used a Sequential class, the dimension of the input image is set to 128(Height), 128(Width), 3(Number of channels). Next, we load the inbuilt standard model of xception. The depthwise separable convolution layer is what powers the Xception. And it heavily uses that in its architecture. This type of convolution is similar to the extreme version of the Inception block. But differs slightly in its working. The effect of having activation on both the depthwise and pointwise steps in the DSC (i.e Deep Separate Convolution). And has observed that learning is faster when there’s no intermediate activation. For this network, we have followed the standard practice \\& configuration for training the model.", "cites": [1603], "cite_extract_rate": 0.5, "origin_cites_number": 2, "insight_result": {"type": "comparative", "scores": {"synthesis": 2.5, "critical": 2.0, "abstraction": 1.5}, "insight_level": "low", "analysis": "The section provides a factual comparison of four neural networks for deepfake detection, including training and inference metrics. It cites one paper briefly to mention MesoNet, but does not synthesize insights across multiple sources or provide deeper analysis. There is limited critical evaluation of the cited methods, and no abstraction or generalization of broader patterns or principles in facial manipulation detection."}}
