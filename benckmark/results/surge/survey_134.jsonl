{"id": "952136ee-ca21-47d9-b72c-e41afd33ec82", "title": "Introduction", "level": "section", "subsections": [], "parent_id": "9526fb53-fc6c-4198-91f0-7315cf30ae6c", "prefix_titles": [["title", "A Survey on Heterogeneous Graph Embedding"], ["section", "Introduction"]], "content": "\\label{sec:introduction}}\n\\IEEEPARstart{H}{eterogeneous} graphs (HGs) , which are capable of composing different types of entities (i.e., nodes) and relations, also known as heterogeneous information network, have become ubiquitous in real world scenarios, ranging from bibliographic networks, social networks to recommendation systems. For example, as shown in Fig. 1(a), a bibliographic network (i.e., academic network) can be represented by a HG, which consists of four types of nodes (author, paper, venue, and term) and three types of edges (author-write-paper, paper-contain-term and conference-publish-paper); and these basic relations can be further derived for more complex semantics over the HG (e.g., author-write-paper-contain-item). It has been well recognized that HG is a powerful model that is able to embrace rich semantics and structural information in real world data. Therefore, researches on HG data have been experiencing tremendous growth in data mining and machine learning, many of which have been successfully applied in real world systems such as recommendation , text analysis , and cybersecurity . \nDue to the ubiquity of HG data, how to learn embeddings of HG is a key research problem in various graph analysis applications, e.g., node/graph classification , and node clustering . Traditionally, to learn HG embeddings, matrix (e.g., adjacency matrix) factorization methods  have been proposed to generate latent-dimension features in a HG. However, the computational cost of decomposing a large-scale matrix is usually very expensive, and also suffers from its statistical performance drawback . To address this challenge, heterogeneous graph embedding (i.e., heterogeneous graph representation learning), aiming to learn a function that maps input space into a lower-dimension space while preserving the heterogeneous structure and semantics, has drawn considerable attentions in recent years. Although there have been ample studies of embedding technology on homogeneous graphs  which consist of only one type of nodes and edges, these techniques cannot be directly applicable to HGs due to the heterogeneity of HG data. More specifically, \ni) the structure in HG is usually semantic dependent, e.g., meta-path structure , implying that the local structure of one node in HG can be very different when considering different types of relations; \nii) different types of nodes and edges have different attributes, which are usually located in different feature spaces, and thus when designing heterogeneous graph embedding methods, especially heterogeneous graph neural networks (HGNNs), we need to overcome the heterogeneity of attributes to fuse information ;\niii) another one is that HG is usually application dependent: for example, the basic structure of HG usually can be captured by meta-path, however meta-path selection is still challenging in reality, which may need sufficient domain knowledge. \nTo tackle the above issues, various heterogeneous graph embedding methods have been proposed , many of which  have demonstrated the success of heterogeneous graph embedding techniques deployed in real world applications including recommendation systems , malware detection systems , and healthcare systems . \n\\begin{figure*}[!t]\n\t\\centering \n\t\\includegraphics[width=\\textwidth]{HIN.pdf}\n\t\\caption{An illustrative example of a heterogeneous graph. (a) An academic network including four types of node (i.e., Author, Paper, Venue, Term) and three types of link (i.e., Publish, Contain, Write). (b) Network schema of the academic network. (c) Two meta-paths used in the academic network (i.e., Author-Paper-Author and Paper-Term-Paper). (d) A meta-graph used in the academic network.}\n\t\\label{HIN_fig}\n\\end{figure*}\nAlthough ample studies of heterogeneous graph embedding have been conducted with various applications in different fields, there have not been systematic and comprehensive survey on heterogeneous graph embedding methods with in-depth analysis of their pros and cons and detailed discussion of their transformativeness and applicability. To bridge this gap, in this paper, we will thoroughly survey the existing works on heterogeneous graph embedding, including representative methods and techniques, deployed systems in real world applications, and publicly available benchmark datasets as well as open-source code/tools. In particular, (1) we will explore recent progress of heterogeneous graph embedding, by introducing its representative methods and techniques with analysis of their pros and cons; then (2) we will introduce and discuss the transformativeness of existing heterogeneous graph embedding methods that have been successfully deployed in real-world applications; afterwards (3) we will summarize publicly available benchmark datasets and open-source code/tools to facilitate researchers and practitioners for future heterogeneous graph embedding works; and finally (4) we will discuss the additional issues and challenges of heterogeneous graph embedding technique and forecast the future research directions in this area. Note that different from the existing surveys which mainly focus on homogeneous graph embedding , we aim at exploring the works on heterogeneous graph embedding. Although there have been few survey works on heterogeneous graph embedding , we make our unique contributions in this work as summarized below. \n\\begin{itemize}\n\t\\item We first discuss the unique challenges brought by the heterogeneity of HG compared with homogeneous graphs; and then we provide a comprehensive survey of existing heterogeneous graph embedding methods, which are categorized based on the information they used in the learning process to address particular type of challenges posed by the HG heterogeneity.\n    \\item For each representative heterogeneous graph embedding method and technique, we provide detailed introduction and further analyze its pros and cons. In addition, we explore the transformativeness and applicability of different types of HG embedding methods in the real-world industrial environments for the first time.\n\t\\item We summarize the open-source code and benchmark datasets, and give a detailed description to the existing graph learning platforms, to facilitate future research and applications in this area.\n\t\\item We also explore the additional issues and challenges of heterogeneous graph embedding and forecast the future research directions in this field.\n\\end{itemize}\nThe remainder of this survey paper is organized as follows. In Section 2, we first introduce the HG concepts and discuss the unique challenges of heterogeneous graph embedding due to the heterogeneity. In Section 3, we categorize and introduce heterogeneous graph embedding methods in details according to the information (e.g., structures, attributes, and application dependent domain knowledge) used in the learning process, based on which we analyze their pros and cons and then discuss their applicability. In Section 4, we further summarize the commonly used techniques in the state-of-the-art heterogeneous graph embedding methods. In Section 5, we further explore the transformativeness of existing heterogeneous graph embedding methods that have been successfully deployed in real-world application systems. Section 5 summarizes the benchmark datasets and open-source code/tools for heterogeneous graph embedding. Section 7 discusses additional issues/challenges of heterogeneous graph embedding and forecasts the future research directions in this field. Finally, Section 8 concludes the paper.", "cites": [1417, 1418, 219, 248, 8451, 553, 1419, 217, 212, 550, 1421, 215, 1420], "cite_extract_rate": 0.3939393939393939, "origin_cites_number": 33, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.5, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section synthesizes information from multiple cited papers to present a coherent narrative on the challenges and importance of heterogeneous graph embedding. It critically identifies key issues like semantic dependency, attribute heterogeneity, and application dependency, and positions its survey as filling a gap in the literature. It abstracts beyond individual papers to generalize the unique characteristics and requirements of HG embedding, offering a high-level analytical perspective."}}
{"id": "2f895674-d2db-4722-8687-0eef28c8b87a", "title": "Basic Concepts", "level": "subsection", "subsections": [], "parent_id": "1f36dd09-1cf3-4b38-a959-430b3478f634", "prefix_titles": [["title", "A Survey on Heterogeneous Graph Embedding"], ["section", "Preliminary"], ["subsection", "Basic Concepts"]], "content": "HG is a graph consisting of different types of entities (i.e., nodes) and/or different types of relations (i.e., edges), which can be defined as follows.\n\\begin{definition}\n\\noindent\n\\textbf{Heterogeneous graph (or heterogeneous information network)} . A HG is defined as a graph $\\mathcal{G}=\\{\\mathcal{V}, \\mathcal{E}\\}$, in which $\\mathcal{V}$ and $\\mathcal{E}$ represent the node set and the link set, respectively. Each node $v \\in \\mathcal{V}$ and each link $e \\in \\mathcal{E}$ are associated with their mapping function $\\phi(v): \\mathcal{V} \\to \\mathcal{A}$ and $\\varphi(e): \\mathcal{E} \\to \\mathcal{R}$. $\\mathcal{A}$ and $\\mathcal{R}$ denote the node types and link types, respectively, where $\\mathcal{A} + \\mathcal{R} > 2$. The \\textbf{network schema} for $\\mathcal{G}$ is defined as $\\mathcal{S}=(\\mathcal{A}, \\mathcal{R})$, which can be seen as a meta template of a heterogeneous graph $\\mathcal{G}=\\{\\mathcal{V}, \\mathcal{E}\\}$ with the node type mapping function $\\phi(v): \\mathcal{V} \\to \\mathcal{A}$ and the link type mapping function $\\varphi(e): \\mathcal{E} \\to \\mathcal{R}$. The network schema is a graph defined over node types $\\mathcal{A}$, with links as relations from $\\mathcal{R}$.\n\\label{HIN}\n\\end{definition}\nHG not only provides the graph structure of the data associations, but also provides a higher-level semantics of the data. An example of HG is illustrated in Fig. \\ref{HIN_fig}(a), which consists of four node types (author, paper, venue, and term) and three link types (author-write-paper, paper-contain-term, and conference-publish-paper); while Fig. \\ref{HIN_fig}(b) illustrates the network schema. Based on a constructed HG, to formulate the semantics of higher-order relationships among entities, meta-path  is further proposed whose definition is given below. \n\\begin{definition}\n\\textbf{Meta-path} . A meta-path $m$ is based on a network schema $\\mathcal{S}$, which is denoted as $m=A_{1}\\stackrel{R_{1}}{\\longrightarrow}A_{2}\\stackrel{R_{2}}{\\longrightarrow} \\cdots \\stackrel{R_{l}}{\\longrightarrow}A_{l+1}$ (simplified to $A_{1}A_{2} \\cdots A_{l+1}$) with node types $A_{1}, A_{2}, \\cdots ,A_{l+1} \\in \\mathcal{A}$ and link types $R_{1}, R_{2}, \\cdots R_{l} \\in \\mathcal{R}$.\n\\label{meta-path}\n\\end{definition}\nNote that different meta-paths describe semantic relationships in different views. For example, the meta-path of ``APA'' indicates the co-author relationship and ``APCPA'' represents the co-conference relation. Both of them can be used to formulate the relatedness over authors. Although meta-path can be used to depict the relatedness over entities, it fails to capture a more complex relationship, such as motifs . To address this challenge, meta-graph  is proposed to use a directed acyclic graph of entity and relation types to capture more complex relationship between two HG entities, defined as follows.\n\\begin{definition}\n\\textbf{Meta-graph} . A meta-graph $\\mathcal{T}$ can be seen as a directed acyclic graph (DAG) composed of multiple meta-paths with common nodes.\nFormally, meta-graph is defined as $\\mathcal{T}=(V_{\\mathcal{T}}, E_{\\mathcal{T}})$, where $V_{\\mathcal{T}}$ is a set of nodes and $E_{\\mathcal{T}}$ is a set of links. For any node $v \\in V_{\\mathcal{T}}, \\phi(v) \\in \\mathcal{A}$; for any link $e \\in E_{\\mathcal{T}}, \\varphi(e) \\in \\mathcal{R}$.\n\\label{metagraph}\n\\end{definition}\nAn example meta-graph is shown in Fig. \\ref{HIN}(d), which can be regarded as the combination of meta-path ``APA'' and ``APCPA'', reflecting a high-order similarity of two nodes. Note that a meta-graph can be symmetric or asymmetric . To learn embeddings of HG data, we formalize the problem of heterogeneous graph embedding as follow.\n\\begin{definition}\n\\textbf{Heterogeneous graph embedding} . Heterogeneous graph embedding aims to learn a function $\\Phi: \\mathcal{V} \\to \\mathbb{R}^{d}$ that embeds the nodes $v \\in \\mathcal{V}$ in HG into a low-dimensional Euclidean space with $d \\ll |\\mathcal{V}|$.\n\\label{HIN embedding}\n\\end{definition}\nTable 1 summarizes symbols used through this paper. \n\\begin{table}[htbp]\n  \\centering\n  \\caption{Notations and Explanations}\n    \\begin{tabular}{cc}\n    \\toprule\n    Notations & Explainations \\\\\n    \\midrule\n\t$d$\t\t\t\t\t\t& dimension of node embeddings \\\\\n\t$N$\t\t\t\t\t\t& Number of nodes \\\\\n\t$m$\t\t\t\t\t\t& Meta-path\\\\\n\t$\\mathbf{h}_{i}$\t\t& Attributes or embeddings of node $i$ \\\\\n    $\\mathbf{M}_{r}$\t\t& Relation-specific matrix of relation $r$ \\\\\n\t$w_{ij}$\t\t\t\t& Weight of link between node $i$ and node $j$ \\\\\n \t$S_{r}$\t\t\t\t\t& Heterogeneous similarity function with relation $r$ \\\\\n    $C_{t}(i)$\t\t\t\t& Context nodes of node $i$ with type $t$ \\\\\n \t$\\mathcal{N}_{i}$\t& Neighbors of node $i$ \\\\\n \t$\\sigma$\t\t\t\t& Sigmoid function \\\\\n \t$\\odot$\t\t\t\t\t& Hadamard product \\\\\n \t$\\oplus$\t\t\t\t& Concatenation operator\\\\\n    \\bottomrule\n    \\end{tabular}\n  \\label{notations}\n\\end{table}", "cites": [1421], "cite_extract_rate": 0.16666666666666666, "origin_cites_number": 6, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 1.5, "abstraction": 2.5}, "insight_level": "low", "analysis": "The section provides a factual summary of basic concepts in heterogeneous graph embedding, including definitions of HG, meta-path, and meta-graph. It integrates minimal content from the cited paper, primarily paraphrasing or listing ideas without deep synthesis or critical evaluation. While it introduces the problem formally, it lacks broader abstraction or analysis of trends in the literature."}}
{"id": "bb61faa4-fd45-45a7-8dc0-951adda5e2f3", "title": "Challenges of HG Embedding due to Heterogeneity", "level": "subsection", "subsections": [], "parent_id": "1f36dd09-1cf3-4b38-a959-430b3478f634", "prefix_titles": [["title", "A Survey on Heterogeneous Graph Embedding"], ["section", "Preliminary"], ["subsection", "Challenges of HG Embedding due to Heterogeneity"]], "content": "\\label{challenges}\nDifferent from homogeneous graph embedding , where the basic problem is preserving structure and property in node embedding . Due to the heterogeneity, heterogeneous graph embedding imposes more challenges, which are illustrated below.\n\\begin{figure*}[t]\n\t\\centering\n\t\\includegraphics[width=\\textwidth]{HINRL_mind.pdf}\n\t\\caption{An overview of heterogeneous graph embedding from the perspective of used information.}\n\t\\label{overview}\n\\end{figure*}\n\\begin{itemize}\n\t\\item \\textbf{Complex structure} (the complex HG structure caused by multiple types of nodes and edges). In a homogeneous graph, the fundamental structure can be considered as the so-called first-order, second-order, and even higher-order structure . All these structures are well defined and have good intuition. However, the structure in HG will dramatically change depending on the selected relations. Let's still take the academic network in Fig. 1(a) as an example, the neighbors of one paper will be authors with the ``write\" relation, while with ``contain\" relation, the neighbors become terms. Complicating things further, the combination of these relations, which can be considered as a higher-order structure in HG, will result in different and more complicated structures. Therefore, how to efficiently and effectively preserve these complex structures is of great challenge in heterogeneous graph embedding, while current efforts have been made towards the meta-path structure  and meta-graph structure , etc.\n\t\\item \\textbf{Heterogeneous attributes} (the fusion problem caused by the heterogeneity of attributes). Since the nodes and edges in a homogeneous graph have the same type, each dimension of the node or edge attributes has the same meaning. In this situation, node can directly fuse the attributes of its neighbors. However, in heterogeneous graph, the attributes of different types of nodes and edges may have different meanings . For example, the attributes of author can be the research fields, while paper may use keywords as attributes. Therefore, how to overcome the heterogeneity of attributes and effectively fuse the attributes of neighbors poses another challenge in heterogeneous graph embedding.\n\t\\item \\textbf{Application  dependent}. HG is closely related to the real world applications, while many practical problems remain unsolved. For example, constructing an appropriate HG may require sufficient domain knowledge in a real world application. Also, meta-path and/or meta-graph are widely used to capture the structure of HG. However, unlike homogeneous graph, where the structure (e.g., the first-order and second-order structure) is well defined, meta-path selection may also need prior knowledge. Furthermore, to better facilitate the real world applications, we usually need to elaborately encode the side information (e.g., node attributes)  or more advanced domain knowledge  to the heterogeneous graph embedding process. \n\\end{itemize}", "cites": [248, 282, 217, 1422, 218, 1419, 1423], "cite_extract_rate": 0.5384615384615384, "origin_cites_number": 13, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.5, "critical": 3.0, "abstraction": 3.0}, "insight_level": "medium", "analysis": "The section provides an analytical overview of the challenges in HG embedding, drawing on multiple cited papers to highlight issues like complex structure, heterogeneous attributes, and application dependency. While it integrates these ideas reasonably well, the synthesis could be deeper by explicitly connecting how different papers address or fail to address these challenges. Critical analysis is present but limited to pointing out limitations, without in-depth evaluation or contrast among methods."}}
{"id": "58c82ce9-4b68-42e0-a14b-80c412135169", "title": "Structure-preserved HG Embedding", "level": "subsection", "subsections": ["7fe4f84a-9095-4ad9-9090-0c4ed0a3aa76", "9069cba5-1600-4adc-8243-12b4cb5d343b", "9e4c7ee5-9644-4309-9ebf-c33d3f998382", "52a5af85-2321-4538-8d73-1e40deab9d15"], "parent_id": "32c48b46-7aa2-42d7-b8b8-0b7f3b7c16c5", "prefix_titles": [["title", "A Survey on Heterogeneous Graph Embedding"], ["section", "Method Taxonomy"], ["subsection", "Structure-preserved HG Embedding"]], "content": "\\label{structure}\nOne basic requirement of graph embedding is to preserve the graph structures properly . Accordingly, the homogeneous graph embedding pays more attention on higher-order graph structures, for example, second-order structures , high-order structures  and community structures .\nHowever, one typical characteristic of HG is that it contains multiple relations among nodes, which inevitably needs to consider the heterogeneity of graph. Therefore, an important direction of heterogeneous graph embedding is to learn semantic information from the graph structures. In this section, we review the typical heterogeneous graph embedding methods based on the basic HG structures, including link (i.e., edge), meta-path, and subgraph. Link is the observed relation between two nodes, meta-path is composed of different types of links and subgraph represents the tiny sub-structure of graph. The three structures are the most fundamental ingredients of HG, which are able to capture the semantic information from different perspectives. In the followings, we will review the typical structure-preserved heterogeneous graph embedding methods based on these three types of structures and then discuss their pros and cons.", "cites": [282, 217], "cite_extract_rate": 0.3333333333333333, "origin_cites_number": 6, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 2.0, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section provides a basic description of structure-preserved HG embedding, referencing general concepts from the cited survey and method papers. However, it lacks synthesis of ideas between the sources, critical evaluation of the approaches, and abstraction to broader principles or frameworks. The narrative remains primarily factual and introductory without deeper analysis or integration."}}
{"id": "7fe4f84a-9095-4ad9-9090-0c4ed0a3aa76", "title": "Link-based HG Embedding", "level": "subsubsection", "subsections": [], "parent_id": "58c82ce9-4b68-42e0-a14b-80c412135169", "prefix_titles": [["title", "A Survey on Heterogeneous Graph Embedding"], ["section", "Method Taxonomy"], ["subsection", "Structure-preserved HG Embedding"], ["subsubsection", "Link-based HG Embedding"]], "content": "One of the most basic information that heterogeneous graph embedding needs to preserve is link. Different from homogeneous graph, link in HG has different types and contains different semantics. To distinguish various types of links, one classical idea is to deal with them in different metric spaces, rather than a unified metric space. A representative work is PME , which treats each link type as a relation and uses a relation-specific matrix to transform the nodes into different metric spaces. In this way, nodes connected by different types of links can be close to each other in different metric spaces, thus capturing the heterogeneity of the graph. The distance function is defined as follows:\n\\begin{equation}\n\tS_{r}(v_{i},v_{j})=w_{ij}\\left\\| \\mathbf{M}_{r} \\mathbf{h}_{i} - \\mathbf{M}_{r} \\mathbf{h}_{j} \\right\\|_{2},\n\\label{eq_PME}\n\\end{equation}\nwhere $\\mathbf{h}_{i}$ and $\\mathbf{h}_{j} \\in \\mathbb{R}^{d \\times 1}$ denote the node embeddings of node $i$ and node $j$, respectively; $\\mathbf{M}_{r} \\in \\mathbb{R}^{d \\times d}$ is the projection matrix of relation $r$; and $w_{ij}$ represents the weight of link between node $i$ and node $j$. Note that Eq. \\ref{eq_PME} can be seen as a metric learning function:\n\\begin{equation}\n\t\\left\\| \\mathbf{M}_{r} ( \\mathbf{h}_{i} - \\mathbf{h}_{j} ) \\right\\|_{2} = \\sqrt{ ( \\mathbf{h}_{i} - \\mathbf{h}_{j} )^\\top \\mathbf{M}_{r}^\\top \\mathbf{M}_{r} ( \\mathbf{h}_{i} - \\mathbf{h}_{j} )},\n\\label{eq_metric}\n\\end{equation}\nwhere $\\mathbf{M}_{r}^\\top \\mathbf{M}_{r} \\in \\mathbb{R}^{d \\times d}$ is the metric matrix of Mahalanobis distance . PME considers the relations between nodes when minimizing the distance of them, thus capturing the heterogeneity of graph. The loss function is the margin-based triple loss function, which requires a distance between the positive and negative samples:\n\\begin{equation}\n\tL=\\sum_{r \\in \\mathcal{R}}\\sum_{(v_{i},v_{j}) \\in E_{r}}\\sum_{(v_{i},v_{k}) \\notin E_{r}}[\\xi + S_{r}(v_{i},v_{j})^2 - S_{r}(v_{i},v_{k})^2]_{+}\n\t\\label{loss_PME}\n\\end{equation}\nwhere $\\xi$ denotes the margin, $E_{r}$ represents the positive links of relation $r$, and $[z]_{+}=\\max(z,0)$. Through Eq. \\ref{loss_PME}, PME makes the node pairs connected by relation $r$ closer to each other than the node pairs without relation $r$.\nBy exploiting the relation-specific matrix to capture the link heterogeneity, different from PME, other methods have been proposed aiming to maximize the similarity of two nodes connected by specific relations. For example, EOE  and HeGAN  use the relation-specific matrix $\\mathbf{M}_{r}$ to calculate the similarity between two nodes, which can be formulated as:\n\\begin{equation}\n\\label{EOE}\n\tS_{r}(v_{i}, v_{j})=\\frac{1}{1+\\exp\\left\\{ -\\mathbf{h}^{\\top}_{i} \\mathbf{M}_{r} \\mathbf{h}_{j} \\right\\}}.\n\\end{equation}\nMore specifically, EOE is proposed to learn embeddings for coupled heterogeneous graphs, which consist of two different but related sub-graphs. It divides the links in HG into intra-graph links and inter-graph links. Intra-graph link connects two nodes with the same type, and inter-graph link connects two nodes with different types. To capture the heterogeneity in inter-graph link, EOE utilizes Eq. \\ref{EOE} as the similarity function of two nodes. Different from EOE, HeGAN uses generative adversarial networks (GAN)  to learn node embeddings for heterogeneous graph. It uses Eq. \\ref{EOE} as a discriminator to determine whether the node embeddings are produced by the generator. Through the game between discriminator and generator, HeGAN can learn more robust node embeddings.\nThe previously discussed methods mainly preserve the link structure based on either the distance or similarity function on node embeddings, while AspEM  and HEER  aim to maximize the probability of existing links. The heterogeneous similarity function is defined as:\n\\begin{equation}\n\tS_{r}=\\frac{\\exp(\\bm{\\mu}^{\\top}_{r}\\mathbf{g}_{ij})}{\\sum_{\\tilde{i} \\in E^{r}_{\\tilde{i}j}} \\exp(\\bm{\\mu}^{\\top}_{r}\\mathbf{g}_{\\tilde{i}j}) + \\sum_{\\tilde{j} \\in E^{r}_{i\\tilde{j}}} \\exp(\\bm{\\mu}^{\\top}_{r}\\mathbf{g}_{i\\tilde{j}})},\n\\end{equation}\nwhere $\\bm{\\mu}_{r} \\in \\mathbb{R}^{d \\times 1}$ is the embedding of relation $r$; $\\mathbf{g}_{ij} \\in \\mathbb{R}^{d \\times 1}$ is the embedding of link between node $i$ and node $j$; $\\mathbf{g}_{ij} = \\mathbf{h}_{i} \\odot \\mathbf{h}_{j}$ and $\\odot$ denotes the Hadamard product; and $E^{r}_{\\tilde{i}j}$ is the set of negative links, which indicates that there is no link between node $\\tilde{i}$ and node $j$. \nIt can be seen that $\\bm{\\mu}^{\\top}_{r}\\mathbf{g}_{ij}$ measures the closeness between link and its corresponding type. Maximizing $S_{r}$ enlarges the closeness between the existing links and their corresponding types, thus capturing the heterogeneity of the graph.\nIn addition to the above methods, there are some methods that draw on techniques from other fields. Similar to the idea of TransE , MELL  uses the equation 'head + relation = tail' to learn the node embeddings for heterogeneous graph. PTE  decomposes the heterogeneous graph into multiple bipartite graphs and employs LINE , which preserves the first- and second-order structures of graph, to learn node embeddings for each bipartite graph. MNE  assigns multiple embeddings for each node and uses a skip-gram technique  to represent information of multi-type relations into a unified space.\nIn summary, we can roughly divide the link-based heterogeneous graph embedding methods into two categories: one is to explicitly preserve the proximity of links ; the other is to preserve the proximity of nodes, which utilizes the information of links implicitly . These two types of methods both make use of the first-order information of HG.", "cites": [1155, 1684, 282, 1425, 1424], "cite_extract_rate": 0.38461538461538464, "origin_cites_number": 13, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.0, "abstraction": 3.5}, "insight_level": "medium", "analysis": "The section synthesizes several methods (PME, EOE, HeGAN, AspEM, HEER, MELL, PTE, MNE) and connects their approaches through the shared goal of preserving link-based structures in heterogeneous graphs, highlighting the use of relation-specific matrices and first-order proximity. It provides some critical evaluation by contrasting how different methods achieve their goals (e.g., distance-based vs. similarity-based vs. probabilistic). It abstracts by grouping the methods into two broad categories and identifying the use of first-order information as a common principle, though it does not fully develop a meta-level framework."}}
{"id": "9069cba5-1600-4adc-8243-12b4cb5d343b", "title": "Path-based HG Embedding", "level": "subsubsection", "subsections": [], "parent_id": "58c82ce9-4b68-42e0-a14b-80c412135169", "prefix_titles": [["title", "A Survey on Heterogeneous Graph Embedding"], ["section", "Method Taxonomy"], ["subsection", "Structure-preserved HG Embedding"], ["subsubsection", "Path-based HG Embedding"]], "content": "Link-based methods can only capture the local structures of HG, i.e., the first-order relation. In fact, the higher-order relation, describing more complex semantic information, is also critical for heterogeneous graph embedding.\nFor example, in Fig. \\ref{HIN}(a), the first-order relation can only reflect the similarity of author-paper, paper-term and paper-venue. While the similarity of author-author, paper-paper and author-conference cannot be well captured. Therefore, the high-order relation is introduced to measure more complex similarity. Because the number of high-order relations is very large, in order to reduce complexity, we usually choose the higher-order relations with rich semantics, called meta-path. In this section, we will introduce some representative meta-path-based heterogeneous graph embedding methods, which can be divided into two categories: random walk-based methods  and hybrid relation-based methods .\nRandom walk-based methods usually use meta-path to guide random walk on a HG, so that the generated node sequence contains rich semantic information. Through preserving the node sequence structure, node embedding can preserve both first-order and high-order proximity . A representative work is  metapath2vec  (shown in Fig. \\ref{mp2v}).\n\\begin{figure}[ht]\n\t\\centering\n\t\\includegraphics[scale=0.5]{metapath2vec.pdf}\n\t\\caption{The architecture of metapath2vec. Node sequence is generated under the meta-path PAP. It projects the embedding of the center node, e.g., $p_{2}$ into latent space and maximizes the probability of its meta-path-based context nodes, e.g., $p_{1}$, $p_{3}$, $a_{1}$ and $a_{2}$, appearing.}\n\t\\label{mp2v}\n\\end{figure}\nMetapath2vec  mainly uses meta-path guided random walk to generate heterogeneous node sequences with rich semantics; and then it designs a heterogeneous skip-gram technique to preserve the proximity between node $v$ and its context nodes, i.e., neighbors in the random walk sequences:\n\\begin{equation}\n\\mathop{\\arg}\\max_{\\theta} \\sum_{v \\in \\mathcal{V}} \\sum_{t \\in \\mathcal{A}} \\sum_{c_{t} \\in C_{t}(v)} \\log p(c_{t}|v;\\theta),\n\\label{mpobj}\n\\end{equation}\nwhere $C_{t}(v)$ represents the context nodes of node $v$ with type $t$. $p(c_{t}|v;\\theta)$ denotes the heterogeneous similarity function on node $v$ and its context neighbors $c_{t}$:\n\\begin{equation}\np(c_{t}|v;\\theta)=\\frac{e^{\\mathbf{h}_{c_{t}} \\cdot \\mathbf{h}_{v}}}{\\sum_{\\tilde{v} \\in \\mathcal{V}}e^{\\mathbf{h}_{\\tilde{v}} \\cdot \\mathbf{h}_{v}}},\n\\label{mpsim}\n\\end{equation}\nFrom the diagram shown in Fig. \\ref{mp2v}, Eq. \\ref{mpsim} needs to calculate the similarity between center node and its neighbors. Then  introduces a negative sampling strategy to reduce the computation. Hence, Eq. \\ref{mpsim} can be approximated as:\n\\begin{equation}\n\t\\log\\sigma(\\mathbf{h}_{c_{t}} \\cdot \\mathbf{h}_{v}) + \\sum_{q=1}^{Q} \\mathbb{E}_{\\tilde{v}^{q} \\sim P(\\tilde{v})} \\left[ \\log\\sigma \\left(- \\mathbf{h}_{\\tilde{v}^{q}} \\cdot \\mathbf{h}_{v} \\right) \\right],\n\\end{equation}\nwhere $\\sigma(\\cdot)$ is the sigmoid function, and $P(\\tilde{v})$ is the distribution in which the negative node $\\tilde{v}^{q}$ is sampled for $Q$ times. Through the strategy of negative sampling, the time complexity is greatly reduced. However, when choosing the negative samples, metapath2vec does not consider the types of nodes, i.e., different types of nodes are from the same distribution $P(\\tilde{v})$. It further designs metapath2vec++, which samples the negative nodes of the same type as the central node, i.e., $\\tilde{v}_{t}^{q} \\sim P(\\tilde{v}_{t})$. The formulation can be rewritten as:\n\\begin{equation}\n\t\\log\\sigma(\\mathbf{h}_{c_{t}} \\cdot \\mathbf{h}_{v}) + \\sum_{q=1}^{Q} \\mathbb{E}_{\\tilde{v}_{t}^{q} \\sim P(\\tilde{v}_{t})} \\left[ \\log\\sigma \\left(- \\mathbf{h}_{\\tilde{v}_{t}^{q}} \\cdot \\mathbf{h}_{v} \\right) \\right].\n\\end{equation}\nAfter minimizing the objective function, metapath2vec and metapath2vec++ can capture both structural information and semantic information effectively and efficiently.\nBased on metapath2vec, a series of variants have been proposed.\nSpacey  designs a heterogeneous spacey random walk to unify different meta-paths with a second-order hyper-matrix to control the transition probability among different node types. JUST  proposes a random walk method with Jump and Stay strategies, which can flexibly choose to change or maintain the type of the next node in the random walk without meta-path. BHIN2vec  proposes an extended skip-gram technique to balance the various types of relations. It treats heterogeneous graph embedding as a multiple relation-based tasks, and balances the influence of different relations on node embeddings by adjusting the training ratio of different tasks. HHNE  conducts the meta-path guided random walk in hyperbolic spaces , where the similarity between nodes can be measured using hyperbolic distance. In this way, some properties of HG, e.g., hierarchical and power-law structure, can be naturally reflected in the learned node embeddings.\nDifferent from random walk-based methods that learn structural and semantic information from generated node sequences, some methods use the combination of first-order relation and high-order relation (i.e., meta-path) to capture the heterogeneity of HG. We call these work as hybrid relation-based methods. A typical work is HIN2vec  (shown in Fig. \\ref{HIN2vec}), which carries out multiple relation prediction tasks jointly to learn the embeddings of nodes and meta-paths.\n\\begin{figure}[ht]\n\\centering\n\\includegraphics[width=\\linewidth]{HIN2vec.pdf}\n\\caption{The architecture of HIN2vec. Through the parameter matrices $\\mathbf{W}_{I}, \\mathbf{W}_{J}$ and $\\mathbf{W}_{R}$, the one-hot vectors of node $i$, node $j$ and relation $r$ are projected into dense vectors. And these three vectors are fused by a neural network to predict whether node $i$ and $j$ are connected by relation $r$.}\n\\label{HIN2vec}\n\\end{figure}\nThe purpose of HIN2vec is to predict whether two nodes are connected by a meta-path, which can be seen as a multi-label classification task. As illustrated in Fig. \\ref{HIN2vec}, given two nodes $i$ and $j$, HIN2vec uses the following function to compute their similarity under the hybrid relation $r$:\n\\begin{equation}\n\tS_{r}(v_i, v_j)=\\sigma(\\sum \\mathbf{W}_{I}\\vec{i} \\odot \\mathbf{W}_{J}\\vec{j} \\odot f_{01}(\\mathbf{W}_{R}\\vec{r})),\n\\end{equation}\nwhere $\\vec{i}, \\vec{j}$ and $\\vec{r} \\in \\mathbb{R}^{N \\times 1}$ denote the one-hot vectors of nodes and relation, respectively; $\\mathbf{W}_{I}, \\mathbf{W}_{J}$ and $\\mathbf{W}_{R} \\in \\mathbb{R}^{d \\times N}$ are the mapping matrices; and $f_{01}(\\cdot)$ is a regularization function, which limits the embedding values between 0 and 1. The loss function is a binary cross-entropy loss:\n\\begin{equation}\n\tE^{r}_{ij}\\log S_{r}(v_i, v_j) + [1-E^{r}_{ij}]\\log [1-S_{r}(v_i, v_j)],\n\\end{equation}\nwhere $E^{r}_{ij}$ denotes the set of positive links. After minimizing the loss function, HIN2vec can learn the embedding of nodes and relations (meta-paths). Besides, in the relation set $R$, it contains not only the first-order structures (e.g., A-P relation) but also the high-order structures (e.g., A-P-A relation). Therefore, the node embeddings can capture different semantics.\nRHINE  is another hybrid relation-based method, which designs different distance functions for different relations, thus enhancing the expressive power of node embeddings. It divides the relations into two categories: Affiliation Relations (ARs) and Interaction Relations (IRs). For ARs, a Euclidean distance function is introduced; while for IRs, RHINE proposes a translation-based distance function. Through the combination of these two distance functions, RHINE can learn relation structure-aware heterogeneous node embeddings.\nIn sum, we can find that random walk-based methods mainly exploit meta-path guided strategy for heterogeneous graph embedding; while hybrid relation-based methods regard a meta-path as high-order relation and learn meta-path based embeddings simultaneously. Compared with random walk-based methods, hybrid relation-based methods can simultaneously integrate multiple meta-paths into heterogeneous graph embedding flexibly.", "cites": [1426, 1684, 1427, 8452], "cite_extract_rate": 0.4444444444444444, "origin_cites_number": 9, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.5, "abstraction": 3.5}, "insight_level": "medium", "analysis": "The section provides a coherent synthesis of path-based HG embedding methods by categorizing them into random walk-based and hybrid relation-based approaches. It integrates insights from multiple cited papers to highlight how meta-paths and different modeling strategies (e.g., Spacey random walk, translation-based distance) contribute to capturing heterogeneous semantics. The analysis includes some critical observations, such as the lack of node-type consideration in negative sampling of metapath2vec, but could offer more nuanced comparison of trade-offs across methods. It identifies broader patterns in the design of HG embedding techniques, particularly in how they handle first-order and high-order relations."}}
{"id": "9e4c7ee5-9644-4309-9ebf-c33d3f998382", "title": "Subgraph-based HG Embedding", "level": "subsubsection", "subsections": [], "parent_id": "58c82ce9-4b68-42e0-a14b-80c412135169", "prefix_titles": [["title", "A Survey on Heterogeneous Graph Embedding"], ["section", "Method Taxonomy"], ["subsection", "Structure-preserved HG Embedding"], ["subsubsection", "Subgraph-based HG Embedding"]], "content": "Subgraph represents a more complex structure in the graph. Incorporating subgraphs into graph embedding can significantly improve the ability of capturing complex structural relationships. In this section, we introduce two widely used subgraphs in HG: one is metagraph, which reflects the high-order similarity between nodes ; the other is the hyperedge\\footnotemark[1], which connects a series of closely related nodes and preserves the indecomposablity among them .\n\\footnotetext[1]{In this paper, we treat the hyperedge as a special kind of subgraph.}\nZhang \\emph{et al.} propose metagraph2vec , which uses a metagraph-guided random walk to generate heterogeneous node sequence. \nThen the heterogeneous skip-gram technique  is employed to learn the node embeddings. Based on this strategy, metagraph2vec can capture the rich structural information and high-order similarity among nodes.\nDifferent from metagraph2vec that only uses metagraphs in the pre-processing step (i.e., metagraph-guided random walk), mg2vec  aims to learn the embeddings for metagraphs and nodes jointly, so that the metagraphs can join the learning process. It first enumerates the metagraphs and then preserves the proximity between nodes and metagraphs:\n\\begin{equation}\n\tP(\\mathbf{M}_{i}|v)=\\frac{\\exp (\\mathbf{M}_{i} \\cdot \\mathbf{h}_{v})}{\\sum_{M_{j} \\in \\mathcal{M}} \\exp (\\mathbf{M}_{j} \\cdot \\mathbf{h}_{v})},\n\\end{equation}\nwhere $\\mathbf{M}_{i}$ is the embedding of metagraph $i$ and $\\mathcal{M}$ denotes the set of metagraphs. Clearly, $P(M_{i}|v)$ represents the first-order relationship between the nodes and its subgraphs. Further, mg2vec preserves the proximity between node pair and its subgraph to capture the second-order information:\n\\begin{equation}\n\tP(\\mathbf{M}_{i}|u, v)=\\frac{\\exp (\\mathbf{M}_{i} \\cdot f(\\mathbf{h}_{u}, \\mathbf{h}_{v}))}{\\sum_{M_{j} \\in \\mathcal{M}} \\exp (\\mathbf{M}_{j} \\cdot f(\\mathbf{h}_{u}, \\mathbf{h}_{v}))},\n\\end{equation}\nwhere $f(\\cdot)$ is a neural network to learn the embeddings of node pairs.\nThrough preserving the first-order and second-order proximity between nodes and metagraphs, mg2vec can capture the structural information and the similarity between nodes and metagraphs.\nDHNE  is a typical hyperedge-based graph embedding method. Specifically, it designs a novel deep model to produce a non-linear tuple-wise similarity function while capturing the local and global structures of a given HG. Taking a hyperedge with three nodes $a, b$ and $c$ as an example. The first layer of DHNE is an autoencoder, which is used to learn latent embeddings and preserve the second-order structures of graph . The second layer is a fully connected layer with embedding concatenated:\n\\begin{equation}\n\t\\mathbf{L}=\\sigma(\\mathbf{W}_{a}\\mathbf{h}_{a} \\oplus \\mathbf{W}_{b}\\mathbf{h}_{b} \\oplus \\mathbf{W}_{c}\\mathbf{h}_{c}),\n\\end{equation}\nwhere $\\mathbf{L}$ denotes the embedding of the hyperedge; $\\mathbf{h}_{a}, \\mathbf{h}_{b}$ and $\\mathbf{h}_{c} \\in \\mathbb{R}^{d \\times 1}$ are the embeddings of node $a$, $b$ and $c$ learn by the autoencoder. $\\mathbf{W}_{a}, \\mathbf{W}_{b}$ and $\\mathbf{W}_{c} \\in \\mathbb{R}^{d' \\times d}$ are the transformation matrices for different node types. Finally, the third layer is used to calculate the indecomposability of the hyperedge:\n\\begin{equation}\n\t\\mathcal{P}=\\sigma(\\mathbf{W}*\\mathbf{L}+\\mathbf{b}),\n\\end{equation}\nwhere $\\mathcal{P}$ denote the indecomposability of the hyperedge; $\\mathbf{W} \\in \\mathbb{R}^{1 \\times 3d'}$ and $\\mathbf{b} \\in \\mathbb{R}^{1 \\times 1}$ are the weight matrix and bias, respectively. A higher value of $\\mathcal{P}$ means these nodes are from the existing hyperedges, otherwise it should be small.\nHEBE  is another hyperedge-based method, which aims to maximize the proximity between the node and the hyperedge it belongs to. After maximizing the proximity, HEBE can preserve the similarity of nodes within the same hyperedge, while reduce the similarity of nodes from different hyperedges. Besides,  proposes hyper-path-based random walk to preserve both the structural information and indecomposability of the hyper-graphs.\nCompared with the structures of link and meta-path, subgraph (with two representative forms of meta-graph and hyperedge) usually contains much higher order structural and semantic information. However, one obstacle of subgraph-based heterogeneous graph embedding methods is the high complexity of subgraph. How to balance the effectiveness and efficiency is required for a practical subgraph-based heterogeneous graph embedding methods, which is worthy of further exploration.", "cites": [1428, 282, 1422, 7355], "cite_extract_rate": 0.5714285714285714, "origin_cites_number": 7, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.5, "critical": 2.5, "abstraction": 3.0}, "insight_level": "medium", "analysis": "The section synthesizes information on subgraph-based HG embedding methods by integrating metagraph and hyperedge approaches from multiple papers. It provides a structured comparison of techniques like metagraph2vec, mg2vec, and DHNE, showing analytical insight into their mechanisms. However, it lacks deeper critical evaluation of their limitations and broader theoretical generalization, which limits its insight level to medium."}}
{"id": "52a5af85-2321-4538-8d73-1e40deab9d15", "title": "Summary", "level": "subsubsection", "subsections": [], "parent_id": "58c82ce9-4b68-42e0-a14b-80c412135169", "prefix_titles": [["title", "A Survey on Heterogeneous Graph Embedding"], ["section", "Method Taxonomy"], ["subsection", "Structure-preserved HG Embedding"], ["subsubsection", "Summary"]], "content": "Generally, structure-preserved heterogeneous graph embedding methods mainly use shallow models, i.e., models without non-linear activation and multiple transformation. A major advantage of this type of methods is that they have good parallelizability and can improve training speed through negative sampling . However, as we can seen, there has been increasingly advanced structural and semantic information from link to path to subgraph, which may improve the performance in nature, but it also requires more calculations. Besides, there are two serious problems: one is that the shallow models need to assign each node a low-dimensional embedding, which requires larger memory spaces to store the parameters. Another is that shallow models can only work on transductive setting, i.e., they cannot learn the embedding of new node. These two shortcomings limit the application of this kind of methods in large-scale industrial scenarios.", "cites": [1684], "cite_extract_rate": 1.0, "origin_cites_number": 1, "insight_result": {"type": "analytical", "scores": {"synthesis": 2.5, "critical": 3.0, "abstraction": 3.0}, "insight_level": "medium", "analysis": "The section provides a concise analytical overview of structure-preserved HG embedding methods, highlighting their use of shallow models and associated limitations such as memory consumption and transductive constraints. While it draws on one cited paper to support the discussion on training speed improvements via negative sampling, the synthesis remains limited to a single source. The analysis is clear and identifies key issues, but deeper connections or comparisons across multiple papers are not fully developed."}}
{"id": "1206051b-c827-4056-9bd9-e456d224f536", "title": "Unsupervised HGNNs", "level": "subsubsection", "subsections": [], "parent_id": "dfe7398d-2680-433e-8824-1178a7ab6c53", "prefix_titles": [["title", "A Survey on Heterogeneous Graph Embedding"], ["section", "Method Taxonomy"], ["subsection", "Attribute-assisted HG Embedding"], ["subsubsection", "Unsupervised HGNNs"]], "content": "Unsupervised HGNNs aim to learn node embeddings with good generalization. To this end, they always utilize the interactions among different types of attributes to capture the potential commonalities.\nHetGNN  is the representative work of unsupervised HGNNs. It consists of three parts: content aggregation, neighbor aggregation and type aggregation.\nContent aggregation is designed to learn fused embeddings from different node contents, such as images, text or attributes:\n\\begin{equation}\n\tf_{1}(v)=\\frac{\\sum_{i \\in C_{v}}[ \\overrightarrow{LSTM} \\{ \\mathcal{FC}(\\mathbf{h}_{i}) \\} \\oplus \\overleftarrow{LSTM} \\{ \\mathcal{FC}(\\mathbf{h}_{i}) \\} ]}{|C_{v}|},\n\\end{equation}\nwhere $C_{v}$ is the type of node $v$'s attributes. $\\mathbf{h}_{i}$ is the $i$-th attributes of node $v$. A bi-directional Long Short-Term Memory (Bi-LSTM)  is used to fuse the embeddings learned by multiple attribute encoder $\\mathcal{FC}$. Neighbor aggregation aims to aggregate the nodes with same type by using a Bi-LSTM to capture the position information:\n\\begin{equation}\n\tf_{2}^{t}(v)=\\frac{\\sum_{v^{'} \\in N_{t}(v)}[\\overrightarrow{LSTM}\\{f_{1}(v^{'})\\} \\oplus \\overleftarrow{LSTM}\\{f_{1}(v^{'})\\}]}{|N_{t}(v)|},\n\\end{equation}\nwhere $N_{t}(v)$ is the first-order neighbors of node $v$ with type $t$. Type aggregation uses an attention mechanism to mix the embeddings of different types and produces the final node embeddings. \n\\begin{equation}\n\t\\mathbf{h}_{v}=\\alpha^{v,v}f_{1}(v)+\\sum_{t \\in O_{v}}\\alpha^{v,t}f_{2}^{t}(v).\n\\end{equation}\nwhere $\\mathbf{h}_{v}$ is the final embedding of node $v$. $O_{v}$ denotes the set of node types. Finally, a heterogeneous skip-gram loss is used as the unsupervised graph context loss to update the node embeddings. Through the three aggregation methods, HetGNN can preserve the heterogeneity of both graph structures and node attributes.\nOther unsupervised methods either capture the heterogeneity of node attributes or the heterogeneity of graph structures. HNE  is proposed to learn embeddings for the cross-model data in HG, but it ignores the various types of links. SHNE  focuses on capturing the semantic information of nodes by designing a deep semantic encoder with gated recurrent units (GRU) . Although it uses heterogeneous skip-gram to preserve the heterogeneity of graph, SHNE is designed specifically for text data. Cen \\emph{et al.} propose GATNE , which aims to learn node embeddings in multiplex graph, i.e., a heterogeneous graph with different types of edges. Compared with HetGNN, GATNE pays more attention to distinguishing different link relationships between the node pairs.", "cites": [7356, 39, 1429], "cite_extract_rate": 0.5, "origin_cites_number": 6, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.5, "critical": 2.0, "abstraction": 2.3}, "insight_level": "low", "analysis": "The section primarily describes the structure and components of HetGNN, GATNE, HNE, and SHNE, with limited synthesis beyond listing their features. It mentions some distinctions between methods (e.g., GATNE focusing on link relationships), but lacks deeper integration of concepts from the cited works. There is minimal critical analysis or abstraction to broader patterns or principles in unsupervised HGNNs."}}
{"id": "71daaab9-21d2-476f-a26e-8b74a6d76135", "title": "Semi-supervised HGNNs", "level": "subsubsection", "subsections": [], "parent_id": "dfe7398d-2680-433e-8824-1178a7ab6c53", "prefix_titles": [["title", "A Survey on Heterogeneous Graph Embedding"], ["section", "Method Taxonomy"], ["subsection", "Attribute-assisted HG Embedding"], ["subsubsection", "Semi-supervised HGNNs"]], "content": "Different from unsupervised HGNNs, semi-supervised HGNNs aim to learn task-specific node embeddings in an end-to-end manner. For this reason, they prefer to use attention mechanism to capture the most relevant structural and attribute information to the task.\nWang \\emph{et al.}  propose heterogeneous graph attention network (HAN), which uses a hierarchical attention mechanism to capture both node and semantic importance. The architecture of HAN is shown in Fig. \\ref{HAN}. \n\\begin{figure}[ht]\n\t\\center\n\t\\includegraphics[width=\\linewidth]{HAN.png}\n\t\\caption{The architecture of HAN . The whole model can be divided into three parts: Node-Level Attention aims to learn the importance of neighbors' features. Semantic-Level Attention aims to learn the importance of different meta-paths. Prediction layer utilizes the labeled nodes to update the node embeddings.}\n\t\\label{HAN}\n\\end{figure}\nIt consists of three parts: node-level attention, semantic-level attention and prediction. Node-level attention aims to utilize self-attention mechanism  to learn the importances of neighbors in a certain meta-path:\n\\begin{equation}\n\t\\alpha_{ij}^{m}=\\frac{\\exp(\\sigma(\\mathbf{a}_{m}^{\\mathrm{T}} \\cdot [\\mathbf{h}_{i}^{'} \\| \\mathbf{h}_{j}^{'}]))}{\\sum_{k \\in \\mathcal{N}_{i}^{m}} \\exp(\\sigma(\\mathbf{a}_{m}^{\\mathrm{T}} \\cdot [\\mathbf{h}_{i}^{'} \\| \\mathbf{h}_{k}^{'}]))},\n\\end{equation}\nwhere $\\mathcal{N}_{i}^{m}$ is the neighbors of node $i$ in meta-path $m$, $\\alpha_{ij}^{m}$ is the weight of node $j$ to node $i$ under meta-path $m$. The node-level aggregation is defined as:\n\\begin{equation}\n\t\\mathbf{h}_{i}^{m}=\\sigma \\left(\\sum_{j \\in \\mathcal{N}_{i}^{m}}\\alpha_{ij}^{m} \\cdot \\mathbf{h}_{j} \\right),\n\\end{equation}\nwhere $\\mathbf{h}_{i}^{m}$ denotes the learned embedding of node $i$ based on meta-path $m$. Because different meta-paths capture different semantic information of HG, a semantic-level attention mechanism is designed to calculated the importance of meta-paths. Given a set of meta-paths $\\{m_{0},m_{1}, \\cdots, m_{P}\\}$, after feeding node features into node-level attention, it has $P$ semantic-specific node embeddings $\\{\\mathbf{H}_{m_{0}},\\mathbf{H}_{m_{1}}, \\cdots, \\mathbf{H}_{m_{P}}\\}$. To effectively aggregate different semantic embeddings, HAN designs a semantic-level attention mechanism:\n\\begin{equation}\n\tw_{m_{i}}=\\frac{1}{|\\mathcal{V}|}\\sum_{i \\in \\mathcal{V}}\\mathbf{q}^{\\mathrm{T}} \\cdot \\tanh(\\mathbf{W} \\cdot \\mathbf{h}_{i}^{m} + \\mathbf{b}),\n\\end{equation}\nwhere $\\mathbf{W} \\in \\mathbb{R}^{d' \\times d}$ and $\\mathbf{b} \\in \\mathbb{R}^{d' \\times 1}$ denote the weight matrix and bias of the MLP, respectively. $\\mathbf{q} \\in \\mathbb{R}^{d' \\times 1}$ is the semantic-level attention vector. In order to prevent the node embeddings from being too large, HAN uses the softmax function to normalize $w_{m_{i}}$. Hence, the semantic-level aggregation is defined as:\n\\begin{equation}\n\t\\mathbf{H}=\\sum_{i=1}^{P}\\beta_{m_{i}} \\cdot \\mathbf{H}_{m_{i}},\n\\end{equation}\nwhere $\\beta_{m_{i}}$ denotes the normalized $w_{m_{i}}$, which represents the semantic importance. $\\mathbf{H} \\in \\mathbb{R}^{N \\times d}$ denotes the final node embeddings. Finally, a task-specific layer is used to fine-tune the node embeddings with a small number of labels and the embeddings $\\mathbf{H}$ can be used in the downstream tasks, such as node clustering and link prediction. HAN is the first to extend GNN to the heterogeneous graph and design a hierarchical attention mechanism, which can capture both structural and semantic information.\nSubsequently, a series of attention-based HGNNs was proposed . MAGNN  designs intra-metapath aggregation and inter-metapath aggregation. The former samples some meta-path instances surrounding the target node and uses an attention layer to learn the importance of different instances, and the latter aims to learn the importance of different meta-paths. HetSANN  and HGT  treat one type of node as query to calculate the importance of other types of nodes around it, through which the method can not only capture the interactions among different types of nodes, but also assign different weights to neighbors during aggregation.  uses meta-paths as virtual edges to enhance the performance of graph attention operator.\nIn addition, there are some HGNNs that focus on other issues. NSHE  proposes to incorporate network schema, instead of meta-path, in aggregating neighborhood information. GTN  aims to automatically identify the useful meta-paths and high-order links in the process of learning node embeddings. RSHN  uses both original node graph and coarsened line graph to design a relation-structure aware HGNN. RGCN  uses multiple weight matrices to project the node embeddings into different relation spaces, thus capturing the heterogeneity of the graph.", "cites": [248, 1431, 1103, 1183, 259, 1430, 38], "cite_extract_rate": 0.7, "origin_cites_number": 10, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.5, "critical": 2.0, "abstraction": 2.5}, "insight_level": "medium", "analysis": "The section provides a clear description of semi-supervised HGNNs, focusing on the HAN model and its hierarchical attention mechanism. It integrates some concepts from other cited papers (e.g., MAGNN, HetSANN, HGT), but the synthesis is limited to listing components and methods without deeper connections or a unifying framework. The content is largely descriptive with minimal critical evaluation or identification of broader trends."}}
{"id": "67784c9d-2609-4c24-9dff-b19068a9a65c", "title": "Summary", "level": "subsubsection", "subsections": [], "parent_id": "dfe7398d-2680-433e-8824-1178a7ab6c53", "prefix_titles": [["title", "A Survey on Heterogeneous Graph Embedding"], ["section", "Method Taxonomy"], ["subsection", "Attribute-assisted HG Embedding"], ["subsubsection", "Summary"]], "content": "As we can see that there are two ways to solve the heterogeneity of attributes: one is to use different encoders or type-specific transformation matrices to map the different attributes into a same space, such as . Another is to treat meta-path as a special edge to connect the nodes with same type, such as . Compared with shallow models, HGNNs have an obvious advantage that they have the ability of inductive learning, i.e., learning embeddings for the out-of-sample nodes . Besides, HGNNs need smaller memory space because they only need to store model parameters. These two reasons are important for the real-world applications. However, they still suffer from the huge time costing in inferencing and retraining.", "cites": [248, 1430], "cite_extract_rate": 0.4, "origin_cites_number": 5, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.0, "critical": 2.5, "abstraction": 2.5}, "insight_level": "medium", "analysis": "The section provides a basic synthesis of two approaches to attribute heterogeneity in HG embedding, referencing the cited papers. It includes a comparison of HGNNs with shallow models by highlighting inductive learning and memory efficiency, which adds some analytical value. However, it lacks deeper critical evaluation of the papers and broader abstraction, remaining somewhat superficial in its analysis."}}
{"id": "b722faf7-eda8-4505-98df-4ba7d37e2b36", "title": "Recommendation", "level": "subsubsection", "subsections": [], "parent_id": "e70e2835-a6cf-4f06-915c-6cdb405e5404", "prefix_titles": [["title", "A Survey on Heterogeneous Graph Embedding"], ["section", "Method Taxonomy"], ["subsection", "Application-oriented HG Embedding"], ["subsubsection", "Recommendation"]], "content": "In recommendation system, the interaction among user and item can be naturally modeled as a HG with two types of nodes. Therefore, recommendation is a typical scenario that widely uses HG information .\nBesides, other types of information, such as the social relationships, can also be easily introduced in HG , applying heterogeneous graph embedding to recommendation application is an important research field.\nEarly works recommend item to a user mainly based on meta-path aware similarity between user and item, such as HeteLearn  and SemRec .\nWith the development of embedding technology, matrix factorization , random walk  and advanced neural networks  are proposed to learn embeddings of user and item, so as to capture the complex interactions.\nHERec  aims to learn the embeddings of users and items under different meta-paths and fuses them for recommendation.\nIt first finds the co-occurrence of users and items based on the meta-path guided random walks on user-item HG. \nThen it uses node2vec  to learn preliminary embeddings from the co-occurrence sequences of users and items. Because the embeddings under different meta-paths contain different semantic information, for better recommendation performance, HERec designs a fusion function to unify the multiple embeddings:\n\\begin{equation}\n\tg(\\mathbf{h}_{u}^{m})=\\frac{1}{|P|}\\sum_{m=1}^{M}(\\mathbf{W}^{m}\\mathbf{h}_{u}^{m}+\\mathbf{b}^{m}),\n\\end{equation}\nwhere $\\mathbf{h}_{u}^{m}$ is the embedding of user node $u$ in meta-path $m$. $M$ denotes the set of meta-paths. The fusion of item embeddings is similar to users. Finally, a prediction layer is used to predict the items that users prefer. HERec optimizes the graph embedding and recommendation objective jointly.\nApart from random walk, some methods try to use matrix factorization to learn user and item embeddings. HeteRec  considers the implicit user feedback in HG. HeteroMF  designs a heterogenous matrix factorization technique to consider the context dependence of different types of nodes. FMG  incorporates meta-graphs into embedding technology, which can capture some special patterns between users and items.\nPrevious methods mainly use shallow models to learn the embeddings of users and items, where the ability of express nonlinear interaction between them is limited. Therefore, some neural network-based methods are proposed.\nOne of the most important techniques is attention mechanism, which aims to find the important users and items in HG based recommendation.\nMCRec  designs a neural co-attention mechanism to capture the relationship between user, item and meta-path. Specifically, it uses the users and items to find the important meta-paths. Meanwhile, the important meta-paths are used to find the important users and items in recommendation. Through this mutual selective attention mechanism, MCRec can not only learn embeddings of users, items and meta-paths, but also capture the complex interactions among them.\nNeuACF  and HueRec  first calculate multiple meta-path-based commuting matrices, where each row represents the user-user similarity or item-item similarity. Then an attention mechanism is designed to learn the importance of different meta-path-based commuting matrices, so as to capture different semantic information.\nAnother type of important techniques is graph neural networks.\nPGCN  converts the user-item interaction sequences into item-item graph, user-item graph and user-sequence graph. Then it designs a HGNN to propagate user and item information in the three graphs, so as to capture the collaborative filtering signals.\nMEIRec  focuses on the problem of intent recommendation in E-commerce, which aims to automatically recommend user intent according to user historical behaviors. It constructs a user-item-query heterogeneous graph and designs a meta-path-guided HGNN to learn the embedding of users, items and queries, which can capture the intent of users.\nGNewsRec  and GNUD  are designed for news recommendation. They consider both the content information of news and the collaborative information between users and news.\n employs graph convolutional network on heterogeneous graphs for basket recommendation.", "cites": [1417, 1010, 1432, 1421, 1419], "cite_extract_rate": 0.29411764705882354, "origin_cites_number": 17, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.0, "abstraction": 3.5}, "insight_level": "medium", "analysis": "The section effectively synthesizes the cited works by categorizing HG embedding methods for recommendation into distinct types (e.g., random walk, matrix factorization, neural network-based). It highlights how each approach addresses the heterogeneity challenge. While it provides some critical evaluation, such as noting the limitations of shallow models in capturing nonlinear interactions, it could offer more depth in comparing the effectiveness or shortcomings of specific techniques. The section identifies broader patterns like the use of attention mechanisms and graph neural networks, showing a moderate level of abstraction."}}
{"id": "f3141113-56c8-422b-abc4-2f31baab2987", "title": "Identification", "level": "subsubsection", "subsections": [], "parent_id": "e70e2835-a6cf-4f06-915c-6cdb405e5404", "prefix_titles": [["title", "A Survey on Heterogeneous Graph Embedding"], ["section", "Method Taxonomy"], ["subsection", "Application-oriented HG Embedding"], ["subsubsection", "Identification"]], "content": "Identification is to find the most likely nodes according to the given conditions on HG. For example, finding potential authors of a given paper or identifying users in cross-platform.\nCurrently, two representative identification applications, author identification  and user identification , have been studied based on heterogeneous graph embedding.\nAuthor identification aims to find the potential authors for an anonymous paper in the academic network. Camel  aims to consider both the content information, e.g., the text of papers, and context information, e.g., the co-occurrence of paper and author. For content information, it designs a content encoder to learn embeddings from the abstract of paper and a metric-based loss function is used to learn the pair-wise relations between authors and papers:\n\\begin{equation}\n\t\\mathcal{L}_{Metric}=\\xi + \\|f(\\mathbf{h}_{v})-\\mathbf{h}_{u}\\|^{2} - \\|f(\\mathbf{h}_{v})-\\mathbf{h}_{u^{'}}\\|^{2},\n\\end{equation}\nwhere $\\xi$ is the margin, $f(\\cdot)$ represents the content encoder and $\\mathbf{h}_{v}$, $\\mathbf{h}_{u}$ and $\\mathbf{h}_{u^{'}}$ denote the attributes of paper, positive author and negative author, respectively.\nFor context information, a meta-path guided walk integrative learning module (MWIL) is proposed to preserve the graph structures:\n\\begin{equation}\n\t\\mathcal{L}_{MWIL}=-\\log \\sigma[f(\\mathbf{h}_{v}) \\cdot \\mathbf{h}_{u}] - \\log \\sigma[-f(\\mathbf{h}_{v}) \\cdot \\mathbf{h}_{u^{'}}].\n\\end{equation}\nIt is worth noting that $\\mathcal{L}_{MWIL}$ is a special skip-gram technique, which aims to preserve the proximity of positive author $u$ of paper $v$ within a walk length.\nThrough optimizing $\\mathcal{L}_{Metric}$ and $\\mathcal{L}_{MWIL}$ jointly, Camel considers both the heterogeneous graph structures and the pair-wise relation of author-paper.\nSimilar to the idea of Camel, PAHNE  considers the pair-wise relations and TaPEm  maximizes the proximity between the paper-author pair and the context path around them.\nCompared with author identification, user identification does not contain the pair-wise relation, i.e., user and paper. Therefore, it focuses on learning discriminating user embeddings with weak supervision information so that the target users can be identified more easily. Player2vec , AHIN2vec  and Vendor2vec  are the principal methods.\nThey can be summarized as a general framework: first, some advanced neural networks, e.g., convolutional neural network (CNN) or recurrent neural network (RNN), are used to learn preliminary node embeddings from the raw features. Then the preliminary node embeddings will be propagated on the graphs, constructed by different meta-paths, to utilize the neighborhood information.\nFinally, a semi-supervised loss function is used to make the node embeddings contain application-specific information. Under the guidance of partially labeled nodes, the node embeddings can distinguish special users from the ordinary users in the graph, which can be used for user identification.", "cites": [1433, 1423], "cite_extract_rate": 0.3333333333333333, "origin_cites_number": 6, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.0, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section effectively synthesizes key concepts and methods from the cited works, particularly linking the objectives of author and user identification in heterogeneous graphs. It provides a coherent narrative by highlighting how different components (e.g., content and context encoders, loss functions) contribute to the overall task. While it offers some critical discussion, such as distinguishing between pair-wise and non-pair-wise identification tasks, deeper limitations or trade-offs could be explored further. The abstraction is strong, as the section outlines a general framework and identifies broader design principles in embedding-based identification methods."}}
{"id": "dfa2d0d7-f0d9-480c-8b55-0436c9a71581", "title": "Miscellanea", "level": "subsection", "subsections": [], "parent_id": "32c48b46-7aa2-42d7-b8b8-0b7f3b7c16c5", "prefix_titles": [["title", "A Survey on Heterogeneous Graph Embedding"], ["section", "Method Taxonomy"], ["subsection", "Miscellanea"]], "content": "In the previous section, we introduce the major applications in heterogeneous graph embedding. There are also some other methods that do not belong to the existing categories. Here, we briefly introduce them.\nThe first is incorporating HG into natural language processing (NLP). Due to the multiple elements in the corpus, e.g., words, entities, sentences or paragraphs, many NLP tasks can be modeled as HG naturally. Graph-to-sequence (Graph2Seq) learning is an important topic in NLP, which aims to transform the graph-structured embeddings to word sequences for text generation . AMR-to-text generation is a typical Graph2Seq task. It generates text from the Abstract Meaning Representation (AMR) graph, where nodes represent the semantic concepts in the text and edges denote the relations between concepts. In order to learn useful information from the AMR graph, Yao \\emph{et al.}  treat AMR graph as a heterogeneous graph and design a heterogeneous graph encoder to learn the semantic information among the concepts. Besides, Hu \\emph{et al.}  propose HGAT for short text classification, which treats the topic, entities and documents as a HG and designs a hierachical attention mechanism to learn the similarity among short texts. GNewsRec  and GNUD  use HG to model the collaborative filtering between news and users in news recommendation task.  incorporates HG into topic model for aspect mining.  uses HG in fake new detection.\nSimilar to NLP, multi-modal data can also be modeled by HG due to the various data forms, e.g., text, images or videos. The potential dependencies and connections among multi-model data can be modeled by HG easily. Therefore, some methods try to use heterogeneous graph embedding to capture the potential dependencies and connections. For example, Community Question Answering (CQA) aims to recommend the suitable answers for each question. Because the answers and questions may contain text and pictures,  treats the answers and question as a heterogeneous graph to capture the potential connections, thus making the state-of-the-art performance.\nBesides, graph embedding in hyperbolic space has received widespread attention . Because whether Euclidean spaces are the optimal isometric spaces is still an unsolved problem, exploring heterogeneous graph embedding in the hyperbolic spaces is a meaningful research direction.  shows that hyperbolic spaces can capture the hierarchical and power-law structure of the heterogeneous graph, which provides a theoretical guarantee for the future work to some extent.\nMoreover, HG embedding are also widely used to model many other tasks, such as entity set expansion , basket recommendation , event categorization  and social network .", "cites": [210, 1432, 7011, 1436, 1435, 1434, 7216], "cite_extract_rate": 0.3888888888888889, "origin_cites_number": 18, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 1.5, "abstraction": 1.8}, "insight_level": "low", "analysis": "The section briefly introduces several methods that incorporate heterogeneous graphs into diverse application domains, such as NLP, multi-modal data, and hyperbolic embedding. However, it lacks synthesis by not deeply connecting or categorizing these methods within a broader framework. There is minimal critical analysis or evaluation of the cited works, and abstraction is limited to only surface-level observations about the general utility of HG in these contexts."}}
{"id": "547347a1-221b-4b82-82ac-0bc26a0a5553", "title": "Technique Summary", "level": "section", "subsections": ["6b9cefb5-9626-4d5e-bb66-aea1a424d814", "a2b7151a-6585-4776-8425-4b7e03f45447", "68804397-10c1-4232-accc-540e8e6cdfe2"], "parent_id": "9526fb53-fc6c-4198-91f0-7315cf30ae6c", "prefix_titles": [["title", "A Survey on Heterogeneous Graph Embedding"], ["section", "Technique Summary"]], "content": "\\label{model}\n\\begin{table*}[t]\n  \\centering\n  \\setlength{\\belowcaptionskip}{0.05cm}\n  \\renewcommand\\arraystretch{1.25}\n  \\caption{Typical heterogeneous graph embedding methods.}\n    \\resizebox{\\linewidth}{!}{\n    \\begin{tabular}{|c|c|c|c|c|c|l|}\n    \\hline\n    Method & \\multicolumn{1}{c|}{Inductive} & \\multicolumn{1}{c|}{\\quad Label \\quad\\quad} & Information & Task  & Technique & \\multicolumn{1}{c|}{Characteristic} \\\\\n    \\hline\n    \\hline\n    mp2vec  &       &       & \\multirow{6}[0]{*}{Strcuture} & \\multirow{6}[0]{*}{Embedding} & \\multirow{7}[0]{*}{\\tabincell{c}{Random walk\\\\(Shallow model)}} & \\multirow{7}[0]{*}{\\tabincell{l}{\\tabitem Easy to parallelize \\\\ \\tabitem Two-stage training \\\\ \\tabitem High memory cost  \\\\ \\\\ Complexity: $\\mathcal{O}(\\tau \\cdot l \\cdot k \\cdot n_{s} \\cdot d \\cdot |\\mathcal{V}|)$} } \\\\\n\\cline{1-3}    Spacey  &       &       &       &       &       &  \\\\\n\\cline{1-3}    JUST   &       &       &       &       &       &  \\\\\n\\cline{1-3}    BHIN2vec  &       &       &       &       &       &  \\\\\n\\cline{1-3}    HHNE  &       &       &       &       &       &  \\\\\n\\cline{1-3}    mg2vec  &       &       &       &       &       &  \\\\\n\\cline{1-5}    HeRec  &       & $\\surd$ & Strcuture+Task & Recommendation &       &  \\\\\n    \\hline\n    PME   &       &       & \\multirow{6}[0]{*}{Strcuture} & \\multirow{15}[0]{*}{Embedding} & \\multirow{6}[0]{*}{\\tabincell{c}{Decomposition\\\\(Shallow model)} } & \\multirow{6}[0]{*}{\\tabincell{l}{\\tabitem Easy to parallelize \\\\ \\tabitem Two-stage training \\\\ \\tabitem High memory cost \\\\ \\\\ Complexity: $\\mathcal{O}(|\\mathcal{E}| \\cdot d)$} } \\\\\n\\cline{1-3}    EOE   &       &       &       &       &       &  \\\\\n\\cline{1-3}    HEER  &       &       &       &       &       &  \\\\\n\\cline{1-3}    MNE   &       &       &       &       &       &  \\\\\n\\cline{1-3}    PTE   &       &       &       &       &       &  \\\\\n\\cline{1-3}    RHINE  &       &       &       &       &       &  \\\\\n\\cline{1-4}\\cline{6-7}    HAN   & $\\surd$ & $\\surd$ & \\multirow{9}[0]{*}{Structure+Attribute} &       & \\multirow{15}[0]{*}{\\tabincell{c}{Message passing\\\\(Deep model)} } & \\multirow{15}[0]{*}{\\tabincell{l}{\\tabitem End-to-End training \\\\ \\tabitem Encoding structures and attributes  \\\\ \\tabitem Semantic fusion \\\\ \\tabitem High training cost \\\\ \\\\Complexity: $\\mathcal{O}(|\\mathcal{V}| \\cdot d_{1} + |\\mathcal{R}| \\cdot d_{2})$} } \\\\\n\\cline{1-3}    MAGNN  & $\\surd$ & $\\surd$ &       &       &       &  \\\\\n\\cline{1-3}    HetSANN  & $\\surd$ & $\\surd$ &       &       &       &  \\\\\n\\cline{1-3}    HGT   & $\\surd$ & $\\surd$ &       &       &       &  \\\\\n\\cline{1-3}    HetGNN  & $\\surd$ &       &       &       &       &  \\\\\n\\cline{1-3}    GATNE  & $\\surd$ &       &       &       &       &  \\\\\n\\cline{1-3}    GTN   &       & $\\surd$ &       &       &       &  \\\\\n\\cline{1-3}    RSHN  &       & $\\surd$ &       &       &       &  \\\\\n\\cline{1-3}    RGCN  & $\\surd$ & $\\surd$ &       &       &       &  \\\\\n\\cline{1-5}    IntentGC  & $\\surd$ & $\\surd$ & \\multirow{6}[0]{*}{\\tabincell{c}{Strcuture\\\\+Attribute+Task} } & \\multirow{3}[0]{*}{Recommendation} &       &  \\\\\n\\cline{1-3}    MEIRec  & $\\surd$ & $\\surd$ &       &       &       &  \\\\\n\\cline{1-3}    GNUD  & $\\surd$ & $\\surd$ &       &       &       &  \\\\\n\\cline{1-3}\\cline{5-5}    Player2vec  & $\\surd$ & $\\surd$ &       & \\multirow{3}[0]{*}{Identification} &       &  \\\\\n\\cline{1-3}    AHIN2vec  & $\\surd$ & $\\surd$ &       &       &       &  \\\\\n\\cline{1-3}    Vendor2vec  & $\\surd$ & $\\surd$ &       &       &       &  \\\\\n    \\hline\n    HIN2vec  &       &       & \\multirow{2}[0]{*}{Strcuture} & \\multirow{5}[0]{*}{Embedding} & \\multirow{8}[0]{*}{\\tabincell{c}{Encoder-decoder\\\\(Deep model)} } & \\multirow{8}[0]{*}{\\tabincell{l}{\\tabitem End-to-End training \\\\ \\tabitem Flexible goal-orientation \\\\ \\\\Complexity: $\\mathcal{O}(|\\mathcal{V}| \\cdot d_{1} + |\\mathcal{E}| \\cdot d_{2})$} } \\\\\n\\cline{1-3}    DHNE  &       &       &       &       &       &  \\\\\n\\cline{1-4}    HNE   & $\\surd$ & $\\surd$ & \\multirow{3}[0]{*}{Structure+Attribute} &       &       &  \\\\\n\\cline{1-3}    SHNE  &       & $\\surd$ &       &       &       &  \\\\\n\\cline{1-3}    NSHE  &       &       &       &       &       &  \\\\\n\\cline{1-5}    PAHNE  &       & $\\surd$ & \\multirow{3}[1]{*}{\\tabincell{c}{Strcuture\\\\+Attribute+Task} } & \\multirow{3}[1]{*}{Identification} &       &  \\\\\n\\cline{1-3}    Camel  &       & $\\surd$ &       &       &       &  \\\\\n\\cline{1-3}    TaPEm  &       & $\\surd$ &       &       &       &  \\\\\n    \\hline\n    HeGAN  &       &       & \\multirow{2}[0]{*}{Strcuture} & \\multirow{2}[0]{*}{Embedding} & \\multirow{3}[0]{*}{\\tabincell{c}{Adversarial\\\\(Deep model)} } & \\multirow{3}[0]{*}{\\tabincell{l}{\\tabitem Robustness \\\\ \\tabitem High complexity \\\\Complexity: $\\mathcal{O}(|\\mathcal{V}| \\cdot |\\mathcal{R}| \\cdot n_{s} \\cdot d)$} } \\\\\n\\cline{1-3}    MV-ACM  &       &       &       &       &       &  \\\\\n\\cline{1-5}    Rad-HGC  &       & $\\surd$ & Strcuture+Task & Malware detection &       &  \\\\\n    \\hline\n    \\end{tabular}}\n  \\label{typicalworks}\n\\end{table*}\nIn the previous section, we category the heterogeneous graph embedding methods based on different problem setting.\nIn this section, from the technical perspective, we summarize the widely used techniques (or models) in heterogeneous graph embedding, which can be generally divided into two categories: shallow model and deep model.", "cites": [1417, 1426, 248, 259, 1419, 1431, 1433, 1183, 1103, 1423, 1428, 1427, 1425, 1429, 1422, 8452, 1430], "cite_extract_rate": 0.4473684210526316, "origin_cites_number": 38, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 1.5, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section provides a descriptive summary of heterogeneous graph embedding methods using a table, but lacks synthesis of ideas or critical evaluation across papers. The integration is minimal, with no attempt to connect or generalize the approaches into a coherent or analytical framework."}}
{"id": "6b9cefb5-9626-4d5e-bb66-aea1a424d814", "title": "Shallow Model", "level": "subsection", "subsections": [], "parent_id": "547347a1-221b-4b82-82ac-0bc26a0a5553", "prefix_titles": [["title", "A Survey on Heterogeneous Graph Embedding"], ["section", "Technique Summary"], ["subsection", "Shallow Model"]], "content": "Early heterogeneous graph embedding methods focus on employing shallow model. They first initialize the node embeddings randomly, and then learn the node embeddings through optimizing some well-designed objective functions.\nWe divide the shallow model into two categories: random walk-based and decomposition-based.\n\\textbf{Random walk-based.} In homogeneous graph, random walk, which generates some node sequences in a graph, is usually used to capture the local structure of a graph . While in heterogeneous graph, the node sequence should contain not only the structural information, but also the semantic information. Therefore, a series of semantic-aware random walk techniques are proposed . For example, metapath2vec  uses meta-path-guided random walk to capture the semantic information of two nodes, e.g., the co-author relationship in academic graph. Spacey  and metagraph2vec  design metagraph-guided random walks, which preserve a more complex similarity between two nodes.\n\\textbf{Decomposition-based.} Decomposition-based techniques aim to decompose HG into several sub-graphs and preserve the proximity of nodes in each sub-graph . PME  decomposes the heterogeneous graph into some bipartite graphs according to the types of links and projects each bipartite graph into a relation-specific semantic space. PTE  divides the documents into word-word graph, word-document graph and word-label graph. Then it uses LINE  to learn the shared node embeddings for each sub-graph. HEBE  samples a series of subgraphs from a HG and preserves the proximity between the center node and its subgraph.", "cites": [1155, 1426, 282, 1427, 1425, 1424, 1422, 1010, 1419], "cite_extract_rate": 0.5294117647058824, "origin_cites_number": 17, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.5, "critical": 2.0, "abstraction": 2.5}, "insight_level": "medium", "analysis": "The section provides a basic categorization of shallow models into random walk-based and decomposition-based approaches and mentions some representative methods. However, the synthesis remains limited, as it does not deeply connect or integrate the underlying ideas across papers. There is little critical analysis or identification of limitations, and abstraction is minimal, with only a superficial attempt to generalize patterns."}}
{"id": "a2b7151a-6585-4776-8425-4b7e03f45447", "title": "Deep Model", "level": "subsection", "subsections": [], "parent_id": "547347a1-221b-4b82-82ac-0bc26a0a5553", "prefix_titles": [["title", "A Survey on Heterogeneous Graph Embedding"], ["section", "Technique Summary"], ["subsection", "Deep Model"]], "content": "Deep model aims to use advanced neural networks to learn embedding from the node attributes or the interactions among nodes, which can be roughly divided into three categories: message passing-based, encoder-decoder-based and adversarial-based.\n\\textbf{Message passing-based.} The idea of message passing is to send the node embedding to its neighbors, which is always used in GNNs. The key component of message passing-based techniques is to design a suitable aggregation function, which can capture the semantic information of HG . \nHAN  designs a hierarchical attention mechanism to learn the importance of different nodes and meta-paths, which captures both structural information and semantic information of HG.\nHetGNN  uses bi-LSTM to aggregate the embedding of neighbors so as to learn the deep interactions among heterogeneous nodes.\nGTN  designs an aggregation function, which can find the suitable meta-paths automatically during the process of message passing.\n\\textbf{Encoder-decoder-based.} Encoder-decoder-based techniques aim to employ some neural networks as encoder to learn embedding from node attributes and design a decoder to preserve some properties of the graphs .\nFor example, HNE  focuses on multi-modal heterogeneous graph. It uses CNN and autoencoder to learn embedding from images and texts, respectively. Then it uses the embedding to predict whether there is a link between the images and texts. \nCamel  uses GRU as encoder to learn paper embedding from the abstracts. A skip-gram objective function is used to preserve the local structures of the graphs.\nDHNE  uses autoencoder to learn embedding for the nodes in a hyperedge. Then it designs a binary classification loss to preserve the indecomposability of the hyper-graph.\n\\textbf{Adversarial-based.} Adversarial-based techniques utilize the game between generator and discriminator to learn robust node embedding. In homogeneous graph, the adversarial-based techniques only consider the structural information, for example, GraphGAN  uses Breadth First Search when generating virtual nodes. In a heterogeneous graph, the discriminator and generator are designed to be relation-aware, which captures the rich semantics on HGs. HeGAN  is the first to use GAN in heterogeneous graph embedding. It incorporates the multiple relations into the generator and discriminator, so that the heterogeneity of a given graph can be considered. MV-ACM  uses GAN to generate the complementary views by computing the similarity of nodes in different views.", "cites": [248, 1431, 1428, 1433, 1429, 1423, 1183, 259, 1430], "cite_extract_rate": 0.5, "origin_cites_number": 18, "insight_result": {"type": "descriptive", "scores": {"synthesis": 3.0, "critical": 2.0, "abstraction": 2.5}, "insight_level": "medium", "analysis": "The section provides a descriptive overview of deep model approaches for heterogeneous graph embedding and categorizes them into three types with examples. It connects some works under the same categories (e.g., message passing-based) but lacks deeper synthesis or a novel framework. There is minimal critical analysis or evaluation of limitations, and while some general patterns are identified, the abstraction remains limited to methodological classifications without deeper principles or trends."}}
{"id": "68804397-10c1-4232-accc-540e8e6cdfe2", "title": "Review", "level": "subsection", "subsections": [], "parent_id": "547347a1-221b-4b82-82ac-0bc26a0a5553", "prefix_titles": [["title", "A Survey on Heterogeneous Graph Embedding"], ["section", "Technique Summary"], ["subsection", "Review"]], "content": "In Table \\ref{typicalworks}, we categorize the typical heterogeneous graph embedding methods through different perspectives. Specifically, from the left to right, we gradually coarsen the properties of each method, so as to summarize their commonalities.\nThe first two columns indicate whether the method has inductive capability and whether it needs labels for training. We can see that most message passing-based methods have the inductive capability because they can update the node embeddings by aggregating neighborhood information. But they need additional labels to guide the training process.\nThe middle two columns show the information and task in each method. It can be seen that most deep learning-based methods are proposed for HG with attributes or specific application, while the shallow model-based methods are mainly designed for the use of structures.\nOne possible reason is that HG with attributes or specific applications usually needs to introduce additional information or domain knowledge. However, modeling the domain knowledge may be complicated, and the relationship with HG may also need to be described carefully. Deep model provides a more powerful support for this kind of complex modeling, and it helps to make better progress in the complex application scenarios. Meanwhile, the emerging HGNNs can naturally integrate graph structures and attributes, so it is more suitable for the complex scenes and content.\nThe last two columns summarize the techniques used in HG embedding and their characteristics. Shallow models are easy to parallel. But they are two-stage training, i.e., the embeddings are not relevant to the downstream tasks, and the memory cost is heavy. On the contrary, deep models are end-to-end training and require less memory space. Besides, message passing-based techniques are good at encoding structures and attributes simultaneously, and integrating different semantic information. Compared with message passing-based techniques, encoder-decoder-based techniques are weak in fusing information due to the lack of messaging mechanism. But they are more flexible to introduce different objective function through different decoders. Adversarial-based methods prefer to utilize the negative samples to enhance the robustness of the embeddings. But the choice of negative samples has a huge influence on the performance, thus leading higher variances .\nIt is worth noting that we also list the complexity of each techniques, where $\\tau$ is the number of random walks, $l$ is the length of random walk, $k$ is the windows size in skip-gram  and $n_{s}$ is the number of samples. The complexity of random walk technique consists of two parts: random walk and skip-gram, both of which are linear with the number of nodes. Decomposition technique needs to divide HGs into sub-graphs according to the type of edges, so the complexity is linear with the number of edges, which is higher than random walk. Message passing technique mainly uses node-level and semantic-level attention to learn node embeddings, so its complexity is related to the number of nodes and node types. As for the encoder-decoder technique, the complexity of encoder is related to the number of nodes, while decoder is usually used to preserve the network structures, so it is linear with the number of edges. Adversarial technique needs to generate the negative samples for each node, so the complexity is related to the number of nodes and negative samples.", "cites": [1684], "cite_extract_rate": 0.5, "origin_cites_number": 2, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.0, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section synthesizes multiple HG embedding techniques by categorizing them based on properties like inductive capability, use of labels, and the types of information they model. It offers critical insights by discussing the strengths and weaknesses of different approaches (e.g., shallow vs. deep models, message passing vs. encoder-decoder). It also abstracts beyond individual methods by identifying broader patterns, such as the relationship between model complexity and training efficiency."}}
{"id": "b5e40b1d-ec0b-40e9-bf50-85c140aad97e", "title": "Real-world Deployed Systems", "level": "section", "subsections": ["d81ded81-1904-4bf9-9496-67189763c7b0", "480bf187-17ce-42ab-8034-9518f74b88a9", "fd0ae542-6a3d-47a0-a7b3-75542ae1aaf3"], "parent_id": "9526fb53-fc6c-4198-91f0-7315cf30ae6c", "prefix_titles": [["title", "A Survey on Heterogeneous Graph Embedding"], ["section", "Real-world Deployed Systems"]], "content": "Heterogeneous graph embedding is closely related with the real-world applications, as heterogeneous objects and interactions are ubiquitous in many practical systems. Here we focus on summarizing the industrial level applications with heterogeneous graph embedding. Different from those methods with specific tasks mentioned in Section~\\ref{application}, methods introduced in this section solve practical problems in applications with industrial data. In addition, for industrial-level applications, we pay more attention to two key components: HG construction with industrial data and graph embedding techniques on the HG.\n\\begin{figure*}[htbp]\n\t\\centering\n\t\\subfigure[E-commerce recommendation HG .]{\n\t\t\\includegraphics[height=1.2in,width=0.3\\linewidth]{commerce.png}\n\t\t\\label{fig:E-commerce HIN}\n\t}\n\t\\hspace{7mm}\n\t\\subfigure[Intent recommendation HG .]{\n\t\t\\includegraphics[height=1.5in,width=0.25\\linewidth]{intent.pdf}\n\t\t\\label{fig:intent}\n\t}\n\t\\hspace{7mm}\n\t\\subfigure[User Profiling HG .]{\n\t\t\\includegraphics[height=1.4in,width=0.3\\linewidth]{Profiling.png}\n\t\t\\label{fig:profiling}\n\t}\n\t\\caption{The representative HGs in E-commerce.}\n\t\\label{fig:ana}\n\\end{figure*}", "cites": [1417], "cite_extract_rate": 0.3333333333333333, "origin_cites_number": 3, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 1.5, "abstraction": 1.5}, "insight_level": "low", "analysis": "The section introduces the topic and provides a brief context, but lacks substantial synthesis of the cited paper. It includes a figure with example HGs but does not elaborate on how the cited paper (IntentGC) contributes to the broader understanding of real-world HG embedding systems. There is minimal critical evaluation or abstraction beyond the specific examples."}}
{"id": "d81ded81-1904-4bf9-9496-67189763c7b0", "title": "E-commerce", "level": "subsection", "subsections": [], "parent_id": "b5e40b1d-ec0b-40e9-bf50-85c140aad97e", "prefix_titles": [["title", "A Survey on Heterogeneous Graph Embedding"], ["section", "Real-world Deployed Systems"], ["subsection", "E-commerce"]], "content": "\\par E-commerce, such as Taobao\\footnote{www.taobao.com} and Amazon\\footnote{www.amazon.com}, is the activity of electronic trading of products on online services. It plays an important role in social economy development. Usually, large-scale heterogeneous objects and interactions, such as users, items, and shops, are involved in an e-commerce platform. Therefore, HG is a powerful and nature network analysis paradigm to model such complex data. HG embedding has been applied to various important services and tasks in e-commerce, such as item recommendation, intent recommendation, user profiling, and fraudster detection.\n\\par Recommendation is an important service of an e-commerce platform. A simple recommendation scenario primarily considers the interactions of users and items. However, due to the real business demands in e-commerce, it is highly desirable to comprehensively model users and items. HG can be used to model the interactions among users, items, and their auxiliary information~ . As shown in Fig.~\\ref{fig:E-commerce HIN}, the HG constructed by IntentGC~  is composed of user part and item part, and each part models the corresponding heterogeneous relationships. IntentGC translates the original HG as a multi-relation graph of users and items and develops a multi-relation graph convolution method to learn node embeddings. Besides integrating\nthe separate auxiliary information of user and item parts, GATNE~  distinguishes the interactions between user and item pairs as multiple types, models this scenario as an attributed multiplex heterogeneous graph and proposes an unified embedding method that captures both attribute and edge information. More recently, to solve the interaction sparsity problem, Xu~\\emph{et al.}  transform the original user-item heterogeneous graph into two semi homogeneous graphs from the perspective of users and items respectively.\n\\par Different from recommending items for users, intent recommendation is a new type of recommendation service in mobile e-commerce Apps, which aims to automatically recommend user intent according to user historical behaviors without any input. Fan~\\emph{et al.}~  propose to represent user intent as default queries in search box and transform the intent recommendation problem as recommending the queries. They construct a HG containing three types of nodes (Users, Items and Queries) and their mutual interactions, shown in Fig. \\ref{fig:intent}. Then, a meta-path-guided HGNN, called MEIRec, is designed to learn the nodes' embeddings of users and queries through aggregating the neighbors along the given meta-paths in an end-to-end manner.  \n\\par User profiling is playing an increasingly important role in providing personalized services in e-commerce platform. Different from previous methods only considering each user as an individual data instance, recent literature begins to model the abundant interaction information of users as a HG to enrich the characteristics of users. Chen \\emph{et al.}~  construct three kinds of objects (i.e., users, items and attributes) as a HG, shown in Fig.~\\ref{fig:profiling}, and propose a hierarchical heterogeneous GAT to predict the traits of users (e.g., gender and age) by aggregating each layer of objects' embeddings. Apart from trait prediction, Zheng \\emph{et al.}~  exploit HG to model the interactions between PID and MID with item ID in the e-commerce user alignment task. Then a Heterogeneous Embedding Propagation (HEP) model, encoding the interaction and edge features into node embeddings, is proposed to predict whether PID and MID across different devices refer to the same person.\n\\par With the development of e-commerce, there are many fraudsters in e-commerce system, who profit from transactions by illegal means. Due to the heterogeneity of fraudsters behavior patterns, some works try to detect these malicious accounts through HG embedding methods. Liu~\\emph{et al.}~  consider behaviours of fraudsters as ``Device aggregation\" and ``Activity aggregation\" in the view of HG, and they propose a GNN, called GEM, which simultaneously models the topology of the heterogeneous account-device graph and the characteristics of accounts activities in the local structure. Moreover, to enrich the embeddings of users, Hu~\\emph{et al.}~  treat the users, merchants, devices in credit payment service as different types of nodes and their interactions as edges in a HG, and propose a meta-path-based heterogeneous graph embedding method, called HACUD, to classify the cash-out user.  Li~\\emph{et al.}~  treat the users and items as nodes in a bipartite graph and associate the reviews as edge features to detect the spam reviews on Xianyu App. Then, a heterogeneous GNN is proposed to classify whether a review is spam or not, based on its local heterogeneous information and global context.\n\\begin{figure*}[htbp]\n\t\\centering\n\t\\subfigure[Malware detection .]{\n\t\\includegraphics[height=1in,width=0.22\\linewidth]{HINDorid.png}\n\t\\label{fig:HinDroid}\n\t}\n\t\\hspace{7mm}\n\t\\subfigure[Key player identification~ .]{\n\t\\includegraphics[height=1in,width=0.28\\linewidth]{AHIN.JPG}\n\t\\label{fig:AHIN security}\n\t}\n\t\\hspace{7mm}\n\t\\subfigure[Drug trafficker identification .]{\n\t\t\\includegraphics[height=1in,width=0.35\\linewidth]{ahin.png}\n\t\t\\label{fig:ahin}\n\t}\n\t\\caption{The representative HGs in cybersecurity applications.}\n\t\\label{fig:security}\n\\end{figure*}", "cites": [1417, 1437, 1429, 1420], "cite_extract_rate": 0.3076923076923077, "origin_cites_number": 13, "insight_result": {"type": "descriptive", "scores": {"synthesis": 3.0, "critical": 2.0, "abstraction": 2.5}, "insight_level": "medium", "analysis": "The section provides a descriptive overview of HG embedding applications in e-commerce by introducing various tasks and methods, such as IntentGC, GATNE, and HACUD. It synthesizes these methods into the broader context of e-commerce systems but lacks deep comparison or critical evaluation of their strengths and limitations. Some level of abstraction is visible, such as identifying the use of HGs for modeling heterogeneous relationships, but the analysis remains largely at the level of individual systems."}}
{"id": "480bf187-17ce-42ab-8034-9518f74b88a9", "title": "Cybersecurity", "level": "subsection", "subsections": [], "parent_id": "b5e40b1d-ec0b-40e9-bf50-85c140aad97e", "prefix_titles": [["title", "A Survey on Heterogeneous Graph Embedding"], ["section", "Real-world Deployed Systems"], ["subsection", "Cybersecurity"]], "content": "Security has been one of the biggest threaten for social development, and it causes countless loss of property and lives. As multiple heterogeneous entities and complex structure are usually involved in security system, recently researchers pay more attention to use HG embedding methods to detect outliers in a wide range of security areas, such as malware detection, key player identification in underground forum, drug trafficker identification.\n\\par With the broad scale proliferation of increasingly interconnected devices, malware (e.g., trojans, ransomware, scamware) that deliberately fulfills the harmful intent to device users has become a major threat to compromise the security in cyberspace . In particular, the explosive growth and increasing sophistication of Android malware call for new defensive techniques that are capable of protecting mobile users against novel threats .\nTo combat the evolving Android malware attacks, HG-based methods have been proposed and applied in anti-malware industry. As shown in Fig.~\\ref{fig:HinDroid}, HinDroid  was first proposed to construct a HG to model the complex relations among application programming interface (APIs) and Android applications (apps), based on which meta-paths are used to formulate the relatedness among apps and multi-kernel learning algorithm is proposed to build the classification model for malware detection. Besides modeling apps and APIs, Fan~\\emph{et al.}~  model more types of entities involved in malware into a HG, such as, file, archive and machine, and a metagraph based embedding method is designed to encode high-level semantic similarities between files. After these methods, a series of HG embedding methods are proposed for dynamic malware detection~ , adversarial attack and defense in malware~ , unknown malware detection~  and cyber threat intelligence~ .\n\\par Besides android malware detection, HG embedding methods also play an important role in detecting targeted objects in other security areas which have multiple types of entities and relations available. Zhang~\\emph{et al.}  extract multiple relations from the underground forum data and construct an attributed HG (AHG) for key player identification, shown in Fig.~\\ref{fig:AHIN security}. By treating the relatedness over users depicted by each meta-path as one view, a multi-view GCN is proposed to identify the key player. As illustrated in Fig.~\\ref{fig:ahin}, Zhang~\\emph{et al.}  leverage AHG to depict vendors, drugs, texts, photos and their associated attributes in darknet markets for drug trafficker identification. Then an attribute-aware AHG embedding method, named \\textit{Vendor2Vec}, consisting of attribute-aware meta-path random walk and skip-gram technique, is proposed to predict whether a given pair of vendors are the same individual or not. \n\\begin{table*}[htbp]\n  \\centering\n  \\caption{A summary of commonly used HG datasets.}\n  \\resizebox{\\linewidth}{!}{\n    \\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}\n    \\hline\n    \\multirow{2}{*}{Dataset} & \\multicolumn{3}{c|}{Statistics} & \\multicolumn{2}{c|}{Side information} & \\multicolumn{4}{c|}{Task}     & \\multirow{2}{*}{Related Papers} \\\\\n\t\\cline{2-10}          & Node & Link & Meta-path & Timestamp & Attribute & Node classification & Multi classification & Recommendation & Link prediction &  \\\\\n    \\hline\n    \\hline\n    DBLP\t& \\begin{tabular}[c]{@{}c@{}} Author(A)\\\\Paper(P)\\\\Term(T)\\\\Venue(V) \\end{tabular} & \\begin{tabular}[c]{@{}c@{}} A-P\\\\P-P\\\\P-T\\\\P-V \\end{tabular} & \\begin{tabular}[c]{@{}c@{}} \\\\APA\\\\APAPA\\\\APCPA\\\\APTPA\\\\APVPA\\\\ \\end{tabular} & $\\surd$ & $\\surd$ & $\\surd$ & $\\surd$ & & $\\surd$ & \\begin{tabular}[c]{@{}c@{}} \\\\  \\\\  \\\\ \\end{tabular} \\\\\n    \\hline\n    Aminer\t& \\begin{tabular}[c]{@{}c@{}} Paper(P)\\\\Author(A)\\\\Keyword(W)\\\\Venue(V)\\\\Conference(C)\\\\Term(T) \\end{tabular} & \\begin{tabular}[c]{@{}c@{}} P-A\\\\P-P\\\\P-V\\\\P-W\\\\P-T\\\\P-C \\end{tabular} & \\begin{tabular}[c]{@{}c@{}} \\\\APA\\\\WPW\\\\APVPA\\\\APTPA\\\\APCPA\\\\APWPA\\\\ \\\\ \\end{tabular} & $\\surd$ & $\\surd$ & $\\surd$ & $\\surd$ & & $\\surd$ & \\begin{tabular}[c]{@{}c@{}} \\\\  \\\\  \\end{tabular} \\\\\n    \\hline\n    Yelp\t& \\begin{tabular}[c]{@{}c@{}} User(U)\\\\Business(B)\\\\Compliment(Co)\\\\City(Ci)\\\\Category(Ca) \\end{tabular} & \\begin{tabular}[c]{@{}c@{}} U-U\\\\U-B\\\\U-Co\\\\B-Ci\\\\B-Ca\\\\ \\end{tabular} & \\begin{tabular}[c]{@{}c@{}} \\\\UBU\\\\UCoU\\\\UBCiBU\\\\UBCaBU\\\\BUB\\\\BCiB\\\\BCaB\\\\BUCoUB\\\\ \\\\\\end{tabular} & $\\surd$ &       & $\\surd$ & $\\surd$ & $\\surd$ & $\\surd$ & \\begin{tabular}[c]{@{}c@{}}  \\\\  \\end{tabular} \\\\\n    \\hline\n    Amazon\t& \\begin{tabular}[c]{@{}c@{}} User(U)\\\\Business(Bu)\\\\Category(C)\\\\Brand(Br)\\\\Aspect(A) \\end{tabular} & \\begin{tabular}[c]{@{}c@{}} \\\\U-Bu\\\\Bu-C\\\\Bu-Br\\\\R-Bu\\\\R-A\\\\ \\\\ \\end{tabular} & N/A &\t\t&  $\\surd$  &       &       & $\\surd$ & $\\surd$ & \\begin{tabular}[c]{@{}c@{}}  \\end{tabular} \\\\\n    \\hline\n    IMDB\t& \\begin{tabular}[c]{@{}c@{}} User(U)\\\\Movie(M)\\\\Actor(A)\\\\Director(D)\\\\Genre(G) \\end{tabular} & \\begin{tabular}[c]{@{}c@{}} A-M\\\\U-M\\\\G-M\\\\D-M \\end{tabular} & \\begin{tabular}[c]{@{}c@{}} \\\\MUM\\\\MAM\\\\MDM\\\\MGM\\\\UMU\\\\UMAMU\\\\UMDMU\\\\UMGMU\\\\ \\\\ \\end{tabular} & & $\\surd$ & $\\surd$ & & $\\surd$ & $\\surd$ & \\begin{tabular}[c]{@{}c@{}}  \\end{tabular} \\\\\n    \\hline\n    Douban\t& \\begin{tabular}[c]{@{}c@{}} User(U)\\\\Movie(M)\\\\Group(G)\\\\Location(L)\\\\Direction(D)\\\\Actor(A)\\\\Type(T) \\end{tabular} & \\begin{tabular}[c]{@{}c@{}} U-U\\\\U-G\\\\U-M\\\\U-L\\\\M-D\\\\M-T\\\\M-A \\end{tabular} & \\begin{tabular}[c]{@{}c@{}} \\\\MUM\\\\MTM\\\\MDM\\\\MAM\\\\UMU\\\\UMAMU\\\\UMDMU\\\\UMTMU\\\\ \\\\ \\end{tabular} & & & $\\surd$ & $\\surd$ & $\\surd$ & $\\surd$ & \\begin{tabular}[c]{@{}c@{}}  \\end{tabular} \\\\\n    \\hline\n    \\end{tabular}}\n  \\label{datasets}\n\\end{table*}", "cites": [1417, 1426, 1438, 248, 1419, 1433, 1423, 1425, 1427, 1424, 1429, 1430], "cite_extract_rate": 0.36363636363636365, "origin_cites_number": 33, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 1.5, "abstraction": 1.5}, "insight_level": "low", "analysis": "The section provides a descriptive overview of HG embedding applications in cybersecurity, mentioning specific methods and their uses (e.g., HinDroid, Vendor2Vec), but lacks synthesis of the underlying principles or connections between them. There is minimal critical evaluation of the cited works, and no abstraction or generalization to broader patterns or frameworks in the field."}}
{"id": "fd0ae542-6a3d-47a0-a7b3-75542ae1aaf3", "title": "Others", "level": "subsection", "subsections": [], "parent_id": "b5e40b1d-ec0b-40e9-bf50-85c140aad97e", "prefix_titles": [["title", "A Survey on Heterogeneous Graph Embedding"], ["section", "Real-world Deployed Systems"], ["subsection", "Others"]], "content": "With the development of biological medicine, medical informatics has received considerable attentions, especially, mining Electronic Health Records (EHR) for reducing error and improving quality of disease diagnosis . Previous work on medical HG mainly utilizes HeteSim~  to analyze the similarities between objects~ . Recently, Hosseini~\\emph{et al.}~  treat the diagnostic and treatment events as the nodes and corresponding relations extracted from raw text as edges in a HG, and propose a meta-path-guided HG embedding method to rank each patient's potential diagnosis.\n\\par Besides, heterogeneous graph embedding is also applied in real-time event prediction on ride-hailing platform, such as Uber\\footnote{www.uber.com} and\nDiDi\\footnote{www.didiglobal.com}. Luo~\\emph{et al.}~  dynamically construct heterogeneous graph for each ongoing event, such as PreView page and request, to encode the attributes of the event and the condition information from its surrounding area. And a multilayer GNN is proposed to learn the impact of historical\nactions and the surrounding environment on the current events, and generate an event embedding to improve the accuracy of the response model. Hong~\\emph{et al.} ~  propose HetETA to leverage HG to model the spatiotemporal information in time-of-arrival (ETA) estimation task. And a multi-component GNN is proposed to model temporal information from different time spans for ETA task.", "cites": [1418], "cite_extract_rate": 0.16666666666666666, "origin_cites_number": 6, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 1.5, "abstraction": 1.5}, "insight_level": "low", "analysis": "The section primarily describes a few real-world applications and methods without effectively synthesizing or connecting them into a broader framework. It lacks critical evaluation of the approaches or their limitations and does not abstract general principles or patterns from the cited works, focusing instead on specific systems and methods."}}
{"id": "bc405c4d-c87f-4018-9315-69febfd16fac", "title": "Open-source Code and Tools", "level": "subsection", "subsections": ["ce22b06c-f927-4ced-ac65-edc6d9e0280a", "3ed32290-5571-4fd8-9a33-0ac6104ca1fe"], "parent_id": "77c45968-ea52-45dd-8b87-23d0646154a5", "prefix_titles": [["title", "A Survey on Heterogeneous Graph Embedding"], ["section", "Benchmarks and Open-source Tools"], ["subsection", "Open-source Code and Tools"]], "content": "Open resources and tools are of great significance to the development of academic research. In this subsection, we provide the resources of heterogeneous graph embedding and introduce some useful open-source platforms and toolkits.\n\\begin{table*}[t]\n  \\centering\n  \\caption{Source code of related papers.}\n    \\begin{tabular}{l|l|c}\n    \\hline\n    Method & Source code & Programing platform\\\\\n    \\hline\n    AspEM  & https://github.com/ysyushi/aspem & Python\\\\\n    HEER   & https://github.com/GentleZhu/HEER & Python\\\\\n    BHIN2vec  & https://github.com/sh0416/BHIN2VEC & Pytorch \\\\\n    HEBE   & https://github.com/olittle/Hebe & C++ \\\\\n    DyHNE  & https://github.com/rootlu/DyHNE & Python \\& Matlab \\\\\n    HIN2vec  & https://github.com/csiesheep/hin2vec & Python \\& C++\\\\\n    HAN    & https://github.com/Jhy1993/HAN & Tensorflow \\\\\n    MAGNN  & https://github.com/cynricfu/MAGNN & Pytorch \\\\\n\tmetapath2vec  & https://github.com/apple2373/metapath2vec & Tensorflow \\\\\n    SHNE   & https://github.com/chuxuzhang/WSDM2019\\_SHNE & Pytorch \\\\\n    HetGNN  & https://github.com/chuxuzhang/KDD2019\\_HetGNN & Pytorch\\\\\n    TaPEm  & https://github.com/pcy1302/TapEM & Python\\\\\n\tHeRec  & https://github.com/librahu/HERec & Python \\\\\n\tFMG    & https://github.com/HKUST-KnowComp/FMG & Python \\& C++ \\\\\n\tHeteRec \t& https://github.com/mukulg17/HeteRec & R\\\\\n    GATNE  & https://github.com/THUDM/GATNE & Pytorch \\\\\n    IntentGC   & https://github.com/peter14121/intentgc-models & Python \\\\\n    \\hline\n    \\end{tabular}\n  \\label{codes}\n\\end{table*}", "cites": [1417, 248, 1433, 1427, 1425, 1424, 1438, 1429, 1419, 1430], "cite_extract_rate": 0.5882352941176471, "origin_cites_number": 17, "insight_result": {"type": "descriptive", "scores": {"synthesis": 1.5, "critical": 1.0, "abstraction": 1.0}, "insight_level": "low", "analysis": "The section is primarily descriptive, listing open-source implementations of various HG embedding methods with minimal synthesis of their shared characteristics or differences. It lacks critical evaluation of the tools and does not abstract beyond the specific repositories to highlight broader trends, challenges, or design principles in open-source HG embedding."}}
{"id": "288a7266-3ccb-4db5-bcd9-957f0004e132", "title": "Preserving HG Structures", "level": "subsection", "subsections": [], "parent_id": "d06fbb62-ed87-4501-8db7-5811c0c8f1ac", "prefix_titles": [["title", "A Survey on Heterogeneous Graph Embedding"], ["section", "Challenges and Future Directions"], ["subsection", "Preserving HG Structures"]], "content": "The basic success of heterogeneous graph embedding builds on the HG structure preservation. This also motivates many heterogeneous graph embedding methods to exploit different HG structures, where the most typical one is meta-path . Following this line, meta-graph structure is naturally considered . However, HG is far more than these structures. Selecting the most appropriate meta-path is still very challenging in the real world. An improper meta-path will fundamentally hinder the performance of heterogeneous graph embedding method. Whether we can explore other techniques, e.g., motif  or network schema  to capture HG structure is worth pursuing. Moreover, if we rethink the goal of traditional graph embedding, i.e., replacing the structure information with the distance/similarity in a metric space, a research direction to explore is whether we can design a heterogeneous graph embedding method which can naturally learn such distance/similarity rather than using pre-defined meta-path/meta-graph.", "cites": [1421, 1438, 1422], "cite_extract_rate": 0.5, "origin_cites_number": 6, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.5, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section effectively synthesizes the concepts of meta-path, meta-graph, and motif from the cited papers to highlight the importance of structure in HG embedding. It offers a critical view by pointing out limitations of existing approaches, such as the rigidity of meta-paths and the neglect of higher-order relations. The section also abstracts these ideas to propose broader research directions, like learning distance/similarity directly in embedding space instead of relying on predefined structures."}}
{"id": "a749fa47-02ca-4cd6-9e91-c70587b2d306", "title": "Capturing HG Properties", "level": "subsection", "subsections": [], "parent_id": "d06fbb62-ed87-4501-8db7-5811c0c8f1ac", "prefix_titles": [["title", "A Survey on Heterogeneous Graph Embedding"], ["section", "Challenges and Future Directions"], ["subsection", "Capturing HG Properties"]], "content": "As mentioned before, many current heterogeneous graph embedding methods mainly take the structures into account. However, some properties, which usually provide additional useful information to model HG, have not been fully considered. One typical property is the dynamics of HG, i.e., a real world HG always evolves over time. Despite that the incremental learning on dynamic HG is proposed , dynamic heterogeneous graph embedding is still facing big challenges. For example,  is only proposed with a shallow model, which greatly limits its embedding ability. How can we learn dynamic heterogeneous graph embedding in deep learning framework is worth pursuing. The other property is the uncertainty of HG, i.e., the generation of HG is usually multi-faceted and the node in a HG contains different semantics. Traditionally, learning a vector embedding usually cannot well capture such uncertainty. Gaussian distribution may innately represent the uncertainty property , which is largely ignored by current heterogeneous graph embedding methods. This suggests a huge potential direction for improving heterogeneous graph embedding.", "cites": [229], "cite_extract_rate": 0.25, "origin_cites_number": 4, "insight_result": {"type": "analytical", "scores": {"synthesis": 2.0, "critical": 3.0, "abstraction": 3.0}, "insight_level": "medium", "analysis": "The section provides some analytical insights by highlighting underexplored HG properties like dynamics and uncertainty. It mentions the limitations of existing methods and suggests potential future directions. However, synthesis is limited as it references only one paper (VGAE) and does not connect ideas across multiple works. The critique is moderate, pointing out issues such as shallow models and the lack of uncertainty modeling."}}
{"id": "4b0cb2b0-59c0-43a1-9fe2-9f3029d67463", "title": "Deep Graph Learning on HG Data", "level": "subsection", "subsections": [], "parent_id": "d06fbb62-ed87-4501-8db7-5811c0c8f1ac", "prefix_titles": [["title", "A Survey on Heterogeneous Graph Embedding"], ["section", "Challenges and Future Directions"], ["subsection", "Deep Graph Learning on HG Data"]], "content": "We have witnessed the great success and large impact of GNNs, where most of the existing GNNs are proposed for homogeneous graph . Recently, HGNNs have attracted considerable attention .\nOne natural question may arise that what is the essential difference between GNNs and HGNNs. More theoretical analysis on HGNNs are seriously lacking. For example, it is well accepted that the GNNs suffer from over-smoothing problem , so will heterogeneous GNNs also have such problem? If the answer is yes, what factor causes the over-smoothing problem in HGNNs since they usually contain multiple aggregation strategies .\nIn addition to theoretical analysis, new technique design is also important. One of the most important directions is the self-supervised learning. It uses the pretext tasks to train the neural networks, thus reducing the dependence on manual labels. . \nConsidering the actual demand that label is insufficient, self-supervised learning can greatly benefit the unsupervised and semi-supervised learning, and has shown remarkable performance on homogeneous graph embedding . Therefore, exploring self-supervised learning on heterogeneous graph embedding is expected to further facilitate the development of this area.\nAnother important direction is the pre-training of HGNNs . Nowadays, HGNNs are designed independently, i.e., the proposed method usually works well for some certain tasks, but the transfer ability across different tasks is ill-considered. When dealing with a new HG or task, we have to train a heterogeneous graph embedding method from scratch, which is time-consuming and requires large amounts of labels. In this situation, if there is a well pre-trained HGNN with strong generalization that can be fine-tuned with few labels, the time and label consumption can be reduced.", "cites": [240, 221, 9141, 248, 1184, 1429, 7357, 180, 1430, 1439, 1440], "cite_extract_rate": 0.7857142857142857, "origin_cites_number": 14, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.5, "critical": 3.0, "abstraction": 3.5}, "insight_level": "medium", "analysis": "The section analytically explores the challenges and future directions of HGNNs by referencing relevant work on self-supervised learning and pre-training, integrating concepts from multiple papers. While it connects these ideas to broader issues like over-smoothing and task transferability, it lacks in-depth comparative evaluation or novel frameworks. The abstraction is moderate, as it identifies general trends but does not elevate them to meta-level principles."}}
{"id": "14b791ca-3f1a-4017-904b-6a92b4787a9d", "title": "Making HG embedding reliable", "level": "subsection", "subsections": [], "parent_id": "d06fbb62-ed87-4501-8db7-5811c0c8f1ac", "prefix_titles": [["title", "A Survey on Heterogeneous Graph Embedding"], ["section", "Challenges and Future Directions"], ["subsection", "Making HG embedding reliable"]], "content": "Except from the properties and techniques in HG, we are also concerned about the ethical issues in HG embedding, such as fairness, robustness and interpretability. Considering that most methods are black boxes, making HG embedding reliable is an important future work.\n\\textbf{Fair HG embedding.} The embeddings learned by methods are sometimes highly related to certain attributes, e.g., age or gender, which may amplify the societal stereotypes in the prediction results . Therefore, learning fair or de-biased embeddings is an important research direction. There are some researches on the fairness of homogeneous graph embedding . However, the fairness of HG is still an unsolved problem, which is an important research direction in the further.\n\\textbf{Robust HG embedding.} Also, the robustness of  HG embedding, especially the adversarial attacking, is always an important problem . Since many real world applications are built based on HG, the robustness of HG embedding becomes an urgent yet unsolved problem. What is the weakness of HG embedding and how to enhance it to improve the robustness need to be further studied.\n\\textbf{Explainable HG embedding.} Moreover, in some risk aware scenarios, e.g., fraud detection  and bio-medicine  , the explanation of models or embeddings is important. A significant advantage of HG is that it contains rich semantics, which may provide eminent insight to promote the explanation of heterogeneous GNNs. Besides, the emerging disentangled learning , which divides the embedding into different latent spaces to improve the interpretability, can also be considered.", "cites": [1441, 917, 7358, 1442, 8453], "cite_extract_rate": 0.625, "origin_cites_number": 8, "insight_result": {"type": "analytical", "scores": {"synthesis": 2.5, "critical": 2.0, "abstraction": 2.5}, "insight_level": "medium", "analysis": "The section provides a general analytical overview of three key aspectsfairness, robustness, and interpretabilityin HG embedding, citing relevant papers. It synthesizes basic ideas from each paper to highlight their relevance to the topic but does not deeply connect or integrate them into a cohesive framework. Critical evaluation is limited, and while the section touches on broader themes, it lacks a meta-level abstraction or a comprehensive analysis of trends and principles."}}
{"id": "f7fd78fd-9946-4824-81a8-571ab9343135", "title": "Technique Deployment in Real-world Applications", "level": "subsection", "subsections": [], "parent_id": "d06fbb62-ed87-4501-8db7-5811c0c8f1ac", "prefix_titles": [["title", "A Survey on Heterogeneous Graph Embedding"], ["section", "Challenges and Future Directions"], ["subsection", "Technique Deployment in Real-world Applications"]], "content": "Many HG-based applications have stepped into the era of graph embedding. This survey has demonstrated the strong performance of heterogeneous graph embedding methods on E-commerce and cybersecurity. Exploring more capacity of heterogeneous graph embedding on other areas holds great potential in the future. For example, in software engineering area, there are complex relations among test sample, requisition form, and problem form, which can be naturally modeled as HG. Therefore, heterogeneous graph embedding is expected to open up broad prospects for these new areas and become promising analytical tool. Another area is the biological systems, which can also be naturally modeled as a HG. A typical biological system contains many types of objects, e.g., Gene Expression, Chemical, Phenotype, and Microbe. There are also multiple relations between Gene Expression and Phenotype . HG structure has been applied to biological system as an analytical tool, implying that heterogeneous graph embedding is expected to provide more promising results. \nIn addition, since the complexity of HGNNs are relatively large and the techniques are difficult to parallelize, it is difficult to apply the existing HGNNs to large-scale industrial scenarios. For example, the number of nodes in E-commerce recommendation may reach one billion . Therefore, successful technique deployment in various applications while resolving the scalability and efficiency challenges will be very promising.", "cites": [1417, 7359], "cite_extract_rate": 1.0, "origin_cites_number": 2, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.0, "critical": 2.5, "abstraction": 3.0}, "insight_level": "medium", "analysis": "The section synthesizes two cited papers to highlight the applicability of heterogeneous graph embedding in real-world domains like E-commerce and biological systems. It provides a general abstraction by identifying common patterns in how HG structures can model complex, multi-typed data. However, it lacks deeper critical evaluation of the cited works, merely stating their relevance without discussing their limitations, trade-offs, or comparative strengths."}}
{"id": "ca0caf90-1d11-463b-a3c0-795e88eed758", "title": "Others", "level": "subsection", "subsections": [], "parent_id": "d06fbb62-ed87-4501-8db7-5811c0c8f1ac", "prefix_titles": [["title", "A Survey on Heterogeneous Graph Embedding"], ["section", "Challenges and Future Directions"], ["subsection", "Others"]], "content": "Last but not least, there are also some important future work that cannot be summarized in the previous sections. Therefore, we carefully discuss them in this subsection.\n\\textbf{Hyperbolic heterogeneous graph embedding.} Some recent researches point out that the underlying latent space of graph may be non-Euclidean, but in hyperbolic space . Some attempts have been made towards hyperbolic graph/heterogeneous graph embedding, and the results are rather promising . However, how to design an effective hyperbolic heterogeneous GNNs is still challenging, which can be another research direction. \n\\textbf{Heterogeneous graph structure learning.} Under the current heterogeneous graph embedding framework, HG is usually constructed beforehand, which is independent on the heterogeneous graph embedding. This may result in that the input HG is not suitable for the final task. HG structure learning can be further integrated with heterogeneous graph embedding, so that they can promote each other. \n\\textbf{Connections with knowledge graph.} Knowledge graph embedding has great potential on knowledge reasoning . However, knowledge graph embedding and heterogeneous graph embedding are usually investigated separately. Recently, knowledge graph embedding has been successfully applied to other areas, e.g., recommender system . It is worth studying that how to combine knowledge graph embedding with heterogeneous graph embedding, and incorporate knowledge into heterogeneous graph embedding.", "cites": [210, 1444, 1443, 1436, 1435, 1165], "cite_extract_rate": 0.8571428571428571, "origin_cites_number": 7, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.5, "critical": 3.0, "abstraction": 3.5}, "insight_level": "medium", "analysis": "The section synthesizes ideas from multiple papers to discuss three emerging directions in HG embedding, connecting them to broader trends in geometric learning and knowledge-based systems. While it provides some critical perspectives, such as the limitations of existing hyperbolic GNNs and the disjointed investigation of knowledge graph and HG embedding, it stops short of a deep comparative or evaluative analysis. The abstraction level is moderate, as it identifies potential integration patterns and general research opportunities."}}
