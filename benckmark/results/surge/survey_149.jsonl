{"id": "76ab8b06-04dc-4d57-9823-e9297b27e414", "title": "Introduction", "level": "section", "subsections": [], "parent_id": "b5e1c939-ea72-4bf2-af5b-7d76e16e5578", "prefix_titles": [["title", "Graph-based Deep Learning for Communication Networks: A Survey"], ["section", "Introduction"]], "content": "\\label{sec:intro}\nCommunication networks are ubiquitous in contemporary society, from the widely used Internet and 4G/5G cellular networks to the fast-growing Internet of Things (IoT) networks. The growing of communication networks has gone beyond the imagination of their designers. For example, based on Cisco Annual Internet Report (2018–2023) White Paper, nearly two-thirds of the global population will have Internet access by 2023~\\footnote{\\url{https://www.cisco.com/c/en/us/solutions/collateral/executive-perspectives/annual-internet-report/white-paper-c11-741490.html}}. It would be very challenging to operate and manage such giant networks and new network types keep bringing new problems. For example, the manual configuration becomes infeasible or inefficient in modern networks. While the research for communication networks has a long history, it is still an active area with a steady stream of new ideas, e.g., Software Defined Networking (SDN) and Space-Air-Ground Integrated Network (SAGIN). The challenges may not only include the traditional ones, e.g., routing and load balancing, power control and resource allocation, but also the emerging ones, e.g., virtual network embedding in SDN.\nTo solve these challenges, various solutions are introduced to the networking domain, especially deep learning~. Represented by deep neural networks, deep learning has achieved a great success in many problems, especially in image recognition, natural language processing, and time series problems~. Deep learning models are also applied in various communication networks and are proven extremely useful for a series of problems, e.g., network design, traffic prediction, resource allocation, etc~. However, in these studies, the network topology structure is not fully utilized because most of the deep neural networks are designed for Euclidean structure data, e.g., images and videos. To amend this shortcoming, graph-based deep learning represented by Graph Neural Networks (GNNs) are proposed for non-Euclidean structure data in recent years~. More recently, GNNs are combined with deep reinforcement learning for making decisions in a series of problems, e.g., GNN is used for processing the graph information and  improving the inter-coflow scheduling ability in distributed computing~.\nGNNs are suitable for problems in communication networks because of their strong learning ability to capture the spatial information hidden in the network topology and their generalization ability to be used in unseen topologies when the networks are dynamic. As to be discussed in this survey, GNN-based solutions are proven effective for a wide range of problems in different network scenarios and are worthy of being explored deeper in the future.\nTo the best of the authors' knowledge, this paper presents the first literature survey of graph-based deep learning studies for problems in communication networks, covering a total of 81 papers ranging from 2016 to 2021 and involving both wired and wireless scenarios. Compared to a recent similar survey~ which only covers the applications of GNNs in wireless networks, our survey has a broader coverage and contains almost all the surveyed studies from~. The scope of communication networks used in this survey is broad, thus the surveyed papers are selected from a wide range of journals and conferences. Because it is still a very rapidly developing research topic of applying graph-based deep learning methods, we also include preprints that have not yet gone through the traditional peer review process (e.g., arXiv papers) to present the latest progress. \nThe surveyed papers are classified into three major scenarios, as organized in Figure~\\ref{fig:fig1}. Some of the common problems are discussed in two or three scenarios, e.g., network modeling, routing, traffic prediction. The other problems are only mentioned in one of these scenarios. This kind of organization is not exclusive, because the idea of SDN can be applied for both the wireless and wired networks. Graph-based deep learning is being frequently used in the assumption of future softwarized networks, without a strict constraint about which type of substrate network is being used. By taking the SDN scenario as a separate section, the relevant discussion would be inspiring for both the future work in the wireless and wired scenarios.\n\\begin{figure}[!htb]\n    \\centering\n    \\includegraphics[width=\\textwidth]{fig1.pdf}\n    \\caption{The organization of this survey.}\n    \\label{fig:fig1}\n\\end{figure}\nIn this survey, the problems to solve, the graph-based solutions and the specific GNN models used in each study are identified and summarized. We also attempt to point out the future directions of applying GNNs in communication networks. Our aim is to provide an up-to-date summary of related work and a useful starting point for new researchers interested in related topics. In addition to this paper, we have also created an open GitHub repository~\\footnote{\\url{https://github.com/jwwthu/GNN-Communication-Networks}} to update new papers continuously.\nOur contributions are summarized as follows:\n1) \\textit{Comprehensive Review}: We present the up-to-date comprehensive review of graph-based deep learning solutions for problems in various types of communication networks, in the past six years (2016-2021).\n2) \\textit{Well-organized Summary}: We summarize the problem to solve, the graph-based solution and the GNNs used in each study in a unified format, which would be useful as a reference manual.\n3) \\textit{Future Directions}: We propose several potential future directions for researchers interested in relevant topics. \nFor reference, the list of the acronyms frequently used in this survey is summarized in Table~\\ref{tab:acronyms}.\n\\begin{center}\n\\begin{longtable}{lp{10cm}}\n\\caption{The list of the acronyms used in this survey.} \\label{tab:acronyms} \\\\\n\\hline Acronym & Full Name \\\\ \\hline \n\\endfirsthead\n\\multicolumn{2}{c}\n{{\\bfseries \\tablename\\ \\thetable{} -- continued from previous page}} \\\\\n\\hline Acronym & Full Name \\\\ \\hline \n\\endhead\n\\hline \\multicolumn{2}{r}{{Continued on next page}} \\\\ \\hline\n\\endfoot\n\\hline\n\\endlastfoot\nBGP & Border Gateway Protocol \\\\\nDC-STGCN & Dual-Channel based Graph Convolutional Network \\\\\nDCRNN & Diffusion Convolutional Recurrent Neural Network \\\\\nDL & Deep Learning \\\\\nDQN & Deep Q Network \\\\\nDRL & Deep Reinforcement Learning \\\\\nFDS-MARL & Fully Decentralized Soft Multi-Agent Reinforcement Learning \\\\\nGASTN & Graph Attention Spatial-Temporal Network \\\\\nGAT & Graph Attention Network \\\\\nGCLR & GNN based Cross Layer optimization by Routing \\\\\nGCN & Graph Convolutional Network \\\\\nGE & Graph Embedding \\\\\nGGS-NN & Gated Graph Sequence Neural Network \\\\\nGIN & Graph Isomorphism Network \\\\\nGN & Graph Network \\\\\nGNN & Graph Neural Network \\\\\nHIGNN & Heterogeneous Interference Graph Neural Network \\\\\nHetGAT & Heterogeneous Graph Attention Network \\\\\nIGCNet & Interference Graph Convolutional Neural Network \\\\\nML & Machine Learning \\\\\nMPGNNs & Message Passing Graph Neural Networks \\\\\nMPLS & Multiprotocol Label Switching \\\\\nMPNN & Message Passing Neural Network \\\\\nMSTNN & Multi-scale Spatial-Temporal Graph Neural Network \\\\\nNFV & Network Function Virtualization \\\\\nREGNNs & Random Edge Graph Neural Networks \\\\\nS-RNN & Structural-RNN \\\\\nSDN & Software Defined Networking \\\\\nSFC & Service Function Chaining \\\\\nSGCRN & Spatiotemporal Graph Convolutional Recurrent Network \\\\\nTCN & Temporal Convolutional Network \\\\\nTGCN & Temporal Graph Convolutional Network \\\\\nUWMMSE & Unfolded iterative Weighted Minimum Mean Squared Error \\\\\nVNE & Virtual Network Embedding \\\\\nVNF & Virtual Network Function \\\\\n\\hline\n\\end{longtable}\n\\end{center}\nThe remainder of this paper is organized as follows. In Section~\\ref{sec:method}, we introduce the progress of conducting literature search and selection. In Section~\\ref{sec:gnns}, we introduce the GNNs used in the reviewed studies. In Section~\\ref{sec:wireless}, we summarize the studies in wireless networks. In Section~\\ref{sec:wired}, we summarize the studies in wired networks. In Section~\\ref{sec:sdn}, we summarize the studies in software defined networks. In Section~\\ref{sec:direction}, we point out future directions. In Section~\\ref{sec:conclusion}, we draw the conclusion.", "cites": [554, 550, 549, 546, 97, 545, 169, 551, 166, 553, 548, 547, 8362, 552], "cite_extract_rate": 0.7777777777777778, "origin_cites_number": 18, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.5, "critical": 2.0, "abstraction": 2.5}, "insight_level": "medium", "analysis": "The introduction provides a general overview of communication networks and the role of deep learning, with some integration of cited works to highlight the relevance of GNNs. However, it primarily describes trends and applications without deep synthesis or critical evaluation. There is limited abstraction, focusing more on specific examples than overarching principles."}}
{"id": "6cb4828c-3021-455e-8c39-9494c3053409", "title": "Survey Methodology", "level": "section", "subsections": [], "parent_id": "b5e1c939-ea72-4bf2-af5b-7d76e16e5578", "prefix_titles": [["title", "Graph-based Deep Learning for Communication Networks: A Survey"], ["section", "Survey Methodology"]], "content": "\\label{sec:method}\nTo collect relevant studies, the literature is searched with various combinations of two groups of keywords. The first group is about the graph-based deep learning techniques, e.g., ``Graph\", ``Graph Embedding\", ``Graph Neural Network\", ``Graph Convolutional Network\", ``Graph Attention Networks\", ``GraphSAGE\", ``Message Passing Neural Network\", ``Graph Isomorphism Network\", etc. The second group is about the communication networks as well as specific problems, e.g., ``Wireless Network\", ``Cellular Network\", ``Computer Network\", ``Software Defined Networking\", ``Traffic Prediction\", ``Routing\", ``Service Function Chaining\", ``Virtual Network Function\", etc. The databases from major publishers are carefully covered one by one, e.g., ACM, Elsevier, IEEE, Springer, Wiley, etc. To track the citation relationship among these papers and avoid missing records from smaller publishers, Google Scholar is also leveraged in the literature search process.\nA total of 81 papers are finally selected and covered in this survey, with the earliest one published in year 2016, as shown in Figure~\\ref{fig:paper_count}. Most of the surveyed papers are published in recent three years, i.e., 2019, 2020, and the first five months of 2021. Compared with 14 papers in 2019, there is a 207\\% growth of papers in 2020, with a total of 43 papers. While there are only 20 papers in the first five months of 2021, it is expected that more relevant studies would be published or publicized in the remaining months with the growing impact of graph-based deep learning methods being applied in the networking domain. We also show the paper statistics for different network types in Figure~\\ref{fig:type_count}. The wireless network scenario draws more attention than the other two and this trend may continue in 2021.\n\\begin{figure}[!htb]\n    \\centering\n    \\includegraphics[width=\\textwidth]{paper_count.pdf}\n    \\caption{The paper count of different types annually.}\n    \\label{fig:paper_count}\n\\end{figure}\n\\begin{figure}[!htb]\n    \\centering\n    \\includegraphics[width=\\textwidth]{type_count.pdf}\n    \\caption{The paper count of different network types annually.}\n    \\label{fig:type_count}\n\\end{figure}\nFor a full coverage of relevant studies, workshop, conference, and journal papers as well as preprint papers are covered in this survey, to track the latest achievements as well as the on-going progress. The journal list (alphabetically) is shown in Table~\\ref{tab:journal}. The conference list (alphabetically) is shown in Table~\\ref{tab:conference}. And the workshop list (alphabetically) is shown in Table~\\ref{tab:workshop}. All the preprint papers are from the arXiv platform~\\footnote{\\url{https://arxiv.org/}}. Since we cover a wide area with various communication networks, the papers are selected from various publications or conference proceedings, some of which may focus on telecommunications or related subjects and the others may be multidisciplinary. As an emerging topic which has not been widely adopted, graph-based deep learning appears in recent years for solving networking-related problems, with only one paper selected for most journals or conferences.\n\\begin{table}[!htb]\n\\centering\n\\caption{List of source journals and the corresponding studies we cover in this study.}\n\\label{tab:journal}\n\\begin{tabular}{ll}\n\\hline\nJournal Name & Studies \\\\\n\\hline\nComputer Networks &  \\\\\nElectronics &  \\\\\nIEEE Access &  \\\\\nIEEE Communications Letters &  \\\\\nIEEE Internet of Things Journal &  \\\\\nIEEE Journal on Selected Areas in Communications &  \\\\\nIEEE Systems Journal &  \\\\\nIEEE Transactions on Industrial Informatics &  \\\\\nIEEE Transactions on Information Forensics and Security &  \\\\\nIEEE Transactions on Mobile Computing &  \\\\\nIEEE Transactions on Network Science and Engineering &  \\\\\nIEEE Transactions on Network and Service Management &  \\\\\nIEEE Transactions on Signal Processing &  \\\\\nIEEE Transactions on Vehicular Technology &  \\\\\nIEEE Transactions on Wireless Communications &  \\\\\nInternational Journal of Network Management &  \\\\\nPerformance Evaluation &  \\\\\nSensors &  \\\\\nTransactions on Emerging Telecommunications Technologies &  \\\\\n\\hline\n\\end{tabular}\n\\end{table}\n\\begin{table}[!htb]\n\\centering\n\\caption{List of source conferences and the corresponding studies we cover in this study.}\n\\label{tab:conference}\n\\begin{tabular}{p{12cm}l}\n\\hline\nConference Name & Studies \\\\\n\\hline\nACM SIGCOMM conference &  \\\\\nACM Symposium on SDN Research (SOSR) &  \\\\\nAsia-Pacific Network Operations and Management Symposium (APNOMS) &  \\\\\nIEEE Annual Consumer Communications \\& Networking Conference (CCNC) &  \\\\\nIEEE Conference on Computer Communications (INFOCOM) &  \\\\\nIEEE Conference on Network Function Virtualization and Software Defined Networks (NFV-SDN) &  \\\\\nIEEE Global Communications Conference (GLOBECOM) &  \\\\\nIEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) &  \\\\\nIEEE International Conference on Communications (ICC) &  \\\\\nIEEE Symposium on Computers and Communications (ISCC) &  \\\\\nIEEE Vehicular Technology Conference (VTC) &  \\\\\nIEEE Wireless Communications and Networking Conference (WCNC) &  \\\\\nIFIP Networking Conference (IFIP Networking) &  \\\\\nInternational Conference on Information Networking (ICOIN) &  \\\\\nInternational Conference on Information and Communication Technology Convergence (ICTC) &  \\\\\nInternational Conference on Network and Service Management (CNSM) &  \\\\\nInternational Conference on Real-Time Networks and Systems (RTNS) &  \\\\\nInternational Conference on Wireless Communications and Signal Processing (WCSP) &  \\\\\nInternational Conference on emerging Networking EXperiments and Technologies (CoNEXT) &  \\\\\nInternational Symposium on Networks, Computers and Communications (ISNCC) &  \\\\\nOpto-Electronics and Communications Conference (OECC) &  \\\\\n\\hline\n\\end{tabular}\n\\end{table}\n\\begin{table}[!htb]\n\\centering\n\\caption{List of source workshops and the corresponding studies we cover in this study.}\n\\label{tab:workshop}\n\\begin{tabular}{p{12cm}l}\n\\hline\nWorkshop Name & Studies \\\\\n\\hline\nAutoML for Networking and Systems Workshop of MLSys Conference &  \\\\\nIEEE Globecom Workshops (GC Wkshps) &  \\\\\nIEEE International Workshop on Signal Processing Advances in Wireless Communications (SPAWC) &  \\\\\nWorkshop on Big Data Analytics and Machine Learning for Data Communication Networks &  \\\\\nWorkshop on Network Meets AI \\& ML &  \\\\\n\\hline\n\\end{tabular}\n\\end{table}", "cites": [6974, 559, 562, 564, 555, 558, 563, 557, 560, 556, 8364, 8363, 7036, 561], "cite_extract_rate": 0.2028985507246377, "origin_cites_number": 69, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 1.5, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section primarily describes the methodology used to gather the surveyed papers, including keyword selection, database coverage, and temporal trends. While it lists some specific problem domains and references the cited papers, it does not synthesize or integrate their findings into a broader narrative. There is minimal critical analysis or abstraction beyond the surface-level description of publication sources and counts."}}
{"id": "7331c726-2776-4f61-a2d5-5b5cd72f0066", "title": "Graphs in Communication Networks", "level": "subsection", "subsections": [], "parent_id": "d6fac988-1d39-4ec5-8199-6d726c943be3", "prefix_titles": [["title", "Graph-based Deep Learning for Communication Networks: A Survey"], ["section", "Graph-based Deep Learning Introduction"], ["subsection", "Graphs in Communication Networks"]], "content": "From the graph theory, a simple graph is defined as $G=(V, E)$, where $V$ is the set of nodes and $E$ is the set of edges between nodes. In communication networks, the edges can be either directed or undirected, depending on the specific problems. Both nodes and edges can be associated with some attributes as the features, either static or dynamic.\nTwo graph examples are given for the wired and wireless scenarios respectively. In Figure~\\ref{fig:fig3}, the communication graph from the Abilene network is presented, which consists of 11 nodes and 14 edges. Each node represents the physical backbone router and the node features include the inflow and outflow traffic volumes. Each edge represents the physical transmission link and the edge features include the transmission metrics, e.g., bandwidth and delay. Similar communication graphs are built from other network topologies, e.g., the Nobel, G\\'{E}ANT, Germany50, and AT\\&T backbone networks, can be found in~.\n\\begin{figure}[!htb]\n    \\centering\n    \\includegraphics[width=\\textwidth]{fig3.pdf}\n    \\caption{An example of the communication graph from the Abilene network.}\n    \\label{fig:fig3}\n\\end{figure}\nIn Figure~\\ref{fig:fig4}, the interference graph for a homogeneous ad-hoc network is presented, which consists of 3 nodes and 3 edges. Different from Figure~\\ref{fig:fig3}, the nodes in Figure~\\ref{fig:fig4} are virtual nodes, each of which corresponds to a transceiver pair (Tx, Rx). The features of node $i$ include the direct channel state information (CSI) $\\mathbf{h}_{ii}$ and other environmental information, e.g., the weight $\\omega_i$ of node $i$~. The undirected edge between node $i$ and node $j$ models the interference between two transceiver pairs and the edge features are the interference CSIs $\\mathbf{h}_{ij}$ and $\\mathbf{h}_{ji}$. The interference graph built for the heterogeneous ad-hoc network case can be further found in~. \n\\begin{figure}[!htb]\n    \\centering\n    \\includegraphics[width=\\textwidth]{fig4.pdf}\n    \\caption{An example of the interference graph from~.}\n    \\label{fig:fig4}\n\\end{figure}\nAn adjacency matrix $\\mathbf{A}$ is introduced to incorporate the network topology information into the architecture of neural networks. Let $e_{ij}$ represents the edge between node $v_i$ and node $v_j$. Then the element of the adjacency matrix $A$ is defined as follows: $A_{ij} = 1$ if $e_{ij} \\in E$, otherwise, $A_{ij} = 0$. Here the binary matrix $A$ only captures the connection relationship. If $\\mathbf{A}$ is symmetric, the graph is undirected, otherwise, the graph is directed. More complex adjacency matrices can be defined similarly, e.g., the distance matrix or the interference matrix. \nFor defining the GNNs in the next part, more notations are introduced here. Based on the connection relationship, $\\mathcal{N}(v_i)$ represents the neighbor node set of $v_i$ and each element of the degree matrix $\\mathbf{D}$ is $\\mathbf{D}_{ii}=\\|\\mathcal{N}(v_i)\\|$. The Laplacian matrix of an undirected graph is introduced and defined as $\\mathbf{L} = \\mathbf{D} - \\mathbf{A}$ and the normalized Laplacian matrix is further defined as $\\tilde{\\mathbf{L}} = \\mathbf{I}_N - \\mathbf{D}^{-\\frac{1}{2}} \\mathbf{A} \\mathbf{D}^{-\\frac{1}{2}}$, where $N$ is the number of nodes and $\\mathbf{I}_N$ is the identity matrix with size $N$. The node feature matrix of a graph is defined as $\\mathbf{X} \\in {R}^{N \\times d}$, where $d$ is the dimension of the node feature vector.", "cites": [561, 565], "cite_extract_rate": 0.4, "origin_cites_number": 5, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 1.5, "abstraction": 2.5}, "insight_level": "low", "analysis": "The section provides basic definitions and examples of graphs in communication networks, including wired and wireless cases, and introduces standard notations used in GNNs. However, it primarily describes these concepts without synthesizing the cited papers into a broader narrative or offering critical analysis of their approaches. Some level of abstraction is present in the introduction of general graph structures and matrices, but the integration and depth of insight remain limited."}}
{"id": "d533c3b7-2947-4ba5-a853-b9d81f3bdf99", "title": "Graph-based Models in Communication Networks", "level": "subsection", "subsections": [], "parent_id": "d6fac988-1d39-4ec5-8199-6d726c943be3", "prefix_titles": [["title", "Graph-based Deep Learning for Communication Networks: A Survey"], ["section", "Graph-based Deep Learning Introduction"], ["subsection", "Graph-based Models in Communication Networks"]], "content": "Since the research for graph-based deep learning is still in a fast pace with new models appearing continuously, we have no intention of conducting a thorough literature search on the graph-based models. In this section, we would focus on a short introduction for the GNNs used in the surveyed studies. For those who are interested in the whole picture of graph neural networks and a deeper discussion of the technical details, recent surveys~ are recommended. The relevant graph-based deep learning models are listed chronologically in Figure~\\ref{fig:fig2}. Please note that the listed conferences may be lagged behind the preprint versions, which could be released one or two years earlier.\n\\begin{figure}[!htb]\n    \\centering\n    \\includegraphics[width=\\textwidth]{fig2.pdf}\n    \\caption{The relevant graph-based deep learning models of this survey.}\n    \\label{fig:fig2}\n\\end{figure}\nAs a pioneering study, GNN is introduced in~, which extends the application of neural networks from Euclidean structure data to non-Euclidean structure data. GNN is based on the message passing mechanism, in which each node updates its state by exchanging information with each other until it reaches a certain stable state. Afterwards, various GNN variants are proposed, e.g., Graph Convolutional Network (GCN) and Graph Attention Networks (GAT).\nWe first introduce the Graph Embedding (GE) models. In mathematics, embedding is a mapping function $f: X \\rightarrow Y$, in which a point in one space $X$ is mapped to another space $Y$. Embedding is usually performed from a high-dimensional abstract space to a low-dimensional space. Generally speaking, the representation mapped to the low-dimensional space is easier for neural networks to handle with. In the case of graphs, graph embedding is used to transform nodes, edges, and their features into the vector space, while preserving properties like graph structure and information as much as possible. For the studies covered in this survey, several graph embedding models are involved, including structure2vec~, GraphSAGE~, and GE~. In a transductive learning approach, Structure2vec~ is based on the idea that if the two sequences composed of all the neighbors of two nodes are similar, then the two nodes are similar. GraphSAGE~ is a representative of inductive learning. It does not directly learn the representation of each node, but learns the aggregation function instead. For the new node, its embedding representation is generated directly without the need to learn again. Furthermore, a novel adversarial regularized framework is proposed for graph embedding in~.\nThen we introduce the GCN models. GCN extends the convolution operation from traditional data (such as images) to graph data, inspired by the convolutional neural networks which are extremely successful for image-based tasks. The core idea is to learn a function mapping, through which a node can aggregate its own features and the features of its neighbors to generate the new representation. Generally speaking, there are two types of GCN models, namely, spectral-based and spatial-based. \nBased on graph signal processing, spectral-based GCNs define the convolution operation in the spectral domain, e.g., the Fourier domain. To conduct the convolution operation, a graph signal is transformed to the spectral domain by the graph Fourier transform. Then the result after the convolution is transformed back by the inverse graph Fourier transform. Several spectral-based GCNs are used in the surveyed studies, e.g., GNN~, ChebNet~, and GCN~, which improve the convolution operation with different techniques. By introducing a parameterization with smooth coefficients, GNN~ attempts to make the spectral filters spatially localized. ChebNet~ learns the diagonal matrix as an approximation of a truncated expansion in terms of Chebyshev polynomials up to $K$th order.\nTo avoid overfitting, $K=1$ is used in GCN~. More specifically, the graph convolution operation $*G$ in GCN is defined as follows:\n\\begin{equation}\n\\mathbf{X}_{*G} = \\mathbf{W} (\\mathbf{I}_N + \\mathbf{D}^{-\\frac{1}{2}} \\mathbf{A} \\mathbf{D}^{-\\frac{1}{2}}) \\mathbf{X}\n\\end{equation}\n\\noindent where $\\mathbf{W}$ is a learnable weight matrix, i.e., the model parameters. To alleviate the potential gradient explosion problem, the graph convolution operation is further transformed into:\n\\begin{equation}\n\\mathbf{X}_{*G} = \\mathbf{W} ( \\tilde{\\mathbf{D}}^{-\\frac{1}{2}} \\tilde{\\mathbf{A}} \\tilde{\\mathbf{D}}^{-\\frac{1}{2}}) \\mathbf{X}\n\\end{equation}\n\\noindent where $\\tilde{\\mathbf{A}} = \\mathbf{A} + \\mathbf{I}_N$ and $\\tilde{\\mathbf{D}}_{ii} = \\sum_{j}{\\tilde{\\mathbf{A}}_{ij}}$.\nSeveral spatial-based GCNs are also used in the surveyed studies, which defines the convolution operation directly on the graph based on the graph topology. To unify different spatial-based variants, Message Passing Neural Network (MPNN)~ proposes the usage of message passing functions, which contain a message passing phase and a readout phase. The message passing phase is defined as follows:\n\\begin{equation}\n\\mathbf{m}_{v_i}^{(t)} = \\sum_{v_j \\in \\mathcal{N}{(v_i)}} \\mathcal{M}^{(t)} (\\mathbf{X}_i^{(t-1)}, \\mathbf{X}_j^{(t-1)}, \\mathbf{e}_{ij})\n\\end{equation}\n\\noindent where $\\mathbf{m}_{v_i}^{(t)}$ is the message aggregated from the neighbors of node $v_i$, $\\mathcal{M}^{(t)}(\\cdot)$ is the aggregation function in the $t$-th iteration, $\\mathbf{X}_i^{(t)}$ is the hidden state of node $v_i$ in the $t$-th iteration, and $\\mathbf{e}_{ij}$ is the edge feature vector between node $v_i$ and node $v_j$. The readout phase is further defined as follows:\n\\begin{equation}\n\\mathbf{X}_i^{(t)} = \\mathcal{U}^{(t)} (\\mathbf{X}_i^{(t-1)},\\mathbf{m}_{v_i}^{(t)})\n\\end{equation}\n\\noindent where $\\mathcal{U}^{(t)}(\\cdot)$ is the readout function in the $t$-th iteration.\nGraph Network (GN)~ also unifies many GNN variants, by learning node-level, edge-level and graph-level representations. Graph Isomorphism Network (GIN)~ takes a step further by pointing out that previous MPNN-based methods are incapable of distinguishing different graph structures based on the graph embedding they produce and adjusting the weight of the central node by a learnable parameter to amend this drawback. Attention-based GNN models can be categorized into the spatial-based type. GAT~ incorporates the attention mechanism into the propagation step and further utilizes the multi-head attention mechanism to stabilize the learning process, which is defined as follows:\n\\begin{equation}\n\\mathbf{X}_i^{(t)} = \\|_k \\sigma (\\sum_{j \\in \\mathcal{N}{(v_i)}} \\alpha^k (\\mathbf{X}_i^{(t-1)}, \\mathbf{X}_j^{(t-1)}) \\mathbf{W}^{(t-1)} \\mathbf{X}_j^{(t-1)})\n\\end{equation}\n\\noindent where $\\|$ is the concatenation operation, $\\sigma$ is the activation method, $\\alpha^{k}(\\cdot)$ is the $k$-th attention mechanism.\nOther than the convolution operation, the recurrent operation can also be applied in the propagation module of GNNs. The key difference is that the convolution operations use different weights while the recurrent operations share the same weights. For example, Gated Graph Sequence Neural Network (GGS-NN)~ uses Gated Recurrent Units (GRU) in the propagation step.\nIn realistic networks, the network topology may change occasionally, e.g., with the addition or deletion of routers, which corresponds to the case of dynamic graphs, instead of static graphs. Several GNN variants are proposed for dealing with dynamic graphs. Diffusion Convolutional Recurrent Neural Network (DCRNN)~ leverages GNNs to collect the spatial information, which is further used in sequence-to-sequence models. By extending the static graph structure with temporal connections, Structural-RNN (S-RNN)~ can learn the spatial and temporal information simultaneously.\nThe last case to discuss is the heterogeneous graph, in which the nodes and edges are multi-typed or multi-modal. For this case, meta-path is introduced as a path scheme which determines the type of node in each position of the path, then one heterogeneous graph can be reduced to several homogeneous graphs to perform graph learning algorithms. To generate the final representation of nodes, graph attention is performed on the meta-path-based neighbors and a semantic attention is used over output embeddings of nodes under all meta-path schemes in Heterogeneous Graph Attention Network (HetGAT)~.", "cites": [546, 231, 242, 180, 8313, 566, 550, 248, 553, 548, 257, 7213, 208, 211, 23, 216, 169], "cite_extract_rate": 0.85, "origin_cites_number": 20, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.0, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section synthesizes multiple graph-based deep learning models effectively, contextualizing their design choices and applications. It abstracts key concepts like transductive vs. inductive learning and differentiates between spectral and spatial GCNs, while also pointing out limitations (e.g., inability to distinguish graph structures). Critical analysis is present but could be deeper, particularly in evaluating trade-offs and performance implications."}}
{"id": "30670314-ebcd-4432-a20b-4702eaddd982", "title": "Pros and Cons of Graph-based Models", "level": "subsection", "subsections": [], "parent_id": "d6fac988-1d39-4ec5-8199-6d726c943be3", "prefix_titles": [["title", "Graph-based Deep Learning for Communication Networks: A Survey"], ["section", "Graph-based Deep Learning Introduction"], ["subsection", "Pros and Cons of Graph-based Models"]], "content": "Machine learning has emerged as a new paradigm to solve various networking problems and to automate network management~. Compared with traditional methods, ML models provide many benefits for solving the networking relevant problems. The first advantage is that machine learning models can automatically learn and improve from experiences without being explicitly programmed~. Even though it takes some efforts to train a machine learning model, the inference time when applying a trained model is much smaller. These efforts are also inevitable when applying a traditional method based on various optimization techniques which may require a long iteration update process. The second advantage is that the machine learning models are more effective in learning wide and dynamically changing data than statistical and heuristic methods. Based on these advantages, machine learning models, especially the deep learning models, have been widely applied in the networking domain.\nThe story does not end here. While machine learning has achieved a great success in many research fields, e.g., computer vision, natural language processing and time series processing. Most of these fields use Euclidean domain data, for which the feed forward neural networks, CNNs and RNNs are enough. However, for other fields, e.g., chemistry and biology, these models are inadequate for learning the non-Euclidean graph data, which contain rich relational information between each pair of neighboring elements. Many kinds of graph structure data also exist in the communication networks as introduced earlier, which is beyond the ability of non-GNN machine learning models. Driven by the graph structure data, GNNs are preferable because GNNs can automatically learn a condensed representation of each node in the network that incorporates the information about the node, its neighbors, and their inter-connecting topology~ and support relational reasoning and combinatorial generalization~. \nBesides the ability of handling graph structure, GNNs bring new opportunities for other challenges that have not been fully solved by previous machine learning models, e.g., the complexity in the network state and nonstationarity in networking, with a better generalization ability. Communication networks are complex and dynamic systems, and the overall networking performance may be affected by many factors, e.g., the latency metric affects networking efficiency by defeating network protocols~. Traditional techniques, e.g., the open shortest path first protocol (OSPF) for routing, are not capable of coping with these challenges. When situations such as link failure and congestion happen, these traditional techniques would not be able to converge quickly with these previously unseen situations. The non-GNN machine learning models will no longer apply when the network topology changes, e.g., link disconnection, and new training data are needed~. Since the topology of the network is usually dynamically changed, dynamic graphs are used in GNNs for the actual network. In other words, GNN is able to understand the complex relationship between topology, routing and traffic in networks, and generalizes trained NN parameters over arbitrary topologies, routing schemes and variable traffic intensity~. It is also proven that GNNs have a higher training efficiency than other neural networks, for example, GNNs converge $O(n \\log n)$ times faster and their generalization error is $O(n)$ times lower theoretically, compared with multilayer perceptrons in a communication networks with $n$ nodes~.\nEven so, GNNs are not the panacea. There are still some concerns about applying GNNs in the networking domain and not all of them have been fully resolved. The first concern is about the collection of training data for GNNs (and other machine learning models too). Compared with the well-developed research areas with large-scale open benchmark datasets, e.g., ImageNet for computer vision, the training datasets are still rare (at least the open ones) for training the effective GNN models. Even for those already used in the existing studies, the data size is limited and is far from the need of being applied in the actual network.\nThe second concern is about the depth of GNN models. For other neural networks, e.g., CNNs, it has been proven effective to use a deeper structure, e.g., ResNet. However, similar benefits are not obvious for GNNs. It has been found that when using more than two GCN layers, the performance becomes worse with more GCN layers. This is because GNNs rely on the aggregation operation on the features of neighbor nodes, the results become too smooth and lack of differentiation after multiple layers. As the network continues to overlap, eventually all nodes will learn the same expression and GNNs fail to work. It is still questionable Whether the graph neural network needs a deep structure, or whether a deep network structure can be designed to avoid the problem of over-smoothness in the networking domain.\nThe third concern is about the stability of GNN models, both under the stochastic perturbations and adversarial attacks~. Stochastic perturbations appear in the communication networks in the situations when link failure and congestion happen. While the adversarial attacks appear when targeted attacks on the underlying networks happen. These problems already exist for other neural networks and more attack types can be designed by leveraging the node features or the graph structure. It has been found that the stability of GNNs is affected by multiple factors, e.g., the graph filter, nonlinearity, architecture width and depth, etc~. And massive efforts have been put to design GNNs which are robust to the perturbations or attacks. With the deeper involvement of GNNs with various networking problems, more potential vulnerable cases would appear which would require a design of more robust GNNs.\nThe last but not the least concern is about the explainability of GNNs for networking problems. The study for the explainability and visualization of deep learning models has a long story and deep learning has been criticized for its ``black-box’’ property. The graph structure brings new challenges for the explainability problem. The development of post-processing techniques to explain the predictions made by GNNs has been made with some progresses, however, the explainability of GNNs in the networking domain has not yet been fully addressed~.", "cites": [7013, 569, 7037, 567, 568], "cite_extract_rate": 0.5, "origin_cites_number": 10, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.2, "critical": 4.0, "abstraction": 4.3}, "insight_level": "high", "analysis": "The section provides a coherent synthesis of multiple cited papers, integrating insights on the limitations and challenges of GNNs in the networking domain, such as data scarcity, over-smoothing, robustness, and explainability. It critically evaluates these issues and contrasts GNNs with traditional and other ML models, offering a nuanced perspective on their suitability for dynamic network environments. The section also abstracts beyond individual works to identify overarching challenges and research gaps, contributing to a broader understanding of GNNs in communication networks."}}
{"id": "c2d57700-f23b-45b4-bd73-47a2b9a116ec", "title": "General Wireless Network", "level": "subsection", "subsections": [], "parent_id": "4b607e1c-c213-4395-84ec-a8cebdbe2428", "prefix_titles": [["title", "Graph-based Deep Learning for Communication Networks: A Survey"], ["section", "Wireless Networks"], ["subsection", "General Wireless Network"]], "content": "Compared with other deep learning models, GNNs have the advantage of handling the topology information, which may not be leveraged in previous studies with Euclidean deep learning models. In densely deployed wireless local area networks, the channel resource is limited. To increase the system throughput, the channels must be allocated efficiently. The features of the channel vectors with the topology information are extracted in~, with the GCN model. Then a deep reinforcement learning is developed for channel allocation, which utilizes the features extracted by GCN. Topology information is also used in~ for wireless network optimization. Combining a GE unit and a deep feed-forward network, a two-stage topology-aware framework is proposed and validated for the network flow optimization problem, which achieves a trade-off between computation time and inference performance.\nCompared with the wired communication, wireless transmission may be imperfect with more errors. While GNNs may be applied in wireless networks, the transmission uncertainty would deteriorate the robustness of GNNs. This challenge is considered in~, in which decentralized GNN binary classifiers are used for multiple problems, e.g., power control or wireless link scheduling. To handle this situation, re-transmission mechanisms are proposed to enhance the robustness of GNN classifiers, for both uncoded and coded wireless communication systems.\nPower allocation or control is an important topic in the wireless network scenario, in which the devices connected to the network may be powered by batteries with a limited energy storage. The transmission in the free space may also interference with each other if the power is not properly controlled. To handle this problem, multiple GNN-based solutions are proposed~. In a series of studies~, Random Edge Graph Neural Networks (REGNNs) are selected as the optimal solution for the power allocation and control optimization problem, with various system constraints. REGNNs outperform baselines with an essential permutation invariance property, which are desirable in networks of growing size. For the optimal power allocation in a single-hop ad hoc wireless network, an iterative weighted minimum mean squared error method named UWMMSE is proposed, in which GNNs are used to learn the model parameters~. UWMMSE effectively reduces the computational complexity without harming the allocation performance, over the classic algorithm for power control. For solving the similar problem in an unsupervised approach, Interference Graph Convolutional Neural Network (IGCNet) is proposed and validated in~, which is robust to imperfect Channel State Information (CSI). Beamforming is further considered in , in which Message Passing Graph Neural Networks (MPGNNs) are proposed to solve both the power control and beamforming problems. Similarly, in an unsupervised approach to learn optimal power allocation decisions, a primal-dual counterfactual optimization approach is proposed in~, in which GNNs are used to handle the network topology.\nTo sum up, the papers in the general wireless network scenario are listed in Table~\\ref{tab:wireless}. The target problem, proposed solution and the relevant GNN component(s) are also listed. The similar tabular format for the paper summary applies in the following sections.\n\\begin{table}[!htb]\n\\centering\n\\caption{List of the papers in the wireless network scenario.}\n\\label{tab:wireless}\n\\begin{tabular}{|p{3.5cm}|p{2cm}|p{3.3cm}|p{3cm}|}\n\\hline\nProblem & Paper & Solution & GNN \\\\\n\\hline\nBinary Classification &  & Decentralized GNN & GCN~, GIN~ \\\\\n\\hline\nChannel Allocation &  & DRL with GCN & ChebNet~ \\\\\n\\hline\nNetwork Flow Optimization &  & Two-stage Topology-aware ML Framework & MPNN~ \\\\\n\\hline\nPower Allocation &  & REGNN & GNN~ \\\\\n\\hline\nPower Allocation &  & UWMMSE Method & GCN~ \\\\\n\\hline\nPower Control &  & REGNN & GNN~ \\\\\n\\hline\nPower Control &  & IGCNet & GIN~ \\\\\n\\hline\nPower Control and Beamforming &  & MPGNNs & GIN~, GCN~ \\\\\n\\hline\nPower Control &  & Unsupervised Primal-dual Counterfactual Optimization & GNN~ \\\\\n\\hline\n\\end{tabular}\n\\end{table}", "cites": [8363, 563, 570, 231, 7213, 571, 8365, 8313, 216, 560, 561, 8364], "cite_extract_rate": 0.7058823529411765, "origin_cites_number": 17, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.5, "critical": 2.0, "abstraction": 2.0}, "insight_level": "medium", "analysis": "The section provides a factual summary of several GNN-based approaches applied to general wireless networks, organizing them into a table. While it mentions some connections between methods (e.g., use of topology information), it lacks deeper synthesis or a unifying narrative. Critical analysis is minimal, with only brief mention of limitations like transmission uncertainty, and abstraction is limited to general problem categories rather than overarching principles or trends in GNN application."}}
{"id": "0cc09064-e3d6-44d2-b01d-073eb729b367", "title": "Cellular Network", "level": "subsection", "subsections": [], "parent_id": "4b607e1c-c213-4395-84ec-a8cebdbe2428", "prefix_titles": [["title", "Graph-based Deep Learning for Communication Networks: A Survey"], ["section", "Wireless Networks"], ["subsection", "Cellular Network"]], "content": "Cellular networks are discussed separately in this part, not only because more than ten papers focus on this specific scenario, but also because the cellular network has a wide application. For example, there were 5.95 billion LTE subscriptions worldwide by the end of Q4 2020~\\footnote{\\url{https://gsacom.com/paper/lte-and-5g-subscribers-march-2021-q4/}}. While the growing trend may be affected by COVID-19, cellular networks are still one of the major approach for accessing the Internet.\nDriven by the huge demand, the research in the cellular network scenario keeps increasing, including those leveraging graph-based deep learning models for some traditional communication problems, e.g., resource allocation, power control and traffic prediction. Driven by the ideas from SDN, some new problems also appear in the cellular network scenario, e.g., network slicing and virtual network embedding. Both types of problems have been investigated in the surveyed papers.\nTo fully utilize the network resources, multipath TCP is considered for 5G networks, which transfer packets over multiple paths concurrently. However, network heterogeneity in 5G networks makes the multipath routing problem become more complex for the existing routing algorithms to handle. A GNN-based multipath routing model is proposed as the solution in~. The experiments under the SDN framework demonstrate that the GNN-based model can achieve a significant throughput improvement.\nTraffic prediction is also considered in cellular networks, with GNN-based solutions being proposed in recent years~. As a prediction problem, the temporal dependencies may be modeled by a recurrent neural network, e.g., Long Short Term Memory (LSTM) or GRU. Different attention mechanisms may also be incorporated. As an improvement over baselines, GNN is capable of modeling the spatial correlation between different nodes, e.g., a cell tower or an access point. Different structures have been explored in existing studies, e.g., GAT in~, GCN in~, and GraphSAGE in~.\nEnergy consumption is another concern for 5G network, which is designed to enable a denser network with microcells, femtocells and picocells. To better control the transmission power, GNN-based power control solutions are proposed in~. Heterogeneous GNNs (HetGNNs) with a novel parameter sharing scheme are proposed for power control in multi-user multi-cell networks~. Take a step further, the joint optimization problem of user association and power control of the downlink is considered in~, in which an unsupervised GNN is used for power allocation and the Spectral Clustering algorithm is used for user association.\nGreen network management is proposed to improve the energy efficiency. A specific problem, the Idle Time Windows (ITWs) prediction, is considered in~. To capture the spatio-temporal features, a novel Temporal Graph Convolutional Network (TGCN) is proposed for learning the network representation, which improves the prediction performance. Also for the denser cell sites, the Integrated Access and Backhaul (IAB) architecture defined by the 3rd Generation Partnership Project (3GPP) is used in~. The IAB topology design is formulated as a graph optimization problem and a combination of deep reinforcement learning and graph embedding is proposed for solving this problem efficiently.\nThe integration of satellite-terrestrial networks is proposed for the future 6G network. In this direction, a High Altitude Platform Station (HAPS) is a network node that operates in the stratosphere at an altitude around 20 km and is instrumental for providing communication services~. For HAPS, GAT is firstly utilized for channel estimation in~, and the proposed GAT estimator outperforms the traditional least square method in full-duplex channel estimation and is also robust to hardware imperfections and changes in small-scale fading characteristics.\nAs a softwarized concept, network slicing has been proposed for 5G network, using network virtualization to divide single network connection into multiple distinct virtual connections that provide services with different Quality-of-Service (QoS) requirements. However, the increasing network complexity is becoming a huge challenge for deploying network slicing. A scalable Digital Twin (DT) technology with GNN is developed in~ for mirroring the network behavior and predicting the end-to-end latency, which can also be applied in unseen network situations. Take a step further, GAT is incorporated into Deep Q Network (DQN) for designing an intelligent resource management strategy in~, which is proven effective through simulations.\nVirtual Network Embedding (VNE) is also a softwarized concept, which can be used for modeling the resource allocation of 5G network slices. Since the VNE problem is NP-hard, heuristic methods and deep learning models are both being proposed for this specific problem. Deep Reinforcement Learning (DRL) and GCN are combined for solving this problem~, in which the episodic Markov Decision Process is solved by different GCN models.\nTo sum up, the papers in the cellular network scenario are listed in Table~\\ref{tab:cellular}.\n\\begin{table}[!htb]\n\\centering\n\\caption{List of the papers in the cellular network scenario.}\n\\label{tab:cellular}\n\\begin{tabular}{|p{4cm}|p{1.5cm}|p{3.5cm}|p{2.5cm}|}\n\\hline\nProblem & Paper & Solution & GNN \\\\\n\\hline\nChannel Estimation &  & GAT-based Estimator & GAT~ \\\\\n\\hline\nIdle Time Windows Prediction &  & TGCN & GCN~ \\\\\n\\hline\nIntegrated Access and Backhaul Topology Design &  & DRL with Graph Embedding & structure2vec~ \\\\\n\\hline\nNetwork Modeling, Network Slicing &  & GNN-based Digital Twin & GraphSAGE~ \\\\\n\\hline\nNetwork Slicing &  & DQN with GAT & GAT~ \\\\\n\\hline\nPower Control &  & Heterogeneous GNNs & HetGAT~ \\\\\n\\hline\nRouting &  & GCLR & MPNN~ \\\\\n\\hline\nTraffic Prediction &  & Graph-based TCN & GraphSAGE~ \\\\\n\\hline\nTraffic Prediction &  & GASTN & S-RNN~ \\\\\n\\hline\nTraffic Prediction &  & DC-STGCN & GCN~ \\\\\n\\hline\nUser Association, Power Control &  & Unsupervised Graph Model & GraphSAGE~ \\\\\n\\hline\nVNE &  & DRL with GCN & GCN~ \\\\\n\\hline\n\\end{tabular}\n\\end{table}", "cites": [572, 242, 180, 559, 566, 573, 248, 557, 216], "cite_extract_rate": 0.391304347826087, "origin_cites_number": 23, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.5, "critical": 2.0, "abstraction": 2.0}, "insight_level": "medium", "analysis": "The section provides a clear and organized overview of the applications of graph-based deep learning in cellular networks, citing various studies and listing them in a table. While it groups similar problems and mentions the use of different GNN architectures, the synthesis remains largely descriptive and does not deeply connect or contextualize the cited works into a broader narrative. There is minimal critical analysis or evaluation of the approaches, and abstraction is limited to surface-level problem categories without identifying overarching principles or trends."}}
{"id": "afa883f5-fb18-47ad-a16e-1f3ea145e835", "title": "Other Wireless Networks", "level": "subsection", "subsections": [], "parent_id": "4b607e1c-c213-4395-84ec-a8cebdbe2428", "prefix_titles": [["title", "Graph-based Deep Learning for Communication Networks: A Survey"], ["section", "Wireless Networks"], ["subsection", "Other Wireless Networks"]], "content": "In this part, we discuss the other formats of wireless networks, with their own challenges and solutions.\nThe first case is the cognitive radio network, which aims to increase the spectrum utilization by secondary users with an opportunistic use of the free spectrum that is not used by the primary users. In this scenario, the challenge is to improve the resource utilization, without degrading the quality of service (QoS) of primary users. To solve this challenge, a joint channel selection and power adaptation scheme is proposed in~, in which GCN is leveraged to extract the crucial interference features. Based on the estimated CSI, a DRL-based framework is further used to allocate spectrum resources efficiently.\nThe second case is the Device-to-Device (D2D) network, which uses the direct communication between two users or devices, without traversing the base station or router. Without deploying additional infrastructure, D2D network is promising for provide communication services with an ultra-low latency. However, there are still many challenges for this objective to happen. To minimize the content fetching delay in D2D network, the joint optimization of cooperative caching and fetching is considered in~ and a DRL-based algorithm is proposed. In the proposed algorithm, GAT is used for cooperative inter-agent coordination. For power control and beamforming in D2D network, an unsupervised learning-based framework is proposed in~, in which heterogeneous graphs and GNNs are used for the characteristics of diversified link features and interference relations. Wireless link scheduling is also considered in a series of studies~. Graph embedding based method is proposed in~, in which the graph embedding process is based on the distances of both communication and interference links, without requiring the accurate CSI. The proposed method manages to reduce the computational complexity for the link scheduling problem significantly.\nThe third case is the Internet of Things (IoT) network, which is designed for connecting smart devices, e.g., smart meters, smart light bulbs, connected valves and pumps, etc. The application of IoT networks covers a wide range, e.g., smart factory, smart agriculture, smart city, etc. The wide application also arises a great number of challenges, e.g., resource utilization efficiency, battery limitation for computation and communication, and security concerns. Some of these challenges can be solved with graph-based methods. One example is the channel estimation problem considered in~, in which Direct-to-satellite (DtS) communication is used for globally connected IoT networks and the high path loss must be considered. GAT is proposed as the solution and further used for the reconfigurable intelligent surfaces in the considered scenario. Another example is the network intrusion detection, which is drawing a growing attention in recent years. GraphSAGE is used in~ for using the edge features and classifying the network flows into benign and attack types. The new solution is proven more effective than the state-of-the-art methods on six benchmark datasets. SDN concepts are also applied in IoT networks and can be combined with graph-based solutions. NFV-enabled Service Function Chain (SFC) is considered in~, in which the challenge is that SFCs should be dynamically and adaptively reconfigured in order to achieve a lower resource consumption and a higher revenue. This problem is formulated as a discrete-time Markov decision process and a deep Dyna-Q (DDQ) approach is proposed as the solution, in which GNNs are used for predicting available virtual network functions (VNFs).\nThe fourth case is the satellite network, in which the communication between satellites are considered. With the growing Low Earth Orbit (LEO) satellites launched by commercial companies, e.g., Starlink and OneWeb, satellite networks are drawing more attention, with a potential application in both IoT and future 6G networks. The traffic prediction problem in the satellite network is considered in~, in which the spatial dependency of the network topology is captured by GCN and the temporal dependency is captured by GRU. The simulation using the satellite network traffic shows the combination with GCN improves the performance of the single GRU model.\nThe last case is the vehicular network, which aims to connect the vehicle nodes. Vehicular network has been proposed for autonomous driving in future smart cities, as an important infrastructure. One challenge is to improve the spectrum allocation efficiency. The vehicle-to-everything (V2X) network is considered in~, in which GNN is used to learn the low-dimensional feature and DRL is used to make spectrum allocation decisions. This kind of GNN-DRL combination has already been used in similar problems of other network types. Another challenge is to reduce the communication latency within vehicular networks, especially in the large-scale and fast-moving scenario. To model the communication latency between the vehicle and the infrastructure, a graph-based framework named SMART is proposed in~, in which GCN is combined with a deep Q-networks algorithm to capture the spatial and temporal patterns within a limited observation zone. Then the latency performance is re-constructed for the whole geographical area.\nTo sum up, the papers in other wireless network scenarios are listed in Table~\\ref{tab:wireless_other}.\n\\begin{table}[!htb]\n\\centering\n\\caption{List of the papers specified in other wireless network scenarios.}\n\\label{tab:wireless_other}\n\\begin{tabular}{|p{3cm}|p{3cm}|p{1.5cm}|p{3cm}|p{2.5cm}|}\n\\hline\nScenario & Problem & Paper & Solution & GNN \\\\\n\\hline\nCognitive Radio Network & Resource Allocation &  & DRL with GCN & GCN~ \\\\\n\\hline\nD2D Network & Cooperative Caching and Fetching &  & FDS-MARL & GAT~ \\\\\n\\hline\nD2D Network & Power Control and Beamforming &  & HIGNN & GN~ \\\\\n\\hline\nD2D Network & Wireless Link Scheduling &  & Graph Embedding based Method & structure2vec~ \\\\\n\\hline\nD2D Network & Wireless Link Scheduling &  & Graph Embedding based Method & structure2vec~ \\\\\n\\hline\nIoT Network & Intrusion Detection &  & E-GraphSAGE & GraphSAGE~ \\\\\n\\hline\nIoT Network & Service Function Chain Dynamic Reconfiguration &  & Deep Dyna-Q Approach & GNN~ \\\\\n\\hline\nSatellite Network & Traffic Prediction &  & GCN-GRU & GCN~ \\\\\n\\hline\nVehicular Network & Communication Latency Modeling &  & SMART Framework & GCN~ \\\\\n\\hline\nVehicular Network & Spectrum Allocation &  & DQN with GNN & GNN~ \\\\\n\\hline\n\\end{tabular}\n\\end{table}", "cites": [573, 566, 555, 574, 242, 180, 208, 565], "cite_extract_rate": 0.4444444444444444, "origin_cites_number": 18, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.5, "critical": 2.0, "abstraction": 2.5}, "insight_level": "medium", "analysis": "The section provides a descriptive overview of different wireless network scenarios and the corresponding graph-based deep learning solutions. It synthesizes the papers to a moderate extent by grouping them under similar network types and problems. However, it lacks critical evaluation of the methods, does not highlight limitations or trade-offs, and offers minimal abstraction beyond the specific systems discussed."}}
{"id": "d380683b-391c-49d7-874a-5ae813c0b7b4", "title": "Wired Networks", "level": "section", "subsections": [], "parent_id": "b5e1c939-ea72-4bf2-af5b-7d76e16e5578", "prefix_titles": [["title", "Graph-based Deep Learning for Communication Networks: A Survey"], ["section", "Wired Networks"]], "content": "\\label{sec:wired}\nFor wired networks, we mainly refer to the computer networks that are connected with cables, such as laptop or desktop computers. A typical example is the Ethernet network. In this section, we first discuss the graph-based studies in the wired network scenario from five aspects, namely, network modeling, network configuration, network prediction, network management, and network security. Then three special cases are further discussed, i.e., blockchain platform, data center network, and optical network.\nGNNs are suitable for network modeling as the computer networks are often modeled as graphs. With the growing trend of contemporary Internet, it becomes more and more challenging to understand the overall network topology, the architecture and different elements of the networks, and their configurations. To solve this challenge, GNNs are proposed for network modeling. They are not only used to reconstruct the existing networks, but also used to model the non-existing networks, in order to provide an estimation of the unseen cases for network operators to make better network deployment decisions in the future. By modeling networks, the estimation of different end-to-end metrics are concerned in surveyed studies, given the input network topology, routing scheme and traffic matrices of the network, in a supervised~ or semi-supervised~ way. Delay and jitter are considered in~, while the throughput of TCP flows and the end-to-end latency of UDP flows are considered in~. Different GNNs are used for the network modeling purpose, including GGS-NN in~, MPNN in~, GN and GNN in~, and GCN in~. GNNs are also used for network calculus analysis in~.\nBased on the modeling ability of GNNs, they are further proposed for network configuration feasibility analysis or decision. Based on the prediction of ensemble GNN model, different network configurations are evaluated in~, bound to the deadline constraints. Border Gateway Protocol (BGP) configuration synthesis is considered in~, which is the standard inter-domain routing protocol to exchange reachability information among Wide Area Networks (WANs). GNN is adopted to represent the network topology with partial network configuration in a system named DeepBGP, which is further validated for both Huawei and Cisco devices while fulfilling operator requirements. Another relevant study is to use GNN for Multiprotocol Label Switching (MPLS) configuration analysis. A GNN-based solution named DeepMPLS is proposed in~ to speed up the analysis of network properties as well as to suggest configuration changes in case a network property is not satisfied. The GNN-based solution manages to achieve low execution times and high accuracies in real-world network topologies.\nGNNs can also be used for network prediction, e.g., delay prediction~ and traffic prediction~. The better prediction is the basis of proactive management. A case study of delay prediction in queuing networks is conducted in~, which uses MPNN for topology representation and network operation. Several studies are concerned about data-driven traffic prediction, based on the real-world network traffic data and GNN-based solutions. A framework named Spatio-temporal Graph Convolutional Recurrent Network (SGCRN) is proposed in~, which combines GCN and GRU and is validated on the network traffic data from four real IP backbone networks. Another framework named Multi-scale Spatial-temporal Graph Neural Network (MSTNN) is proposed for Origin-Destination Traffic Prediction (ODTP) and two real-world datasets are used for evaluation~. Inspired by the prediction model DCRNN~ developed for road traffic, a nonautoregressive graph-based neural network is used in~ for network traffic prediction and evaluated on the U.S. Department of Energy's dedicated science network.\nNetwork prediction results can be used further for network operation optimization and management~, e.g., traffic engineering, load balancing, routing, etc. For the time point of preparing this survey, routing is considered with graph-based deep learning models~. Instead of using reinforcement learning, a novel semi-supervised architecture named Graph-Query Neural Network is proposed in~ for shortest path and max-min routing. Another graph-based framework named NGR is proposed in~ for shortest-path routing and load balancing. These graph-based routing solutions are validated with use-cases and show high accuracies and resilience to packet loss.\nLast but not the least, graph-based deep learning solutions are used for network security problems in computer networks~. Automatic detection for Botnets, which is the source of DDoS attacks and spam, is considered in~. GNN is used to detect the patterns hidden in the botnet connections and is proven more effective than non-learning methods. Their dataset is also made available for future studies. In another study, intrusion detection is considered~. A GCN-based framework named Alert-GCN is proposed to solve the intrusion alert problem as a node classification task. The alert graph is built with the alert information from farther neighbors, which is used as the input for the GCN module. The experiments demonstrate that Alert-GCN outperforms traditional classification models in correlating alerts.\nTo sum up, the papers in the wired network scenario are listed in Table~\\ref{tab:wired}.\n\\begin{table}[!htb]\n\\centering\n\\caption{List of the papers in the wired network scenario.}\n\\label{tab:wired}\n\\begin{tabular}{|p{3.5cm}|p{2cm}|p{3.3cm}|p{3cm}|}\n\\hline\nProblem & Paper & Solution & GNN \\\\\n\\hline\nBGP Configuration Synthesis &  & DeepBGP & GraphSAGE~, GNN~ \\\\\n\\hline\nBotnet Detection &  & GNN Approach & GCN~ \\\\\n\\hline\nCommunication Delay Estimation &  & GNNs with Semi-supervised Learning & GCN~ \\\\\n\\hline\nDelay Prediction &  & Message-passing Neural Networks & MPNN~ \\\\\n\\hline\nIntrusion Detection &  & Alert-GCN & GCN~ \\\\\n\\hline\nMPLS Configuration Analysis &  & DeepMPLS & GNN~ \\\\\n\\hline\nNetwork Calculus Analysis &  & DL-assisted Tandem Matching Analysis & GNN~ \\\\\n\\hline\nNetwork Configuration Feasibility &  & Ensemble GNN Model & GN~ \\\\\n\\hline\nNetwork Modeling &  & RouteNet & MPNN~ \\\\\n\\hline\nNetwork Modeling &  & Extended RouteNet & MPNN~ \\\\\n\\hline\nNetwork Modeling &  & Graph-based DL & GN~, GNN~ \\\\\n\\hline\nNetwork Modeling &  & DeepComNet & GGS-NN~ \\\\\n\\hline\nRouting &  & Graph-Query Neural Network & GNN~ \\\\\n\\hline\nRouting and Load Balancing &  & DL-based Distributed Routing & GNN~ \\\\\n\\hline\nTraffic Prediction &  & SGCRN & GCN~\\\\\n\\hline\nTraffic Prediction &  & MSTNN & GAT~ \\\\\n\\hline\nTraffic Prediction &  & Nonautoregressive Graph-based Neural Network & DCRNN~ \\\\\n\\hline\n\\end{tabular}\n\\end{table}\nOther than the general computer network case, three specific network cases are discussed with graph-based methods.\nThe first case is the blockchain platform, which is well-known by the public thanks to Bitcoin, the most famous cryptocurrency. Generally speaking, the blockchain is a chain of blocks that store information with digital signatures in a decentralized and distributed network, which has a wide range of applications other than digital cryptocurrencies, e.g., financial and social services, risk management, healthcare facilities, etc~. A specific task of encrypted traffic classification is considered in~ for Decentralized Applications (DApps). A GNN-based DApp fingerprinting method named GraphDApp is proposed for this task and a novel graph structure named Traffic Interaction Graph (TIG) is constructed as the representation of encrypted DApp flows as well as the input for GNNs. Real-world traffic datasets from 1,300 DApps with more than 169,000 flows are used for experiments, of which the result shows that GraphDApp is superior to the other state-of-the-art methods in terms of classification accuracy.\nThe second case is the data center network, which connects all data centers to share data or computation abilities. Nowadays, data centers are heavily used for cloud services. In such circumstances, traffic engineering is becoming more and more important for the data center network to avoid traffic congestion and improve routing efficiency. However, this task is still challenging, especially when the network topology changes. In a recent study~, the generalization ability of GNNs is used for predicting Flow Completion Time (FCT) and a GNN-based optimizer is further designed for flow routing, flow scheduling and topology management. The experiments demonstrate both the high inference accuracy and the FCT reduction ability of GNNs.\nThe last case is the optical network, which uses light signals, instead of electronic ones, to send information between two or more points. There are many unique problems when light signals are used for communication, e.g., wavelength assignment. The optimal resource allocation in a special network type, i.e., Free Space Optical (FSO) fronthaul network, is considered in~ and GNNs are used for evaluating and choosing the resource allocation policy. The routing optimization for an Optical Transport Network (OTN) scenario is considered in~ and the learning and generalization capabilities of GNNs are combined with DRL for routing in unseen network typologies. Similar to cellular and computer networks, traffic prediction is also considered in the optical network scenario~, with the solution combined by GCN and GRU.\nTo sum up, the papers in other wired network scenarios are listed in Table~\\ref{tab:wired_other}.\n\\begin{table}[!htb]\n\\centering\n\\caption{List of the papers specified in other wired network scenarios.}\n\\label{tab:wired_other}\n\\begin{tabular}{|p{3cm}|p{3cm}|p{1.5cm}|p{3cm}|p{2.5cm}|}\n\\hline\nScenario & Problem & Paper & Solution & GNN \\\\\n\\hline\nBlockchain Platform & Encrypted Traffic Classification &  & GNN-based DApps Fingerprinting & GIN~ \\\\\n\\hline\nData Center Network & Traffic Optimization &  & GNN-based Optimizer & GN~ \\\\\n\\hline\nOptical Network & Resource Allocation &  & GNN & GNN~ \\\\\n\\hline\nOptical Network & Routing &  & DRL with GNN & MPNN~ \\\\\n\\hline\nOptical Network & Traffic Prediction &  & GCN-GRU & GCN~ \\\\\n\\hline\n\\end{tabular}\n\\end{table}", "cites": [6974, 231, 242, 180, 575, 562, 7213, 208, 211, 577, 23, 556, 216, 578, 576], "cite_extract_rate": 0.4166666666666667, "origin_cites_number": 36, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.5, "critical": 2.0, "abstraction": 2.5}, "insight_level": "medium", "analysis": "The section provides a descriptive overview of graph-based deep learning applications in wired networks, organizing them into categories such as network modeling, configuration, and security. While it references multiple works and connects them thematically, it lacks deeper critical analysis or evaluation of their limitations. The abstraction is limited to general problem-solution pairings without identifying overarching principles or trends."}}
{"id": "b304ab9b-aafc-4a79-8290-b2b605e725f5", "title": "Software Defined Networks", "level": "section", "subsections": [], "parent_id": "b5e1c939-ea72-4bf2-af5b-7d76e16e5578", "prefix_titles": [["title", "Graph-based Deep Learning for Communication Networks: A Survey"], ["section", "Software Defined Networks"]], "content": "\\label{sec:sdn}\nSDN emerges as the most promising solution for bringing a revolution in how networks are built. Based on the white paper released by the Open Networking Foundation (ONF), the explosion of mobile devices and content, server virtualization, and advent of cloud services are among the trends driving the networking industry to reexamine traditional network architectures~\\footnote{\\url{https://opennetworking.org/sdn-resources/whitepapers/software-defined-networking-the-new-norm-for-networks/}}. While SDN was proposed back to 1996, its concept has gone through a lot of changes ever since then. Based on the a widely used definition in~, in the SDN architecture, the control and data planes are decoupled, network intelligence and state are logically centralized, and the underlying network infrastructure is abstracted from the applications.\nThe central control ability of SDN becomes the basis of network optimization in many scenarios and arises several problems which are in the scope of graph-based deep learning methods. Based on the surveyed studies in this paper, there is a growing trend of using GNNs with SDN, or the SDN concept in specific network scenarios. The benefits of this combination are two-folds. For GNNs, SDN provides the ability of measuring network performance, which is used as the data for training GNNs. For SDN, GNNs act as the best option of using the network topology information in modeling and optimizing the networks. In recent years, many graph-based solutions are proposed for various problems with the SDN concept.\nBased on topology, routing, and input traffic, MPNN-based network models are proven to produce accurate estimates of the per-source/destination per-packet delay distribution and loss, with a worst Mean Relative Error (MRE) of 15.4\\%, and the estimation can be further used for efficient routing optimization and network planning~. The decoupling of the control plane and data plane gives more computing power for routing optimization. Based on this observation, an intelligent routing strategy based on graph-aware neural networks is designed in~, in which a novel graph-aware convolution structure is constructed to learn topological information efficiently. In another study for routing optimization, a GN-based solution is proposed for maximum bandwidth utilization, which achieves a satisfactory accuracy and a prediction time 150 times faster than Genetic Algorithm (GA)~.\nIn SDN, network virtualization is a powerful way to efficient utilize the network infrastructure. Virtual Network Functions (VNFs) are virtualized network services running on physical resources. How to map VNFs into shared substrate networks has become a challenging problem in SDN, known as Virtual Network Embedding (VNE) or VNF placement, which is already proven to be NP-hard. To efficiently solve this problem, a bunch of heuristic algorithms are proposed in the literature. Recently, graph-based models have also been used for this problem~, which can get near-optimal solutions in a short time. To predict future resource requirements for VNFs, a GNN-based algorithm using the VNF forwarding graph topology information is proposed in~. Deployed in a virtualized IP multimedia subsystem and tested with real VoIP traffic traces, the new algorithm achieves an average prediction accuracy of 90\\% and improves the call setup latency by over 29\\%, compared with the case without using GNNs. A parallelizable VNE solution based on spatial GNNs is proposed for accelerating the embedding process in~, which improves the revenue-to-cost ratio by about 18\\%, compared to other simulated algorithms. Similarly, GNN-based algorithms are proposed for VNF resource prediction and management in a series of studies~. On another aspect, DRL is often combined with GNNs for automatic virtual network embedding~. Asynchronous DRL enhanced GNN is proposed in~ for topology-aware VNF resource prediction in dynamic environments. An efficient algorithm combining DRL with GCN is proposed in~, with up to 39.6\\% and 70.6\\% improvement on acceptance ratio and average revenue, compared with the existing state-of-the-art solutions. A more specific problem, i.e., traffic flow migration among different network function instances, is considered in~, in which GNN is used for migration latency modeling and DRL is used for deploying dynamic and effective flow migration policies.\nLast but not the least, Service Function Chaining (SFC) is considered in several studies~. SFC uses SDN's programmability to create a service chain of connected virtual network services, resulting in a service function path that provides an end-to-end chain and traffic steering through them. Graph-structured properties of network topology can be extracted by GNNs, which outperforms DNNs for SFC~. However, most of the existing studies for SFC use a supervised learning approach, which may not be suitable for dynamic VNF resources, various requests, and changes of topologies. To solve this problem, DRL is applied for training models on various network topologies with unlabeled data in~ and achieves remarkable flexibility in new topologies without re-designing and re-training, while preserving a similar level of performance compared to the supervised learning method. DRL is also used for adaptive SFC placement to maximize the long-term average revenue~.\nTo sum up, the papers in the SDN scenario are listed in Table~\\ref{tab:sdn}.\n\\begin{table}[!htb]\n\\centering\n\\caption{List of the papers in the SDN scenario.}\n\\label{tab:sdn}\n\\begin{tabular}{|p{3.5cm}|p{2cm}|p{3.3cm}|p{3cm}|}\n\\hline\nProblem & Paper & Solution & GNN \\\\\n\\hline\nNetwork Modeling &  & RouteNet & MPNN~ \\\\\n\\hline\nRouting &  & Revised Graph-aware Neural Networks & A Novel Graph-aware Convolution Structure \\\\\n\\hline\nRouting Optimization, Bandwidth Utilization Maximization &  & GN-based Model & GN~ \\\\\n\\hline\nSFC &  & DRL with GNN & GNN~ \\\\\n\\hline\nSFC &  & GNN-based SFC & GCN~ \\\\\n\\hline\nSFC Deployment, Traffic Steering &  & Knowledge-Defined Networking System with GNN & GNN~ \\\\\n\\hline\nSFC Placement &  & DRL-SFCP & GCN~ \\\\\n\\hline\nTraffic Flow Migration in NFV &  & DRL with GNN & GN~ \\\\\n\\hline\nVNE &  & GraphViNE Solution & GraphSAGE~, GE~ \\\\\n\\hline\nVNE &  & DRL with GCN & GCN~ \\\\\n\\hline\nVNF Deployment Prediction &  & GNN-based Algorithm & GNN~ \\\\\n\\hline\nVNF Management &  & GNN-based Algorithm & GNN~ \\\\\n\\hline\nVNF Placement &  & DRL with GNN & GN~ \\\\\n\\hline\nVNF Resource Prediction &  & Asynchronous DRL enhanced GNN & GNN~ \\\\\n\\hline\nVNF Resource Prediction &  & GNN-based Algorithm & GNN~ \\\\\n\\hline\n\\end{tabular}\n\\end{table}", "cites": [242, 564, 257, 558, 208, 216, 7036, 579], "cite_extract_rate": 0.3076923076923077, "origin_cites_number": 26, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.5, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section demonstrates strong synthesis by grouping the surveyed works into coherent subcategories (e.g., routing, VNE, SFC) and connecting the application of GNNs in SDN with their benefits in modeling and optimization. It provides some critical analysis by pointing out the limitations of supervised learning in dynamic SDN scenarios and noting the advantages of DRL. The section abstracts beyond individual papers by identifying overarching themes like the synergy between SDN's centralized control and GNNs' topology-awareness, and by discussing implications for future research."}}
{"id": "e9629497-306f-44a7-9c73-74545121cda2", "title": "Future Directions", "level": "section", "subsections": [], "parent_id": "b5e1c939-ea72-4bf2-af5b-7d76e16e5578", "prefix_titles": [["title", "Graph-based Deep Learning for Communication Networks: A Survey"], ["section", "Future Directions"]], "content": "\\label{sec:direction}\nIn this section, we discuss some future directions for graph-based deep learning in communication networks. Even though different network scenarios and applications are already covered in this survey, there are still many open research opportunities for this topic.\nThe first research direction is the combination of GNNs and other artificial intelligence techniques. Some examples are already seen in this survey, e.g., the combination of GNN and GRU for traffic prediction~, the combination of GNN and DRL for resource allocation~, routing~, and VNE~. The advantages of GNNs include its learning ability for topological dependencies and the generalization capability for unseen network typologies, but GNN is not a panacea. For example, for some cases which is lack of training data or is too expensive to collect real data, Generative Adversarial Nets (GANs)~ is a possible solution. Even though GANs have been widely used in other fields, e.g., image and video, the combination of GANs and GNNs~ has not been applied for communication networks, at least in the scope of this survey. Another example is the Automated Machine Learning (AutoML) technique~, which can be used for optimizing the GNN parameters automatically.\nAnother research direction is to apply graph-based deep learning on larger networks. In most of the surveyed studies, the network topology is small, e.g., less than 100 nodes, compared with contemporary networks. However, the modeling of larger networks would require huge computation requirements. Graph partitioning and parallel computing infrastructures are two possible solutions for this problem. A larger network may be decomposed into smaller ones that is within the computing capacity. However, the optimal divide-and-conquer approach remains unknown and may vary in different network scenarios. Another concern is that whether it is worthy of achieving narrow performance margins in the cost of the increased computation burden caused by graph-based models, compared with traditional methods.\nFinally, we believe this is still an early stage of the research about graph-based deep learning for communication networks. There are many opportunities of applying novel GNNs in traditional networking problems in a wider range of network scenarios, especially those who get little or no attention for now. The studies covered in this survey are only the beginning of this exciting research area. And we would keep track of this area and update the progress and new publications in the public Github repository.", "cites": [576], "cite_extract_rate": 0.125, "origin_cites_number": 8, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.0, "critical": 3.0, "abstraction": 3.0}, "insight_level": "medium", "analysis": "The section provides an analytical overview by discussing future research directions and connecting GNNs with other AI techniques like DRL, GRU, and GANs, as seen in the cited paper. It identifies limitations such as lack of generalization and computational costs, showing some critical awareness. However, it does not deeply evaluate or contrast multiple sources or propose a novel synthesis of ideas, which limits its abstraction and critical depth."}}
