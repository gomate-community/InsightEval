\section{Demonstration System}
\label{sec:system}
% 作者分工：闫强

As illustrated in Figure~\ref{fig:interface}, InsightEval provides an intuitive web-based interface that guides users through the entire insight evaluation workflow. The left panel serves as the system homepage and input area, where users upload a target paper PDF along with its reference PDFs and initiate the analysis with a single click. Real-time progress indicators keep users informed as the system processes each stage. The right panel presents the results of each pipeline module in a step-by-step tabbed layout, enabling transparent and interactive exploration. Below, we outline the four key functionalities accessible through this interface:

\begin{figure}[t]
    \centering
    % TODO: Insert interface screenshot
    \fbox{\parbox{0.95\columnwidth}{\centering [Figure Placeholder: Interface Screenshot]\\ Left: Homepage with PDF upload and progress tracking\\ Right: Four-stage pipeline results}}
    \caption{The InsightEval demonstration interface. Left: system homepage with paper and reference PDF upload. Right: step-by-step pipeline results including sentence extraction, evidence retrieval, multi-dimensional scoring, and report synthesis.}
    \label{fig:interface}
\end{figure}

(1)~\textbf{Opinion Sentence Extraction.} The system first parses the uploaded PDF via MinerU~\cite{mineru} and segments the full text into individual sentences. It then detects citation markers (e.g., bracketed numbers such as [1] or author-year references) to distinguish cited sentences from contextual ones. Each sentence is classified as either a \textit{citation sentence} or a \textit{context sentence}, with statistics (total sentence count and citation count) displayed to provide an immediate overview of the paper's citation structure.

(2)~\textbf{Evidence Agentic Retrieval.} From the identified citation sentences, the system employs an LLM-based agent to filter genuine \textit{viewpoint sentences}---those that express the author's original analytical claims rather than mere factual citations. For each viewpoint sentence, the system resolves its citation numbers to the corresponding reference PDFs provided by the user, retrieves semantically relevant passages via RAG-based retrieval, and constructs aligned \textit{(viewpoint, evidence)} pairs. The retrieved evidence is presented alongside each viewpoint with source attribution and relevance indicators.

(3)~\textbf{Multi-Dimensional Scoring.} Each viewpoint--evidence pair is evaluated by an LLM through chain-of-thought (CoT) reasoning across three complementary dimensions: \textit{Depth} (1--5), measuring whether the viewpoint goes beyond surface-level evidence; \textit{Breadth} (1--5), assessing cross-source synthesis across multiple references; and \textit{Height} (1--5), evaluating the level of conceptual abstraction. The scores are visualized through a radar chart for each viewpoint, along with a detailed rationale explaining the LLM's scoring logic.

(4)~\textbf{Report Synthesis.} Finally, the system aggregates all viewpoint-level scores and generates a comprehensive paper-level insight report. The report includes an overall insightfulness score, an executive summary synthesized from the paper's introduction and scored viewpoints, and a structured strengths-and-weaknesses analysis. This holistic assessment enables researchers to quickly identify the most insightful contributions of a paper as well as areas where argumentation depth could be improved.
