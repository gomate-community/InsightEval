{"id": "9f8d3c3d-dd73-4be2-949f-6388307ef8c8", "title": "Introduction", "level": "section", "subsections": [], "parent_id": "32f5c325-ad32-4a99-bf88-0a6a7380d5c1", "prefix_titles": [["title", "A survey of active learning algorithms for supervised remote sensing image classification"], ["section", "Introduction"]], "content": "\\PARstart{N}{owadays}, the recourse to statistical learning models~ is  a common practice for remote sensing data users; models such as Support Vector Machines (SVM,~) or neural networks~ are considered as state of the art algorithms for the classification of landuse using  new generation satellite imagery~. Applications of such models to very high spatial~ or spectral~ resolution have proven their efficiency for handling remote sensing data.\nHowever, the performances of supervised algorithms strongly depend on the representativeness of the data used to train the classifier~. This constraint makes the generation of an appropriate training set a difficult and expensive task requiring extensive manual analysis of the image. This is usually done by visual inspection of the scene or by field surveys and successive labeling of each sample.\nIn the case of field surveys, which is usual for medium resolution, hyperspectral or SAR images, the discovery of a new label is expensive -- both in terms of time and money -- because it involves terrain campaigns. Therefore, there is a limit to the number of pixels that can be acquired. For this reason, compact and informative training sets are needed. \nIn the case of visual inspection or photo-interpretation, more common in VHR imagery, it is easier to collect data samples, since the labeling can be done directly on the image. However, the labeling is often done by mass selection on screen and several neighboring pixels carrying the same information are included. As a consequence, the training set is highly redundant. Such a redundancy considerably slows down the training phase of the model. \\mitch{, because several pixels carrying the same information are evaluated.}{} Moreover,  the inclusion of noisy pixels may result in a wrong representation of the class statistics, which may lead to poor classification performances and/or overfitting~. For these reasons, a training set built by photointerpretation should also be kept as small as possible and focused on those pixels effectively improving the performance of the model.\nSumming up, besides being small, a desirable training set must be constructed in a smart way, meaning it must represent correctly the class \\mitch{statistics and covering the entirety of the data variability}{boundaries by sampling discriminative pixels}. This is particularly critical in very high spatial and spectral resolution image classification, which deal with large \\mitch{}{and/or} complex features spaces using limited training information only~. \nIn the machine learning literature this approach to sampling is known as \\emph{active learning}. The leading idea is that a classifier trained on a small set of well-chosen examples can perform  as well as a classifier trained on a larger number of randomly chosen examples, while it is computationally cheaper~. Active learning focuses on the interaction between the user and the classifier. In other words, the model returns to the user the  pixels whose classification outcome is the most uncertain. After accurate labeling by the user, pixels are included into the training set in order to reinforce the model. This way, the model is optimized on well-chosen difficult examples, maximizing its generalization capabilities.\nThe active learning framework has demonstrated its effectiveness when applied to large datasets needing accurate selection of examples~. This is suitable for remote sensing applications, where the number of pixels among which the search is performed is large and manual definition is - as stated above - redundant and time consuming.\nAs a consequence, active learning algorithms gain an increasing interest in remote sensing image processing and several approaches have been proposed to solve image classification tasks. This paper presents the general framework of active learning and reviews some of the methods that have been proposed in remote sensing literature. Note that this survey only covers remote sensing application of active learning principles: for a general introduction and survey of the most recent developments in the machine learning community, please refer to~.\nThe remainder of the paper is organized as follows: Section~\\ref{sec:AL} presents the general framework of active learning and the families of methods that will be detailed in \\red{Sections~\\ref{sec:committee} to~\\ref{sec:poster}}, as well as the references to specific methods. Section~\\ref{sec:data} presents the datasets considered in the experiments. Section~\\ref{sec:res} compares the different approaches numerically. Section~\\ref{sec:disc} gives an overview and guidelines for potential users. Section~\\ref{sec:concl} concludes the paper.", "cites": [8400], "cite_extract_rate": 0.05, "origin_cites_number": 20, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.0, "critical": 2.5, "abstraction": 3.5}, "insight_level": "medium", "analysis": "The introduction provides a clear analytical overview of the challenges in building training sets for remote sensing classification and positions active learning as a solution. It synthesizes the problem context and connects it to the cited paper on active learning with statistical models. However, it does not deeply compare or critique specific methods from the cited literature, limiting its critical depth. The section abstracts some general principles, such as the need for compact and informative training sets, but stops short of providing a novel meta-level framework."}}
{"id": "d0e71651-ef54-4cae-9092-e430dfc27eb8", "title": "Adaptive maximum disagreement (AMD)", "level": "subsection", "subsections": [], "parent_id": "9c33e713-e531-4890-ab4a-b33425a0f7dd", "prefix_titles": [["title", "A survey of active learning algorithms for supervised remote sensing image classification"], ["section", "Committee based active learning"], ["subsection", "Adaptive maximum disagreement (AMD)"]], "content": "When confronted to high dimensional data, it may be relevant to construct the committee by splitting the feature space into a number of subsets, or \\emph{views}~. Di and Crawford~ exploit this principle to generate different views of a hyperspectral image on the basis of the block-diagonal structure of the covariance matrix. By generating views corresponding to the different blocks, independent classifications of the same pixel can be generated and an entropy-based heuristic can be used similarly to $n$EQB.\nGiven a partition of the $d$-dimensional input space into $V$ disjoint views accounting for data subsets $\\x^v$ such that $\\bigcup_{v=1}^V \\x^v = \\x $, the `Adaptive maximum disagreement ' (AMD) heuristic selects candidates according to the following rule:\n\\begin{equation}\n\t\\hat{\\x}^{\\text{AMD}} = \\arg\\max_{\\x_i \\in U} H^{\\text{MV}}(\\x_i)\n\t\\label{eq:AMD}\n\\end{equation}\nwhere the multiview entropy $H^{\\text{MV}}$ is assessed over the predictions of classifiers using a specific view $v$:\n\\begin{align}\n\t&H^{\\text{MV}}(\\x_i) =  -\\sum_{\\omega=1}^{N_i} p^{\\text{MV}}(y^*_{i,v} = \\omega|\\x^v_i) \\mbox{log}\\left[p^{\\text{MV}}(y^*_{i,v}= \\omega|\\x^v_i)\\right]\\\\\n\t& \\text{where} \\qquad p^{\\text{MV}}(y^*_i = \\omega|\\x^v_i) = \\frac{\\sum_{v=1}^V W^{\\epsilon-1}(v,\\omega) \\delta(y^*_{i,v}, \\omega )}{\\sum_{v=1}^V\\sum_{j = 1}^{N_i} W^{\\epsilon-1}(v,\\omega)} \\nonumber\n\\label{eq:MVentr}\n\\end{align}\nwhere the $\\delta(y_{i,v}^*,\\omega )$ operator returns the value $1$ if the classifier using the view $v$ classifies the sample $y_i$ into class $\\omega$ and $0$ otherwise. $\\mathbf{W}^{\\epsilon-1}$ is a $N \\times V$ weighting matrix incorporating the abilities of discrimination between the views in the different classes. At each iteration, $\\mathbf{W}^{\\epsilon-1}$ is updated on the basis of the true labels of the pixels sampled at iteration $\\epsilon-1$:\n\\begin{equation}\nW^\\epsilon(v,\\omega) = W^{\\epsilon-1}(v,\\omega)+\\delta(y_{i,v},\\omega ), \\quad \\forall i \\in S\n\\label{eq:W}\n\\end{equation}\nand its columns are normalized to a unitary sum. This matrix weights the confidence of each view to predict a given class. In~, the selection is done on a  subset of $U$ containing the candidate pixels maximizing the uncertainty, which are the pixels for which  the committee has predicted the highest number of classes. This way, the computational load of the algorithm is reduced.", "cites": [8401], "cite_extract_rate": 0.5, "origin_cites_number": 2, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.0, "critical": 2.5, "abstraction": 2.5}, "insight_level": "medium", "analysis": "The section provides a clear explanation of the Adaptive Maximum Disagreement (AMD) method, integrating concepts from the cited paper on multi-view active learning. It synthesizes the core idea of using independent feature subsets (views) and the entropy-based selection mechanism. However, it lacks deeper critical evaluation of the method's limitations or comparative advantages, and the abstraction remains limited to the specific approach rather than broader patterns in active learning for remote sensing."}}
