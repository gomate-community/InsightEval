{"id": "fa7bad1c-82f4-427a-82f6-b8a50d818f06", "title": "Introduction", "level": "section", "subsections": [], "parent_id": "adaab269-4459-49f1-a6b5-c00e3a2b1ce1", "prefix_titles": [["title", "Domain Generalization: A Survey"], ["section", "Introduction"]], "content": "\\label{sec:introduction}}\n\\IEEEPARstart{I}{f} an image classifier was trained on photo images, would it work on sketch images? What if a car detector trained using urban images is tested in rural environments? Is it possible to deploy a semantic segmentation model trained using sunny images under rainy or snowy weather conditions? Can a health status classifier trained using one patient's electrocardiogram data be used to diagnose another patient's health status? Answers to all these questions depend on how well the machine learning models can deal with one common problem, namely the \\emph{domain shift} problem. Such a problem refers to the distribution shift between  a set of training (source) data and a set of test (target) data~.\nMost statistical learning algorithms strongly rely on an over-simplified assumption, that is, the source and target data are independent and identically distributed (i.i.d.), while ignoring out-of-distribution (OOD) scenarios commonly encountered in practice. This means that they are not designed with the domain shift problem in mind, and as a consequence, a learning agent trained only with source data will typically suffer significant performance drops on an OOD target domain.\nThe domain shift problem has seriously impeded large-scale deployments of machine learning models. One might be curious if recent advances in deep neural networks~, known as deep learning~, can mitigate this problem. Studies in~ suggest that deep learning models' performance degrades significantly on OOD datasets, even with just small variations in the data generating process. This highlights the fact that the successes achieved by deep learning so far have been largely driven by supervised learning with large-scale annotated datasets like ImageNet~---again, relying on the i.i.d.~assumption.\nResearch on how to deal with domain shift has been extensively conducted in the literature. A straightforward solution to bypass the OOD data issue is to collect some data from the target domain to adapt a source-domain-trained model. Indeed, this domain adaptation (DA) problem has received much attention~. However, DA relies on a strong assumption that target data is accessible for model adaptation, which does not always hold in practice.\nIn many applications, target data is difficult to obtain or even unknown before deploying the model. For example, in biomedical applications where domain shift occurs between different patients' data, it is impractical to collect each new patient's data in advance~; in traffic scene semantic segmentation it is infeasible to collect data capturing all different scenes and under all possible weather conditions~; when dealing with data stream, the model is also required to be intrinsically generalizable~.\nTo overcome the domain shift problem, as well as the absence of target data, the problem of \\emph{domain generalization} (DG) was introduced~. Specifically, the goal in DG is to learn a model using data from a single or multiple related but distinct source domains in such a way that the model can generalize well to any OOD target domain.\nSince the first formal introduction in 2011 by Blanchard et al.~, a plethora of methods have been developed to tackle the OOD generalization issue~. This includes methods based on aligning source domain distributions for domain-invariant representation learning~, exposing the model to domain shift during training via meta-learning~, and augmenting data with domain synthesis~, to name a few. From the application point of view, DG has not only been studied in computer vision like object recognition~, semantic segmentation~ and person re-identification~, but also in other domains such as speech recognition~, natural language processing~, medical imaging~, and reinforcement learning~.\nIn this survey, we aim to provide a timely and comprehensive literature review to summarize, mainly from the technical perspective, the learning algorithms developed over the last decade, and provide insights on potential directions for future research.", "cites": [166, 2702, 5068, 5066, 5061, 2700, 5063, 8578, 5064, 2686, 2703, 2707, 5062, 5067, 2729, 5065, 2690, 97, 2801, 2776, 7611, 8582, 1606, 8580, 2684, 2699, 2711, 3222, 1627], "cite_extract_rate": 0.6904761904761905, "origin_cites_number": 42, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.0, "abstraction": 4.0}, "insight_level": "high", "analysis": "The introduction synthesizes multiple papers to frame domain generalization within the broader context of domain shift and deep learning limitations, connecting key technical approaches (e.g., domain alignment, meta-learning, data augmentation). It critically highlights that deep learning models still struggle with OOD generalization even under minor distribution shifts and notes the impracticality of domain adaptation in real-world settings. The section abstracts from individual methods to emphasize overarching challenges and motivations, such as the need for intrinsic generalizability when target data is inaccessible."}}
{"id": "e7501d41-dd20-4a2e-9edd-a03fdc3a435a", "title": "A Brief History of Domain Generalization", "level": "subsection", "subsections": [], "parent_id": "b8bf2065-8427-419e-9247-aaae579e5f9b", "prefix_titles": [["title", "Domain Generalization: A Survey"], ["section", "Background"], ["subsection", "A Brief History of Domain Generalization"]], "content": "\\label{sec:bg;subsec:history_DG}\nThe domain generalization (DG) problem was first formally introduced by Blanchard et al.~ as a machine learning problem, while the term \\emph{domain generalization} was later coined by Muandet et al.~. Unlike other related learning problems such as domain adaptation or transfer learning, DG considers the scenarios where target data is \\emph{inaccessible} during model learning. In~, the motivation behind DG originates from a medical application called automatic gating of flow cytometry data. The objective is to design algorithms to automate the process of classifying cells in patients' blood samples based on different properties, e.g., to distinguish between lymphocytes and non-lymphocytes. Such a technology is crucial in facilitating the diagnosis of the health of patients since manual gating is extremely time-consuming and requires domain-specific expertise. However, due to distribution shift between different patients' data, a classifier learned using data from historic patients does not generalize to new patients, and meanwhile, collecting new data for model fine-tuning is impractical, thus motivating research on the DG problem.\nIn computer vision, a seminal work done by Torralba and Efros~ raised attention on the cross-domain generalization issue. They performed a thorough investigation into the cross-dataset generalization performance of object recognition models using six popular benchmark datasets. Their findings suggested that dataset biases, which are difficult to avoid, can lead to poor generalization performance. For example, as shown in~, a person classifier trained on Caltech101~ obtained a very low accuracy (11.8\\%) on LabelMe~, though its same-dataset performance was near-perfect (99.6\\%). Following~, Khosla et al.~ targeted the cross-dataset generalization problem in classification and detection tasks, and proposed to learn domain-specific bias vectors and domain-agnostic weight vectors based on support vector machine (SVM) classifiers.", "cites": [2690], "cite_extract_rate": 0.16666666666666666, "origin_cites_number": 6, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.5, "critical": 2.0, "abstraction": 2.0}, "insight_level": "medium", "analysis": "The section provides a factual overview of the origin and motivation of domain generalization, citing key papers in the field. It synthesizes a basic narrative by connecting the introduction of DG to early applications in medical imaging and computer vision. However, it lacks deeper critical analysis or abstraction to broader principles, focusing mainly on summarizing the cited works without evaluating their strengths, weaknesses, or implications."}}
{"id": "c69db8f8-b538-437d-9049-ac7ad55bc7bc", "title": "Problem Definition", "level": "subsection", "subsections": [], "parent_id": "b8bf2065-8427-419e-9247-aaae579e5f9b", "prefix_titles": [["title", "Domain Generalization: A Survey"], ["section", "Background"], ["subsection", "Problem Definition"]], "content": "\\label{sec:bg;subsec:problem_def}\nWe first introduce some notations that will be used throughout this survey. Let $\\mathcal{X}$ be the input (feature) space and $\\mathcal{Y}$ the target (label) space, a \\emph{domain} is defined as a joint distribution $P_{XY}$ on $\\mathcal{X} \\times \\mathcal{Y}$.\\footnote{We use $P_{XY}$ and $P(X,Y)$ interchangeably.} For a specific domain $P_{XY}$, we refer to $P_X$ as the marginal distribution on $X$, $P_{Y|X}$ the posterior distribution of $Y$ given $X$, and $P_{X|Y}$ the class-conditional distribution of $X$ given $Y$.\nIn the context of DG, we have access to $K$ similar but distinct source domains $\\mathcal{S} = \\{ S_k = \\{ (x^{(k)}, y^{(k)}) \\} \\}_{k=1}^K$, each associated with a joint distribution $P_{XY}^{(k)}$. Note that $P_{XY}^{(k)} \\neq P_{XY}^{(k')}$ with $k \\neq k'$ and $k, k' \\in \\{1,...,K\\}$. The goal of DG is to learn a predictive model $f: \\mathcal{X} \\to \\mathcal{Y}$ using only source domain data such that the prediction error on an unseen target domain $\\mathcal{T} = \\{ x^{\\mathcal{T}} \\}$ is minimized. The corresponding joint distribution of the target domain $\\mathcal{T}$ is denoted by $P_{XY}^{\\mathcal{T}}$. Also, $P_{XY}^{\\mathcal{T}} \\neq P_{XY}^{(k)}$, $\\forall k \\in \\{1,...,K\\}$.\n\\keypoint{Multi-Source DG}\nDG has typically been studied under two different settings, namely \\emph{multi-source DG} and \\emph{single-source DG}. The majority of research has been dedicated to the multi-source setting, which assumes multiple distinct but relevant domains are available (i.e., $K > 1$). As stated in~, the original motivation for studying DG is to leverage multi-source data to learn representations that are invariant to different marginal distributions. This makes sense because without having access to the target data, it is challenging for a source-learned model to generalize well. As such, using multiple domains allows a model to discover stable patterns across source domains, which generalize better to unseen domains.\n\\keypoint{Single-Source DG}\nIn contrast, the single-source setting assumes training data is homogeneous, i.e., they are sampled from a single domain ($K = 1$). This problem is closely related to the topic of OOD robustness~, which investigates model robustness under image corruptions. Essentially, single-source DG methods do not require domain labels for learning and thus they are applicable to multi-source scenarios as well. In fact, most existing methods able to solve single-source DG do not distinguish themselves as a single- or a multi-source approach, but rather a more generic solution to OOD generalization, with experiments covering both single- and multi-source datasets~.\n\\begin{table*}[ht!]\n    \\centering\n    \\tabstyle{5pt}\n    \\caption{Commonly used domain generalization datasets (categorized mainly based on applications).}\n    \\label{tab:datasets}\n    \\resizebox{\\textwidth}{!}{\n    \\begin{tabular}{l r c l}\n    \\toprule\n    & \\textbf{\\# samples} & \\textbf{\\# domains} & \\textbf{Characterization of domain shift} \\\\\n    \\midrule\n    \\textbf{Handwritten digit recognition} & \\\\\n    \\quad- Rotated MNIST~ & 70,000 & 6 & Rotations (0, 15, 30, 45, 60 \\& 75) \\\\\n    \\quad- Digits-DG~ & 24,000 & 4 & MNIST~, MNIST-M~, SVHN~, SYN~ \\\\\n    \\midrule\n    \\textbf{Object recognition} & \\\\\n    \\quad- VLCS~ & 10,729 & 4 & Caltech101~, LabelMe~, PASCAL~, SUN09~ \\\\\n    \\quad- Office-31~ & 4,652 & 3 & Amazon, webcam, dslr \\\\\n    \\quad- OfficeHome~ & 15,588 & 4 & Art, clipart, product, real \\\\\n    \\quad- PACS~ & 9,991 & 4 & Photo, art, cartoon, sketch \\\\\n    \\quad- DomainNet~ & 586,575 & 6 & Clipart, infograph, painting, quickdraw, real, sketch \\\\\n    \\quad- miniDomainNet~ & 140,006 & 4 & Clipart, painting, real, sketch \\\\\n    \\quad- ImageNet-Sketch~ & 50,000 & 2 & Real vs sketch images \\\\\n    \\quad- VisDA-17~ & 280,157 & 2 & Synthetic vs real images \\\\\n    \\quad- CIFAR-10-C~ & 60,000 & - & Artificial corruptions \\\\\n    \\quad- CIFAR-100-C~ & 60,000 & - & Artificial corruptions \\\\\n    \\quad- ImageNet-C~ & $\\approx$1.3M & - & Artificial corruptions \\\\\n    \\quad- ImageNet-R~ & 30k & - & Image style changes \\\\\n    \\quad- ImageNet-A~ & 7,500 & - & Naturally adversarial examples \\\\\n    \\quad- TerraInc~ & 24,788 & 4 & Geographical locations \\\\\n    \\quad- NICO++~ & 232.4k & 10 & Contexts (e.g., grass, water, winter, indoor, outdoor) \\\\\n    \\quad- Visual Decathlon~ & 1,659,142 & 10 & Data sources (10 datasets) \\\\ \n    \\midrule\n    \\textbf{Action recognition} & \\\\\n    \\quad- IXMAS~ & 1,650 & 5 & 5 camera views, 10 subjects (see~) \\\\\n    \\quad- UCF-HMDB~ & 3,809 & 2 & Data sources (2 datasets) (see~) \\\\\n    \\midrule\n    \\textbf{Semantic segmentation} & \\\\\n    \\quad- SYNTHIA~ & 2,700 & 15 & 4 locations, 5 weather conditions (see~) \\\\\n    \\quad- GTA5-Cityscapes~ & 29,966 & 2 & Synthetic vs real images \\\\\n    \\midrule\n    \\textbf{Person re-identification} & \\\\\n    \\quad- Market-Duke~ & 69,079 & 2 & Camera views, cities, streets, etc. \\\\\n    \\midrule\n    \\textbf{Face recognition} & \\\\\n    \\quad- Face~ & $>$5M & 9 & Data sources (9 datasets) \\\\\n    \\midrule\n    \\textbf{Face anti-spoofing} & \\\\\n    \\quad- COMI~ & $\\approx$8,500 & 4 & Data sources (4 datasets) \\\\\n    \\midrule\n    \\textbf{Speech recognition} & \\\\\n    \\quad- Google Speech Command~ & 65k & 1,888 & Speakers \\\\\n    \\midrule\n    \\textbf{Sentiment classification} & \\\\\n    \\quad- Amazon Reviews~ & $>$340k  & 4 & Books, DVD, electronics, kitchen appliances \\\\\n    \\midrule\n    \\textbf{WILDS}~ (only show 3 out of 10 datasets here) & \\\\\n    \\quad- Camelyon17-WILDS~ & 455,954 & 5 & Hospitals \\\\\n    \\quad- FMoW-WILDS~ & 523,846 & 80 & Time, geographical regions \\\\\n    \\quad- iWildCam-WILDS~ & 203,029 & 323 & Camera traps \\\\\n    \\midrule\n    \\textbf{Medical imaging} & \\\\\n    \\quad- Multi-site Prostate MRI Segmentation~ & 116 & 6 & Clinical centers \\\\\n    \\quad-  Chest X-rays~ & - & 3 & Data sources (NIH~, ChexPert~, RSNA) \\\\\n    \\midrule\n    \\textbf{Reinforcement learning} & \\\\\n    \\quad- Coinrun~ & - & - & Scenes, difficulty levels \\\\\n    \\quad- OpenAI Procgen Benchmark~ & - & - & States, scenes, rewards, difficulty levels \\\\\n    \\bottomrule\n    \\end{tabular}\n    }\n\\end{table*}", "cites": [5068, 2786, 128, 7493, 2685, 1790, 2769, 3291, 1733, 5076, 8588, 2703, 5074, 1505, 5073, 5075, 2781, 2899, 2785, 7058, 2733, 5071, 196, 1606, 5077, 2784, 2755, 5070, 2684, 7614, 5072, 5069], "cite_extract_rate": 0.5614035087719298, "origin_cites_number": 57, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.5, "critical": 2.0, "abstraction": 2.5}, "insight_level": "medium", "analysis": "The section provides a formal problem definition for domain generalization and lists multiple datasets from various application areas. While it references relevant papers, it does not deeply synthesize their contributions, nor does it critically evaluate their strengths or weaknesses. The abstraction is limited to categorizing datasets by application and domain shift, without identifying broader theoretical or methodological trends."}}
{"id": "d367062a-5b03-4a52-9efe-d3edda4f95e3", "title": "Datasets and Applications", "level": "subsection", "subsections": [], "parent_id": "b8bf2065-8427-419e-9247-aaae579e5f9b", "prefix_titles": [["title", "Domain Generalization: A Survey"], ["section", "Background"], ["subsection", "Datasets and Applications"]], "content": "\\label{sec:bg;subsec:data_app}\nDG has been studied across many application areas including computer vision, speech recognition, medical imaging, and so on. Table~\\ref{tab:datasets} summarizes the commonly used datasets based on different applications. Below we briefly discuss their basics.\n\\begin{figure*}[t]\n    \\centering\n    \\includegraphics[width=.95\\textwidth]{figs/datasets.pdf}\n    \\caption{Example images from three domain generalization benchmarks manifesting different types of domain shift. In (a), the domain shift mainly corresponds to changes in font style, color and background. In (b), dataset-specific biases are clear, which are caused by changes in environment/scene and viewpoint. In (c), image style changes are the main reason for domain shift.\n    }\n    \\label{fig:datasets}\n\\end{figure*}\n\\keypoint{Handwritten Digit Recognition}\nThe commonly used digit datasets include MNIST~, MNIST-M~, SVHN~, and SYN~. In general, these datasets differ in font style, stroke color, and background. MNIST contains images of handwritten digits. MNIST-M mixes MNIST's images with random color patches. SVHN comprises images of street view house numbers while SYN is a synthetic dataset. See Fig.~\\ref{fig:datasets}(a) for some example images. Rotation has also been exploited to synthesize domain shift~~.\n\\keypoint{Object Recognition}\nhas been the most common task in DG where the domain shift varies substantially across different datasets. In VLCS~ and Office-31~, the domain shift is mainly caused by changes in environments or viewpoints. As exemplified in Fig.~\\ref{fig:datasets}(b), the scenes in VLCS vary from urban to rural areas and the viewpoints are often biased toward either a side-view or a non-canonical view. Image style changes have also been commonly studied, such as PACS~ (see Fig.~\\ref{fig:datasets}(c)), OfficeHome~, DomainNet~, and ImageNet-Sketch~. Other types of domain shift include synthetic-vs-real~, artificial corruptions~, and data sources~.\n\\keypoint{Action Recognition}\nLearning generalizable representations is also crucial for video understanding like action recognition. IXMAS~ has been widely used as a cross-view action recognition benchmark~, which contains action videos collected from five different views. In addition to view changes, different subjects or environments (like indoor vs outdoor) can also create domain shift and lead to model failures.\n\\keypoint{Semantic Segmentation}\nis critical to autonomous driving. Though this task has been greatly advanced by deep neural networks, the performance is still far from being satisfactory when deploying trained deep models in novel scenarios, such as new cities or unseen weather conditions~. Since it is impractical to collect data covering all possible scenarios, DG is pivotal in facilitating large-scale deployment of semantic segmentation systems. The SYNTHIA dataset~ contains synthetic images of different locations under different weather conditions. Generalization from GTA5~ to real image datasets like Cityscapes~ has also been extensively studied~.\n\\keypoint{Person Re-Identification (Re-ID)}\nplays a key role in security and surveillance applications. Person re-ID is essentially an instance retrieval task, aiming to match people across disjoint camera views (each seen as a distinct domain). Most existing methods in re-ID~ have been focused on the same-dataset setting, i.e., training and test are done on the same set of camera views, with performance almost reaching saturation. Recently, cross-dataset re-ID~ has gained much attention: the objective is to generalize a model from source camera views to unseen target camera views, a more challenging but realistic setting. The domain shift often occurs in image resolution, viewpoint, lighting condition, background, etc.\n\\keypoint{Face Recognition}\nhas witnessed significant advances driven by deep learning in recent years~. However, several studies~ have suggested that deep models trained even on large-scale datasets like MS-Celeb-1M~ suffer substantial performance drops when deployed in new datasets with previously unseen domains, such as low resolution~, large variations in illumination/occlusion/head pose~, or drastically different viewpoints~.\n\\keypoint{Face Anti-Spoofing}\naims to prevent face recognition systems from being attacked using fake faces~, such as printed photos, videos or 3D masks. Conventional face anti-spoofing methods do not take into account distribution shift, making them vulnerable to unseen attack types~. There is no specifically designed DG dataset for this task. A common practice is to combine several face anti-spoofing datasets for model training and do evaluation on an unseen dataset, e.g., using CASIA-MFSD~, Oulu-NPU~ and MSU-MFSD~ as the sources and Idiap Replay-Attack~ as the target.\n\\keypoint{Speech Recognition}\nSince people speak differently (e.g., different tones or pitches) it is natural to regard each speaker as a domain~. The commonly used dataset is Google Speech Command~, which consists of 1,888 domains (speakers) and around 65,000 samples.\n\\keypoint{Sentiment Classification}\nis a common task studied in natural language processing, which aims to classify opinions in texts as either positive or negative (hence a binary classification problem)~. Amazon Reviews~ contains reviews for four categories (domains) of products: books, DVD, electronics and kitchen appliances.\n\\keypoint{The WILDS Benchmark}\nhas been recently introduced, with a goal to study distribution shift faced in the wild~. The benchmark contains a total of ten datasets, which cover a wide range of pattern recognition tasks, such as animal classification, cancer detection, molecule classification, and satellite imaging. Table~\\ref{tab:datasets} shows three datasets from WILDS that have been commonly used by the DG community~.\n\\keypoint{Medical Imaging}\nDG is also critical to medical imaging where domain shift is often related to variations in clinical centers or patients~. Two commonly used medical imaging datasets are Multi-site Prostate MRI Segmentation~ and Chest X-rays~, each containing data aggregated from multiple clinical centers with domain shift caused by, e.g., different scanners or acquisition protocols.\n\\keypoint{Reinforcement Learning (RL)}\nhas a dramatically different paradigm than supervised or unsupervised learning: RL aims to maximize rewards obtained through continuous interactions with an environment. Generalization in RL has been a critical issue where agents or policies learned in a training environment often suffer from overfitting and hence generalize poorly to unseen environments~. Domain shift in RL is mostly associated with environmental changes, such as different scenes, states, or even rewards. There is a large body of work focused on improving generalization in RL. We refer readers to  for a more comprehensive survey in the topic of generalizable RL.\n\\begin{table*}[t]\n\\centering\n\\tabstyle{15pt}\n\\caption{Comparison between domain generalization and its related topics.}\n\\label{tab:compare_topics}\n\\resizebox{\\textwidth}{!}{\n    \\begin{tabular}{l | x{.5cm} x{.5cm} | x{.5cm} x{.5cm} | x{.5cm} x{.5cm} | c}\n    \\toprule\n     & \\multicolumn{2}{c|}{$K$} & \\multicolumn{2}{c|}{$P_{XY}^{\\mathcal{S}}$ vs $P_{XY}^{\\mathcal{T}}$} & \\multicolumn{2}{c|}{$\\mathcal{Y}_S$ vs $\\mathcal{Y}_T$} & \\multirow{2}{*}{Access to $P_{X}^{\\mathcal{T}}$?} \\\\\n     & $=1$ & $>1$ & $=$ & $\\neq$  & $=$ & $\\neq$ & \\\\\n    \\midrule\n    Supervised Learning & \\cmark &  & \\cmark &  & \\cmark &  &  \\\\\n    Multi-Task Learning &  & \\cmark & \\cmark &  & \\cmark &  &  \\\\\n    Transfer Learning & \\cmark & \\cmark &  & \\cmark &  & \\cmark & \\cmark \\\\\n    Zero-Shot Learning & \\cmark & & & \\cmark & & \\cmark & \\\\\n    Domain Adaptation & \\cmark & \\cmark &  & \\cmark & \\cmark & \\cmark & \\cmark \\\\\n    Test-Time Training & \\cmark & \\cmark & & \\cmark & \\cmark & & \\cmark$^\\dagger$ \\\\\n    \\textbf{Domain Generalization} & \\cmark & \\cmark &  & \\cmark & \\cmark & \\cmark &  \\\\\n    \\bottomrule\n    \\end{tabular}\n}\n\\begin{flushleft}\n\\footnotesize\n\\itshape\n$K$: number of source domains/tasks. $P_{XY}^{S/T}$: source/target joint distribution. $\\mathcal{Y}_{S/T}$: source/target label space. $P_X^{\\mathcal{T}}$: target marginal. $\\dagger$: Limited in quantities, like a single example or mini-batch.\n\\end{flushleft}\n\\end{table*}", "cites": [5068, 1222, 5083, 8585, 5084, 1790, 5080, 2718, 8877, 2769, 7888, 7616, 5082, 1733, 1505, 8589, 8588, 5073, 2785, 2733, 8878, 5081, 7887, 1606, 5077, 5085, 5079, 2755, 2761, 5070, 2684, 2702, 5078], "cite_extract_rate": 0.532258064516129, "origin_cites_number": 62, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.5, "critical": 2.0, "abstraction": 2.0}, "insight_level": "medium", "analysis": "The section provides a factual overview of datasets and applications in domain generalization but lacks deep synthesis or abstraction of ideas across the cited works. It mentions some papers in the context of specific datasets and tasks, but there is little analytical discussion of how these approaches relate or contrast with one another. Critical evaluation of the methods or limitations is also limited."}}
{"id": "c2a6cac0-f828-4abc-ac19-0961dde1e39b", "title": "Evaluation", "level": "subsection", "subsections": [], "parent_id": "b8bf2065-8427-419e-9247-aaae579e5f9b", "prefix_titles": [["title", "Domain Generalization: A Survey"], ["section", "Background"], ["subsection", "Evaluation"]], "content": "\\label{sec:bg;subsec:eval}\nEvaluation of DG algorithms often follows the \\emph{leave-one-domain-out} rule~: given a dataset containing at least two distinct domains, one or multiple of them are used as source domain(s) for model training while the rest are treated as target domain(s); a model learned from the source domain(s) is directly tested in the target domain(s) without any form of adaptation. Two problem scenarios have been studied: single- vs multi-source DG. It is worth noting that some datasets contain label shift, meaning that the label space between source and target changes (termed heterogeneous DG~). For instance, in the problem of person re-ID, identities between training and test are different; in this case the source-learned representation is directly used for image matching.\n\\keypoint{Evaluation Metrics}\nTwo metrics have been commonly adopted, namely \\emph{average} and \\emph{worst-case} performance. The former concerns about the average performance in held-out domains, which is used in most domain shift scenarios. In contrast, the latter focuses on the worst performance among held-out domains, which is often used in the case of sub-population shift~ and has been widely adopted by the causal inference community~ as well as some datasets in the WILDS benchmark~.\n\\keypoint{Model Selection}\nconcerns about which model (checkpoint), architecture or hyper-parameters to choose for evaluation, which has recently been identified by  as a crucial step in the evaluation pipeline. As summarized in , there are three model selection criteria: \\romannum{1}) \\emph{Training-domain validation}, which holds out a subset of training data for model selection; \\romannum{2}) \\emph{Leave-one-domain-out validation}, which keeps one source domain for model selection; \\romannum{3}) \\emph{Test-domain validation (oracle)}, which performs model selection using a random subset of test domain data. As suggested by , the last criterion would lead to overly optimistic or pessimistic results and thus should be used with care. Another important lesson from  is that specially designed DG methods often perform similarly with the plain model (known as Empirical Risk Minimization) when using larger neural networks and an extensive search of hyper-parameters. Therefore, it is suggested that future evaluation should cover different neural network architectures and ensure comparison is made using the same model selection criterion.", "cites": [2788, 8580, 2769, 2684, 195], "cite_extract_rate": 0.8333333333333334, "origin_cites_number": 6, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.5, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section synthesizes evaluation practices from multiple DG papers, integrating concepts such as leave-one-domain-out and heterogeneous DG into a coherent framework. It critically discusses the implications of different model selection criteria, citing specific findings from the literature. The section also abstracts from individual papers to highlight broader issues in evaluation methodology and suggest best practices for future research."}}
{"id": "70100759-a63d-44a7-a329-80d2982c08ea", "title": "Related Topics", "level": "subsection", "subsections": [], "parent_id": "b8bf2065-8427-419e-9247-aaae579e5f9b", "prefix_titles": [["title", "Domain Generalization: A Survey"], ["section", "Background"], ["subsection", "Related Topics"]], "content": "\\label{sec:bg;subsec:related_topics}\nIn this section, we discuss the relations between DG and its related topics, and clarify their differences. See Table~\\ref{tab:compare_topics} for an overview.\n\\keypoint{Supervised Learning}\ngenerally aims to learn an input-output mapping by minimizing the following risk: $\\mathbb{E}_{(x, y) \\sim \\hat{P}_{XY}} \\ell( f(x), y )$, where $\\hat{P}_{XY}$ denotes the empirical distribution rather than the real data distribution $P_{XY}$, which is inaccessible. The hope is that once the loss is minimized, the learned model can work well on data generated from $P_{XY}$, which heavily relies on the i.i.d.~assumption. The crucial difference between SL and DG is that in the latter training and test data is drawn from different distributions, thus violating the i.i.d.~assumption. DG is arguably a more practical setting in real-world applications~.\n\\keypoint{Multi-Task Learning (MTL)}\nThe goal of MTL is to simultaneously learn multiple related tasks ($K>1$) using a single model~. As shown in Table~\\ref{tab:compare_topics}, MTL aims to make a model perform well on the same set of tasks that the model was trained on ($\\mathcal{Y}_S = \\mathcal{Y}_T$), whereas DG aims to generalize a model to unseen data distributions ($P_{XY}^{\\mathcal{S}} \\neq P_{XY}^{\\mathcal{T}}$). Though being different in terms of the problem setup, the MTL paradigm has been exploited in some DG methods, notably for those based on self-supervised learning~. Intuitively, MTL benefits from the effect of regularization brought by parameter sharing~, which may in part explain why the MTL paradigm works for DG.\n\\keypoint{Transfer Learning (TL)}\naims to transfer the knowledge learned from one (or multiple) problem/domain/task to a different but related one~. A well-known TL example in contemporary deep learning is fine-tuning: first pre-train deep neural networks on large-scale datasets, such as ImageNet~ for vision models or BooksCorpus~ for language models; then fine-tune them on downstream tasks~. Given that pre-trained deep features are highly transferable, as shown in several studies~, a couple of recent DG works~ have researched how to preserve the transferable features learned via large-scale pre-training when learning new knowledge from source synthetic data for synthetic-to-real applications. As shown in Table~\\ref{tab:compare_topics}, a key difference between TL and DG lies in whether the target data is used. In TL, the target data is required for model fine-tuning for new downstream tasks, whereas in DG we assume to have no access to the target data, thus focusing more on model generalization. Nonetheless, TL and DG share some similarities: the target distribution in both TL and DG is different from the source distribution; in terms of label space, TL mainly concerns disjoint label space, whereas DG considers both cases, i.e., same label space for homogeneous DG and disjoint label space for heterogeneous DG.\n\\keypoint{Zero-Shot Learning (ZSL)}\nis related to DG in the sense that the goal in both problems is to deal with unseen distributions. Differently, distribution shift in ZSL is mainly caused by label space changes~, i.e., $P_Y^{\\mathcal{T}} \\neq P_Y^{\\mathcal{S}}$, since the task is to recognize new classes, except for generalized ZSL~ which considers both new and old classes at test time; while in DG, domain shift mostly results from covariate shift~, i.e., only the marginal distribution changes ($P_X^{\\mathcal{T}} \\neq P_X^{\\mathcal{S}}$).\\footnote{It is worth mentioning that a recent ZSL work~ has studied ZSL+DG, i.e., distribution shift occurs in both $P_Y$ and $P_X$, which is analogous to heterogeneous DG.} To recognize unseen classes in ZSL, a common practice is to learn a mapping between the input image space and the attribute space~ since the label space is disjoint between training and test data. Interestingly, attributes have also been exploited in DG for learning domain-generalizable representations~.\n\\keypoint{Domain Adaptation (DA)}\nis the closest topic to DG and has been extensively studied in the literature~. Both DA and DG aim to tackle the domain shift problem (i.e., $P_{XY}^{\\mathcal{S}} \\neq P_{XY}^{\\mathcal{T}}$) encountered in new test environments. Differently, DA assumes the availability of sparsely labeled~ or unlabeled~ target data for model adaptation, hence having access to the marginal $P_X^{\\mathcal{T}}$. Though there exist different variants of DA where some methods do not explicitly use target data during training, such as zero-shot DA~ that exploits task-irrelevant but target domain-relevant data (equivalent to accessing the marginal), their main idea remains unchanged, i.e., to leverage additional data that expose information related to the target domain. As shown in Table~\\ref{tab:compare_topics}, research in DA shares some commonalities with DG, such as single-~ and multi-source~ DA, and heterogeneous DA~.\n\\keypoint{Test-Time Training (TTT)}\nalso called test-time adaptation~, blurs the boundary between DA and DG. As shown in Table~\\ref{tab:compare_topics}, TTT is related to both DA and DG because TTT also deals with the domain shift problem. One one hand, TTT (mostly) bears a resemblance with source-free DA~---both assume source data is inaccessible after model training. On the other hand, TTT differs from DA in that only a single~ or mini-batch~ test data is used for model \\emph{tuning}, which is often done in an online manner~ and of course, without human supervision. It is also worth mentioning that datasets used in the TTT community largely overlap with those in DG, such as CIFAR-C~ and ImageNet-C~. In terms of performance, TTT likely outperforms DG~ due to the use of test data for parameter update, but is limited to scenarios where deployment devices have sufficient compute power. Moreover, TTT might not fit realtime applications if the tuning time is too ``long.''\n\\begin{table*}\n    \\centering\n    \\tabstyle{5pt}\n    \\caption{Categorization of domain generalization (DG) methods.}\n    \\label{tab:categorization_dg_methods}\n    \\resizebox{\\textwidth}{!}{\n        \\begin{tabular}{l c l}\n        \\toprule\n        & \\textbf{Domain labels} & \\textbf{References} \\\\\n        \\midrule\n        \\multicolumn{3}{l}{\\textbf{Domain Alignment} (\\S~\\ref{sec:methods;subsec:alignment})} \\\\\n        \\quad- Minimizing Moments & \\cmark &  \\\\\n        \\quad- Minimizing Contrastive Loss & \\cmark &  \\\\\n        \\quad- Minimizing the KL Divergence & \\cmark &  \\\\\n        \\quad- Minimizing Maximum Mean Discrepancy & \\cmark &  \\\\\n        \\quad- Domain-Adversarial Learning & \\cmark &  \\\\\n        \\midrule\n        \\textbf{Meta-Learning} (\\S~\\ref{sec:methods;subsec:meta_learning}) & \\cmark &  \\\\\n        \\midrule\n        \\multicolumn{3}{l}{\\textbf{Data Augmentation} (\\S~\\ref{sec:methods;subsec:data_aug})} \\\\\n        \\quad- Image Transformations & \\xmark &  \\\\\n        \\quad- Task-Adversarial Gradients & \\xmark &  \\\\\n        \\quad- Domain-Adversarial Gradients & \\cmark &  \\\\\n        \\quad- Random Augmentation Networks & \\xmark &  \\\\\n        \\quad- Off-the-Shelf Style Transfer Models & \\cmark &  \\\\\n        \\quad- Learnable Augmentation Networks & \\cmark &  \\\\\n        \\quad- Feature-Based Augmentation & \\cmark &  \\\\\n        \\midrule\n        \\multicolumn{3}{l}{\\textbf{Ensemble Learning} (\\S~\\ref{sec:methods;subsec:ensemble})} \\\\\n        \\quad- Exemplar-SVMs & \\xmark &  \\\\\n        \\quad- Domain-Specific Neural Networks & \\cmark &  \\\\\n        \\quad- Domain-Specific Batch Normalization & \\cmark &  \\\\\n        \\quad- Weight Averaging & \\xmark &  \\\\\n        \\midrule\n        \\multicolumn{3}{l}{\\textbf{Self-Supervised Learning} (\\S~\\ref{sec:methods;subsec:self_supervised})} \\\\\n        \\quad- Single Pretext Task & \\xmark &  \\\\\n        \\quad- Multiple Pretext Tasks & \\xmark &  \\\\\n        \\midrule\n        \\multicolumn{3}{l}{\\textbf{Learning Disentangled Representations} (\\S~\\ref{sec:methods;subsec:disentangled})} \\\\\n        \\quad- Decomposition & \\cmark &  \\\\\n        \\quad- Generative Modeling & \\cmark &  \\\\\n        \\midrule\n        \\textbf{Regularization Strategies} (\\S~\\ref{sec:methods;subsec:reg}) & \\xmark &  \\\\\n        \\midrule\n        \\multicolumn{3}{l}{\\textbf{Reinforcement Learning} (\\S~\\ref{sec:methods;subsec:rl})} \\\\\n        \\quad- Data augmentation & \\xmark &  \\\\\n        \\quad- Self-Supervision & \\xmark &  \\\\\n        \\bottomrule\n        \\end{tabular}\n    }\n    \\begin{flushleft}\n        \\footnotesize\n        \\itshape\n        Note that methods requiring domain labels can only be applied to multi-source DG while those not requiring domain labels are applicable to both multi- and single-source DG.\n    \\end{flushleft}\n\\end{table*}", "cites": [5086, 961, 3306, 2795, 5080, 324, 2760, 5089, 5087, 5063, 5103, 5064, 5088, 5062, 2690, 5092, 2733, 5098, 5094, 2717, 6983, 2758, 8584, 7116, 1223, 5068, 5107, 5104, 2695, 128, 2796, 2685, 2705, 2686, 8589, 5076, 5073, 5106, 2719, 2292, 2728, 196, 5096, 2761, 2800, 8579, 2601, 5066, 2755, 5101, 2700, 2798, 5095, 8877, 8879, 5097, 2793, 629, 5077, 7889, 8580, 5100, 2684, 5091, 2699, 7614, 2789, 3303, 8581, 2724, 5110, 2713, 5090, 2704, 2714, 5099, 5109, 2743, 5093, 5082, 5105, 2703, 8588, 2707, 7890, 5102, 8570, 1606, 2600, 5108, 2759, 2702, 3222], "cite_extract_rate": 0.7153846153846154, "origin_cites_number": 130, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.2, "critical": 3.7, "abstraction": 4.3}, "insight_level": "high", "analysis": "The section analytically connects DG with related fields (e.g., TL, DA, ZSL) by identifying key differences and shared principles. It synthesizes concepts from multiple papers to clarify assumptions, objectives, and techniques across these areas, and abstracts broader themes like domain invariance, data augmentation, and meta-learning. While it does not extensively critique individual papers, it provides a nuanced framework for understanding DG in relation to other generalization paradigms."}}
{"id": "2f8c54fa-7180-4121-8bcd-fa042002b4ce", "title": "Domain Alignment", "level": "subsection", "subsections": ["e7f0c23e-e2cb-4b01-9bce-932ed148ddb3", "fe6ec83f-4b98-4544-849a-bae902181f8d"], "parent_id": "ee272460-becb-4d78-9e01-e04bba4c1221", "prefix_titles": [["title", "Domain Generalization: A Survey"], ["section", "Methodologies: A Survey"], ["subsection", "Domain Alignment"]], "content": "\\label{sec:methods;subsec:alignment}\nMost existing DG approaches belong to the category of domain alignment~, where the central idea is to minimize the difference among source domains for learning domain-invariant representations (see Fig.~\\ref{fig:domain_alignment}). The motivation is straightforward: features that are invariant to the source domain shift should also be robust to any unseen target domain shift. Domain alignment has been applied in many DG applications, e.g., object recognition~, action recognition~, face anti-spoofing~, and medical imaging analysis~. Domain labels are required for domain alignment methods.\nTo measure the distance between distributions and thereby achieve alignment, there are a wide variety of statistical distance metrics for us to borrow, such as the simple $\\ell_2$ distance, $f$-divergences, or the more sophisticated Wasserstein distance~. However, designing an effective domain alignment method is a non-trivial task because one needs to consider \\emph{what to align} and \\emph{how to align}. In the following sections, we analyze the existing alignment-based DG methods from these two aspects.", "cites": [8879, 8588, 2690, 2719, 2728, 5088, 5102], "cite_extract_rate": 0.6363636363636364, "origin_cites_number": 11, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.5, "critical": 2.0, "abstraction": 2.5}, "insight_level": "medium", "analysis": "The section provides a general overview of domain alignment methods and lists several application areas and techniques, but it does not deeply connect or synthesize the cited papers into a cohesive framework. It mentions the necessity of domain labels and the challenges in designing effective alignment methods but lacks critical evaluation or comparison of the approaches. Some abstraction is attempted by highlighting the general idea of domain-invariant representations, but broader patterns or principles are not clearly articulated."}}
{"id": "e7f0c23e-e2cb-4b01-9bce-932ed148ddb3", "title": "What to Align", "level": "subsubsection", "subsections": [], "parent_id": "2f8c54fa-7180-4121-8bcd-fa042002b4ce", "prefix_titles": [["title", "Domain Generalization: A Survey"], ["section", "Methodologies: A Survey"], ["subsection", "Domain Alignment"], ["subsubsection", "What to Align"]], "content": "Recall that a domain is modeled by a joint distribution $P(X,Y)$ (see \\S~\\ref{sec:bg;subsec:problem_def} for the background), we can decompose it into\n\\begin{align}\nP(X,Y) &= P(Y|X) P(X), \\label{eq:p(y|x)p(x)} \\\\\n       &= P(X|Y) P(Y). \\label{eq:p(x|y)p(y)}\n\\end{align}\nA common assumption in DG is that distribution shift only occurs in the marginal $P(X)$ while the posterior $P(Y|X)$ remains relatively stable~ (see Eq.~\\eqref{eq:p(y|x)p(x)}). Therefore, numerous domain alignment methods have been focused on aligning the marginal distributions of source domains~.\nFrom a causal learning perspective~, it is valid to align $P(X)$ only when $X$ is the cause of $Y$. In this case, $P(Y|X)$ is not coupled with $P(X)$ and thus remains stable when $P(X)$ varies. However, it is also possible that $Y$ is the cause of $X$, and as a result, shift in $P(X)$ will also affect $P(Y|X)$. Therefore, some domain alignment methods~ proposed to instead align the class-conditional $P(X|Y)$, assuming that $P(Y)$ does not change (see Eq.~\\eqref{eq:p(x|y)p(y)}). For example, Li et al.~ learned a feature transformation by minimizing for all classes the variance of class-conditional distributions across source domains. To allow $P(Y)$ to change along with $P(X|Y)$, i.e., heterogeneous DG, Hu et al.~ relaxed the assumption made in~ by removing the minimization constraint on marginal distributions and proposed several discrepancy measures to learn generalizable features.\nSince the posterior $P(Y|X)$ is what we need at test time, Wang et al.~ introduced hypothesis invariant representations, which are obtained by directly aligning the posteriors within each class regardless of domains via the Kullbackâ€“Leibler (KL) divergence.", "cites": [8879, 8581, 2754, 2690, 2714], "cite_extract_rate": 0.5555555555555556, "origin_cites_number": 9, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.0, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section effectively synthesizes multiple papers by connecting domain alignment strategies through probabilistic decomposition and causal reasoning. It offers abstraction by identifying broader patterns, such as assumptions about distribution shifts and the role of causality. While it points out differences in assumptions (e.g., homogeneous vs. heterogeneous DG), it could provide deeper comparative or critical analysis of the limitations of these approaches."}}
{"id": "fe6ec83f-4b98-4544-849a-bae902181f8d", "title": "How to Align", "level": "subsubsection", "subsections": [], "parent_id": "2f8c54fa-7180-4121-8bcd-fa042002b4ce", "prefix_titles": [["title", "Domain Generalization: A Survey"], ["section", "Methodologies: A Survey"], ["subsection", "Domain Alignment"], ["subsubsection", "How to Align"]], "content": "Having discussed what to align in the previous section, here we turn to the exact techniques used in the DG literature for distribution alignment.\n\\keypoint{Minimizing Moments}\nMoments are parameters used to measure a distribution, such as mean (1st-order moment) and variance (2nd-order moment) calculated over a population. Therefore, to achieve invariance between source domains, one can learn a mapping function (e.g., a simple projection matrix~ or a complex non-linear function modeled by deep neural networks~) with an objective of minimizing the moments of the transformed features between source domains, in terms of variance~ or both mean and variance~.\n\\keypoint{Minimizing Contrastive Loss}\nis another option for reducing distribution mismatch~, which takes into account the semantic labels. There are two key design principles. The first is about how to construct the anchor group, the positive group (same class as the anchor but from different domains) and the negative group (different class than the anchor). The second is about the formulation of the distance function (e.g., using $\\ell_2$~ or softmax~). The objective is to pull together the anchor and the positive groups, while push away the anchor and the negative groups.\n\\keypoint{Minimizing the KL Divergence}\nAs a commonly used distribution divergence measure, the KL divergence has also been employed for domain alignment~. In~, domain-agnostic posteriors within each class are aligned via the KL divergence. In~, the KL divergence is used to force all source domain features to be aligned with a Gaussian distribution.\n\\keypoint{Minimizing Maximum Mean Discrepancy (MMD)}\nThe MMD distance~ measures the divergence between two probability distributions by first mapping instances to a reproducing kernel Hilbert space (RKHS) and then computing the distance based on their mean. Using the autoencoder architecture, Li et al.~ minimized the MMD distance between source domain distributions on the hidden-layer features, and meanwhile, forced the feature distributions to be similar to a prior distribution via adversarial learning~.\n\\keypoint{Domain-Adversarial Learning}\nDifferent from explicit distance measures like the MMD, adversarial learning~ formulates the distribution minimization problem through a minimax two-player game. Initially proposed by Goodfellow et al.~, adversarial learning was used to train a generative model, which takes as input random noises and generates photorealistic images. This is achieved by learning a discriminator to distinguish between real and the generated fake images (i.e., minimizing the binary classification loss), while encouraging the generator to fool the discriminator (i.e., maximizing the binary classification loss). In particular, the authors in~ theoretically justified that generative adversarial learning is equivalent to minimizing the Jensen-Shannon divergence between the real distribution and the generated distribution. Therefore, it is natural to use adversarial learning for distribution alignment, which has already been extensively studied in the domain adaptation area for aligning the source-target distributions~.\nIn DG, adversarial learning is performed between source domains to learn source domain-agnostic features that are expected to work in novel domains~. Simply speaking, the learning objective is to make features confuse a domain discriminator, which can be implemented as a multi-class domain discriminator~, or a binary domain discriminator in a per-domain basis~. Typically, the learning steps alternate between the feature generator and the domain discriminator(s)~. However, one can simplify the process to achieve single-step update by using the gradient-reversal layer~ to flip the sign of the gradients back-propagated from the domain discriminator(s)~.\nTo enhance domain alignment, researchers have also combined domain-adversarial learning with explicit distance measures like moments minimization~, or with some regularization constraints such as entropy~.\n\\keypoint{Multi-Task Learning}\nhas also been explored for domain alignment~. Different from directly minimizing the distribution divergence, MTL facilitates the learning of generic features by parameter sharing~. This is easy to understand: in order to simultaneously deal with different tasks the features have to be generic enough. In~, the authors proposed a denoising autoencoder architecture (later employed in~) where the encoder is shared but the decoder is split into domain-specific branches, each connected to a reconstruction task. The model was trained with two objectives, one being self-domain reconstruction while the other being cross-domain reconstruction, which aim to force the hidden representations to be as generic as possible.\nDomain alignment is still a popular research direction in DG. This idea has also been extensively studied in the domain adaptation (DA) literature~, but with a rigorous theoretical support~. In particular, the DA theory introduced in~ suggested that minimizing the distribution divergence between source and target has a huge impact on lowering the upper-bound of the target error. However, in DG we cannot access the target data and therefore, the alignment is performed only among source domains. This inevitably raises a question of whether a representation learned to be invariant to source domain shift is guaranteed to generalize to an unseen domain shift in the target data. To solve this concern, one can focus on developing novel theories to explain how alignment in source domains improves generalization in unseen domains.\n\\begin{figure}[t]\n    \\centering\n    \\includegraphics[width=\\columnwidth]{figs/meta_learning_paradigm.pdf}\n    \\caption{A commonly used meta-learning paradigm~ in domain generalization. The source domains (i.e., art, photo and cartoon from PACS~) are divided into disjoint meta-source and meta-target domains. The outer learning, which simulates domain shift using the meta-target data, back-propagates the gradients all the way back to the base parameters such that the model learned by the inner algorithm with the meta-source data improves the outer objective. The red arrows in this figure denote the gradient flow through the second-order differentiation.}\n    \\label{fig:meta_learning_paradigm}\n\\end{figure}", "cites": [8581, 2724, 5111, 5086, 5066, 2755, 2714, 5101, 5093, 2686, 5088, 8879, 8588, 5112, 2690, 2719, 2728, 5113, 2793, 5102, 5096, 2717, 2684, 7116], "cite_extract_rate": 0.631578947368421, "origin_cites_number": 38, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.5, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section synthesizes and organizes diverse domain alignment techniques (e.g., moments, MMD, adversarial learning, multi-task learning) into a coherent structure, connecting ideas from multiple papers. It also includes critical reflections on limitations, such as the question of whether source domain invariance guarantees target domain generalization, and explores combinations of methods to improve effectiveness. The abstraction level is strong as it moves beyond individual papers to highlight broader principles in domain generalization."}}
{"id": "da9c51f3-35ad-4014-8b7c-018e0df15131", "title": "Meta-Learning", "level": "subsection", "subsections": [], "parent_id": "ee272460-becb-4d78-9e01-e04bba4c1221", "prefix_titles": [["title", "Domain Generalization: A Survey"], ["section", "Methodologies: A Survey"], ["subsection", "Meta-Learning"]], "content": "\\label{sec:methods;subsec:meta_learning}\nMeta-learning has been a fast growing area with applications to many machine learning and computer vision problems~. Also known as learning-to-learning, meta-learning aims to learn from episodes sampled from related tasks to benefit future learning (see~ for a comprehensive survey on meta-learning). The meta-learning paper most related to DG is MAML~, which divides training data into meta-train and meta-test sets, and trains a model using the meta-train set in such a way to improve the performance on the meta-test set. The MAML-style training usually involves a second-order differentiation through the update of the base model, thus posing issues on efficiency and memory consumption for large neural network models~. In~, MAML was used for parameter initialization, i.e., to learn an initialization state that is only a few gradient steps away from the solution to the target task.\nThe motivation behind applying meta-learning to DG is to expose a model to domain shift during training with a hope that the model can better deal with domain shift in unseen domains. Existing meta-learning DG methods can only be applied to multi-source DG where domain labels are provided.\nThere are two components that need to be carefully designed, namely \\emph{episodes} and \\emph{meta-representation}. Specifically, episodes construction concerns how each episode should be constructed using available samples, while meta-representation answers the question of what to meta-learn.\n\\keypoint{Episodes Construction}\nMost existing meta-learning-based DG methods~ followed the learning paradigm proposed in~---which is the first method applying meta-learning to DG. Specifically, source domains are divided into non-overlapping \\emph{meta-source} and \\emph{meta-target} domains to simulate domain shift. The learning objective is to update a model using the meta-source domain(s) in such a way that the test error on the meta-target domain can be reduced, which is often achieved by bi-level optimization. See Fig.~\\ref{fig:meta_learning_paradigm} for a graphical representation.\n\\keypoint{Meta-Representation}\nis a term defined in~ to represent the model parameters that are meta-learned. Most deep learning methods meta-learned the entire neural network models~. Balaji et al.~ instead proposed to meta-learn the regularization parameters. In~, a stochastic neural network is meta-learned to handle uncertainty. In~, an MRI segmentation model is meta-learned, along with two shape-aware losses to ensure compactness and smoothness in the segmentation results. Batch normalization layers are meta-learned in~ to cope with the training-test discrepancy in CNN feature statistics.\nOverall, meta-learning is a promising direction to work on given its effectiveness in not only DG but also a wide range of applications like few-shot classification~, object detection~ and image generation~. However, meta-learning in DG still suffers the same issue with that in domain alignment---a representation is only learned to be robust under source domain shift (simulated by meta-source and meta-target domains). Such an issue could be aggravated if the source domains are limited in terms of diversity. As observed from recent work~, both meta-learning and domain alignment methods are underperformed by methods based on directly augmenting the source training data---a topic that will be visited later. One might alleviate the generalization issue in meta-learning, as well as in domain alignment, by combining them with data augmentation. Moreover, advances may also be achieved by designing novel meta-learning algorithms in terms of meta-representation, meta-optimizer, and/or meta-objective.\\footnote{These terms are defined in~.}\n\\begin{figure*}[t]\n    \\centering\n    \\includegraphics[width=.9\\textwidth]{figs/data_aug_pipelines.pdf}\n    \\caption{\n    Based on the formulation of the transformation $A(\\cdot)$, existing data augmentation methods can be categorized into four groups. \\textbf{a)} The first group enhances the generalization of the classifier $f$ by applying hand-engineered image transformations like random crop or color augmentation to simulating domain shift. \\textbf{b)} The second group is based on adversarial gradients obtained from either a category classifier ($h = f$) or a domain classifier. \\textbf{c)} The third group models $A(\\cdot)$ using neural networks, such as random CNNs~, an off-the-shelf style transfer model~, or a learnable image generator~. \\textbf{d)} The final group injects perturbation into intermediate features in the task model.\n    }\n    \\label{fig:data_aug_pipelines}\n\\end{figure*}\n\\begin{figure}[t]\n    \\centering\n    \\includegraphics[width=.75\\columnwidth]{figs/image_transformations.pdf}\n    \\caption{Common image transformations used as data augmentation in domain generalization~.}\n    \\label{fig:image_transformations}\n\\end{figure}", "cites": [5068, 7109, 2798, 8877, 5109, 5063, 2686, 8589, 5114, 2703, 5097, 1695, 5115, 8580, 2761, 2699, 8579], "cite_extract_rate": 0.7391304347826086, "origin_cites_number": 23, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.5, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section synthesizes key ideas from multiple meta-learning papers in the DG context, integrating themes like episodes construction and meta-representation. It provides a critical perspective by highlighting limitations, such as reliance on source domain diversity and underperformance compared to data augmentation approaches. The section abstracts beyond individual methods to identify broader design principles and potential future directions in meta-learning for DG."}}
{"id": "7fb3487e-b6a8-4a7f-8558-51ec8de73457", "title": "Data Augmentation", "level": "subsection", "subsections": [], "parent_id": "ee272460-becb-4d78-9e01-e04bba4c1221", "prefix_titles": [["title", "Domain Generalization: A Survey"], ["section", "Methodologies: A Survey"], ["subsection", "Data Augmentation"]], "content": "\\label{sec:methods;subsec:data_aug}\nData augmentation has been a common practice to regularize the training of machine learning models to avoid over-fitting and improve generalization~, which is particularly important for over-parameterized deep neural networks. The basic idea in data augmentation is to augment the original $(x, y)$ pairs with new $(A(x), y)$ pairs where $A(\\cdot)$ denotes a transformation, which is typically label-preserving. Not surprisingly, given the advantages of data augmentation, it has been extensively studied in DG where $A(\\cdot)$ is usually seen as a way of simulating domain shift and the design of $A(\\cdot)$ is key to performance.\nBased on how $A(\\cdot)$ is formulated, data augmentation methods generally fall into four groups. See Fig.~\\ref{fig:data_aug_pipelines} for an overview. Below we provide more detailed reviews, with a more fine-grained categorization where adversarial gradients are divided into task-adversarial gradients and domain-adversarial gradients; and model-based augmentation is further split into three sub-groups: random augmentation networks, off-the-shelf style transfer models, and learnable augmentation networks.\n\\keypoint{Image Transformations}\nThis type of approach exploits traditional image transformations, such as random flip, rotation and color augmentation. Fig.~\\ref{fig:image_transformations} visualizes some effects of transformations. Though using image transformations does not require domain labels during learning, the selection of transformations is usually problem-specific. For example, for object recognition where image style changes are the main domain shift, one can choose transformations that are more related to color intensity changes, such as \\texttt{brightness}, \\texttt{contrast} and \\texttt{solarize} in Fig.~\\ref{fig:image_transformations}. To avoid manual picking, one can design a searching mechanism to search for the optimal set of transformations that best fit the target problem. An example is~ where the authors proposed an evolution-based searching algorithm and used a worst-case formulation to make the transformed images deviate as much as possible from the original image distribution. One can also select transformations according to the specific downstream task. For instance,  addressed the universal feature learning problem in face recognition by synthesizing meaningful variations such as lowering image resolution, adding occlusions and changing head poses.\nTraditional image transformations have been shown very effective in dealing with domain shift in medical images~. This makes sense because image transformations can well simulate changes in color and geometry caused by device-related domain shift, such as using different types of scanners in different medical centers. However, image transformations can be limited in some applications as they might cause label shift, such as digit recognition or optical character recognition where the horizontal/vertical flip operation is infeasible. Therefore, transformations should be carefully chosen to not conflict with the downstream task.\n\\keypoint{Task-Adversarial Gradients}\nInspired by adversarial attacks~, several data augmentation methods are based on using adversarial gradients obtained from the task classifier to perturb the input images~. In doing so, the original data distribution is expanded, allowing the model to learn more generalizable features. Though this type of approach is often developed for tackling single-source DG, the idea can also be directly applied to multi-source scenarios.\n\\keypoint{Domain-Adversarial Gradients}\nWhen it comes to multi-source DG where domain labels are provided, one can exploit domain-adversarial gradients to synthesize domain-agnostic images. For instance,  trained a domain classifier and used its adversarial gradients to perturb the input images. Intuitively, by learning with domain-agnostic images, the task model is allowed to learn more domain-invariant patterns.\nSince adversarial gradients-based perturbation is purposefully designed to be visually imperceptible~, methods based on adversarial gradients are often criticized for not being able to simulate real-world domain shift, which is much more complicated than salt-and-pepper noise~. Furthermore, the computational cost is often doubled in these methods because the forward and backward passes need to be computed twice, which could pose serious efficiency issues for large neural networks. Below we discuss model-based methods that formulate the transformation $A(\\cdot)$ using neural networks and can produce more diverse visual effects.\n\\keypoint{Random Augmentation Networks}\nRandConv~ is based on the idea of using randomly initialized, single-layer convolutioinal neural network to transform the input images to ``novel domains.'' Since the weights are randomly sampled from a Gaussian distribution at each iteration and no learning is performed, the transformed images mainly contain random color distortions, which do not contain meaningful variations and are best to be mixed with the original images before passing to the task network.\n\\keypoint{Off-the-Shelf Style Transfer Models}\nTaking advantage of the advances in style transfer~, several DG methods~ use off-the-shelf style transfer models like AdaIN~ to represent $A(\\cdot)$, which essentially maps images from one source domain to another for data augmentation. Instead of transferring image styles between source domains, one can exploit external styles to further diversify the source training data~. Though these methods do not need to train the style transfer component, they still need domain labels for domain translation.\n\\keypoint{Learnable Augmentation Networks}\nThis group of methods aims to learn augmentation neural networks to synthesize new domains~. In~, domain-agnostic images are generated by maximizing the domain classification loss with respect to the image generator. In~, pseudo-novel domains are synthesized by maximizing for each source domain the domain distance measured by optimal transport~ between the original and synthetic images.\n\\keypoint{Feature-Based Augmentation}\nThough the above learnable augmentation models have shown promising results, their efficiency is a main concern as they need to train heavy image-to-image translation models. Another line of research focuses on feature-level augmentation~. Motivated by the observation that image styles are captured in CNN feature statistics, MixStyle~ achieves style augmentation by mixing CNN feature statistics between instances of different domains. In~, Mixup~ is applied to mixing instances of different domains in both pixel and feature space.", "cites": [2702, 2704, 961, 2700, 2795, 154, 892, 5109, 5063, 314, 2705, 2703, 7191, 2707, 5062, 5097, 196, 5077, 5100, 166, 2699, 2800], "cite_extract_rate": 0.8461538461538461, "origin_cites_number": 26, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.2, "critical": 3.5, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section synthesizes a diverse set of papers to present a structured overview of data augmentation methods for domain generalization. It organizes methods into categories and subcategories, linking them with shared principles such as adversarial gradients and style transfer. The section also critically discusses limitations, such as the inability to simulate real-world domain shifts and computational inefficiencies. It abstracts key design considerations, such as the trade-off between realism and diversity in augmentation, and the role of feature statistics in generalization."}}
{"id": "1858806d-2dbd-4aab-9557-930d4ca0ec2a", "title": "Ensemble Learning", "level": "subsection", "subsections": [], "parent_id": "ee272460-becb-4d78-9e01-e04bba4c1221", "prefix_titles": [["title", "Domain Generalization: A Survey"], ["section", "Methodologies: A Survey"], ["subsection", "Ensemble Learning"]], "content": "\\label{sec:methods;subsec:ensemble}\nAs an extensively studied topic in machine learning research, ensemble learning~ typically learns multiple copies of the same model with different initialization weights or using different splits of training data, and uses their ensemble for prediction. Such a simple technique has been shown very effective in boosting the performance of a single model across a wide range of applications~.\n\\keypoint{Exemplar-SVMs}\nare a collection of SVM classifiers, each learned using one positive instance and all negative instances~. As the ensemble of such exemplar SVMs have shown excellent generalization performance on the object detection task in~, Xu et al.~ have extended exemplar-SVMs to DG. In particular, given a test sample the top-K exemplar classifiers that give the highest prediction scores (hence more confident) are selected for ensemble prediction. Such an idea of learning exemplar classifiers was also investigated in~ for DG.\n\\keypoint{Domain-Specific Neural Networks}\nSince CNNs excel at discriminative feature learning~, it is natural to replace hand-engineered SVM classifiers with CNN-based models for ensemble learning. A common practice is to learn domain-specific neural networks, each specializing in a source domain~. Rather than learning an independent CNN for each source domain~, it is more efficient, and makes more sense as well, to share between source domains some shallow layers~, which capture generic features~. Another question is how to compute the prediction. One can simply use the ensemble prediction averaged over all individuals with equal weights (e.g.,~). Alternatively, weighted averaging can be adopted where the weights are estimated by, for example, a source domain classifier aiming to measure the similarity of the target sample to each source domain~. Also, the weights can be used to determine the most confident candidate whose output will serve for final prediction~.\n\\keypoint{Domain-Specific Batch Normalization}\nIn batch normalization (BN)~, the statistics are computed on-the-fly during training and their moving averages are stored in buffers for inference. Since the statistics typically vary in different source domains, one could argue that mixing statistics of multiple source domains is detrimental to learning generalizable representations. One solution is to use domain-specific BNs~, one for each source domain for collecting domain-specific statistics. This is equivalent to constructing domain-specific classifiers but with parameter sharing for most parts of a model except the normalization layers. Such a design was later adopted in~ for dealing with MRI segmentation. In~, the domain-specific predictions are aggregated using as weights the distance between a test data's instance-level feature statistics and the source domain BN statistics.\n\\keypoint{Weight Averaging}\naggregates model weights at different time steps during training to form a single model at test time~. Unlike explicit ensemble learning where multiple models (or model parts) need to be trained, weight averaging is a more efficient solution as the model only needs to be trained once. In~, the authors have demonstrated that weight averaging can greatly improve model robustness under domain shift. In fact, such a technique is orthogonal to many other DG approaches and can be applied as a post-processing method to further boost the DG performance.\n\\begin{figure}[t]\n    \\centering\n    \\includegraphics[width=\\columnwidth]{figs/pretext_tasks.pdf}\n    \\caption{Common pretext tasks used for self-supervised learning in domain generalization. One can use a single pretext task, like solving Jigsaw puzzles~ or predicting rotations~, or combine multiple pretext tasks in a multi-task learning fashion.}\n    \\label{fig:pretext_tasks}\n\\end{figure}", "cites": [2503, 2796, 305, 2685, 126, 5116, 5064, 97, 629, 71, 2759, 2758, 8584, 2789], "cite_extract_rate": 0.6086956521739131, "origin_cites_number": 23, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.5, "critical": 2.0, "abstraction": 2.0}, "insight_level": "medium", "analysis": "The section provides a factual overview of ensemble learning approaches in domain generalization and describes several methods such as exemplar-SVMs, domain-specific neural networks, and domain-specific batch normalization. While it connects some ideas (e.g., the role of normalization layers in domain-specific models), it lacks deeper comparative or critical analysis of the approaches and does not highlight broader theoretical principles or limitations. The synthesis is moderate, but the section remains largely descriptive in nature."}}
{"id": "22cbbf3f-8e61-4244-a18f-53f8faed628d", "title": "Self-Supervised Learning", "level": "subsection", "subsections": [], "parent_id": "ee272460-becb-4d78-9e01-e04bba4c1221", "prefix_titles": [["title", "Domain Generalization: A Survey"], ["section", "Methodologies: A Survey"], ["subsection", "Self-Supervised Learning"]], "content": "\\label{sec:methods;subsec:self_supervised}\nSelf-supervised learning is often referred to as learning with free labels generated from data itself (see~ for a comprehensive survey on self-supervised learning). In computer vision, this can be achieved by teaching a model to predict the transformations applied to the image data, such as the shuffling order of patch-shuffled images~ or rotation degrees~. See Fig.~\\ref{fig:pretext_tasks} for illustrations.\nSo why can self-supervised learning improve DG? An intuitive explanation is that solving pretext tasks allows a model to learn generic features regardless of the target task, and hence less over-fitting to domain-specific biases~. An obvious advantage of self-supervised learning is that it can be applied to both single- and multi-source scenarios without requiring any domain labels.\n\\keypoint{Single Pretext Task}\nIn addition to using the standard classification loss, Carlucci et al.~ taught a neural network to solve the Jigsaw puzzles problem~, hoping that the network can learn regularities that are more generalizable across domains. Similarly, Wang et al.~ used the Jigsaw solving task as an intrinsic supervision, together with an extrinsic supervision implemented using metric learning. Reconstruction has also been investigated for DG, such as learning an autoencoder to reconstruct image pixels/features~.\n\\keypoint{Multiple Pretext Tasks}\nIt is also possible to combine multiple pretext tasks. In~, the authors combined two pretext tasks, namely solving Jigsaw puzzles and predicting rotations. In~, three pretext tasks are combined, namely reconstructing the Gabor filter's response, predicting rotations, and predicting feature cluster assignments~. Overall, using multiple pretext tasks gives a better performance than using a single pretext task, as shown in~.\nCurrently, these self-supervised learning-based DG methods have only been evaluated on the object recognition task. It is still unclear whether they will work on a wider range of OOD generalization tasks, which would be interesting to investigate in future work. Another concerns are that in general none of the existing pretext tasks is universal, and that the selection of pretext tasks is problem-specific. For instance, when the target domain shift is related to rotations, the model learned with the rotation prediction task will capture rotation-sensitive information, which is harmful to generalization.\nRecent state-of-the-art self-supervised learning methods~ are mostly based on combining contrastive learning with data augmentation. The key idea is to pull together the same instance (image) undergone different transformations (e.g., random flip and color distortion) while push away different instances to learn instance-aware representations. Different from predicting transformations such as rotation, contrastive learning aims to learn transformation-invariant representations. Future work can explore whether invariances learned via contrastive learning can better adapt to OOD data.", "cites": [126, 8588, 5076, 9094, 7890, 5104, 128, 2503, 7116, 122, 322, 2517], "cite_extract_rate": 1.0, "origin_cites_number": 12, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.5, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section synthesizes multiple papers on self-supervised learning for domain generalization, connecting common themes such as pretext tasks, invariance learning, and the use of autoencoders. It offers critical analysis by pointing out limitations like the non-universality of pretext tasks and potential harms when tasks align with domain-specific shifts. The discussion abstracts beyond individual papers to highlight broader principles and potential future directions in the field."}}
{"id": "b8a091a9-9ac8-412c-8ab4-53ed5e5dc026", "title": "Learning Disentangled Representations", "level": "subsection", "subsections": [], "parent_id": "ee272460-becb-4d78-9e01-e04bba4c1221", "prefix_titles": [["title", "Domain Generalization: A Survey"], ["section", "Methodologies: A Survey"], ["subsection", "Learning Disentangled Representations"]], "content": "\\label{sec:methods;subsec:disentangled}\nInstead of forcing the entire model or features to be domain-invariant, which is challenging, one can relax this constraint by allowing some parts to be domain-specific, essentially learning disentangled representations. The existing approaches falling into this group are either based on decomposition~ or generative modeling~, both requiring domain labels for feature disentanglement.\n\\keypoint{Decomposition}\nAn intuitive way to achieve disentangled representation learning is to decompose a model into two parts, one being domain-specific while the other being domain-agnostic. Based on SVMs, Khosla et al.~ decomposed a classifier into domain-specific biases and domain-agnostic weights, and only kept the latter when dealing with unseen domains. This approach was later extended to neural networks in~. One can also design domain-specific modules such as in~ where domain-specific binary masks are imposed on the final feature vector to distinguish between domain-specific and domain-invariant components. Another solution is to apply low-rank decomposition to a model's weight matrices in order to identify common features that are more generalizable~.\n\\keypoint{Generative Modeling}\nhas been a powerful tool for learning disentangled representations~. In~, a variational autoencoder (VAE) is utilized to learn three independent latent subspaces for class, domain and object, respectively. In~, two separate encoders are learned in an adversarial way to capture identity and domain information respectively for cross-domain face anti-spoofing.", "cites": [5107, 2684, 2743, 1002], "cite_extract_rate": 0.5714285714285714, "origin_cites_number": 7, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.5, "critical": 2.0, "abstraction": 2.5}, "insight_level": "medium", "analysis": "The section provides a basic synthesis of methods related to disentangled representation learning in domain generalization, grouping them into 'decomposition' and 'generative modeling' categories. However, it largely describes each paper's approach without in-depth comparison or critique of their strengths and limitations. Some abstraction is evident in the use of categories, but the analysis remains shallow and does not elevate the discussion to a higher conceptual level."}}
{"id": "62fdeb38-1208-47f2-b665-5d25d4505ae0", "title": "Regularization Strategies", "level": "subsection", "subsections": [], "parent_id": "ee272460-becb-4d78-9e01-e04bba4c1221", "prefix_titles": [["title", "Domain Generalization: A Survey"], ["section", "Methodologies: A Survey"], ["subsection", "Regularization Strategies"]], "content": "\\label{sec:methods;subsec:reg}\nSome approaches focus on regularization strategies designed based on some heuristics. Wang et al.~ argued that generalizable features should capture the global structure/shape of objects rather than relying on local patches/textures, and therefore proposed to suppress the predictive power of auxiliary patch-wise CNNs (maximizing their classification errors), implemented as a stack of 1$\\times$1 convolution layers. With a similar motivation, Huang et al.~ iteratively masked out over-dominant features with large gradients, thus forcing the model to rely more on the remaining features. These methods do not require domain labels for learning, and are orthogonal to other DG methods like those based on domain alignment~ and data augmentation~. Therefore, one could potentially combine them to improve the performance in practice.", "cites": [2703, 2707, 5073, 5063, 2728, 7614], "cite_extract_rate": 0.8571428571428571, "origin_cites_number": 7, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 2.0, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section provides a basic description of regularization strategies in domain generalization by mentioning several papers, but it lacks deeper synthesis, critical evaluation, or abstraction. It briefly connects these methods by noting their shared characteristic of not requiring domain labels, yet it does not compare them, analyze their strengths/limitations, or generalize to broader principles in DG."}}
{"id": "de9b702c-fab5-4de5-8000-5c958f3b8cd0", "title": "Reinforcement Learning", "level": "subsection", "subsections": [], "parent_id": "ee272460-becb-4d78-9e01-e04bba4c1221", "prefix_titles": [["title", "Domain Generalization: A Survey"], ["section", "Methodologies: A Survey"], ["subsection", "Reinforcement Learning"]], "content": "\\label{sec:methods;subsec:rl}\nDomain shift in reinforcement learning (RL) not only occurs in visual appearance (color/style changes, etc.) but also in other aspects like dynamics (transition function) or rewards (e.g., gravity/friction changes)~. For visual domain shift, many of the DG methods surveyed above seem applicable for RL, such as data augmentation methods~, but not for the latter that requires more problem-specific designs. Below we briefly discuss some representative generalization methods developed for RL. Please refer to  for a more comprehensive survey.\n\\keypoint{Data Augmentation}\nThe main idea is to augment the visual signal sent to an RL agent to make it more domain-generalizable. A common approach is to use label-preserving transformations~ like color jittering or Cutout~. One can also implement the concept of domain randomization~, which visually randomizes an environment through, e.g., computer simulators~ or random neural networks~. When convolutional neural networks are used, one can adopt the MixStyle~ approach discussed in Sec.~\\ref{sec:methods;subsec:data_aug} to create ``novel'' domains in the feature space.\n\\keypoint{Self-Supervision}\nCombining RL with self-supervised learning, which does not require manual labels, has also been explored. The general pipeline is to augment an RL model with auxiliary loss(es). For instance, Yarats et al.~ proposed a reconstruction loss based on auto-encoders; Laskin et al.~ combined RL with an unsupervised contrastive learning loss.", "cites": [2601, 2600, 2707, 5080, 5110, 5087, 2695, 8319, 8570], "cite_extract_rate": 0.9, "origin_cites_number": 10, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.5, "critical": 2.0, "abstraction": 2.3}, "insight_level": "medium", "analysis": "The section provides a basic summary of generalization methods in RL, citing several relevant papers on data augmentation and self-supervision. It makes minimal connections between the cited works, offering a somewhat fragmented overview rather than a cohesive synthesis. While it identifies the applicability of some DG techniques to RL, it lacks deeper critical evaluation or abstraction into broader principles."}}
{"id": "f6960177-8f28-407a-8e1c-ced95d7b4165", "title": "Theories", "level": "section", "subsections": [], "parent_id": "adaab269-4459-49f1-a6b5-c00e3a2b1ce1", "prefix_titles": [["title", "Domain Generalization: A Survey"], ["section", "Theories"]], "content": "\\label{sec:theories}\nUnlike domain adaptation in which plenty of learning bounds with theoretical guarantees have been proposed~, bounding the risk for domain generalization (DG) is challenging due to the absence of target data. Nonetheless, some attempts have been made to address this problem, which are briefly reviewed in this section.\nMost existing theoretical studies are subject to specific model classes, such as kernel methods~, or have strong assumptions that cannot be simply applied to broader DG methods. In~, the latent feature space of all possible domains (including both source and target) is assumed to have a linear dependency, meaning that each domain is a linear combination of other domains. Based on the linear dependency assumption, a rank regularization method is proposed and combined with a distribution alignment method. In~, source domains are assumed to form a convex hull so that minimizing the maximum pairwise distance within the source domains would lead to a decrease in the distance between any two domains in the convex hull. In~, DG is cast into an online game where a player (model) minimizes the risk for a ``new'' distribution presented by an adversary at each time-step. In~, proxy measures that correlate well with ``true'' OOD generalization are investigated.\nMore recently, there are a couple of emerging studies~ that aim to provide more generic bounds, with more relaxed assumptions, for DG. In~, feature distribution is quantified by two terms: \\romannum{1}) a variation term measuring the stability of feature representations across domains; \\romannum{2}) an informativeness term indicating the discriminativeness of feature representations (i.e., how well they can be used to distinguish different classes). Then, the error on unseen domains is bounded by an expansion function based on the variation term, subject to the learnability of feature representations measured using the informativeness term.\nIn~, the generalization gap is bounded in terms of the model's Rademacher complexity, suggesting that a lower model complexity with strong regularization can improve generalization in unseen domains---which echoes the findings in~: properly regularized Empirical Risk Minimization with leave-one-domain-out cross-validation is a strong DG baseline.", "cites": [7891, 2691, 2788, 2689, 2690, 5117, 5118, 2714, 8578, 5088, 5101], "cite_extract_rate": 0.9166666666666666, "origin_cites_number": 12, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.0, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section demonstrates strong synthesis by organizing diverse theoretical approaches into a coherent narrative, including assumptions, formulations (e.g., linear dependency, convex hulls, online learning), and recent trends. It provides some critical perspective by noting limitations such as strong assumptions and the challenge of generalizing to arbitrary OOD data. The abstraction is solid, identifying overarching concepts like feature stability, model complexity, and distribution alignment as key themes in DG theory."}}
{"id": "f84a8cd2-22a2-42b3-8697-ca3507b24160", "title": "Model Architecture", "level": "subsection", "subsections": [], "parent_id": "3f5d2bd7-1caf-4610-b596-2794f2035e45", "prefix_titles": [["title", "Domain Generalization: A Survey"], ["section", "Future Research Directions"], ["subsection", "Model Architecture"]], "content": "\\label{sec:futdir;subsec:model}\n\\keypoint{Dynamic Architectures}\nThe weights in a convolutional neural network (CNN), which serve as feature detectors, are normally fixed once learned from source domains. This may result in the representational power of a CNN model restricted to the seen domains while generalizing poorly when the image statistics in an unseen domain are significantly different. One potential solution is to develop \\emph{dynamic} architectures~, e.g., with weights conditioned on the input~. The key is to make neural networks' parameters (either partly or entirely) dependent on the input while ensuring that the model size is not too large to harm the efficiency. Dynamic architectures such as dynamic filter networks~ and conditional convolutions~ have been shown effective on generic visual recognition tasks like classification and segmentation. It would be interesting to see whether such a flexible architecture can be used to cope with domain shift in DG.\n\\keypoint{Adaptive Normalization Layers}\nNormalization layers~ have been a core building block in contemporary neural networks. Following~, a general formulation for different normalization layers can be written as $\\gamma \\frac{x-\\mu}{\\sigma} + \\beta$, where $\\mu$ and $\\sigma$ denote mean and variance respectively; $\\gamma$ and $\\beta$ are learnable scaling and shift parameters respectively. Typically, $(\\mu, \\sigma)$ are computed on-the-fly during training but are saved in buffers using their moving averages for inference. Regardless of whether they are computed within each instance or based on a mini-batch, they can only represent the distribution of training data. The affine transformation parameters, i.e., $\\gamma$ and $\\beta$, are also learned for source data only. Therefore, a normalization layer's parameters are not guaranteed to work well under domain shift in unseen test data. It would be a promising direction to investigate how to make these parameters adaptive to unseen domains~.", "cites": [5119, 675, 57, 156, 150, 5120, 8377, 71], "cite_extract_rate": 1.0, "origin_cites_number": 8, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.5, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section synthesizes information from multiple papers on dynamic architectures and adaptive normalization, connecting them to the broader challenge of domain shift in domain generalization. It abstracts these methods into general design principles (e.g., input-conditioned parameters, adaptiveness of normalization layers) and critically highlights limitations, such as the rigidity of standard normalization layers and the potential inefficiency of overly flexible models. While not offering a novel framework, it provides a thoughtful analytical perspective on promising architectural directions."}}
{"id": "5b953645-d00e-4174-82f6-398952ef9388", "title": "Learning", "level": "subsection", "subsections": [], "parent_id": "3f5d2bd7-1caf-4610-b596-2794f2035e45", "prefix_titles": [["title", "Domain Generalization: A Survey"], ["section", "Future Research Directions"], ["subsection", "Learning"]], "content": "\\label{sec:futdir;subsec:learning}\n\\keypoint{Learning without Domain Labels}\nMost existing methods leveraged domain labels in their models. However, in real-world applications it is possible that domain labels are difficult to obtain, e.g., web images crawled from the Internet are taken by arbitrary users with arbitrary domain characteristics and thus the domain labels are extremely difficult to define~. In such scenarios where domain labels are missing, many top-performing DG approaches are not viable any more or the performance deteriorates~. Though this topic has been studied in the past (e.g.,~), methods that can deal with the absence of domain labels are still scarce and noncompetitive with methods that utilize domain labels. Considering that learning without domain labels is much more efficient and scalable, we encourage more future work to tackle this topic. We also suggest future work that uses domain labels evaluate the ability of functioning without proper domain labels---if applicable---like the random grouping experiment done in~.\n\\keypoint{Learning to Synthesize Novel Domains}\nThe DG performance can greatly benefit from increasing the diversity of source domains. This is also confirmed in a recent work~ where the authors emphasized the importance of having diverse training distributions to out-of-distribution (OOD) generalization. However, in practice it is impossible to collect training data that cover all possible domains. As such, learning to synthesize novel domains can be a potential solution. Though this idea has been roughly explored in a couple of recent DG works~, the results still have much room for improvements.\n\\keypoint{Avoiding Learning Shortcut}\nShortcut learning can be interpreted as a problem of learning ``easy'' representations that can perform well on training data but are irrelevant to the task~. For example, given the task of distinguishing between digits blended with different colors, a neural network might be biased toward recognizing colors rather than the digit shapes during training, thus leading to poor generalization on unseen data~. Such a problem can be intensified on multi-source data in DG as each source domain typically contains its own domain-specific bias. As a consequence, a DG model might simply learn to memorize the domain-specific biases, such as image styles~, when tasked to differentiate between instances from different domains. The shortcut learning problem has been overlooked in DG.\n\\keypoint{Causal Representation Learning}\nCurrently, the common pipeline used in DG, as well as in many other fields, for representation learning is to learn a mapping $P(Y|X)$ by sampling data from the marginal distribution $P(X)$ with an objective to match the joint distribution $P(X,Y) = P(Y|X)P(X)$ (typically via maximum likelihood optimization). However, the learned representations have turned out to be lacking in the ability to adapt to OOD data~. A potential solution is to model the underlying causal variables (e.g., by autoencoder~) which cannot be directly observed but are much more stable and robust under distribution shift. This is closely related to the topic of causal representation learning, a recent trend in the machine learning community~.\n\\keypoint{Exploiting Side Information}\nSide information (sometimes called meta-data) has been commonly used to boost the performance of a pattern recognition system. For example, depth information obtained from RGB-D sensors can be used alongside RGB images to improve the performance of, e.g., generic object detection~ or human detection~. In DG, there exist a few works that utilize side information, such as attribute labels~ or object segmentation masks~. In terms of attributes, they could be more generalizable because they capture mid- to low-level visual cues like colors, shapes and stripes, which are shared among different objects and less sensitive to domain biases~. Notably, attributes have been widely used in zero-shot learning to recognize unseen classes~. In contrast, features learned for discrimination are usually too specific to objects, such as dog ears and human faces as found in top-layer CNN features~, which are more likely to capture domain biases and hence less transferable between tasks~.\n\\keypoint{Transfer Learning}\nA couple of recent works~ have focused on the transfer learning perspective when designing DG methods for synthetic-to-real applications. Given a model pre-trained on large real datasets like ImageNet~, the main goal is to learn new knowledge that is useful to the downstream task from synthetic data, and in the meantime, to maintain the knowledge on real images that was acquired from pre-training. Such a setting is closely related to learning-without-forgetting (LwF)~. In particular, a technique used in~ was borrowed from LwF~, i.e., minimizing the divergence between the new model's output and the old model's output to avoid erasing the pre-trained knowledge. Synthetic-to-real transfer learning is a realistic and practical setting but research in this direction has been less explored for DG.\n\\keypoint{Semi-Supervised Domain Generalization}\nMost existing DG research assumes data collected from each source domain are fully annotated so the proposed methods are purely based on supervised learning, which are unable to cope with unlabeled data. However, in practice the size of labeled data could well be limited due to high annotation cost, but collecting abundant unlabeled data is much easier and cheaper. This leads to a more realistic and practical setting termed semi-supervised domain generalization~, which has recently picked up attention from the DG community. In~, pseudo-labels are assigned to unlabeled source data and an off-the-shelf style transfer model is used to augment the domain space. In~, feature statistics are mixed between labeled and pseudo-labeled source data for data augmentation. Since designing data-efficient, and yet generalizable learning systems is essential for practical applications, we believe semi-supervised domain generalizable is worth investigating for future work.\n\\keypoint{Open Domain Generalization}\nis a recently introduced problem setting~ where a model is learned from heterogeneous source domains with different label sets (with overlaps) and deployed in unseen domains for recognizing known classes while being able to reject unknown classes. This problem setting is related to existing heterogeneous DG~ but focuses on classification applications and emphasizes the ability to detect (reject) unknown classes, which is often studied in open-set recognition~. In~, a variant of Mixup~ is proposed for data augmentation at both feature and label level, and a confidence threshold is used to reject test samples that likely belong to unknown classes.", "cites": [5123, 2713, 8585, 3013, 5121, 5124, 499, 5122, 4415, 2703, 5126, 2707, 5062, 8589, 3202, 7191, 5106, 2762, 2793, 629, 1597, 4944, 7889, 6983, 5125, 2746, 2684, 2699, 2711], "cite_extract_rate": 0.8787878787878788, "origin_cites_number": 33, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.5, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section demonstrates strong synthesis by integrating multiple papers under key themes like causal learning, semi-supervised DG, and open-set DG. It provides critical analysis by highlighting limitations, such as the lack of methods for learning without domain labels and the underperformance of synthesized domain approaches. The abstraction is high, as it identifies broader trends like shortcut learning, the role of domain diversity, and the importance of causal representations in generalization."}}
{"id": "ce8173de-f689-4f92-8486-a2d5061e6a92", "title": "Benchmarks", "level": "subsection", "subsections": [], "parent_id": "3f5d2bd7-1caf-4610-b596-2794f2035e45", "prefix_titles": [["title", "Domain Generalization: A Survey"], ["section", "Future Research Directions"], ["subsection", "Benchmarks"]], "content": "\\label{sec:futdir;subsec:benchmarks}\n\\keypoint{Incremental Learning + DG}\nMost existing research on DG implicitly assumes that source domains are fixed and a model needs to be learned only once. However, in practice, it might well be the case that source domains are incrementally introduced, thus requiring incremental learning~. For instance, in cross-dataset person re-identification we might well have access to, say only two datasets at the beginning for model learning, e.g.,~Market1501~ and DukeMTMC-reID~, but later another dataset comes in, e.g.,~CUHK03~, which increases the number of source datasets from two to three. In this case, several problems need to be addressed, such as \\romannum{1}) how to efficiently fine-tune the model on the new dataset without training from scratch using all available datasets, \\romannum{2}) how to make sure the model does not over-fit the new dataset and forget the previously learned knowledge, and \\romannum{3}) will the new dataset be beneficial or detrimental to the DG performance on the target domain.\n\\keypoint{Heterogeneous Domain Shift}\nThe current DG datasets mainly contain homogeneous domain shift, which means the source-source and source-target shifts are highly correlated with each other. For example, on PACS~ the source-source domain shift and the source-target domain shift are both related to image style changes; on Rotated MNIST~ rotation is the only cause of domain shift. However, in real-world scenarios the target domain shift is unpredictable and less likely to be correlated with the source domain shift, e.g., the source domains might be photo, art and sketch but the target domain might be images of novel viewpoints; or the source domains contain digit images with different rotations but the target domain images might be in a different font style or background. Such a setting, which we call heterogeneous domain shift, has never been brought up but is critical to practical applications.", "cites": [8588, 5075, 2684, 5127], "cite_extract_rate": 0.6666666666666666, "origin_cites_number": 6, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.0, "critical": 3.5, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section provides a thoughtful analysis of current limitations in DG benchmarks, particularly addressing the lack of consideration for incremental learning and heterogeneous domain shifts. It synthesizes concepts from the cited works to frame these issues in a broader context. The critical evaluation of benchmark assumptions and the abstraction to a conceptual 'heterogeneous domain shift' setting demonstrate a strong analytical perspective."}}
