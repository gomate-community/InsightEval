{"id": "bda39eab-e9c6-47ab-8897-26d79998749b", "title": "Introduction", "level": "section", "subsections": [], "parent_id": "42e77c1c-0c8b-4e28-9d53-60920d7558be", "prefix_titles": [["title", "From Distributed Machine Learning to Federated Learning: A Survey"], ["section", "Introduction"]], "content": "With billions of connected Internet of Things (IoT) devices , smartphones  and large websites around the world, in recent years, we have witnessed huge amounts of data generated and dispersed over various mobile devices of end users, or the data centers of different organizations. As the data contain sensitive information of end users or organizations, such as facial images, location-based services, health information , or personal economic status, moving the raw data from personal devices or data centers of multiple organizations to a centralized server or data center may pose immediate or potential information leakage. Due to the concerns of data security and data privacy, legal restrictions, such as the Cybersecurity Law of the Peopleâ€™s Republic (CLPR) of China , the General Data Protection Regulation (GDPR)  in European Union, the Personal Data Protection Act (PDP)  in Singapore, the California Consumer Privacy Act (CCPA) , and the Consumer Privacy Bill of Rights (CPBR)  in the United States, have been introduced and put in practice, which makes data aggregation from distributed devices, multiple regions, or organizations, almost impossible . In addition, computing and storage resources are also typically distributed in multiple regions  and organizations , which cannot be aggregated in a single data center.\nFederated Learning (FL) emerges as an efficient approach to exploit the distributed resources to collaboratively train a machine learning model. FL is a distributed machine learning approach where multiple users collaboratively train a model, while keeping the raw data decentralized without being moved to a single server or data center .\nFL not only exploits the distributed resources to efficiently carry out the training process of machine learning, but also promises to provide security and privacy for the decentralized raw data. Within FL, the raw data, or the data generated based on the raw data with security processing, serves as the training data. FL only allows the intermediate data to be transferred among the distributed computing resources while avoiding the transfer of training data. \nThe distributed computing resources refer to mobile devices of end users or servers of multiple organizations.\nFL brings the code to the data, instead of bringing the data to the code, and it addresses the fundamental problems of privacy, ownership, and locality of data .\nIn this way, FL can enable multiple users to train a model while satisfying the legal data restrictions.\nTraditional centralized machine learning approaches typically gather the distributed raw data generated on different devices or organizations to a single server or a cluster with shared data storage, which may bring serious data privacy and security concerns . \nThe centralized approaches, in general, are associated with diverse challenges, including computational power and training time, and most importantly, security and privacy with respect to distributed data .\nFL differs from the centralized approach in three aspects. First, FL does not allow direct raw data communication, while the centralized approach has no restriction. Second, FL exploits the distributed computing resources in multiple regions or organizations, while the centralized approach generally only utilizes a single server or a cluster in a single region, which belongs to a single organization. Third, FL generally takes advantage of encryption or other defense techniques to ensure the data privacy or security, while the centralized approach pays little attention to these security issues .\nThe term ``federated learning'' was first introduced in 2016 , which focuses on the unbalanced and non-Independent and Identically Distributed (non-IID) data in mobile devices. \nThe concept of FL was extended to three data scenarios, i.e., horizontal, vertical, and hybrid . \nThe horizontal FL addresses the decentralized data of the same features, while the identifications are different. The vertical FL handles the decentralized data of the same identifications with different features. The hybrid FL deals with the data of different identifications and different features. Then, FL is formally defined as a machine learning approach where multiple clients collaborate in solving a machine learning problem while the raw data is stored locally and is neither exchanged nor transferred . \nAn FL system is an efficient tool to carry out FL with decentralized data and resources. Several open-source FL systems, e.g., FATE , PaddleFL , TensorflowFL , and Pysyft , are now intensively used by both research communities, e.g., healthcare , and computer visions , and by industrial groups, e.g., WeBank . Although various FL systems exist, the architecture of FL systems has common features: In particular, they share the capability to collaboratively train a machine learning model. Most FL systems are composed of four layers, i.e., presentation, user services, FL training, and infrastructure. These four layers enable FL system users to design, execute, and analyze machine learning models with distributed data.\nAlthough FL differs from the centralized machine learning approaches, it not only utilizes novel techniques designed for FL, but also takes advantage of the techniques designed for distributed machine learning. \nFL exploits parallelization techniques designed for distributed machine learning.\nFor instance, horizontal FL exploits the data parallelism, which trains multiple instances of the same model on different subsets of the training dataset . Vertical FL utilizes model parallelism to distribute parallel paths of a single model to multiple devices in order to handle the data of different features  . \nMultiple aggregation algorithms  are proposed to aggregate the models in distributed computing resources.\nData transfer techniques are also utilized in FL, e.g., model compression . \nAs FL promises to provide data security and data privacy, diverse defense techniques, e.g., differential privacy , homomorphic encryption , and Robustness Aggregation , are designed to address the possible attacks .\nThere have been a few surveys of FL. Some works  provide a comprehensive study of FL, from the taxonomy of FL to the techniques, e.g., the efficiency, data privacy, security, and applications of FL. Some surveys  focus on the data privacy and security of FL. Other surveys present the application of FL in a specific area, e.g., healthcare informatics , mobile edge networks , and neural architecture searches , and they personalize global models to work better for individual clients . However, few of them present the architecture of FL or analyze parallelization techniques in FL.\nIn this paper, we provide a survey of federated learning and the related parallelization techniques. The main contributions of this paper are:\n\\begin{itemize}\n    \\item A four-layer FL system architecture, which is useful for discussing the techniques for FL. This architecture can also be a baseline for other work and can help with the assessment and comparison of FL systems.\n    \\item A taxonomy of FL-related techniques, including the parallelization techniques, the aggregation algorithms, and the techniques for data communication and security, with a comparative analysis of the existing solutions.\n    \\item A discussion of research issues to improve the efficiency and security of FL systems.\n\\end{itemize}\nThis paper is organized as follows. Section \\ref{sec:overview} gives an overview of the execution of FL, including the FL system architectures and basic functional architecture of FL systems. Section \\ref{sec:pexec} focuses on the techniques used for distributed training of FL and aggregation methods. Section \\ref{sec:security} presents the techniques for distributed execution, data communication and data security of FL. Section \\ref{sec:frameworks} demonstrates the existing FL frameworks.\nSection \\ref{sec:future} discusses the open issues raised for the execution of FL with distributed resources. Section \\ref{sec:con} summarizes the main findings of this study.", "cites": [3469, 1315, 5419, 3477, 591, 8917, 659, 5422, 5423, 1311, 5424, 671, 627, 5420, 600, 582, 5421], "cite_extract_rate": 0.4722222222222222, "origin_cites_number": 36, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.5, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section synthesizes insights from multiple cited papers to establish a clear narrative on the evolution from distributed machine learning to federated learning. It abstracts key concepts such as FL architecture, parallelization types, and security mechanisms, integrating them into a structured overview. The section also identifies gaps in existing surveys and positions its contributions critically in relation to the literature."}}
{"id": "4f50be54-11aa-4ae8-ae5e-fb6d0e6797e6", "title": "Basic Concepts", "level": "subsection", "subsections": [], "parent_id": "2371347b-6739-4c7c-b6c1-b23b3b02d8ed", "prefix_titles": [["title", "From Distributed Machine Learning to Federated Learning: A Survey"], ["section", "An Overview of Federated Learning"], ["subsection", "Basic Concepts"]], "content": "Machine learning is the process to automatically extract the models or patterns from data . \nThe models or patterns are expressed as machine learning models.\nA machine learning model is an ensemble of a model structure, which is typically expressed as a Directed Acyclic Graph (DAG), data processing units, e.g., activation functions in Deep Neural Networks (DNNs), and the associated parameters or hyper-parameters. \nThe input data can be processed through a machine learning model to generate the output, e.g., the prediction results or the classification results, which is the inference process.\nThe machine learning model is generated based on the training data, which is the training process.\nDuring the training process, the parameters or the model structure of the machine learning model  is adjusted based on a training algorithm in order to improve the performance, e.g., the accuracy or the generalization capacity. The training algorithm is also denoted by machine learning algorithms. The duration of the training process is training time.\nAccording to whether the training data have labels, the training process of machine learning can be classified into four types , i.e., supervised learning, unsupervised learning, semi-supervised learning, and reinforcement learning. Supervised learning represents that a machine learning task exploits the training data composed of input features and the corresponding labels . In this paper, we focus on this type of training data. For instance, each data point in the training dataset contains $(x,y)$, where $x$ represents the input features and $y$ represents the desired output value. Unsupervised learning represents that a machine learning task exploits the training data, which only consists of input features without output values; i.e., each data point only contains $x$ and does not have $y$. Semi-supervised learning represents that one (generally small) part of the training data contains output values, while the other (generally small) part of the training does not. Reinforcement learning represents that each iteration in the training process considers its observation of the environment from the last iteration. \nWhile the training data become huge, e.g., on the order of terabyte , or when the training data is inherently distributed or too big to store on single machines , the training process is carried out using distributed resources, which is distributed machine learning. One of the important features of the distributed machine learning is that it can significantly accelerate the training speed so as to reduce the training time. Diverse parallelization techniques are used in distributed machine learning. For instance, Graphics Processing Units (GPUs) using Single Instruction Multiple Data (SIMD)  and Tensor Processing Units (TPUs) using Multiple Instructions Multiple Data (MIMD)  are exploited . In addition, distributed machine learning takes advantage of three types of parallelism to parallelize the training process, i.e., data parallelism , model parallelism , and pipeline parallelism  . With the data parallelism approach, the training data is partitioned as many times as the number of computing resources, and all computing resources subsequently apply the same machine learning algorithm to process different chunks of the data sets . With the model parallelism approach, exact copies of the entirety of the data (the training data or the intermediate data)\nare processed by each computing resource, each of which exploits different parts of the machine learning model . The pipeline parallelism approach combines the data parallelism and the model parallelism. With this approach, each computing resource processes a part of the training data with a part of the machine learning model, while the processing, e.g., computation or communication, at each node can be parallelized . \nFL is a distributed machine learning approach where multiple users collaboratively train a model, while keeping the raw data distributed without being moved to a single server or data center .\nThe model used for FL is denoted by FL model.\nFL is first proposed to handle the unbalanced and non-Independent and Identically Distributed (non-IID) data of the same features in mobile devices .\nThen, the concept of FL is extended to the distributed data of diverse features in multiple organizations  or various regions .\nFL systems are used within one or multiple phases of the life cycle of FL models. An FL system is a distributed system to manage the distributed training process with distributed resources.\nFL is a special type of distributed machine learning, which differs from other distributed machine learning approaches in the following three points.\nFirst, FL does not allow direct raw data communication, while other approaches have no restriction. \nAs the raw data are of multiple ownerships, FL approaches with this restriction can meet the requirements defined by the related laws, e.g., CLPR , GDPR , PDPA , CCPA , and CPBR .\nIn particular, the consent (GDPR Article 6) and the data minimalization principle (GDPR Article 5) limit data collection and storage to only what is consumer-consented and what is absolutely necessary for processing .\nSecond, FL exploits the distributed computing resources in multiple regions or organizations, while the other approaches generally only utilize a single server or a cluster in a single region, which belongs to a single organization. FL enables the collaboration among multiple organizations.\nThird, FL generally takes advantage of encryption or other defense techniques to ensure the data privacy or security, while the other approaches pay little attention to this security issue . FL promises to ensure the privacy and security of the raw data, as the leakage of information may incur significant financial  and reputational  losses. \nDuring the training process of FL, an optimization problem is solved as shown in Formula \\ref{eq:problem}. Given $n$ training dataset $\\mathcal{D} = {D_1, D_2, ..., D_n}$, where each data point $(x,y)\\sim\\mathcal{D}$, the problem of FL is to learn a function $\\widehat F$ from all possible hypotheses $\\mathcal{H}$, while minimizing the expectation of loss over the distribution of all the dataset $\\mathcal{D}$. \n\\begin{equation}\n\\label{eq:problem}\n    \\widehat F = \\underset{F\\in\\mathcal{H}}{\\mathrm{argmin}} \\underset{(x,y)\\in\\mathcal{D}}{\\mathbb{E}} L(y, F(x)),\n\\end{equation}\nwhere $L(y, F(x))$ refers to the loss of $F(x)$ to the label $y$. \nDuring the training process, the Stochastic Gradient Descent (SGD) approach  is generally used to minimize the loss function using Formula \\ref{eq:gd}.\n\\begin{equation}\n\\label{eq:gd}\n    F_{k+1}(x)\\gets F_k(x) - \\eta_k \\nabla F_k(x),\n\\end{equation}\nwhere $F_k(x)$ refers to the learned model in the $k^{th}$ iteration,  $\\nabla F_k(x)$ refers to the gradient of the model at the $k^{th}$ iteration based on the model already obtained $F_k(x)$ and the training dataset, $\\eta_k$ refers to the learning rate, and $F_{k+1}(x)$ refers to the update model of the $k^{th}$ iteration. Within each iteration, there are two phases, i.e., forward propagation and backward propagation. The forward propagation calculates the output based on the input data $x$ using the model, while the backward propagation calculates the gradients $\\nabla F_k(x)$ and updates the model.\nWhen the calculation is distributed among multiple computing resources, the gradients or models of each computing resource are aggregated using an aggregation algorithm (see details in Section \\ref{sebsec:aggre}), in order to achieve consensus of multiple models and to generate a global model. \\liu{The learning rate can be dynamically adapted using a local adaptive optimizer, e.g., Adam, and/or cross-round learning rate schedulers .}", "cites": [1315, 591, 5426, 659, 5425, 671, 600, 166, 582], "cite_extract_rate": 0.37037037037037035, "origin_cites_number": 27, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.5, "critical": 2.0, "abstraction": 2.5}, "insight_level": "medium", "analysis": "The section provides a clear and factual overview of basic concepts in federated learning and distributed machine learning, drawing from multiple cited papers. However, it lacks deep synthesis of ideas across sources and primarily serves as a descriptive summary. Some abstraction is attempted, particularly in distinguishing FL from other distributed learning methods, but the analysis remains limited and does not offer a novel framework or critical evaluation."}}
{"id": "cd1b4108-9163-49ab-bfbc-9fe67cc3a340", "title": "FL Model Life Cycle", "level": "subsection", "subsections": [], "parent_id": "2371347b-6739-4c7c-b6c1-b23b3b02d8ed", "prefix_titles": [["title", "From Distributed Machine Learning to Federated Learning: A Survey"], ["section", "An Overview of Federated Learning"], ["subsection", "FL Model Life Cycle"]], "content": "The life cycle of an FL model is a description of the state transitions of an FL model from creation to completion . Lo \\textit{et al.}  propose that the life cycle of an FL model consists of 8 phases: initiated, broadcast, trained, transmitted, aggregated, evaluated, deployed, and monitored. Kairouz \\textit{et al.}  propose that the life cycle of an FL model includes 6 phases: problem identification, client instrumentation, simulation prototyping, federated model training, model evaluation, and deployment. However, they focus on the FL with distributed data in mobile devices. In this paper, we adopt a combination of workflow life cycle views  with a few variations , condensed into four phases:\n\\begin{enumerate}\n    \\item The composition phase  is for the creation of an FL model, which is used to address a specific machine learning problem, e.g., classification. First, a machine learning model is created to address the problem with certain requirements, e.g., the requirement of accuracy. Then, the machine learning model is adapted to FL scenarios. For instance, if the distributed data is of different features, the machine learning model is partitioned (see details in Section \\ref{subsubsec:modelP}) to process the distributed data. \n    \\item The FL training phase  is for the training phase of the FL model. During this phase, a training strategy, which includes parallelism and aggregation algorithms (see details in Section \\ref{sec:pexec}), is used to update the parameters, hyper parameters, and even the structure of the network, in order to improve the accuracy and the generalization capacity of the FL model.  \n    \\item The FL model evaluation phase  is to apply the trained FL models, in order to analyze the performance of the trained FL models on a simulation platform or a real distributed system . As a result, the FL models with the best performance are selected. If the FL models do not meet the requirements, the FL model should be modified, or the training phase should be carried out again.\n    \\item The FL model deployment phase  is to deploy the FL model in a real-life scenario to process the data. If the final model can be shared without restriction, there is no difference between the FL model deployment and the model generated from a traditional centralized approach. Otherwise, the deployment of the final model should consider the ownership of the corresponding parts. \n\\end{enumerate}", "cites": [591, 612, 671, 5427], "cite_extract_rate": 0.8, "origin_cites_number": 5, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.0, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section synthesizes and integrates multiple life cycle models from cited papers (Lo et al. and Kairouz et al.), creating a condensed and coherent four-phase framework. It critically evaluates the focus and scope of the existing models, particularly noting Kairouz et al.'s emphasis on mobile devices. The abstraction is strong as it generalizes the model life cycle across FL scenarios, highlighting adaptations needed for real-world deployment and privacy considerations."}}
{"id": "afff657f-2ca3-4a0d-b609-6427f5eee76c", "title": "Presentation Layer", "level": "subsubsection", "subsections": [], "parent_id": "78f72b80-7c28-4237-9e16-d97c8c144603", "prefix_titles": [["title", "From Distributed Machine Learning to Federated Learning: A Survey"], ["section", "An Overview of Federated Learning"], ["subsection", "Functional Architecture of FL Systems"], ["subsubsection", "Presentation Layer"]], "content": "The presentation layer is a User Interface (UI) for the interaction between Users and FL systems at one or multiple stages of the FL model life cycle. The UI can be textual or graphical. This interface is responsible for designing a new FL model or choosing an existing machine learning model as an FL model. In addition, this layer also supports the modules at the user services layer, e.g., shows the status of the distributed training process. The textual UI is largely used for designing FL models \\liu{based on the command line or scripts }. The models can be directly expressed using Python, with the textual interface in PaddleFL , TensorFlowFL , PySyft , and FATE . A graphic UI can make the interaction more practical, while the users can drag or drop the data processing element to design an FL model. For instance, FATE  provides a Graphic UI (GUI) through a web portal. However, the graphic portal also exploits textual programming languages as inner representations of an FL model.", "cites": [656], "cite_extract_rate": 0.2, "origin_cites_number": 5, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.5, "critical": 2.0, "abstraction": 2.0}, "insight_level": "medium", "analysis": "The section provides a basic overview of the presentation layer in FL systems, integrating a few examples from cited frameworks. However, it lacks deeper synthesis of ideas and critical evaluation of the cited works. While it mentions the use of textual and graphical UIs, the discussion remains at a surface level without identifying broader trends or principles in the field."}}
{"id": "8ca8a082-7841-461b-ad59-49e7d8fef8fe", "title": "User Services Layer", "level": "subsubsection", "subsections": [], "parent_id": "78f72b80-7c28-4237-9e16-d97c8c144603", "prefix_titles": [["title", "From Distributed Machine Learning to Federated Learning: A Survey"], ["section", "An Overview of Federated Learning"], ["subsection", "Functional Architecture of FL Systems"], ["subsubsection", "User Services Layer"]], "content": "The user service layer supports the expected functionalities, i.e., \\liu{monitoring and steering and log; interpretability and explainability; and graph data.} The monitoring enables the users to get the real-time status of the distributed training process. As the training process of FL models can be very long, e.g., from several hours to days , it is of much importance to track the execution status, which allows the user to verify whether the training proceeds normally. The log service is generally supported by major FL systems, which can be used to analyze the training process. In addition, the log generated during the training process can be used to debug the system or adjust the FL model. FATE provides a visual monitoring board to users through its GUI. When there are unexpected results or errors during the training process, steering enables users to adjust the training process in order to reduce the time necessary to carry out the distributed training from scratch. Most FL systems can enable the users to stop the training, while the adjustment of parameters is not fully supported by major FL systems. The interpretability of FL is to describe the internals of an FL system in a way that is understandable to humans . The explainability focuses on explaining the representation of data inside an FL model . With interpretability and explainability, the FL system can \\liu{provide} a description of the results of the trained FL model based on the training data and the distributed training process. Shapley values have been used to provide the interpretability , while both the interpretability and explainability remain open challenges as each is hard to fully support. \n\\liu{In the real world, graph data widely exist in multiple domains, and a bunch of FL approaches have been proposed to handle the decentralized graph data for community detection , financial crime , and especially knowledge graph completion .\nFL is particularly useful in the field of knowledge graph completion, as a knowledge graph could not only contain text but also images or other type of data, i.e., multimodal Knowledge Graphs ; and the completion is realized in a collaborative fashion within an FL system .\nThe decentralized graphs can be inter-graph, i.e., the decentralized data belongs to multiple graphs, or intra-graph, i.e., the decentralized data is within one big graph , while most of the existing works focus on the intra-graph situation.\nHorizontal FL techniques can be exploited on the Graph Neural Networks (GNN)  with encryption techniques  (see details in Section \\ref{subsubsec:infrastructure}) while the performance of FL may be much worse than that of centralized GNNs .\nThe aggregation algorithms (see details in Section \\ref{subsubsec:centralized}) are also proposed based on the FedAvg  or optimal transportation . \nIn addition, decentralized aggregation algorithms (see details in Section \\ref{subsubsec:decentralized}) are also proposed to deal with the decentralized graph data for social network  and drug discovery .\nWhile the fine-tuning of the FL system is time-consuming, Bayesian optimization  and evolutionary optimization strategies  are utilized to automatically tune the hyper-parameters and the network structure, respectively.  \nGraph data can be vertically distributed where the features of the nodes are distributed across multiple data owners, and a data owner may or may not have the edges. Vertical FL exploits embeddings  or autoencoders  to represent the nodes, which can be transferred to train a GNN. In addition, the differential privacy (see details in Section \\ref{subsubsec:infrastructure}) is combined with the embeddings to protect the data privacy  of knowledge graphs. }", "cites": [5429, 591, 5434, 8918, 5437, 5435, 5433, 5432, 7927, 5428, 5430, 7926, 8502, 5436, 5438, 5431], "cite_extract_rate": 0.8888888888888888, "origin_cites_number": 18, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.2, "critical": 3.5, "abstraction": 3.8}, "insight_level": "high", "analysis": "The section synthesizes multiple papers to present a structured view of the user services layer in FL systems, particularly focusing on graph data and interpretability. It connects different aspects such as monitoring, steering, logging, and explainability across various FL frameworks, and highlights open challenges. The critical analysis is evident in pointing out limitations like incomplete parameter adjustment support and performance trade-offs, and it abstracts to broader patterns such as the handling of intra vs. inter-graph data in FL."}}
{"id": "6af71683-cb7e-4e75-87a8-c21ef2982fdc", "title": "FL Training Layer", "level": "subsubsection", "subsections": [], "parent_id": "78f72b80-7c28-4237-9e16-d97c8c144603", "prefix_titles": [["title", "From Distributed Machine Learning to Federated Learning: A Survey"], ["section", "An Overview of Federated Learning"], ["subsection", "Functional Architecture of FL Systems"], ["subsubsection", "FL Training Layer"]], "content": "The FL training layer carries out the distributed training process with distributed data and computing resources. This layer consists of three modules: parallelization, scheduling, and fault-tolerance. FL parallelization exploits diverse types of parallelism, e.g., data parallelism, model parallelism, and pipeline parallelism, to generate executable tasks. Through the FL scheduling module, an FL system produces a Scheduling Plan (SP) of executable tasks, which aims at fully exploiting distributed computing resources and preventing training stalling. During the training process, the SP is generally defined by a training algorithm, which aggregates the updates, i.e., gradients or models, from each computing resource in order to generate a final machine learning model. The FL fault-tolerance mechanism handles the failures or errors of task execution and the connection of distributed resources. Reactive approaches are generally exploited, e.g., using check-points, restart, and task replication . A reactive approach reduces the effect of failures after perceiving failures . An FLEP, which captures the execution directives, typically the result of compiling and optimizing the training process of FL models, is generated at this layer.", "cites": [590], "cite_extract_rate": 0.5, "origin_cites_number": 2, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.5, "critical": 2.0, "abstraction": 2.0}, "insight_level": "medium", "analysis": "The section provides a descriptive overview of the FL training layer, mentioning its three modules and some techniques. It integrates basic ideas from the cited paper (e.g., scalability and task scheduling), but lacks deeper synthesis with other sources or a broader framework. There is minimal critical analysis or abstraction beyond specific system components."}}
{"id": "cfb855a7-c817-4897-9235-30d180850302", "title": "Infrastructure Layer", "level": "subsubsection", "subsections": [], "parent_id": "78f72b80-7c28-4237-9e16-d97c8c144603", "prefix_titles": [["title", "From Distributed Machine Learning to Federated Learning: A Survey"], ["section", "An Overview of Federated Learning"], ["subsection", "Functional Architecture of FL Systems"], ["subsubsection", "Infrastructure Layer"]], "content": "\\label{subsubsec:infrastructure}\nThe infrastructure layer provides the interaction between an FL system and the distributed resources, including the computing resources, storage resources, network resources, and data resources. This layer contains three modules: a data security module, a data transfer module, and a distributed execution module. The data security module generally exploits Differential Privacy (DP)  and encryption techniques, e.g., homomorphic , to protect the raw data used during the training process. Although the raw data cannot be directly transferred, intermediate data, e.g., the gradients or models, can be communicated among distributed computing resources. The data transfer module exploits data compression techniques  to improve the data transfer efficiency. \nAt this layer, the FLEP generated at the FL training layer is carried out within the distributed execution module; i.e., concrete tasks are executed in distributed computing resources.", "cites": [617, 7608], "cite_extract_rate": 0.6666666666666666, "origin_cites_number": 3, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 1.5, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section provides a basic descriptive overview of the infrastructure layer in federated learning systems, mentioning techniques like differential privacy and data compression. However, it integrates cited papers minimally, lacks critical evaluation of their approaches, and offers limited abstraction beyond the specific functions described."}}
{"id": "9be6bb25-a2cc-4134-abfd-4e31f8d8b0b1", "title": "Parallelism \\& FL Types", "level": "subsection", "subsections": ["0430fcfa-cd31-4b1c-bf51-10d342c0d942", "62c91cb4-aacb-47de-82b2-8f4949518fdc", "1b1418f9-bcb1-4bbe-b99b-80b182bd318e"], "parent_id": "5dfeced7-075b-4276-abd0-1ff3e9bb48a7", "prefix_titles": [["title", "From Distributed Machine Learning to Federated Learning: A Survey"], ["section", "Distributed Training"], ["subsection", "Parallelism \\& FL Types"]], "content": "Three types of parallelism exist for distributed machine learning: data parallelism, model parallelism, and pipeline parallelism . FL can be classified to three types, i.e., horizontal, vertical, and hybrid . The horizontal FL generally exploits data parallelism, and the vertical FL typically takes advantage of model parallelism. However, the hybrid FL relies on transfer learning , which is not a parallelism approach and is out of the scope of this paper. \n\\begin{figure}[htbp]\n    \\centering\n    \\includegraphics[width=0.65\\textwidth]{figures/dnn.pdf}\n    \\caption{An example of a neural network.}\n    \\label{fig:dnn}\n\\end{figure}\nIn this section, we take an example of a neural network as shown in Figure \\ref{fig:dnn} to explain the parallelism. In the example, we assume that the model contains three layers and seven data processing nodes (neurons), i.e., $A_1$, $A_2$, $B_1$, $B_2$, $B_3$, $C_1$, $C_2$, $D$. The arrows represent the data flow among different data processing nodes. The execution of the data processing nodes at each layer can be carried out in parallel, while the execution of different layers should be performed sequentially. The input data contains 4 data points. We assume two/three computing resources owned by two/three users. Each has a part of the input data.\n\\begin{figure}[htbp]\n    \\centering\n    \\includegraphics[width=0.6\\textwidth]{figures/datap.pdf}\n    \\caption{Data parallelism. The forward and backward process of $I^1$ and $I^2$ is performed in computing resource 1, while that of $I^3$ and $I^4$ is performed in computing resource 2 at the same time. Then the model or gradient is transferred to calculate an average model or gradient to be sent to each computing resource for the following training.}\n    \\label{fig:datap}\n\\end{figure}", "cites": [600, 1315, 671], "cite_extract_rate": 0.6, "origin_cites_number": 5, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.5, "critical": 2.0, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section provides a basic description of parallelism types in distributed machine learning and their relation to federated learning (FL) types. While it integrates some concepts from cited papers, such as horizontal and vertical FL, the synthesis is minimal and primarily serves to categorize rather than to connect deeper insights. There is little critical evaluation or abstraction beyond specific examples."}}
{"id": "0430fcfa-cd31-4b1c-bf51-10d342c0d942", "title": "Data Parallelism", "level": "subsubsection", "subsections": [], "parent_id": "9be6bb25-a2cc-4134-abfd-4e31f8d8b0b1", "prefix_titles": [["title", "From Distributed Machine Learning to Federated Learning: A Survey"], ["section", "Distributed Training"], ["subsection", "Parallelism \\& FL Types"], ["subsubsection", "Data Parallelism"]], "content": "Data parallelism is realized by having the data processing performed in parallel at different computing resources, with the same model, on different data points. As shown in Figure \\ref{fig:datap}, data parallelism is exploited when the ensemble of data points is distributed among different computing resources. During the training process of FL, the training data is not transferred among different computing resources, while the intermediate data, e.g., the models or the gradients $\\nabla F_k(x)$ in Formula \\ref{eq:gd}, are transferred. \nThe data in each computing resource can be Independent and Identically Distributed Data (IID) or non-IID. FL focuses on the non-IID , while other distributed machine learning approaches mainly focus on IID data. \nWith the data parallelism, the FL is horizontal , i.e., the data and the calculation are horizontally distributed among multiple computing resources.\nIn addition, this parallelism generally corresponds to the cross-device FL , where a large number of devices (mobiles or edge devices) collaboratively participate in training a single global model to have good accuracy.\nWhen the number of devices is small, e.g., 2-100, and the computing resources are from diverse organizations, this parallelism also corresponds to cross-silo FL . In addition to the general data-parallel schemes for federated learning, some specific privacy-preserved distributed statistical tricks have been invented for federated sparse models~.\n\\begin{figure}[htbp]\n    \\centering\n    \\includegraphics[width=0.75\\textwidth]{figures/modelp.pdf}\n    \\caption{Model parallelism. The dashed arrows represent inter-computing resource communication. For each input data point $I$, different parts, i.e., $I_{A_1}$ and $I_{A_2}$, are distributed at different computing resources.}\n    \\label{fig:modelp}\n\\end{figure}", "cites": [671, 582, 591], "cite_extract_rate": 0.6, "origin_cites_number": 5, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.5, "critical": 2.0, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section provides a basic descriptive overview of data parallelism in federated learning, integrating definitions and distinctions between FL and other distributed learning approaches from the cited papers. However, it lacks deeper synthesis of ideas across the sources and does not offer critical evaluation or significant abstraction beyond the surface-level explanation."}}
{"id": "62c91cb4-aacb-47de-82b2-8f4949518fdc", "title": "Model Parallelism", "level": "subsubsection", "subsections": [], "parent_id": "9be6bb25-a2cc-4134-abfd-4e31f8d8b0b1", "prefix_titles": [["title", "From Distributed Machine Learning to Federated Learning: A Survey"], ["section", "Distributed Training"], ["subsection", "Parallelism \\& FL Types"], ["subsubsection", "Model Parallelism"]], "content": "\\label{subsubsec:modelP}\nModel parallelism is realized by having independent data processing nodes distributed at different computing resources, so as to process the data points of specific features. \nTwo data processing nodes can be either independent, i.e., the execution of any node does not depend on the output of the other one; or dependent, i.e., there is a data dependency between them .\nAs shown in Figure \\ref{fig:modelp}, model parallelism is achieved when different parts of each data point are distributed at different computing resources. \nFor instance, the data process on Node $A_1$ and that of $A_2$ can be carried out in parallel.\nWith the model parallelism, vertical FL, where the data points and calculation are vertically distributed among multiple computing resources , is realized.\nIn this case, the original model needs to be partitioned to be distributed at different computing resources.\nTwo organizations generally apply this type of FL when each organization owns parts of the features of users and they would like to collaboratively train a model using the data of all the features, which corresponds to cross-silo FL .\nMost studies of vertical federated learning only support two parties (with or without a central coordinator) . \nFor instance, SecureGBM  is proposed to train a tree-based Gradient Boosting Machine (GBM).\nIn order to support multiple parties, the idea of multi-view learning  is exploited in a multi-participant, multi-class vertical federated learning framework .\n\\begin{figure}[htbp]\n    \\centering\n    \\includegraphics[width=0.7\\textwidth]{figures/pipelinep.pdf}\n    \\caption{Pipeline parallelism. The dashed arrows represent inter computing resource communication.}\n    \\label{fig:pipelinep}\n\\end{figure}", "cites": [600, 5439, 671, 668, 591], "cite_extract_rate": 0.625, "origin_cites_number": 8, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.5, "critical": 2.0, "abstraction": 2.5}, "insight_level": "medium", "analysis": "The section provides a descriptive overview of model parallelism in federated learning and links it to vertical FL, citing relevant papers. While it mentions limitations (e.g., most vertical FL studies support only two parties), it lacks deeper comparative or evaluative analysis of the cited approaches. Some abstraction is attempted, such as distinguishing between independent and dependent nodes, but the section remains largely focused on summarizing methods rather than offering a synthesized or meta-level understanding."}}
{"id": "1b1418f9-bcb1-4bbe-b99b-80b182bd318e", "title": "Pipeline Parallelism", "level": "subsubsection", "subsections": [], "parent_id": "9be6bb25-a2cc-4134-abfd-4e31f8d8b0b1", "prefix_titles": [["title", "From Distributed Machine Learning to Federated Learning: A Survey"], ["section", "Distributed Training"], ["subsection", "Parallelism \\& FL Types"], ["subsubsection", "Pipeline Parallelism"]], "content": "Pipeline parallelism is realized by having dependent data processing nodes distributed at different computing resources . As shown in Figure \\ref{fig:pipelinep}, the data processing nodes are distributed at multiple computing resources. While data point $I^3_A$ is processed in computing resource 1, the outputs of $A_1$ and $A_2$ are processed in computing resource 2, and the outputs of $B_1$, $B_2$, and $B_3$ are processed in computing resource 3. With this type of parallelism, the dependent data processing nodes can process the data in parallel. As this parallelism may incur many inter-computing resource data transfers, it is not widely used for FL.", "cites": [5425], "cite_extract_rate": 0.5, "origin_cites_number": 2, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 2.0, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section provides a basic description of pipeline parallelism and its implementation, referencing the GPipe paper to illustrate how data processing is distributed. However, it lacks deeper synthesis of the concept with other parallelism types, offers minimal critical evaluation of the method or the cited work, and does not abstract broader principles or trends in distributed training for federated learning."}}
{"id": "10053136-8ab4-4b06-aec3-a7a9b0e56bc3", "title": "Aggregation Algorithms", "level": "subsection", "subsections": ["e5dd26ef-00aa-4b84-aa33-7ff2605aebde", "508677b5-4dbe-4b11-ad6a-7789cb9e091d", "ecce2209-838c-4800-b0a9-49b94ea5037a"], "parent_id": "5dfeced7-075b-4276-abd0-1ff3e9bb48a7", "prefix_titles": [["title", "From Distributed Machine Learning to Federated Learning: A Survey"], ["section", "Distributed Training"], ["subsection", "Aggregation Algorithms"]], "content": "\\label{sebsec:aggre}\nWith the horizontal FL and data parallelism, aggregation algorithms are used to aggregate the models or gradients generated from the forward and backward propagation in each computing resource. The aggregation algorithms can be either centralized, or hierarchical, and decentralized. The centralized aggregation algorithms generally rely on a centralized server, i.e., a parameter server, to synchronize or schedule the execution of distributed computing resources, while hierarchical aggregation algorithms rely on multiple parameter servers for the model aggregation.\nThe decentralized aggregation algorithms make each computing resource equally perform the calculation based on a predefined protocol, without relying on a centralized server. \\liu{Please refer to  for the details of federated optimization. The characteristics are summarized in Table \\ref{tal:aggregation}, which can be used to choose appropriate algorithms in a specific situation.  }\n\\begin{table}[ht]\n\\centering\n\\caption{\\liu{Comparison among diverse types of aggregation algorithms. ``Complexity'' represents the complexity to implement the algorithms (``H'' represents high complexity, ``M'' represents medium complexity, and ``L'' represents low complexity). ``Trust'' represents whether the aggregation algorithms require that the data owners trust the centralized server. ``Imbalance'' represents whether the algorithms can address the unbalanced data. ``High-latency'' represents whether the algorithms can support the high-latency model or gradient data transfer. ``Y'' represents that the algorithms support the functionality while ``N'' represents that the algorithms do not support the functionality.}}\n\\label{tal:aggregation}\n\\begin{tabular}{|c|c|c|c|c|c|}\n\\hline\nType & Complexity & Trust & Imbalance & High-latency \\\\\n\\hline\nCentralized & L & Y & N & N \\\\\n\\hline\nHierarchical & M & Y & Y & Y \\\\\n\\hline\nDecentralized & H & N & N & Y \\\\\n\\hline\n\\end{tabular}\n\\end{table}", "cites": [636], "cite_extract_rate": 1.0, "origin_cites_number": 1, "insight_result": {"type": "comparative", "scores": {"synthesis": 2.5, "critical": 2.0, "abstraction": 2.0}, "insight_level": "medium", "analysis": "The section provides a basic comparison of different aggregation algorithm types (centralized, hierarchical, decentralized) and references a paper on federated optimization, but it lacks detailed synthesis of the cited work. It uses a table to summarize characteristics, but the analysis remains superficial without in-depth evaluation or discussion of trade-offs. The abstraction level is limited to categorizing attributes rather than offering deeper principles or trends."}}
{"id": "e5dd26ef-00aa-4b84-aa33-7ff2605aebde", "title": "Centralized Aggregation", "level": "subsubsection", "subsections": [], "parent_id": "10053136-8ab4-4b06-aec3-a7a9b0e56bc3", "prefix_titles": [["title", "From Distributed Machine Learning to Federated Learning: A Survey"], ["section", "Distributed Training"], ["subsection", "Aggregation Algorithms"], ["subsubsection", "Centralized Aggregation"]], "content": "\\label{subsubsec:centralized}\n\\begin{figure}[htbp]\n    \\centering\n    \\includegraphics[width=0.7\\textwidth]{figures/cenagg.png}\n    \\caption{The architecture of centralized aggregation. ``CR'' represents computer resource. $\\omega$ represents the local parameters or the weights of the model calculated in each computing resource. $\\mathrm{g}$ represents the local gradients in backward propagation in each computing resource. $\\overline{\\omega}$ represents the global model calculated in the parameter server. $\\overline{\\mathrm{g}}$ represents the global gradients calculated in the parameter server.}\n    \\label{fig:centra}\n\\end{figure}\nAs shown in Figure \\ref{fig:centra}, a single parameter server is used to calculate the average models or gradients sent from multiple computing resources (mobiles).\nThe weights of the model (model) or the gradients are calculated in each computing resource, which are transferred to a parameter server. \nThe parameter server calculates global gradients or global models according to a centralized aggregation algorithm.\nThe global gradients or global models are transferred to each computing resource for the following computation. \nThe update of the model is based on the SGD defined in Formula \\ref{eq:gd} in both computing resources, or on the parameter server.\nA bunch of centralized aggregation algorithms have been proposed.\nFederated Averaging (FedAvg)  algorithm is introduced as the aggregation method in Google's implementation of an FL system. A centralized server aggregates the machine learning models from selected users. Then, a global model is generated using a weighted sum of each aggregated machine learning model. Afterward, the global model is shared with selected users, and the training process is continued in the computing resource of selected users. \nHowever, the trained model of FedAvg may be biased towards computing resources with favorable network conditions . \nWhile FedAvg is a straightforward approach, some other methods are proposed to address additional problems. \nA Federated Stochastic Block Coordinate Descent (FedBCD)  algorithm is proposed to reduce the number of communication rounds by enabling multiple local updates before the model communication between a user and the server. In addition, FedBCD also considers the regularization during the training process. The training problem with regularization can be formulated as:\n\\begin{equation}\n\\label{eq:regularizer}\n    \\widehat F = \\underset{F_\\theta\\in\\mathcal{H}}{\\mathrm{argmin}} \\underset{(x,y)\\sim\\mathcal{D}}{\\mathbb{E}} L(y, F_\\theta(x)) + \\lambda \\cdot \\gamma(\\theta),\n\\end{equation}\nwhere $F$, $D$, $\\mathcal{H}$ are the same as those in Formula \\ref{eq:problem}, while $\\gamma(\\cdot)$ denotes the regularizer and $\\lambda$ is the hyper-parameter. The regularization is exploited to improve the generalization capacity of the trained machine learning model. As the fairness among multiple users is important for an FL system, the Stochastic Agnostic Federated Learning (SAFL)  algorithm and the FedMGDA+  algorithm are proposed to achieve fairness during the training process of FL. The fairness represents that the data distribution among multiple users can be equally considered without the influence of unrelated factors. \nFairness may also refer to two other concepts: (1) A user gets a final model according to the contribution ; and/or (2) Uniform accuracy distribution among all the distributed computing resources , which are out of the scope of this paper.\nIn addition, while the computing resources may be heterogeneous, FedProx  is proposed to tackle the heterogeneity in an FL system. FedProx enables multiple iterations in each computing resource, while minimizing a cost function based on the local loss function and the global model. Furthermore, in order to address permutation of data processing nodes during the training process, Federated Matched Averaging (FedMA)  is proposed. FedMA exploits an existing approach, i.e., BBP-MAP , to generate a matrix, in order to align the data processing nodes of the models from computing resources and the server.  SCAFFOLD  is proposed to reduce the communication rounds, using stateful variables in the distributed computing resources. Attention-augmented mechanism is exploited in Attentive Federated Aggregation (FedAttOpt)  to aggregate the knowledge generated from each computing resource (client), based on the contribution of the model from each client. \nWhen the data distribution is heterogeneous among users, personalization remains an open problem. In order to address this problem, the model can be split into local layers and global layers, which has been proposed in adaptive personalized federated learning (APFL) , FedPer , and pFedMe . The local layers are trained with the decentralized data in each computing resource of users, while the global layers are trained in the computing resources of users and the server. However, it is difficult to choose a dataset and its partition among clients to measure the personalization brought by APFL or FedPer, so as to prove the improvement compared with FedAvg.\nThe attention-augmented mechanism helps reduce the communication rounds.\nIn addition, knowledge distillation can also be exploited to aggregate the models, while requiring that there is data in the centralized server .\nAll these algorithms can handle non-IID data. A comparison among the aforementioned algorithms is proposed in Table \\ref{tal:aggre}. \n\\begin{table}[ht]\n\\centering\n\\caption{Comparison among aggregation algorithms. ``Reg'' represents regularization. Heterogeneity represents that the computing resources are heterogeneous. ``Firness'' represents that the data distribution among multiple users can be equally considered without the influence of unrelated factors. ``Permutation'' refers to the permutation of data processing nodes during the training process.  ``C-E'' represents communication efficient. ``S'' represents that the algorithm supports the functionality, while ``N'' represents that the algorithm does not have support. }\n\\label{tal:aggre}\n\\begin{tabular}{|c|c|c|c|c|c|}\n\\hline\nAlgorithm & Reg & Fairness & Heterogeneity & Permutation & C-E \\\\\n\\hline\nFedAvg & N & N & N & N & N \\\\\n\\hline\nFedBCD & S & N & N & N & S \\\\\n\\hline\nSAFL & N & S & N & N & N \\\\\n\\hline\nFedMGDA+ & N & S & N & N & S \\\\\n\\hline\nFedProx & N & N & S & N & S \\\\\n\\hline\nFedMA & N & N & N & S & S \\\\\n\\hline\nSCAFFOLD& N & N & N & N & S \\\\\n\\hline\nFedAttOpt& N & N & N & N & S \\\\\n\\hline\n\\end{tabular}\n\\end{table}", "cites": [635, 602, 7928, 5440, 5443, 5441, 5445, 8919, 5442, 582, 5444, 5446, 632], "cite_extract_rate": 0.8125, "origin_cites_number": 16, "insight_result": {"type": "comparative", "scores": {"synthesis": 3.0, "critical": 3.0, "abstraction": 2.5}, "insight_level": "medium", "analysis": "The section synthesizes multiple aggregation algorithms from cited works, providing a comparative overview of their features. It includes a table to contrast functionalities like regularization, fairness, heterogeneity handling, and communication efficiency. However, it lacks deeper critical evaluation of these methods or broader abstraction beyond the listed features."}}
{"id": "508677b5-4dbe-4b11-ad6a-7789cb9e091d", "title": "Hierarchical Aggregation", "level": "subsubsection", "subsections": [], "parent_id": "10053136-8ab4-4b06-aec3-a7a9b0e56bc3", "prefix_titles": [["title", "From Distributed Machine Learning to Federated Learning: A Survey"], ["section", "Distributed Training"], ["subsection", "Aggregation Algorithms"], ["subsubsection", "Hierarchical Aggregation"]], "content": "\\begin{figure}[htbp]\n    \\centering\n    \\includegraphics[width=0.95\\textwidth]{figures/hier.png}\n    \\caption{The architecture of hierarchical aggregation. ``CR'' represents computer resource. $\\omega$ represents the local parameters or the weights of the model calculated in each computing resource. $\\mathrm{g}$ represents the local gradients in backward propagation in each computing resource. $\\overline{\\omega}$ represents the region or global model calculated in each parameter server. $\\overline{\\mathrm{g}}$ represents the region or global gradients calculated in each parameter server. The region model or gradients are calculated by a region parameter server, while the global model or gradients are calculated by a global parameter server.}\n    \\label{fig:hier}\n\\end{figure}\nAs shown in Figure \\ref{fig:hier}, a hierarchical architecture is also exploited using multiple parameter servers. \nA two-layer hierarchical architecture is proposed to reduce the time to transfer models between a parameter server and computing resources . The hierarchical architecture uses a global parameter server (GPS) and multiple region parameter servers. Each region parameter server (RPS) is implemented in a cell base station where the computing resources (mobiles) can be connected, with low latency. A hierarchical algorithm, i.e., Hierarchical Federated Learning (HFL) is deployed to realize the model aggregation. Within each iteration of HFL, each RPS calculates an average model using the models of the computing resources within its cluster. It sends the averaged model to the GPS, and it receives a global averaged model at every certain iteration. Afterward, it broadcasts the averaged model to all its computing resources. Some other algorithms, e.g., HierFAVG , HFEL , and LanFL , are similar to HFL, while the SPS is an edge or Local-Area Network (LAN) parameter server and the MPS is a parameter server implemented on the cloud or a Wide-Area Network (WAN). These algorithms take advantage of hierarchical architecture to reduce high-latency model or gradient data transfer, so as to accelerate the training process. In addition, by well-clustering the computing resources to groups, the hierarchical architecture is also exploited to address unbalanced data distributed among multiple computing resources , or to address data privacy .", "cites": [646, 644, 5448, 5447, 5449], "cite_extract_rate": 0.7142857142857143, "origin_cites_number": 7, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.0, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section synthesizes information from multiple papers to present a coherent framework of hierarchical aggregation in federated learning. It abstracts the common design pattern of using region and global parameter servers to address communication latency and data privacy. While it does not deeply critique specific papers, it does highlight the motivations and benefits of the hierarchical approach across different contexts."}}
{"id": "ecce2209-838c-4800-b0a9-49b94ea5037a", "title": "Decentralized Aggregation", "level": "subsubsection", "subsections": [], "parent_id": "10053136-8ab4-4b06-aec3-a7a9b0e56bc3", "prefix_titles": [["title", "From Distributed Machine Learning to Federated Learning: A Survey"], ["section", "Distributed Training"], ["subsection", "Aggregation Algorithms"], ["subsubsection", "Decentralized Aggregation"]], "content": "\\label{subsubsec:decentralized}\n\\begin{figure}[htbp]\n    \\centering\n    \\includegraphics[width=0.8\\textwidth]{figures/decentral.png}\n    \\caption{The architecture of decentralized aggregation. ``CR'' represents computer resource. $\\omega$ represents the local parameters, or the weights of the model calculated in each computing resource. $\\mathrm{g}$ represents the local gradients in backward propagation in each computing resource. When two computing resources are neighbors, they can communicate with each other.}\n    \\label{fig:decentralized}\n\\end{figure}\nWhile collaboratively training a machine learning model with a decentralized aggregation algorithm, the computing resources can be organized with a {\\em connected} topology and can communicate with a peer-to-peer manner, as shown in Figure \\ref{fig:decentralized}. The degree and connectivity of the topology affects the communication efficiency and the convergence rate of the aggregation algorithm. \nFor a given topology, we define $w_{i,j}$, the weight to scale information flowing from node $j$ to node $i$, as follows\\vspace{-2mm}\n\\begin{align}\\label{wij}\nw_{ij}\n\\begin{cases}\n> 0 & \\mbox{if node $j$ is connected to node $i$, or $i=j$;} \\\\\n= 0 & \\mbox{otherwise.}\\vspace{-2mm}\n\\end{cases}\n\\end{align}\nWe further define the {\\bf topology matrix} $W = [w_{ij}]_{i,j=0}^{n-1} \\in \\mathbb{R}^{n\\times n}$ as the matrix to represent the topology. \nIn the remainder of this paper, \nwe assume that $W$ satisfies \n$W\\mathds{1} = \\mathds{1}$ \nand $\\mathds{1}^T W = \\mathds{1}^T$, \ni.e., both the row sum and the column sum of $W$ are equal to $1$, \nso as to guarantee that the neighborhood averaging will asymptotically approach the global averaging . \nWhen a computing resource $j$ is directly connected to computing resource $i$, i.e., $w_{i,j} \\neq 0$, computing resource $j$ is the neighbor of computing resource $i$.\n\\liu{Please note that the weight $w_{i,j}$ denotes the confidence node $i$ has in the information it receives from node $j$ , which is different from the bandwidth or data transfer capacity in a network.}\nThe centralized aggregation algorithm is a special type of decentralized aggregation with a star topology while only the centralized server communicates with its neighbors.\n\\liu{A well designed topology, e.g., an exponential graph , can improve the convergence rate, which accelerates the training speed.}\nWith the decentralized SGD (D-SGD), each computing resource maintains a local copy of \nthe global model parameters, and it updates the local copy using the models of its neighbors. \nAccording to the order to conduct neighborhood averaging and gradient descent, D-SGD has two common types of realizations: Average-With-Communication (AWC)  and Average-Before-Communication (ABC) .\nAWC can overlap communication and gradient computation, while ABC needs to sequentially calculate and communicate the gradient or model. \nHowever, ABC is robust , and it converges fast in terms of iterations by exploiting its large learning rate.\nIn addition, the decentralized aggregation algorithms can be classified to Full Communication (FC)  and Partial Communication (PC)  according to the number of neighbors. Within the iterations of FC, each computing resource calculates an averaged model or gradient, based on all the models or gradients of the last version from all its neighbors. However, within the iterations of PC, each computing resource calculates an averaged model or gradient based on one or multiple chosen neighbors. With PC, the selection of the neighbors can be based on a gossip algorithm . For instance, a random neighbor can be selected ; the neighbors that provide benign models are selected to avoid attack .", "cites": [5452, 8920, 5450, 7930, 5451, 7929], "cite_extract_rate": 0.5, "origin_cites_number": 12, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.0, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section synthesizes multiple papers to present a coherent explanation of decentralized aggregation in federated learning, using a common framework (topology matrix and communication strategies). It offers a critical perspective by discussing the trade-offs between AWC and ABC, and between FC and PC. The analysis abstracts key principles such as topology design and neighbor selection, moving beyond specific examples to highlight generalizable concepts."}}
{"id": "8048e455-33dd-411a-bdf6-5bafe4141358", "title": "Distributed Data Processing", "level": "subsection", "subsections": [], "parent_id": "cd0b3f18-6523-488f-aaa8-addaf533ff9f", "prefix_titles": [["title", "From Distributed Machine Learning to Federated Learning: A Survey"], ["section", "Data Manipulation"], ["subsection", "Distributed Data Processing"]], "content": "While the bandwidth within a single data center is high, e.g., InfiniBand, the High Performance Computing (HPC) libraries, e.g., Message Passing Interface (MPI)  or NVIDIA Collective Communications Library (NCCL) , are widely exploited for distributed data processing . With MPI or NCCL, the gradients or models in each computing resource can be easily calculated using ring-AllReduce algorithm . However, one of the drawbacks of the HPC libraries is that they lack support for fault-tolerance, as the HPC libraries are designed for high performance servers with high quality networks. When any computing resource within the network becomes unavailable, the distributed training process may be broken.\nHowever, as an FL system is generally implemented for the collaboration of large amounts of mobile device users or different organizations, the network connection among computing resources is of moderate quality, i.e., the bandwidth is not as good as that within a single data center, and the latency is high.\nFor instance, the Internet upload speed is typically much slower than the download speed . Also, some users with unstable wireless communication channels may consequently drop out due to disconnection from the Internet .\nIn this environment, the connection between computing resources and parameter servers has a high possibility of becoming disabled. Thus,  Remote Procedure Call (RPC) frameworks are widely exploited, as this kind of framework can ignore the disconnected computing resources and continue the distributed training of an FL system , e.g., PaddleFL , PySyft , or TensorflowFL .", "cites": [5454, 623, 655, 659, 5453], "cite_extract_rate": 0.5, "origin_cites_number": 10, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.5, "critical": 3.0, "abstraction": 3.0}, "insight_level": "medium", "analysis": "The section provides an analytical overview of distributed data processing in FL, contrasting HPC libraries like MPI and NCCL with RPC-based frameworks. It synthesizes key ideas from the cited papers regarding network constraints and fault tolerance, though the integration is not particularly novel. The section critically highlights limitations of HPC libraries in FL settings, such as lack of fault tolerance, and identifies the need for more suitable communication strategies."}}
{"id": "09ac7749-f7de-46a4-bc72-304efd143b4a", "title": "Data Transfer", "level": "subsection", "subsections": [], "parent_id": "cd0b3f18-6523-488f-aaa8-addaf533ff9f", "prefix_titles": [["title", "From Distributed Machine Learning to Federated Learning: A Survey"], ["section", "Data Manipulation"], ["subsection", "Data Transfer"]], "content": "As the network connection is of moderate quality, the data transfer module mainly focuses on data compression to transfer intermediate data, e.g., gradients or models. \nSketched updates are proposed for gradient compression to accelerate the data transfer during the distributed training within a single data center .\nWith the data parallelism and centralized aggregation algorithm, before sending the intermediate data, the intermediate data can be sketched with subsampling , quantization , sparsification , or projection to lower dimensional spaces , in each computing resource, in order to reduce the cost to transfer data.\nSubsampling refers to transferring only a random subset of the intermediate data .\nQuantization methods encode each value using a fixed number of bits, so as to reduce the length of gradients or models .\nWith the sparsification approach, only selected parts of the intermediate data are transferred, while the selection is based on a threshold, e.g., the gradients larger than a threshold are selected . Then, when the intermediate data is received in the server, they are decompressed to be aggregated according to the aggregation algorithms presented in Section \\ref{subsubsec:centralized}. The convergence of the quantization approach is analyzed in , which shows that this approach can also provide good convergence rates . In addition, irrelevant intermediate data can be precluded to be transferred to the server, in order to substantially reduce the communication overhead .", "cites": [613, 7932, 623, 622, 7931, 5456, 5457, 5455, 625, 8366], "cite_extract_rate": 0.7692307692307693, "origin_cites_number": 13, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.5, "critical": 2.5, "abstraction": 3.0}, "insight_level": "medium", "analysis": "The section synthesizes key data compression techniques (subsampling, quantization, sparsification, projection) from multiple papers, linking them to the broader goal of reducing communication overhead in federated learning. It provides a coherent narrative on how these techniques are applied in practice. However, while it mentions the convergence of quantization and the motivation for compression, it lacks deeper comparative analysis or critique of the methods' trade-offs and limitations. The abstraction is moderate, identifying general categories of compression strategies but not offering a meta-level theoretical framework."}}
{"id": "7a14e4c6-106a-4ec2-8926-70aed111f75a", "title": "Data Privacy", "level": "subsubsection", "subsections": [], "parent_id": "4a182037-a6a4-48d6-aa9c-0986bac2c4b8", "prefix_titles": [["title", "From Distributed Machine Learning to Federated Learning: A Survey"], ["section", "Data Manipulation"], ["subsection", "Data Security"], ["subsubsection", "Data Privacy"]], "content": "The techniques to protect data privacy consist of three types: Trusted Execution Environment (TEE), encryption, Differential Privacy (DP), and anti-Generative Adversarial Network (GAN) methods. These techniques can be combined in FL systems, e.g., the combination of DP and TEE in , the combination of encryption and DP , and the combination of DP and anti-GAN .\nA TEE is an environment where the execution is secured and no information can be leaked to unauthorized users. \nIntel SGX technique  has been first proposed as a secure environment while providing a set of security-related instruction codes built within Intel Central Processing Units (CPUs). \nThen, the implementation of machine learning models has been carried out in the TEE, i.e., Intel SGX, in order to enable collaborative data analysis based on machine learning algorithms while providing a security guarantee . Afterwards, the TEE has been exploited in FL systems, in order to protect the privacy of data in two ways. The first way is to put the entire training process in the TEE of each distributed computing resource to protect the data privacy during the distributed training . The second way is to use TEE to check a small part of the distributed training, while exploiting insecure computing resources, e.g., GPUs, to reduce the training time . \nAs an encryption technique, homomorphic encryption has been used to ensure the data privacy for FL systems .\nHomomorphic encryption  allows specific types of computations to be carried out on encrypted input data, and to generate an encrypted result, which matches the result of the same computations on the decrypted input data. \n\\liu{Two main branches of homomorphic encryption exist, i.e., fully homomorphic encryption and partially homomorphic encryption. \nThe fully homomorphic encryption supports both addition and multiplication on ciphertext, while partially homomorphic encryption only supports either an addition or a multiplication operation on ciphertext, which corresponds to less computational flexibility and better runtime efficiency. \nBoth the fully and partially homomorphic encryptions can be exploited with the horizontal and vertical federated learning.}\nAs sharing gradients also leaks the information of training data \\liu{in horizontal federated learning} , it is of much importance to protect the privacy of the intermediate data.\nThus, the intermediate data can be encrypted using a homomorphic encryption algorithm before being sent to a parameter server . In this way, the intermediate data remain encrypted during the aggregation process while only the computing resource can decrypt the encrypted intermediate data. \nEven if the transferred encrypted intermediate data is leaked, the information of gradients or models remains safe, and the privacy of the training data is ensured.\n\\liu{In addition, partial homomorphic encryption, e.g., Paillier , is exploited in vertical federated learning .}\nHowever, the homomorphic encryption incurs significant costs in computation and communication during distributed training . In order to reduce the overhead of homomorphic encryption, a set of quantized gradients are encrypted . \nDifferential Privacy (DP) protects the data privacy by adding artificial noise to a small part of raw data, while ensuring that the modification does not substantially affect the performance of the machine learning models . \nDP is widely used in FL systems as the first step to process the raw data, and the output is the training data to be used for the distributed training . With more added noise, the privacy is better protected, i.e., there is less possibility to leak raw data information, while it takes more time to converge for the machine learning models . A trade-off between the privacy protection and the convergence performance can be made by selecting a certain number of distributed resources . However, DP may not be able to ensure the data privacy under certain attacks, e.g., Generative Adversarial Network (GAN) attacks .\nA well-trained machine learning model can leak information about the training data based on the intermediate data, e.g., gradients . GANs can be used to generate data similar to the training data based on a well-trained machine learning model  in either a parameter server  or a distributed computing resource . \nThe adversary can reconstruct other participating clientsâ€™ private data, even if it has no knowledge of the label information using the GANs.\nThus, during the distributed training process of FL systems, a malicious user can exploit GANs to infer the training data of other users. DP can be used to prevent the GAN-based attack . In addition, fake training data can be generated based on a GAN and original raw data, which is then used during the distributed training process to prevent the GAN-based attack .", "cites": [3469, 5460, 3477, 892, 5459, 5461, 5462, 5439, 5458, 3478, 7933, 614, 5463, 7608, 5441, 5464, 7727], "cite_extract_rate": 0.4857142857142857, "origin_cites_number": 35, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.5, "abstraction": 3.0}, "insight_level": "medium", "analysis": "The section effectively synthesizes various data privacy techniques in FL (TEE, encryption, DP, and anti-GAN methods) and connects them to relevant works. It critically evaluates limitations, such as DP's vulnerability under GAN attacks and homomorphic encryption's overhead. However, while it identifies some patterns (e.g., encryption's role in gradient privacy), it stops short of offering more abstract, meta-level insights or a novel unifying framework."}}
{"id": "cecfb28f-1aff-43d4-9671-2b7aa114b7c6", "title": "Model Security", "level": "subsubsection", "subsections": [], "parent_id": "4a182037-a6a4-48d6-aa9c-0986bac2c4b8", "prefix_titles": [["title", "From Distributed Machine Learning to Federated Learning: A Survey"], ["section", "Data Manipulation"], ["subsection", "Data Security"], ["subsubsection", "Model Security"]], "content": "We mainly focus on poisoning attacks in this section. \nThe objective of poisoning attacks is to reduce the accuracy of machine learning models using artificially designed data, i.e., data poisoning, or models, i.e., model poisoning, in one or several distributed computing resources during the model aggregation process (see details in in Section \\ref{subsubsec:centralized}). There are two ways to carry out poisoning attacks, i.e., data poisoning and model poisoning. \nData poisoning can be realized by modifying the features  or the labels  of the input data. For instance, malicious users can modify the data points of a certain class $C$ to other classes, and they can then use the modified data points to participate in the distributed training. \nThe modification of the labels is denoted by the label flipping attack.\nAs a result, the accuracy of the trained model has low accuracy in terms of Class $C$ . \nModel poisoning refers to the attacks in which the updated intermediate data, e.g., gradients or models, are poisoned before being sent to a parameter server in order to reduce the accuracy of the trained model . The goal of the model poisoning is to reduce the performance of the trained model on targeted tasks or classes, while the performance of the model remains unchanged in terms of other tasks or classes . \nData poisoning eventually realizes the model poisoning, as it enables some computing resources to update poisoned intermediate data based on the calculation of poisoned training data . \nHowever, model poisoning can be more powerful than data poisoning, as model poisoning directly influences the weights of the models and trains in a way that benefits the attack .\nBoth the data poisoning and the model poisoning rely on the backdoor attacks to modify the training data or the intermediate data . Backdoor attacks are performed by embedding the hidden instructions into machine learning models, so that the infected model performs well on benign testing samples when the backdoor is not activated, while its prediction will be changed to the attacker-specified target label when the backdoor is activated by the attacker . \nIn order to defend against these data attacks or model attacks, the malicious users should be identified by analyzing the updated intermediate data using dimensionality reduction methods, e.g., Principal Component Analysis (PCA) , anomaly detection , or interpretability techniques .\nIn addition, the model poisoning can be incurred by Byzantine failures of certain distributed computing resources . With Byzantine failures, some computing resources (bad users) are manipulated by attackers during the distributed training process, which significantly degrades the performance of the global model in terms of test error . \nIn order to make the training process robust against the Byzantine failures, the bad users can be identified by analyzing the updated intermediate data using a hidden Markov model  or via secure aggregation protocols .", "cites": [2673, 5468, 5470, 5465, 5451, 5471, 5467, 7038, 3415, 597, 5469, 5466], "cite_extract_rate": 0.9230769230769231, "origin_cites_number": 13, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.5, "critical": 3.0, "abstraction": 3.5}, "insight_level": "medium", "analysis": "The section synthesizes concepts from multiple papers to explain the relationship between data and model poisoning in federated learning, with a focus on backdoor attacks and Byzantine failures. It provides a coherent narrative by integrating different types of threats and defenses. While it includes some analysis of attack mechanisms and mitigation strategies, it primarily summarizes findings without in-depth comparisons or critiques of the cited works. The abstraction level is moderate, as it identifies broader attack categories and general defense approaches rather than offering a novel conceptual framework."}}
{"id": "727148cb-019c-4e5c-9d02-e8f0c8fb671c", "title": "Federated Learning Frameworks", "level": "section", "subsections": ["37621a76-9ea9-4868-9b62-1b2d192ce562", "c27dbf26-a266-414a-aa80-dc2e4d0fee2b", "d79e2f48-eba0-495e-b5ac-cb343eff8f4d", "baf085e7-c8e0-4563-86bc-a6f1583fb40d", "c6708387-e962-4e76-9ea7-b422245775eb"], "parent_id": "42e77c1c-0c8b-4e28-9d53-60920d7558be", "prefix_titles": [["title", "From Distributed Machine Learning to Federated Learning: A Survey"], ["section", "Federated Learning Frameworks"]], "content": "\\label{sec:frameworks}\nFL systems are widely applied in diverse domains, e.g., \nmobile service, healthcare , and finance .\nAn FL system generally exploits an FL framework, which is deployed on distributed resources.\nIn this section, we present four widely used FL frameworks: PaddleFL , TensorFlowFederated , FATE , and PySyft .", "cites": [5420, 5423], "cite_extract_rate": 0.3333333333333333, "origin_cites_number": 6, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 1.5, "abstraction": 1.5}, "insight_level": "low", "analysis": "The section primarily describes four FL frameworks (PaddleFL, TensorFlowFederated, FATE, and PySyft) and briefly mentions their applications in domains like healthcare. It cites two papers but does not effectively synthesize their content into a broader narrative or integrate their insights meaningfully. There is minimal critical analysis or abstraction, as the section lacks comparative evaluation or identification of overarching principles in FL frameworks."}}
{"id": "37621a76-9ea9-4868-9b62-1b2d192ce562", "title": "PaddleFL", "level": "subsection", "subsections": [], "parent_id": "727148cb-019c-4e5c-9d02-e8f0c8fb671c", "prefix_titles": [["title", "From Distributed Machine Learning to Federated Learning: A Survey"], ["section", "Federated Learning Frameworks"], ["subsection", "PaddleFL"]], "content": "PaddleFL is an open source federated learning framework based on PaddlePaddle , which is supported by Baidu. At the presentation layer, PaddleFL provides a textual UI for the interaction between users and the FL system. At the User Services layer, PaddleFL provides the log and monitoring supports, and it can leverage the interpretability module  of PaddlePaddle in the future. At the FL training layer, PaddleFL can realize data parallelism (horizontal FL) and model parallelism (vertical FL). It supports multiple aggregation algorithms, e.g., FedAvg, and fault-tolerance. At the infrastructure layer, PaddleFL exploits RPC for the distributed execution. PaddleFL exploits DP to protect the data security. PaddleFL is widely used in multiple domains, e.g., Natural Language Processing (NLP), Computing Vision (CV) , and recommendation.", "cites": [5422], "cite_extract_rate": 0.3333333333333333, "origin_cites_number": 3, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 1.5, "abstraction": 1.5}, "insight_level": "low", "analysis": "The section primarily provides a factual description of the PaddleFL framework, listing its layers, features, and applications. It mentions a single cited paper (FedVision) but does not integrate or synthesize its content meaningfully. There is little critical analysis or abstraction to broader trends or principles in federated learning."}}
{"id": "c27dbf26-a266-414a-aa80-dc2e4d0fee2b", "title": "TensorFlowFederated", "level": "subsection", "subsections": [], "parent_id": "727148cb-019c-4e5c-9d02-e8f0c8fb671c", "prefix_titles": [["title", "From Distributed Machine Learning to Federated Learning: A Survey"], ["section", "Federated Learning Frameworks"], ["subsection", "TensorFlowFederated"]], "content": "TensorFlow Federated (TFF)  is an open-source framework for federated learning on decentralized data, which is supported by Google. TFF also provides a textual UI through Python. TFF supports the monitoring and log functionality at the user service layer. TFF supports data parallelism (horizontal FL), multiple aggregation algorithms, and fault-tolerance of mobile devices. TFF exploits RPC for the distributed execution and DP for the protection of data privacy.\nTFF enables Android mobile users to predict the next word while using the keyboard on their mobile phones .", "cites": [5419, 582], "cite_extract_rate": 0.6666666666666666, "origin_cites_number": 3, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 1.5, "abstraction": 1.5}, "insight_level": "low", "analysis": "The section provides a factual description of TensorFlow Federated (TFF) and its features, with minimal synthesis of the cited papers. It mentions TFF's use of DP and federated averaging but does not integrate or elaborate on how these relate to the broader insights in the cited works. There is no critical evaluation or abstraction to broader principles or trends in federated learning."}}
{"id": "baf085e7-c8e0-4563-86bc-a6f1583fb40d", "title": "PySyft", "level": "subsection", "subsections": [], "parent_id": "727148cb-019c-4e5c-9d02-e8f0c8fb671c", "prefix_titles": [["title", "From Distributed Machine Learning to Federated Learning: A Survey"], ["section", "Federated Learning Frameworks"], ["subsection", "PySyft"]], "content": "PySyft  is an open-source FL framework based on the PyTorch framework .\nPySyft is written in Python and provides a textual UI based on Python.\nPySyft mainly supports the data parallelism and model parallelism based on an aggregator or orchestrating server. The aggregator or orchestrating server sends a part of the model to participating clients to process local data and gets results for federated averaging. PySyft exploits DP and encryption techniques to protect the data security. PySyft exploits multiple communication protocols for distributed execution, e.g., RPC, websocket  etc.", "cites": [656], "cite_extract_rate": 0.3333333333333333, "origin_cites_number": 3, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 1.5, "abstraction": 1.5}, "insight_level": "low", "analysis": "The section provides a factual description of PySyft, focusing on its features, supported parallelism types, and security mechanisms. While it references a paper that introduces a privacy-preserving deep learning framework, it does not explicitly connect PySyft to the broader concepts or innovations described in that paper. There is minimal synthesis, no critical evaluation of the framework or its limitations, and no abstraction to broader patterns or principles in FL frameworks."}}
{"id": "c6708387-e962-4e76-9ea7-b422245775eb", "title": "\\liu{Concluding Remarks", "level": "subsection", "subsections": [], "parent_id": "727148cb-019c-4e5c-9d02-e8f0c8fb671c", "prefix_titles": [["title", "From Distributed Machine Learning to Federated Learning: A Survey"], ["section", "Federated Learning Frameworks"], ["subsection", "\\liu{Concluding Remarks"]], "content": "}\n\\liu{\nDiverse FL frameworks exist while each has its advantage. We summarize the characteristics of each framework in Table \\ref{tal:FLFramework}, so as to help select a proper framework for use. From the table, we can see that all the frameworks implement the centralized aggregation algorithms, while employing DP and HE for the data security. PaddleFL can exploit Paddle to realize data, model, and pipeline parallelism. FATE and TFF are based on Tensorflow as the engine, while FATE can provide Web portal UI, which is convenient for novices. PySyft is compatible with PyTorch, which can easily handle the PyTorch-based tasks, while PaddleFL is compatible with Paddle, which can easily deal with rich pre-trained models published in PaddleHub .}\n\\begin{table}[ht]\n\\centering\n\\caption{\\liu{Comparison among diverse frameworks. ``Aggregation'' represents the type of aggregation algorithms. ``Textual'' represents the textual UI, while ``Web'' represents Web portal.}}\n\\label{tal:FLFramework}\n\\begin{tabular}{|c|c|c|c|c|c|}\n\\hline\nFramework & Engine & Aggregation & UI & Parallelism & Security \\\\\n\\hline\nPaddleFL & Paddle & Centralized & textual & Data/Model/Pipeline & DP/HE \\\\\n\\hline\nTFF & TensorFlow & Centralized & textual & Data/Model & DP/HE \\\\\n\\hline\nFATE & TensorFlow & Centralized & Web & Data/Model & DP/HE \\\\\n\\hline\nPySyft & PyTorch & Centralized & textual & Data & DP/HE \\\\\n\\hline\n\\end{tabular}\n\\end{table}\n\\liu{Table \\ref{tal:FrameworkSupport} represents the support of diverse types of FL in terms of data distribution. All the frameworks support horizontal FL, while vertical FL is supported by three frameworks except TFF. PySyft cannot directly support the vertical FL, while PyVertical , which is built upon PySyft, can be used to support vertical FL with the compatibility of PyTorch models. The hybrid FL is only supported by Paddle and FATE. In addition, all the frameworks support the execution with GPU. In practice, although PaddleFL may correspond to slightly longer time, the accuracy of the trained model can be higher that of TFF and FATE, while PySyft may generate ``out of memory'' errors .}\n\\begin{table}[ht]\n\\centering\n\\caption{\\liu{Comparison among diverse frameworks for the support of diverse FL types, e.g., horizontal FL, vertical FL, and hybrid FL, and GPU. $\\|$\\checkmark$\\|$ represents that the support is not realized by itself but a close one.}}\n\\label{tal:FrameworkSupport}\n\\begin{tabular}{|c|c|c|c|c|c|}\n\\hline\n\\multicolumn{2}{|c|}{} & PaddleFL & TFF & FATE & PySyft \\\\\n\\hline\n\\multirow{3}{*}{Types} & Horizontal & \\checkmark & \\checkmark & \\checkmark & \\checkmark \\\\\n\\cline{2-6}\n& Vertical & \\checkmark & \\xmark & \\checkmark & $\\|$\\checkmark$\\|$ \\\\\n\\cline{2-6}\n& Hybrid & \\checkmark & \\xmark & \\checkmark & \\xmark \\\\\n\\hline\n\\multicolumn{2}{|c|}{GPU} & \\checkmark & \\checkmark & \\checkmark & \\checkmark \\\\\n\\hline\n\\end{tabular}\n\\end{table}", "cites": [7934], "cite_extract_rate": 0.3333333333333333, "origin_cites_number": 3, "insight_result": {"type": "comparative", "scores": {"synthesis": 2.5, "critical": 2.0, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section provides a factual comparison of different federated learning frameworks, emphasizing their features such as parallelism, security, UI, and FL type support. While it references Paper 1 in the context of PyVertical, it does so minimally and without deeper integration or synthesis. There is limited critical evaluation or abstraction to broader principles, keeping the insight level on the lower side."}}
{"id": "9866dd12-79cc-42bf-8557-f19459ea5936", "title": "Benchmarks", "level": "subsection", "subsections": [], "parent_id": "226ea081-07c1-4d87-ad04-18733a7f7202", "prefix_titles": [["title", "From Distributed Machine Learning to Federated Learning: A Survey"], ["section", "Research Directions"], ["subsection", "Benchmarks"]], "content": "Several datasets exist for experiments on FL systems. For instance, Federated Extended MNIST (FEMNIST)  is built by partitioning the data in Extended MNIST  based on each writer.\nShakespeare  is built from The Complete Works of William Shakespeare  based on each speaking role. \nBoth of these datasets can be used for horizontal FL. However, no public datasets exist for vertical FL or transfer FL. In addition, no open decentralized IID or non-IID distribution of popular datasets, e.g., ImageNet , exist for FL systems.", "cites": [653, 582], "cite_extract_rate": 0.4, "origin_cites_number": 5, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 2.0, "abstraction": 1.5}, "insight_level": "low", "analysis": "The section provides a basic factual summary of existing FL benchmarks and mentions the absence of datasets for certain FL settings. It integrates minimal information from the cited papers, offering no critical evaluation or deeper analysis of their limitations. There is little abstraction or generalization of patterns in benchmark design or usage."}}
{"id": "b6673d3f-9d3e-4599-b8f4-93fdf908307f", "title": "Interpretability", "level": "subsection", "subsections": [], "parent_id": "226ea081-07c1-4d87-ad04-18733a7f7202", "prefix_titles": [["title", "From Distributed Machine Learning to Federated Learning: A Survey"], ["section", "Research Directions"], ["subsection", "Interpretability"]], "content": "Deep neural networks have excellent performance in various areas, while it is often difficult to understand the results of deep neural network models, especially within FL systems.\nShapley values have been used to provide the interpretability , while it focuses on vertical FL. When multiple users collaboratively train an FL model, it remains an open problem to evaluate the contributions of each user, which helps provide evidence for the incentive of each user. \nThe primary incentive for clients to participate in federated learning is obtaining better models , while the benefit of participating in federated learning for clients who have sufficient private data to train accurate local models is disputable. \nInterpretability can help understand the contributions of each user and provide an objective opinion on the incentive strategy within an FL system.\nIn addition, the interpretability helps domain experts to understand the relationship between data and the final trained model in critical domains, e.g., healthcare and finance.\nHowever, the interpretability within FL systems remains an open problem.", "cites": [5421, 5437], "cite_extract_rate": 1.0, "origin_cites_number": 2, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.0, "critical": 2.5, "abstraction": 3.0}, "insight_level": "medium", "analysis": "The section integrates concepts from both cited papers, particularly the use of Shapley values for interpretability and the challenge of user incentives in FL. It connects these ideas to discuss how interpretability supports incentive strategies and domain understanding. However, the analysis lacks deeper evaluation or comparison of the approaches, and the generalization is moderate, focusing mainly on specific FL contexts like healthcare and finance."}}
{"id": "35e51ec5-ea11-4e9b-a3ee-cbf4853180ca", "title": "Federated Learning on Graphs", "level": "subsection", "subsections": [], "parent_id": "226ea081-07c1-4d87-ad04-18733a7f7202", "prefix_titles": [["title", "From Distributed Machine Learning to Federated Learning: A Survey"], ["section", "Research Directions"], ["subsection", "Federated Learning on Graphs"]], "content": "Graphs or graph neural networks (GNN)  have gained increasing popularity in multiple domains, e.g., social network, knowledge graph, and recommender system. FL frameworks for graphs, i.e., GraphFL , and GNN, i.e., SGNN , have been proposed to train a model with decentralized graphs. However, the data security of FL on graphs remains an open problem. \\liu{In addition, while a multimodal knowledge graph could not only contain text but also images or other type of data , it is worth further exploration to efficiently support the multimodel knowledge graph construction within an FL system .}", "cites": [7935, 5438, 180], "cite_extract_rate": 0.6, "origin_cites_number": 5, "insight_result": {"type": "analytical", "scores": {"synthesis": 2.5, "critical": 2.0, "abstraction": 2.0}, "insight_level": "medium", "analysis": "The section briefly introduces FL on graphs and references three relevant papers, but the synthesis is limited, offering only a high-level overview without connecting deeper ideas. It identifies one open problem (data security) and a potential research direction (multimodal KGs), indicating some level of critical and abstract thinking, but the analysis remains shallow and does not provide a comprehensive evaluation or comparison of the cited works."}}
{"id": "e54c8539-ee3c-4e42-b5a8-6e639fe2d31f", "title": "\\liu{Imbalanced Data", "level": "subsection", "subsections": [], "parent_id": "226ea081-07c1-4d87-ad04-18733a7f7202", "prefix_titles": [["title", "From Distributed Machine Learning to Federated Learning: A Survey"], ["section", "Research Directions"], ["subsection", "\\liu{Imbalanced Data"]], "content": "}\n\\liu{\nAlthough FL focuses on the non-IID data, the real-world decentralized data usually exhibit an imbalanced distribution . While the imbalanced data exist in multiple areas, such as computer vision , bioinformatics, and biomedicine , learning from such data requires special attention upon data sampling , data augmentation , and loss function designs . The imbalanced data is related to diverse tasks, e.g., two-class or multi-class classification . However, an optimized approach can be proposed to address the imbalanced data within FL systems.}", "cites": [8921, 5472, 5473], "cite_extract_rate": 0.375, "origin_cites_number": 8, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 1.5, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section briefly mentions the issue of imbalanced data in federated learning and notes its relevance to multiple domains and tasks, but it lacks a clear synthesis of the cited papers. It does not compare or critically evaluate the approaches proposed in these papers. The content is primarily descriptive and lacks deeper abstraction or insight into broader patterns or principles of handling imbalanced data in FL."}}
