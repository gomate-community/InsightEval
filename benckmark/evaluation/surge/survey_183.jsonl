{"id": "d21ff4e5-f21c-4a4a-8406-db1935c2eddd", "title": "Introduction", "level": "section", "subsections": ["e31f9e05-f817-4490-9b7c-0609e22e4c3b", "4e1c24f5-e7a5-433e-a8c2-9c11eab5f9eb"], "parent_id": "d94801ff-a764-4596-9ca6-d904958ff3d5", "prefix_titles": [["title", "A Survey on Deep Learning Event Extraction: Approaches and Applications"], ["section", "Introduction"]], "content": "\\label{sec:introduction}}\n\\IEEEPARstart{E}{vent} Extraction (EE) is an important yet challenging task in information extraction research. As a particular form of information, an event refers to a specific occurrence of something that happens in a certain time and a certain place involving one or more participants, which can usually be described as a change of state~. \nThe event extraction task aims at extracting such event information from unstructured plain texts into a structured form, which mostly describes “who, when, where, what, why” and “how” of real-world events that happened. In terms of application, the task facilitates people to retrieve event information and analyze people’s behaviors, arousing information retrieval , recommendation , intelligent question answering , knowledge graph construction , and other event-related applications . \nEvent extraction can be divided into two groups: close-domain event extraction  and open-domain event extraction . \nEvents are usually considered in a predefined event schema, where some specific people and objects are interacted at a specific time and place. \nThe close-domain event extraction task aims to find words that belong to a specific event schema, which refers to an action or state change that occurs, and its extraction targets include time, place, person, and action, etc.\nIn the open-domain event extraction task, events are considered as a set of related descriptions of a topic, which can be formulated into a classification or clustering task. \nOpen-domain event extraction refers to acquiring a series of events related to a specific theme, usually composed of multiple events.\nWhether the close-domain or open-domain event extraction task, the purpose of event extraction is to capture the event types that we are interested in from numerous texts and show the essential arguments of events in a structured form.\nDeep learning event extraction on general domain has a lot of work and has been a relatively mature research taxonomy.\nIt discovers event mentions from texts and extracts events containing event triggers and event arguments, where event mentions are termed as sentences containing one or more triggers and arguments.\nEvent extraction requires to identify the event, classify event type, identify the argument, and judge the argument role.\nSpecifically, trigger identification and trigger classification are usually formed as the event detection task , while argument identification and argument role classification are usually defined as an argument extraction task.\nThe trigger classification is a multi-classification classification  task to classify the type of each event.\nThe role classification task is a multi-class classification task based on word pairs, determining the role relationship between any pair of triggers and entities in a sentence.\nFrom a technical perspective, event extraction can depend on some other foundational natural language processing (NLP) tasks such as named entity recognition (NER) , semantic parsing , and relation extraction .\n\\begin{figure*}[t]\n    \\centering\n    \\includegraphics[width=0.95\\linewidth]{fig/flow.pdf}\n    \\caption{The flowchart of deep learning event extraction on general domain.}\n    \\label{figure1}\n    \\label{img}\n\\end{figure*} \nWe give the flow chart of deep learning event extraction on the general domain, as shown in Fig. \\ref{figure1}.\nThe event extraction is to find the focused event type and extract its arguments with it roles.\nFor a pipeline paradigm event extraction, it is necessary to distinguish the event type in the text for a given text, called trigger classification. \nFor different event types, different event schema is designed. \nThen, event arguments are extracted according to the schema, which includes argument identification and argument role classification sub-tasks. \nIn the earliest stage, argument role classification is regarded as a word classification task, and each word in the text is classified.\nIn addition, there are sequence labeling, machine reading comprehension (MRC) and sequence-to-structure generation methods.\nFor a joint paradigm event extraction, the model classifies the event type and argument roles simultaneously to avoid error coming from trigger classification sub-task.", "cites": [1666, 1659, 1664, 8476, 1658, 1669, 1671, 1663, 1670, 1661, 1668, 7498, 1667, 1660, 1662, 1665], "cite_extract_rate": 0.47058823529411764, "origin_cites_number": 34, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.5, "critical": 2.0, "abstraction": 2.3}, "insight_level": "medium", "analysis": "The section provides a descriptive overview of event extraction, introducing key concepts and task divisions. It cites relevant papers but primarily uses them to support definitions and background rather than synthesizing insights or presenting comparative or critical analysis. Some integration is present, such as mentioning open- and closed-domain approaches, but lacks deeper evaluation or meta-level abstraction."}}
{"id": "e31f9e05-f817-4490-9b7c-0609e22e4c3b", "title": "Contributions", "level": "subsection", "subsections": [], "parent_id": "d21ff4e5-f21c-4a4a-8406-db1935c2eddd", "prefix_titles": [["title", "A Survey on Deep Learning Event Extraction: Approaches and Applications"], ["section", "Introduction"], ["subsection", "Contributions"]], "content": "For the traditional event extraction method, the feature designing is necessary, while for the deep learning event extraction method on general domain, the features can be end-to-end extracted by deep learning models.\nThe existing reviews mainly introduce the extraction of subject events, where there are few event extraction methods based on deep learning models .  \nIn recent years, a large number of event extraction methods have been proposed, and the event extraction methods based on Transformer have achieved significant improvement . \nFurthermore, event extraction is no longer limited to classification and sequence annotation manner , but can also be formulated in machine reading comprehension and generation  manner.\nTherefore, we comprehensively analyze the existing deep learning-based event extraction methods on general domain and outlook for future research work.\nThe main contributions of this paper are as follows:\n\\begin{itemize}\n\\item We introduce the general domain event extraction technology, review the development history of event extraction methods, and point out that the event extraction methods with deep learning have become the mainstream. \nWe summarize the necessary information of deep learning models according to year of publication in Table~\\ref{tab:BasicInformation}.\n\\item We analyze various deep learning-based extraction paradigm and models, including their advantages and disadvantages in detail. We introduce the currently available datasets and give the formulation of main evaluation metrics. We summarize the necessary information of primary datasets in Table~\\ref{tab:datasets}.\n\\item We summarize event extraction accuracy scores on ACE 2005 dataset in Table~\\ref{ace} and event extraction applications. We conclude the review by discussing the future research trends facing the event extraction. \n\\end{itemize}\n\\begin{figure*}[t]\n    \\centering\n    \\includegraphics[width=0.9\\linewidth]{fig/figure2.pdf}\n    \\caption{A diagram of event extraction. The example can be divided into two type of event. The type of Die is triggered by ``died\" with three argument roles of \\textit{Place}, \\textit{Victim} and \\textit{Instrument} and the type of \\textit{Attack} is triggered by ``fired\" with three argument roles of \\textit{Place}, \\textit{Target} and \\textit{Instrument}.}\n    \\label{figure2}\n    \\label{img}\n\\end{figure*}", "cites": [1672], "cite_extract_rate": 0.1111111111111111, "origin_cites_number": 9, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.0, "critical": 2.5, "abstraction": 3.0}, "insight_level": "medium", "analysis": "The section synthesizes the evolution of event extraction methods, particularly highlighting the shift from traditional to deep learning approaches and the introduction of new paradigms like QA and generation. It connects these ideas to present a coherent overview. However, while it mentions the QA paradigm from the cited paper, it lacks deeper critical evaluation of its limitations or trade-offs. The abstraction is moderate, as it generalizes trends such as the move toward end-to-end models and new task formulations."}}
{"id": "8f9614d7-c599-4615-a6b1-cefdce66e64d", "title": "Classification-based Task", "level": "subsubsection", "subsections": [], "parent_id": "0637c8f2-7bed-4aff-a6a3-0b64363d818b", "prefix_titles": [["title", "A Survey on Deep Learning Event Extraction: Approaches and Applications"], ["section", "Preliminary"], ["subsection", "Event Extraction Manner"], ["subsubsection", "Classification-based Task"]], "content": "For the classification task , authors usually predefine $n$ event types and their corresponding argument roles, $e.g.$ the event $e_i$ ($i \\in [1, n]$) contains a set of argument roles [$r_{i,1}, r_{i,2}..., r_{i, l}$].\nGiven an input event mention $m$, the model needs to output a result vector $T$, where the $i$-th argument $T_i$ represents the probability that $m$ belongs to the event $e_i$.\nIn the classification-based task, the trigger identification is to classify whether a word is a trigger.\nAfter obtaining the final event (or a set) $e_k$ of $m$, the model outputs a matrix $R$ where the argument $R_{i, j}$ means the probability that the extracted argument $a_i$ belongs to argument roles $r_{k, j}$. As shown in Fig. \\ref{task}(a), \nit classifies each entity to a predefined argument role.", "cites": [1673], "cite_extract_rate": 0.5, "origin_cites_number": 2, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 1.5, "abstraction": 1.5}, "insight_level": "low", "analysis": "The section provides a basic description of the classification-based task in event extraction, including task definitions and output formats. It includes a single cited paper, but does not integrate its ideas cohesively into the explanation of the task. There is little critical analysis or abstraction beyond the specific paper, as it primarily describes the task framework without evaluating the cited method or identifying broader trends."}}
{"id": "b4dc6c14-5e9a-4cbd-84eb-5c8101380019", "title": "Machine Reading Comprehension-based Task", "level": "subsubsection", "subsections": [], "parent_id": "0637c8f2-7bed-4aff-a6a3-0b64363d818b", "prefix_titles": [["title", "A Survey on Deep Learning Event Extraction: Approaches and Applications"], ["section", "Preliminary"], ["subsection", "Event Extraction Manner"], ["subsubsection", "Machine Reading Comprehension-based Task"]], "content": "The machine reading comprehension model  can understand a piece of text in natural language and answer questions about it .\nIn the machine reading comprehension-based task, the trigger identification is also to classify whether a word is a trigger.\nFirstly, a question schema is designed for each argument role $r$, called $Q_{r}$.\nSince different event types have different arguments, the model needs to first identify the event type to which the text belongs.\nThen, the argument roles to be extracted are determined according to the event types.\nFinally, the event extraction method based on machine reading comprehension is to input the text $T$, and apply the designed questions $Q_{r}$ one by one to the extraction model, as shown in Fig. \\ref{task}(b). The model extracts the answer $A_{r}$, which is the corresponding argument for each argument role $r$.", "cites": [1674], "cite_extract_rate": 0.25, "origin_cites_number": 4, "insight_result": {"type": "descriptive", "scores": {"synthesis": 1.5, "critical": 1.0, "abstraction": 1.5}, "insight_level": "low", "analysis": "The section provides a basic description of the machine reading comprehension-based event extraction approach but does not effectively synthesize or connect ideas from multiple sources. It cites only one paper (Paper 1) and does not integrate broader literature or show how this approach relates to others in the field. Additionally, there is no critical evaluation or abstraction of principles, focusing instead on a procedural summary of the method."}}
{"id": "ae3e9a4a-61ba-42a0-a17a-8b700061373c", "title": "Sequence labeling-based Task", "level": "subsubsection", "subsections": [], "parent_id": "0637c8f2-7bed-4aff-a6a3-0b64363d818b", "prefix_titles": [["title", "A Survey on Deep Learning Event Extraction: Approaches and Applications"], ["section", "Preliminary"], ["subsection", "Event Extraction Manner"], ["subsubsection", "Sequence labeling-based Task"]], "content": "Sequence labeling task  is a multi-classification task  based on word level, which can directly match event arguments based on word level event type extraction. The event extraction mainly includes two core tasks: identifying and classifying event categories and extracting event arguments. Event extraction based on sequence labeling can simply and quickly realize the matching of event type and event argument without additional features. \nIn the sequence labeling-based task, the trigger identification is to label a word is a trigger.\nThe sequence labeling method marks out the target from the text, which is suitable for the event extraction task.\nAs shown in Fig. \\ref{task}(c), for a given text $T={x_{1}, x_{2}, \\dots, x_{N}}$ and event schema, the argument role $r$ corresponding to the argument is labeled with the sequence labeling model.\nThe output $y={y_{1}, y_{2}, \\dots, y_{N}}$ of sequence labeling model is to tag all words in the text.", "cites": [1676, 1675], "cite_extract_rate": 0.3333333333333333, "origin_cites_number": 6, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 1.5, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section provides a basic description of the sequence labeling-based task for event extraction, mentioning its key components such as trigger identification and argument role labeling. While it cites two papers, it does not integrate their contributions into a broader narrative or explain how they advance the field. There is minimal critical analysis or abstraction of overarching principles, and the section remains largely descriptive in nature."}}
{"id": "5a440f16-785d-4139-86f9-924599c629af", "title": "Pipeline-based Paradigm", "level": "subsection", "subsections": [], "parent_id": "2e7f2c2d-a649-4255-ba0d-3a89bf98e2b6", "prefix_titles": [["title", "A Survey on Deep Learning Event Extraction: Approaches and Applications"], ["section", "Event Extraction Paradigm"], ["subsection", "Pipeline-based Paradigm"]], "content": "The pipeline-based method treats all sub-tasks as independent classification problems . \nThe pipeline approach is widely used since it simplifies the entire event extraction task.\nThe pipeline-based event extraction method, as shown in Fig. \\ref{Du}, converts event extraction tasks into a multi-stage classification problem. The required classifiers include:\n1) A trigger classifier is used to determine whether the term is the event trigger and the type of event. 2) An argument classifier is used to determine whether the word is the argument of the event. 3) An argument role classifier is used to determine the category of arguments. \nThe classical deep learning-based event extraction model Dynamic Multi-Pooling Convolutional Neural Network (DMCNN)  uses two dynamic multi-pooling convolutional neural networks for trigger classification and argument classification. The trigger classification model identifies the trigger. If there is a trigger, the argument classification model is used to identify arguments and their roles. \nPLMEE  also uses two models employing trigger extraction and argument extraction. Argument extractor uses the result of trigger extraction to reason. It performs well through introducing Bidirectional Encoder Representation from Transformers (BERT) .\nPipeline-based event extraction methods provide additional information for subsequent sub-tasks through previous sub-tasks, and take advantage of dependencies between subtasks.\nDu et al.  adopt a question answering method to implement event extraction. Firstly, the model identifies the trigger in the input sentence through the designed question template of the trigger. The input of the model includes the input sentence and question. Then, it classifies the event type according to the identified trigger. The trigger can provide additional information for trigger classification, but the result of wrong trigger identification can also affect trigger classification. Finally, the model identifies the event argument and classifies argument roles according to the schema corresponding to the event type. In argument extraction, the model utilizes the answers of the previous round of history content.\nThe most significant defect of this method is error propagation.\nIntuitively, if there is an error in trigger identification in the first step, then the accuracy of argument identification will be lowed. \nTherefore, when using pipelines to extract events, there will be error cascading and task splitting problems.\nThe pipeline event extraction method can extract event arguments by using the information of triggers. \nHowever, this requires high accuracy of trigger identification. \nA wrong trigger will seriously affect the accuracy rate of argument extraction. \nTherefore, the pipeline event extraction method considers the trigger as the core of an event.\n\\textbf{Summary.} The pipeline-based method transforms the event extraction task into a multi-stage classification problem. The pipeline-based event extraction method first identifies the triggers, and argument identification is based on the result of the trigger identification. It considers the trigger as the core of an event. Yet, this staged strategy will lead to error propagation. The recognition error of the trigger will be passed to the argument classification stage, which will lead to the degradation of the overall performance. Moreover, because the trigger detection always precedes the argument detection, the argument won’t be considered while detecting triggers. Therefore, each link is independent and lacks interaction, ignoring the impact between them. Thus, the overall dependency relationship cannot be handled. The classic case is DMCNN . \n\\begin{figure*}[ht]\n    \\centering\n    \\includegraphics[width=0.95\\linewidth]{fig/joint.pdf}\n    \\caption{The simplified architecture of joint-based event extraction paradigm.}\n    \\label{fig:DBRNN}\n    \\label{img}\n\\end{figure*}", "cites": [1672, 7, 1677], "cite_extract_rate": 0.42857142857142855, "origin_cites_number": 7, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.5, "critical": 3.0, "abstraction": 3.0}, "insight_level": "medium", "analysis": "The section synthesizes key concepts from multiple papers, such as trigger and argument classification, and integrates them into a coherent explanation of the pipeline-based paradigm. It identifies a major limitation—error propagation—and explains its implications for performance. However, the analysis is somewhat standard and does not offer a novel framework or deep comparative critique of the cited methods, limiting the level of abstraction and critical depth."}}
{"id": "cd5fd787-7c30-4332-adc2-8f515ddd69b0", "title": "Joint-based Paradigm", "level": "subsection", "subsections": [], "parent_id": "2e7f2c2d-a649-4255-ba0d-3a89bf98e2b6", "prefix_titles": [["title", "A Survey on Deep Learning Event Extraction: Approaches and Applications"], ["section", "Event Extraction Paradigm"], ["subsection", "Joint-based Paradigm"]], "content": "Event extraction is of great practical value in NLP.\nBefore using deep learning to model event extraction tasks, the joint learning method has been studied in event extraction.\nAs shown in Fig.~\\ref{fig:DBRNN},\nthis method identifies the triggers and arguments according to candidate triggers and entities in the first stage. In the second stage, to avoid the error information propagation from event type, trigger classification and argument role classification are realized simultaneously. It classifies trigger ``died\" to \\textit{Die} event type, and argument ``Baghdad\" to \\textit{Place} argument role, etc.\nThe deep learning event extraction method based on the joint model mainly uses the deep learning and the joint learning to interact with the feature learning, which can avoid the extended learning time and the complex feature engineering~.\nLi et al.~ study the joint learning of trigger extraction and argument extraction tasks based on the traditional feature extraction method and obtain the optimal result through the structured perceptron model.\nZhu et al.~ design efficient discrete features, including local features of all information contained in feature words and global features that can connect trigger with argument information.\nNguyen et al.~ successfully construct local features and global features through deep learning and joint learning. \nIt uses a recurrent neural network to combine event recognition and argument role classification.\nThe local features constructed are text sequence features and local window features.\nThe input text consists of word vectors, entity vectors, and event arguments. Then the text is transferred to the recurrent neural network model to obtain the sequence characteristics of the deep learning.\nA deep learning model with memory is also proposed to model it. It mainly aimed at the global characteristics between event triggers, between event arguments, and between event triggers and event arguments to improve the performance of tasks simultaneously.\nEvent extraction involves related tasks such as entity recognition, which helps improve event extraction.\nLiu et al.  use the local characteristics of arguments to assist role classification.\nThey adopted a joint learning task for entities for the first time, aiming to reduce the complexity of the task. \nThe previous methods input the dataset with characteristics which are marked and output the event. \nChen et al.  simplify the process, namely plain text input and output. In the middle of the process, it is the joint learning on event arguments.\nThis joint learning factor mainly provides the relationship and entity information of different events within each input event.\nThe above joint learning method can achieve joint modeling event extraction of triggers and arguments. \nHowever, in the actual work process, the extraction of triggers and arguments is carried out successively rather than concurrently, which is an urgent problem to be discussed later.\nBesides, if an end-to-end mode is added to the deep learning, the feature selection workload will be significantly reduced, which will also be discussed later.\nThe joint event extraction method avoids the influence of trigger identification error on event argument extraction, considering trigger and argument are equally important, but it cannot use the information of triggers. \n\\textbf{Summary.} \nIn order to overcome the shortcomings of the pipeline method, researchers proposed a joint method. The joint method constructs a joint learning model to trigger recognition and argument recognition, where the trigger and argument can mutually promote each other’s extraction effect. The experiment proves that the effect of the joint learning method is better than the pipeline learning method. The classic case is Joint Event Extraction via Recurrent Neural Networks (JRNN) .\nThe joint event extraction method avoids trigger identification on event argument extraction, but it cannot use the information of trigger. The joint event extraction method considers that the trigger and argument in an event are equally important.\nHowever, neither pipeline-based event extraction nor joint-based event extraction can avoid the impact of event type prediction errors on the performance of argument extraction. Moreover, these methods can not share information among different event types and learn each type independently, which is disadvantageous to the event extraction with only a small amount of labeled data.\n\\begin{table*}[t]\n\\centering\n\\caption{Basic information of different models. ED: event detection, AE: argument extraction, NER: named entity recognition, MRC: machine reading comprehension.}\n\\label{tab:BasicInformation}\n \\linespread{2}\n\\resizebox{\\textwidth}{!}{\n\\begin{tabular}{c|ccccccccc}\n\\toprule\n\\textbf{Year} & \\textbf{Model}  & \\textbf{Setting} & \\textbf{Manner}      & \\textbf{Venue} & \\textbf{Datasets} &\\textbf{ED}&\\textbf{AE} &\\textbf{NER} \\\\\\hline\n\\multirow{9}{*}{2021}&TEXT2EVENT  & supervised& generation & ACL & ACE05-EN, ERE-EN &\\checkmark &\\checkmark & - \\\\\n& CasEE  & supervised & sequence labeling & ACL(Findings) & FewFC &\\checkmark &\\checkmark & - \\\\\n&CLEVE  &supervised& classification & ACL & ACE, MAVEN &\\checkmark &\\checkmark &\\checkmark \\\\\n&FEAE  &supervised& MRC& ACL & RAMS &\\checkmark &\\checkmark &\\checkmark \\\\\n&GIT  &supervised&classification &ACL & ChFinAnn \\footnotemark[1] &  \\checkmark &\\checkmark &\\checkmark \\\\\n&NoFPFN  &supervised&classification &ACL(Findings)& ChFinAnn &  \\checkmark &\\checkmark &\\checkmark \\\\\n& DualQA    &  semi-supervised& MRC\n & AAAI  & ACE, FewFC& -&\\checkmark&-\\\\\n&GRIT &supervised& generation &EACL&(Message Understanding Conference) MUC-4& \\checkmark&\\checkmark&-\\\\\n& Wen et al.  &supervised& classification & NAACL &ACE& \\checkmark&\\checkmark&-\\\\\\cline{1-9}\n& HPNet  &supervised& sequence labeling & COLING& ACE2005, Text Analysis Conference 2015 (TAC2015) & \\checkmark&\\checkmark&-\\\\\n & M2E2  & weakly supervised& classification&ACL&  M2E2 & \\checkmark&\\checkmark&-\\\\\n & MQAEE        & supervised & MRC & EMNLP  & ACE& \\checkmark&\\checkmark&-\\\\\n & Du et al.         & supervised & MRC & EMNLP  & ACE& \\checkmark&\\checkmark&-\\\\\n &  Min et al.           & supervised & classification & LREC  &ACE   &-&\\checkmark&-\\\\\n&Chen et al.  &supervised& MRC & EMNLP &ACE&-&\\checkmark&-\\\\\n&EEGCN  & supervised& sequence labeling & EMNLP(Findings) & ACE&\\checkmark&-&-\\\\\\cline{1-9}\n\\multirow{11}{*}{2019} & Doc2EDAG\\footnotemark[2]   & supervised& generation & EMNLP  &  ChFinAnn  &\\checkmark&\\checkmark&\\checkmark\\\\\n & Chen et al. & supervised & MRC & arXiv  & ACE &\\checkmark&\\checkmark&- \\\\\n & GAIL-ELMo\\footnotemark[3]  & supervised& sequence labeling & Data Intell.  & ACE &\\checkmark&\\checkmark&\\checkmark \\\\\n & DYGIE++  & supervised& sequence labeling & EMNLP  & ACE, SciERC, etc.  &\\checkmark&\\checkmark&-\\\\\n & HMEAE  &supervised& classification & EMNLP  & ACE, TAC-KBP &-&\\checkmark& \\checkmark\\\\\n & Han et al.  & supervised& classification & EMNLP  & TB-Dense, MATRES &\\checkmark&\\checkmark&\\checkmark\\\\\n & PLMEE           & supervised & sequence labeling & ACL& ACE &\\checkmark&\\checkmark&\\checkmark\\\\\n & JointTransition           & supervised&classification & IJCAI & ACE &\\checkmark&\\checkmark&\\checkmark \\\\\n & Joint3EE           &supervised& sequence labeling & AAAI & ACE &\\checkmark&\\checkmark&- \\\\\n & Chan et al.  & supervised& classification & ACL  & ACE &\\checkmark&\\checkmark&\\checkmark \\\\\n & Li et al.          & supervised & MRC & ACL    & ACE, CoNLL04   &\\checkmark&\\checkmark&-\\\\\\cline{1-9}\n\\multirow{8}{*}{2018}  & DCFEE\\footnotemark[4]~ & distance supervision & sequence labeling   & ACL &NO.(ANN, POS, NEG)& \\checkmark &\\checkmark &-\\\\\n & Zeng et al.      & distance supervision& sequence labeling & AAAI  & FBWiki, ACE &\\checkmark&\\checkmark&\\checkmark\\\\\n & Huang et al. & supervised &classification & ACL &ACE &\\checkmark&\\checkmark&-  \\\\\n & DEEB-RNN\\footnotemark[5]  & supervised& classification & ACL &ACE &\\checkmark&-&-  \\\\\n & SELF  & supervised& classification& ACL &ACE, TAC-KBP &\\checkmark&-&-  \\\\\n & DBRNN           & supervised& classification & AAAI &ACE &\\checkmark&\\checkmark&\\checkmark \\\\\n & JMEE           & supervised& sequence labeling & EMNLP & ACE &\\checkmark&\\checkmark&\\checkmark \\\\\n & Ferguson et al.          & semi-supervised& classification& NAACL&ACE, TAC-KBP &\\checkmark&\\checkmark&- \\\\\\cline{1-9}\n\\multirow{2}{*}{2017} & DMCNN-MIL\\footnotemark[6]           & distance supervision& classification & ACL& ACE &\\checkmark&\\checkmark&\\checkmark  \\\\\n & Liu et al. & supervised& classification& ACL &ACE &\\checkmark&-&-  \\\\\\cline{1-9}\n\\multirow{6}{*}{2016}  & RBPB\\footnotemark[7]~  & supervised& classification & ACL  & ACE &\\checkmark&\\checkmark&- \\\\\n & Zeng et al.        & supervised & sequence labeling & NLPCC  &  ACE  &\\checkmark&\\checkmark&- \\\\\n & JRNN  & supervised& sequence labeling & NAACL  & ACE &\\checkmark&\\checkmark&\\checkmark \\\\\n & JOINTEVENTENTITY  & supervised & sequence labeling & NAACL  & ACE &\\checkmark&\\checkmark&\\checkmark \\\\\n & BDLSTM-TNNs   &  supervised & classification & CCL  & ACE &\\checkmark&\\checkmark&\\checkmark \\\\\n & Liu et al.   &supervised& classification & ACL  & ACE &\\checkmark&-&- \\\\\\cline{1-9}\n\\multirow{1}{*}{2015}  & DMCNN~   &supervised& classification & ACL & ACE&\\checkmark&\\checkmark&\\checkmark  \\\\\n\\bottomrule\n\\end{tabular}\n}\n\\end{table*}\n\\footnotetext[1]{http://www.cninfo.com.cn/new/index}\n\\footnotetext[2]{The EDAG means entity-based directed acyclic graph.}\n\\footnotetext[3]{The ELMo means embeddings from language models.}\n\\footnotetext[4]{The DCFEE means document-level Chinese financial event extraction.}\n\\footnotetext[5]{The DEEB means document embedding enhanced Bi-RNN.}\n\\footnotetext[6]{The DMCNN-MIL means dynamic multi-pooling convolutional neural network with multi-instance learning.}\n\\footnotetext[6]{The RBPB means regularization-based pattern balancing method for event extraction.}", "cites": [1677, 1681, 1683, 1669, 1686, 1678, 1663, 1672, 1684, 1679, 1682, 8477, 7060, 1685, 1680], "cite_extract_rate": 0.3125, "origin_cites_number": 48, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.5, "critical": 3.0, "abstraction": 3.5}, "insight_level": "medium", "analysis": "The section synthesizes several joint learning methods for event extraction by connecting ideas across multiple papers, though the narrative is somewhat fragmented. It provides a critical perspective by pointing out limitations such as the inability to use trigger information and the issue of event type prediction errors. The abstraction level is moderate as it identifies the joint paradigm's broader purpose and contrasts it with the pipeline approach."}}
{"id": "bc48c721-2cf4-4959-a898-18683c6c4e81", "title": "Deep Learning Event Extraction Models", "level": "section", "subsections": ["6efc6255-6848-45f5-bb35-64beaec9d521", "151aca2d-9492-4b7d-ba3c-b32461f636ce", "4d0c9653-8736-43eb-b1f2-3343e1845c38", "11c1fe36-9428-4066-9f9e-871a4063e251", "dc2d9b02-91ba-4dc1-b1e0-7e22ca2b9f51"], "parent_id": "d94801ff-a764-4596-9ca6-d904958ff3d5", "prefix_titles": [["title", "A Survey on Deep Learning Event Extraction: Approaches and Applications"], ["section", "Deep Learning Event Extraction Models"]], "content": "\\label{Section 4}\nTraditional event extraction methods are challenging to learn in-depth features, making it difficult to improve the task of event extraction that depends on complex semantic relations.\nMost recent event extraction works are based on a deep learning architecture like Convolutional Neural Networks (CNN) , Recurrent Neural Network (RNN) \n, Graph Neural Network (GNN) , Transformer , or other networks . \nAs shown in TABLE \\ref{tab:BasicInformation}, we show the basic information of existing models according to the publish year. It includes the domain which is the model exploring, venue the model published, and datasets the model used. Furthermore, we conclude whether each model contains event detection, argument extraction and named entity recognition.\nThe deep learning method can capture complex semantic relations and significantly improve multiple event extraction data sets. We introduce several typical event extraction models.", "cites": [7061, 1687, 1684, 1685], "cite_extract_rate": 0.2857142857142857, "origin_cites_number": 14, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 1.5, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section provides a basic description of deep learning models used in event extraction and lists some relevant papers, but it lacks meaningful synthesis of their contributions or how they interrelate. There is minimal critical analysis, and no broader theoretical or methodological abstraction is attempted. The narrative remains primarily factual and summary-based."}}
{"id": "4d0c9653-8736-43eb-b1f2-3343e1845c38", "title": "Attention-based Models", "level": "subsection", "subsections": [], "parent_id": "bc48c721-2cf4-4959-a898-18683c6c4e81", "prefix_titles": [["title", "A Survey on Deep Learning Event Extraction: Approaches and Applications"], ["section", "Deep Learning Event Extraction Models"], ["subsection", "Attention-based Models"]], "content": "The automatic extraction of event features by deep learning model and the enhancement of event features by external resources mainly focus on the information of event triggers, and less on the information of event arguments and inter-word dependencies.\nSentence-level sequential modeling suffer a lot from the low efficiency in capturing very long-range dependencies.\nFurthermore, RNN-based and CNN-based models do not fully model the associations between events.\nThe modeling of structural information in the attention mechanism has gradually attracted the attention of researchers.\nAs research methods are constantly proposed, models that add attention mechanisms appear gradually, as shown in Fig. \\ref{figure5}.\nThe attention mechanism's feature determines that it can use global information to model local context without considering location information. \nIt has a good application effect when updating the semantic representation of words. \nBy controlling the different weight information of each part of the sentence, the attention mechanism makes the model pay attention to the important feature information of the sentence while ignoring other unimportant feature information, and rationally allocate resources to extract more accurate results.\nAt the same time, the attention mechanism itself can be used as a kind of alignment, explaining the alignment between input and output in the end-to-end model, to make the model more interpretable.\n\\begin{figure}[ht]\n    \\centering\n    \\includegraphics[width=0.95\\linewidth]{fig/attention-based.pdf}\n    \\caption{The architecture of attention-based event extraction.}\n    \\label{figure5}\n    \\label{img}\n\\end{figure} \nSome researchers also use a hierarchical attention mechanism to conduct the global aggregation of information.\nThe jointly multiple event extraction (JMEE)  composes of four modules: word representation, syntactic graph convolution network, self-attention trigger classification, and argument classification modules. \nThe information flow is enhanced by introducing a syntax shortcut arc. \nThe graph convolution network based on attention is used to jointly model the graph information to extract multiple event triggers and arguments.\nFurthermore, it optimizes a biased loss function when jointly extract event triggers and arguments to settle the dataset imbalances.", "cites": [1685], "cite_extract_rate": 1.0, "origin_cites_number": 1, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.5, "critical": 3.0, "abstraction": 3.5}, "insight_level": "medium", "analysis": "The section provides a coherent analytical overview of attention-based models in event extraction, integrating key ideas from the cited paper (JMEE) and placing them in the context of broader deep learning challenges. It discusses the mechanism’s strengths and how it addresses limitations of RNNs and CNNs. While it identifies some patterns and general advantages of attention, the critique remains limited to pointing out known weaknesses without deep evaluation or contrast across multiple works."}}
{"id": "11c1fe36-9428-4066-9f9e-871a4063e251", "title": "Graph Convolutional Network-based (GCN-based) Models", "level": "subsection", "subsections": [], "parent_id": "bc48c721-2cf4-4959-a898-18683c6c4e81", "prefix_titles": [["title", "A Survey on Deep Learning Event Extraction: Approaches and Applications"], ["section", "Deep Learning Event Extraction Models"], ["subsection", "Graph Convolutional Network-based (GCN-based) Models"]], "content": "Syntactic representations present an efficient method for straight linking words to their informative context for event detection in sentences . \nNguyen et al.  which investigate a convolutional neural network based on dependency trees to perform event detection are the first to integrate dependency tree relation information into neural event detection.\nThe model uses the proposed model with graph convolutional networks (GCNs)  and entity mention-based pooling.\nThey propose a novel pooling method that relies on entity mentions to aggregate convolution vectors.\nThe model operates a pooling over the graph-based convolution vectors of the current word and the entity mentions in the sentences. \nThe model aggregates convolution vectors to generate a single vector representation for event type prediction. \nThe model is to explicitly model the information from entity mentions to improve performance for event detection. \nIn , the Text Analysis Conference Knowledge Base Population (TAC-KBP) time slot is used to fill the quaternary time representation proposed in the task, and the model predicts the earliest and latest start and end times of the event, thus representing the ambiguous time span of the event.\nThe model constructs a document-level event graph for each input document based on shared arguments and time relationships and uses a graph-based attention network method to propagate time information on the graph, as shown in Fig. \\ref{Wen}, where entities are underlined and events are in bold face.\nWen et al. construct a document-level event diagram method based on event-event relationships for input documents.\nThe event arguments in the document are extracted. The events then are arranged in the order of time according to keywords such as \\textit{Before} and \\textit{After} and the time logic of the occurrence of the events. Entity argument are shared among different events.\nThe model implementation incorporates events into a more accurate timeline. \n\\begin{figure}[ht]\n    \\centering\n    \\includegraphics[width=\\linewidth]{fig/graph.pdf}\n    \\caption{The example event graph. The solid line consists of event arguments, while the dashed line graph is constructed based on time relationships .}\n    \\label{figure6}\n    \\label{Wen}\n\\end{figure} \n\\begin{figure}[ht]\n    \\centering\n    \\includegraphics[width=0.95\\linewidth]{fig/BERT-based.pdf}\n    \\caption{The architecture of PLMEE  for extraction.}\n    \\label{figure6}\n    \\label{img}\n\\end{figure}", "cites": [8410, 1684], "cite_extract_rate": 0.3333333333333333, "origin_cites_number": 6, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 1.5, "abstraction": 1.8}, "insight_level": "low", "analysis": "The section primarily describes GCN-based models for event extraction, focusing on specific features like dependency tree integration and entity mention-based pooling. It mentions two papers but does not effectively synthesize their ideas into a broader narrative. There is minimal critical analysis or identification of overarching principles, and the text appears to be a factual summary with limited insight."}}
{"id": "dc2d9b02-91ba-4dc1-b1e0-7e22ca2b9f51", "title": "Transformer-based Models", "level": "subsection", "subsections": [], "parent_id": "bc48c721-2cf4-4959-a898-18683c6c4e81", "prefix_titles": [["title", "A Survey on Deep Learning Event Extraction: Approaches and Applications"], ["section", "Deep Learning Event Extraction Models"], ["subsection", "Transformer-based Models"]], "content": "It is challenging to exploit one argument that plays different roles in various events to improve event extraction.\nYang et al.  employ a method to separate the argument prediction in terms of argument roles for overcoming the roles overlap problem. \nMoreover, this method automatically generates labeled data by editing prototypes and screening developed samples through ranking the quality due to inadequate training data. \nThey present a framework, Pre-trained Language Model-based Event Extractor (PLMEE) , as shown in Fig. \\ref{figure6}. The PLMEE promotes event extraction by using a combination of an extraction model and a generation method based on pre-trained language models.\nIt is a two-stage task, including trigger extraction and argument extraction, and consists of a trigger extractor and an argument extractor, both of which rely on BERT's feature representation.\nThen it exploits the importance of roles to re-weight the loss function. \nGAIL  is an ELMo-based  model utilizing a generative adversarial network to help the model focus on harder-to-detect events.\nThey propose an entity and event extraction framework based on generative adversarial imitation learning. It is an inverse reinforcement learning (IRL) method employing generative adversarial networks (GAN).\nThe model directly evaluates the correct and incorrect labeling of instances in entity and event extraction through a dynamic mechanism using IRL.\nDYGIE++\\footnote{The DYGIE means dynamic graph information extraction.}  is a BERT-based framework that models text spans and captures within-sentence and cross-sentence context.\nMuch information extraction tasks, such as named entity recognition, relationship extraction, event extraction, and co-reference resolution, can benefit from the global context across sentences or from phrases that are not locally dependent.\nThey carry out event extraction as additional task and span update in the relation graph of event trigger and its argument.\nThe span representation is constructed on the basis of multi-sentence BERT coding.\n\\textbf{Summary.}\nMost of the traditional event extraction methods adopt the artificial construction method for feature representation and use the classification model to classify triggers and identify the role of the argument.\nIn recent years, the deep learning has shown outstanding effects in image processing, speech recognition, and natural language processing, etc. To settle drawbacks of traditional methods, deep learning-based event extraction is systematically discussed. Before the emergence of BERT model, the mainstream method is to find the trigger from the text and judge the event type of the text according to the trigger.\nRecently, with the introduction of the event extraction model by BERT, the method of identifying event types based on the full text has become mainstream.\nIt is because BERT has outstanding contextual representation ability and performs well in text classification tasks, especially when there is only a small amount of data.", "cites": [1682, 8385], "cite_extract_rate": 0.5, "origin_cites_number": 4, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.5, "critical": 2.5, "abstraction": 3.0}, "insight_level": "medium", "analysis": "The section integrates key concepts from the cited papers, particularly in connecting the use of pre-trained language models (like BERT and ELMo) with event extraction tasks. It provides a coherent narrative on the evolution from traditional methods to modern deep learning approaches, especially highlighting the shift to full-text event type identification. While it includes some analysis of the models' design and advantages, it lacks deeper evaluation or comparison of their limitations and performance trade-offs."}}
{"id": "87f28dbd-b2f1-4618-bd7c-44c8b744839d", "title": "Open-domain Event Extraction Scenario", "level": "subsection", "subsections": [], "parent_id": "f4e4a409-41b8-40da-a197-43844ed6ad78", "prefix_titles": [["title", "A Survey on Deep Learning Event Extraction: Approaches and Applications"], ["section", "Event Extraction Scenarios"], ["subsection", "Open-domain Event Extraction Scenario"]], "content": "In the absence of a predefined event pattern, open domain event extraction is designed to detect events from text and, in most cases, to cluster similar events through extracted event keywords. Event keywords are those words/phrases that primarily describe events, sometimes further divided into triggers and parameters.\nOpen-domain event extraction  does not have a fixed argument role template. Therefore, arguments are often obtained by extracting key words. Chau et al. propose a method to filter irrelevant headlines and perform preliminary event extraction, relying on public news headlines. Both price and text are fed back into a 3D convolutional neural network to learn correlations between events and market movements.\nLiu et al.  design a novel latent variable neural model using a unsupervised generative method to explore latent event type vectors and entity mention redundancy. Experimental results show that it is scalable to very large corpus.", "cites": [1667, 1664], "cite_extract_rate": 0.6666666666666666, "origin_cites_number": 3, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 2.0, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section provides a basic description of open-domain event extraction and mentions two papers, but it does not synthesize their contributions into a broader narrative. It lacks critical evaluation of the methods or their limitations and offers minimal abstraction beyond the specific papers, merely stating what each paper does without identifying general trends or principles."}}
{"id": "c34cb1b7-1449-4403-a3b6-518ffb8cca2f", "title": "Low-Resource Event Extraction Scenario", "level": "subsection", "subsections": [], "parent_id": "f4e4a409-41b8-40da-a197-43844ed6ad78", "prefix_titles": [["title", "A Survey on Deep Learning Event Extraction: Approaches and Applications"], ["section", "Event Extraction Scenarios"], ["subsection", "Low-Resource Event Extraction Scenario"]], "content": "Due to the arduously expensive annotation in data emerging, there usually only exist insufficient data to train an accurate EE model with fully-supervised methods. \nIn this survey, we term such a situation as the low-resource scenario.\nTo alleviate the data sparsity, existing researches have explored distant supervision~ methods to boost annotation data.\nBesides, several promising methods also investigate semi-supervised methods~ or multilingual methods (See Sec.~\\ref{Sec.Multilingual}) to enrich supervision information.\nRecently, several researches have explored EE in three typical low-resource settings, including few-shot learning setting, zero-shot learning setting and incremental learning setting. \nIn this section, we will briefly introduce recent EE methods in the above settings as a quick reference.\n\\myparagraph{Few-shot Learning Setting}\nRecently, few-shot learning methods~ have been widely researched in several NLP tasks~, which aims to conduct task predictions with extremely limited (few-shot, like 1-shot, 3-shot, ... ) observed training samples.\nIn event extraction area, most existing studies focus on the event detection subtask applied in the few-shot learning setting (FSED).\nThe first line of works~ aims to conduct trigger classification given the candidate triggers with meta-learning methods. \nTo approach real applications, the second line of works~ jointly conducts trigger identification and trigger classification with only plain textual data. \nAmong them, Cong et al.~ further learn robust sequence label transition scores with a prototypical amortized conditional random fields (CRF), achieving significant improvements.\n\\myparagraph{Zero-shot Learning Setting}\nMost of the previous supervised EE methods rely on features derived from manual annotations, which cannot handle new event types without additional annotations.\nAn extremely challenging low-resource scenario is to achieve EE without any available labeled data.\nTo investigate the possibility of this scenario, recent researches~ explore zero-shot learning (ZSL) for event extraction.  \nHuang et al.~ firstly address this problem, which exploits the structural ontology of event mentions and types for representations, and conducts predictions with a semantic similarity measurement.\nLyu et al.~ further investigates transfer learning methods for new events, which formulates EE into textual entailment (TE) and question answering (QA) queries (e.g. “A city was attacked” entails “There is an attack”), and exploits pretrained TE/QA models for direct transfer.\nThough these methods still have a large gap from supervised approaches, they reveal an insightful vision and provide possible improvement directions for the extremely low-resource EE.\n\\myparagraph{Incremental Learning Setting}\nExisting ED methods usually require a fixed number of event types, and perform once-and-for-all training on a fixed dataset.\nSuch a paradigm usually encounters challenges when there continually occur new event types along with new emerging data.\nFor realistic consideration, a practical ED system ought to incrementally learn new event types and simultaneously remain predictive on existing types, instead of requiring a fixed dataset to re-train all the event types again.\nRecent researches~ on incremental learning (also called continual learning or lifelong learning) focus on the catastrophic forgetting, where the learned system usually suffers from significant performance drop on old types when it adapts to new types.\nCao et al.~ is the first work to tackle the incremental ED, which solves catastrophic forgetting and semantic ambiguity issues by a proposed knowledge consolidation network, achieving effective performance on incremental ED.", "cites": [1690, 1694, 1663, 1689, 1691, 1693, 1697, 1688, 1695, 1692, 1696, 1677], "cite_extract_rate": 0.5454545454545454, "origin_cites_number": 22, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.0, "abstraction": 3.5}, "insight_level": "medium", "analysis": "The section synthesizes multiple papers under the low-resource scenario by organizing them into three sub-settings (few-shot, zero-shot, and incremental learning), providing a coherent narrative. It includes some critical analysis, such as acknowledging the limitations of zero-shot methods compared to supervised approaches. While it identifies patterns like the use of meta-learning and semantic similarity, it could offer a more meta-level abstraction or a deeper comparative evaluation to reach a higher insight level."}}
{"id": "e65e378a-d2cc-465c-a422-a2f74bce5b23", "title": "Chinese Event Extraction Scenario", "level": "subsection", "subsections": [], "parent_id": "f4e4a409-41b8-40da-a197-43844ed6ad78", "prefix_titles": [["title", "A Survey on Deep Learning Event Extraction: Approaches and Applications"], ["section", "Event Extraction Scenarios"], ["subsection", "Chinese Event Extraction Scenario"]], "content": "Comparing with event extraction in English corpus, Chinese Event Extraction can be regarded as a special case of event extraction, having particular properties and challenges.\nEarly methods~ conduct Chinese EE using elaborately designed linguistic features.\nIn the following, neural network based approaches~ are proposed to reduce the heavy rely on feature engineering.\nNote that comparing with English EE, Chinese EE suffer from the absence of natural word  delimiters and are thus conducted  at token-wise instead of word-wise.\nTo alleviate the semantic limitation at token-wise in Chinese, exquisite methods are designed to incorporate the word-level information to enrich the token semantics.\nSpecifically, Lin et al.~ proposes Nugget Proposal Networks (NPN), which derives hybrid character representations for event trigger tagging, by capturing both the structural and semantic information from characters and words.\nStill, the scope of event triggers in NPN are restricted within a fix-sized window, making it inflexible and suffering from the overlapping between event triggers.\nConsequently, Ding et al.~ propose  Trigger-aware Lattice Neural Network (TLNN), which makes advantage of the Lattice-structure~ to incorporate the word and character semantics.\nSince NPN and TLNN limit that each character could interact with only one matched word, Cui et al.~ propose a heterogeneous graph equipped with two types of nodes (words/characters) and three kinds of edges to maximally preserve word-character interactions.\n\\begin{table*}[!htbp]\n\\centering\n\\caption{Summary statistics for the datasets. (Doc denotes the number of documents in dataset, Sen denotes the number of sentences in dataset).}\n\\label{tab:datasets}\n    \\begin{tabular}{l|ccccl}\n    \\toprule\n    \\textbf{Datasets} & \\textbf{Doc} & \\textbf{Sen} & \\textbf{Event Type} &\\textbf{Language} & \\textbf{Related Papers}  \\\\ \\midrule\n    MUC-4 &  1700  & -  & 5 & -  &  \\\\ \\hline\n    Google & 11,909  & -  & 30  & English  &  \\\\ \\hline\n    Twitter & 1,000 & - & 20 & English &  \\\\ \\hline\n    NO.ANN, NO.POS, NO.NEG (DCFEE) & 2,976 & - & 4 &  Chinese &  \\\\\\hline\n    ChFinAnn (Doc2EDAG) & 32,040 & - & 5 & Chinese &  \\\\ \\hline\n    ACE 2005 & 599 & 18,117 & 33 & Multi-language &  \\\\ \\hline\n    TAC KBP 2015 & 360 & 12,976 & 38 & English &  \\\\ \\hline\n    TAC KBP 2016& 500 & 9,042 & 18 & Multi-language &  \\\\ \\hline\n    Rich ERE & 50  &  &  & English &  \\\\ \\hline\n    FSED & - & 70,852 & 100 & English &  \\\\ \\hline\n    GNBusiness & 12,985 & 1,450,336  & - & English &  \\\\ \\hline\n    FSD & - & 2,453 & 20 & English &  \\\\ \\hline\n    FBI dataset & - & - & 3 & English &  \\\\ \\bottomrule\n    RAMS & 3,993 & - & 139 & English &  \\\\ \\bottomrule\n    WIKIEVENTS & 246 & 6,132 & - & English &  \\\\ \\bottomrule\n    MAVEN & 4,480 & 49,873 & 168 & English &   \\\\ \\bottomrule\n\\end{tabular}\n\\end{table*}", "cites": [1699, 1698, 1663, 1670, 1667, 1679, 1697, 7060], "cite_extract_rate": 0.3235294117647059, "origin_cites_number": 34, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.5, "critical": 3.0, "abstraction": 3.0}, "insight_level": "medium", "analysis": "The section provides an analytical overview of Chinese event extraction by highlighting linguistic differences and methodological adaptations compared to English EE. It synthesizes key contributions from several cited papers (e.g., NPN, TLNN, and the heterogeneous graph approach by Cui et al.) to create a narrative around overcoming token-level limitations. However, the critical evaluation is somewhat limited, with only general mentions of issues like inflexibility and overlapping triggers. Some pattern recognition is evident, but broader principles or frameworks are not deeply abstracted."}}
{"id": "248944b3-dec6-4aad-81e4-2a8873bf25b1", "title": "Sentence-level", "level": "subsection", "subsections": [], "parent_id": "80698e1c-cc51-4079-85e5-4575dfb9d764", "prefix_titles": [["title", "A Survey on Deep Learning Event Extraction: Approaches and Applications"], ["section", "Event Extraction Corpus"], ["subsection", "Sentence-level"]], "content": "\\myparagraph{Automatic Content Extraction (ACE) }\nThe ACE 2005 is the most widely-used dataset in event extraction. It contains a complete set of training data in English, Arabic, and Chinese for the ACE 2005 technology evaluation.\nThe corpus consists of various types of data annotated for entities, relationships, and events by the Language Data Alliance (LDC).\nIt includes 599 documents with 8 event types, 33 event subtypes, and 35 argument roles \\footnote{https://catalog.ldc.upenn.edu/LDC2006T06}. \n\\myparagraph{Text Analysis Conference Knowledge base Filling (TAC KBP)} \nAs a standalone component task in KBP, the goal of TAC KBP event tracking (from 2015 to 2017) is to extract information about the event so that it is suitable for input into the knowledge base. \nTAC KBP 2015 $\\footnote{https://tac.nist.gov/2015/KBP/data.html}$ defines 9 different event types and 38 event subtypes in English. TAC KBP 2016 $\\footnote{https://tac.nist.gov/2016/KBP/data.html}$ and TAC KBP 2017 $\\footnote{https://tac.nist.gov/2017/KBP/data.html}$ have corpora in three languages: English, Chinese, and Spanish, where they own 8 event types and 18 event subtypes. \n\\myparagraph{Rich ERE} \nIt extends entities, relationships, and event ontologies, and extends the concept of what is Taggable.\nRich ERE also introduced the concept of event jumping to address the pervasive challenge of event co-referencing, particularly with regard to event references within and between documents and granularity changes in event arguments, paving the way for the creation of (hierarchical or nested) cross-document representations of events.\n\\myparagraph{FSED}\nBased on ACE 2005 and TAC KBP 2017, FSED dataset~\nis a generated dataset tailored particularly for few-shot scenario. In details, it contains 70,852 mentions with 19 event types and 100 event subtypes. \n\\myparagraph{GNBusiness}\nGNBusiness  collects news reports from Google Business News to describe each event from different sources. It obtains 55,618 business articles with 13,047 news clusters in 288 batches from Oct. 17, 2018, to Jan. 22, 2019.\nThe full text corpus is released as GNBusinessFull-Text $\\footnote{https://github.com/lx865712528/ACL2019-ODEE}$.\n\\myparagraph{FSD} \nThe first story detection (FSD) dataset  is a story detection dataset including 2,499 tweets.\nResearchers filter out events mentioned in fewer than 15 samples considering events mentioned in several samples are usually not important. It includes 2,453 tweets with 20 events types.\n\\myparagraph{FBI dataset} \nThe FBI’s city-level hate crime reports (FBI) dataset  is built by scraping about 370k unlabeled news articles in the “Fire and Crime” category of Patch. It contains two classes for classifying if there is a specific hate crime in the text. Furthermore, it labels the attributes of hate crime articles.\n\\begin{table}[t]\n\t\\centering\n\t\\caption{The notations used in evaluation metrics.}\n\t\\label{tab:metrics}\n\t\\label{Metrics}\n\t\\resizebox{\\columnwidth}{!}{\n    \\renewcommand\n    \\scalebox{0.98}{\n\t\\begin{tabular}{p{43pt}<{\\centering}p{250pt}<{\\centering}}\\toprule\n\t\t\\textbf{Notations} & \\textbf{Descriptions} \\\\\n\t\t\\midrule\n\t    $T$&The reference trigger\\\\\n        $TD$&The detected trigger\\\\\n        $N_{T}$&The actual number of triggers\\\\\n        $N_{TD}$&The number of detected triggers\\\\\n        $T_{t}$&The true event type\\\\\n        $TD_{t}$&The detected event type\\\\\n        $A$&The reference argument\\\\\n\t    $AD$&The detected argument\\\\\n\t    $N_{A}$&The actual number of arguments\\\\\n\t    $N_{AD}$&The number of detected arguments\\\\\n\t    $A_{r}$&The detected argument role\\\\\n\t    $AD_{r}$&The number of detected arguments\\\\\n\t\t\\bottomrule\n\t\\end{tabular}\n\t}}\n\\end{table}\n\\begin{table*}[t]\n\\centering\n\\caption{Comparison of event extraction methods on ACE 2005 using entity annotations. We show the performance of trigger classification and argument role classification sub-tasks.}\n\\label{ace}\n\\resizebox{\\textwidth}{!}{\n\\begin{tabular}{lcccccccccc}\n\\toprule\n\\multirow{2}{*}{\\textbf{Year-Method}}& \\multirow{2}{*}{\\textbf{Neural Network}} & \\multirow{2}{*}{\\textbf{External Resource}} &\\multirow{2}{*}{\\textbf{Paradigm}}  & \\multicolumn{3}{c}{\\textbf{Trigger Classification}}       & \\multicolumn{3}{c}{\\textbf{Role Classification}}             \\\\\\cline{5-10}\n  & &  &  & \\textbf{P}     &\\textbf{R}      & \\textbf{F1}   & \\textbf{P}       & \\textbf{R}      & \\textbf{F1}   \\\\\\hline \n2008 - Ji et al.       & -     & -  &-  & 60.2 & 76.4 & 67.3     & 51.3    & 36.4     & 42.6    \\\\\\hline  \n2010 - Liao et al.  & -  & - &-  & 68.7  & 68.9   & 68.8    & 45.1  & 44.1  & 44.6   \\\\\\hline \n2011 - Hong et al.     & -  & - &-  & 72.9  & 64.3     & 68.3   & 51.6   & 45.5     & 48.4    \\\\\\hline \n2013 - Li et al.  & - & -  &-& 73.7 & 62.3 & 67.5 & 64.7 & 44.4 & 52.7   \\\\\\hline \n2015 - Nguyen et al.   & \\checkmark  & - &- & 71.8  & 66.4  & 69.0  & -    & -   & -     \\\\\\hline \n2015 - DMCNN    & \\checkmark & - &Pipeline & 75.6       & 63.6  & 69.1     & 62.2  & 46.9    & 53.5     \\\\\\hline \n2016 - JRNN  & \\checkmark   & - &Joint & 66.0  & 73.0   & 69.3   & 54.2   & 56.7   & 55.4  \\\\\\hline \n2016 - JOINTEVENTENTIT   & -  & - &Joint  & 75.1  & 63.3  & 68.7  & 70.6   & 36.9   & 48.4   \\\\\\hline \n2016 - NC-CNN   & \\checkmark   & - &- & -  & -  & 71.3 & -  & -  & -  \\\\\\hline \n2016 - HNN  & \\checkmark  & - &- & 84.6  & 64.9  & 73.4  & -  & -   & -    \\\\\\hline \n2016 - BDLSTM-TNNs &  \\checkmark  &  - & Joint &  75.3 & 63.4 & 68.9  & 62.9  & 47.5   & 54.1    \\\\\\hline\n2017 - DMCNN-MIL   & \\checkmark  & \\checkmark  &Joint   & 75.5  & 66.0    & 70.5  & 62.8  & 50.1 & 55.7       \\\\\\hline   \n-\n2018 - DEEB-RNN   & \\checkmark  & - &Pipeline & 72.3  & 75.8 & 74  & -  & -   & -    \\\\\\hline\n2018 - SELF   & \\checkmark   & - &Pipeline & 71.3  & 74.7 & 73.0  & -  &-    &   -  \\\\\\hline\n2018 - GMLATT  &  \\checkmark & - &Joint  & 78.9  & 66.9 & 72.4  &  - &  -  & -    \\\\\\hline\n2018 - Zeng et al.       & \\checkmark  &\\checkmark & Pipeline & \\textbf{85.3}  & 79.9 & \\textbf{82.5}  & 41.9  & 34.6   &  37.9   \\\\\\hline\n2019 - Liu et al.       & \\checkmark  &  -& Joint & 62.5  & 35.7 &  45.4 & -  &  -  & -    \\\\\\hline\n2019 - GAIL-ELMo  &   \\checkmark &  - & Joint & 74.8  & 69.4 & 72.0  & 61.6  &  45.7  &  52.4   \\\\\\hline\n2019 - HMEAE  &  \\checkmark  &  -& Joint &  - & - &  - &  62.2 &  56.6  & 59.3    \\\\\\hline\n2019 - JointTransition      & \\checkmark  & - & Joint  &  74.4 & 73.2 & 73.8  & 55.7  & 51.1   &  53.3   \\\\\\hline\n2019 - PLMEE   &  \\checkmark &  - & Joint & 81.0  & \\textbf{80.4} & 80.7  & 62.3  &  54.2  & 58.0    \\\\\\hline\n2021-Li et al.    &  \\checkmark  &  -& - & -  & - &71.1   & -  &  - &53.7   \\\\\\hline\n2021-GATE (En2ZH)    & \\checkmark  &  -& Joint & -  & - & -  & -  &  - & 63.2  \\\\\\hline\n2021-CasEE   &  \\checkmark  &  -& Joint & 77.9  & 78.5 &78.2   & \\textbf{71.3}  &  \\textbf{71.5} &\\textbf{71.4}   \\\\\n\\bottomrule\n\\end{tabular}\n}\n\\end{table*}\n\\begin{table*}[t]\n\\centering\n\\caption{Comparison of event extraction methods on ACE 2005 without using entity annotations. Even Text2Event model does not use token annotations. We show the performance of trigger classification and argument role classification sub-tasks.}\n\\label{ace05}\n\\resizebox{\\textwidth}{!}{\n\\begin{tabular}{lcccccccccc}\n\\toprule\n\\multirow{2}{*}{\\textbf{Year-Method}}& \\multirow{2}{*}{\\textbf{Neural Network}} & \\multirow{2}{*}{\\textbf{External Resource}} &\\multirow{2}{*}{\\textbf{Paradigm}}  & \\multicolumn{3}{c}{\\textbf{Trigger Classification}}       & \\multicolumn{3}{c}{\\textbf{Role Classification}}             \\\\\\cline{5-10}\n  & &  &  & \\textbf{P}     &\\textbf{R}      & \\textbf{F1}   & \\textbf{P}       & \\textbf{R}      & \\textbf{F1}   \\\\\\hline \n2016 - Liu et al.   & \\checkmark  & \\checkmark &Joint & 77.6   & 65.2  & 70.7 & - & -   & -  \\\\\\hline \n2016 - Huang et al.& \\checkmark  & \\checkmark &Joint  & \\textbf{80.7}  & 50.1  & 61.8  & 51.9  & 39.4   & 44.8     \\\\\\hline\n2016 - RBPB & \\checkmark  & - &Pipeline & 70.3  & 67.5 & 68.9  & 54.1  &  53.5  &  53.8   \\\\\\hline\n2017 - Liu et al.  & \\checkmark  & - &Pipeline& 78.0 & 66.3  & 71.7 & -  & -  & -   \\\\\\hline \n2018 - DEEB-RNN   & \\checkmark  & - &Pipeline & 72.3  & 75.8 & 74  & -  & -   & -    \\\\\\hline\n2018 - SELF   & \\checkmark   & - &Pipeline & 71.3  & \\textbf{74.7} & 73.0  & -  &-    &   -  \\\\\\hline\n2018 - GMLATT  &  \\checkmark & - &Joint  & 78.9  & 66.9 & 72.4  &  - &  -  & -    \\\\\\hline\n2019 - Joint3EE      &  \\checkmark &  - & Joint&  68.0 & 71.8 &  69.8 & 52.1  &  52.1  & 52.1    \\\\\\hline\n2019 - Chen et al. &  \\checkmark  &  - & Joint & 66.7  & 74.7 & 70.5  & 44.3  &  40.7  &  42.4   \\\\\\hline\n2019 - DYGIE++  & \\checkmark  & - & Joint  & -  & - & 69.7  &  - &  -  & 48.8    \\\\\\hline\n2020 - Chen et al.   &  \\checkmark &  -& Pipeline & 66.7  & 74.7 & 70.5  & 44.3  &  40.7  & 42.4    \\\\\\hline\n2020 - MQAEE   &  \\checkmark &  -& Pipeline & -  & - & \\textbf{73.8}  & -  &  - & \\textbf{55.0}    \\\\\\hline\n2020 - Du et al.   &  \\checkmark &  - &Pipeline & 71.1  & 73.7 & 72.3  & \\textbf{56.7}  &  50.2  & 53.3    \\\\\\hline\n2021-Text2Event   &  \\checkmark &  -& Joint & 69.6  &74.4 & 71.9  & 52.5 &  \\textbf{55.2} & 53.8    \\\\\n\\bottomrule\n\\end{tabular}\n}\n\\end{table*}", "cites": [452, 1681, 1683, 1669, 1672, 1667, 1697, 1682, 1680], "cite_extract_rate": 0.23076923076923078, "origin_cites_number": 39, "insight_result": {"type": "comparative", "scores": {"synthesis": 2.0, "critical": 2.0, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section provides a factual comparison of datasets and includes a table with performance metrics of various methods on ACE 2005. However, it lacks synthesis of ideas across the cited papers, minimal critical evaluation of their approaches, and does not abstract broader patterns or principles. It primarily serves as a descriptive and comparative overview without deeper analytical insight."}}
{"id": "632088f6-5f98-492f-ad23-876794763b26", "title": "Quantitative Results", "level": "section", "subsections": [], "parent_id": "d94801ff-a764-4596-9ca6-d904958ff3d5", "prefix_titles": [["title", "A Survey on Deep Learning Event Extraction: Approaches and Applications"], ["section", "Quantitative Results"]], "content": "\\label{Section 8}\nThis section mainly summarizes existing event extraction work and compares performance on the ACE 2005 dataset, as shown in Table \\ref{ace} and \\ref{ace05}. \nThe evaluation metrics include precision, recall, and F1.\nIn recent years, event extraction methods are primarily based on deep learning models.\nAs shown in Table \\ref{ace}, in terms of the value of F1, the deep learning-based method is superior to the machine learning-based method and pattern matching method in both event detection and argument extraction. GATE (En2ZH)\\footnote{En2ZH means that the model trained on English and evaluated on Chinese.}  is under single-source transfer from English to Chinese, which performs well on argument role classification task. Li et al.  propose a document-level neural event argument extraction model. It is applied for ACE 2005 for zero-shot event extraction seen all event types.\nWe can get the validity of the event extraction method based on deep learning models.\nIt may indicate that the deep learning-based method can better learn the dependencies among arguments in the event extraction task.\nIn the deep learning-based model, the BERT-based approach performs the best, both in Table \\ref{ace} and \\ref{ace05}.\nIt shows that BERT can better learn the context information of the sentence and learn word representation according to the current text. It better learns the semantic association of words in the current context and helps to learn the association between arguments.\nComparing the pipeline based methods (RBPB , and DEEB-RNN ) with the join based methods (JRNN , and DBRNN ) without Transformer , it can be seen that the event extraction method of the joint model is better than the pipeline model, especially for the argument role classification task.\nFrom DMCNN , and DMCNN-MIL , it can be concluded that when external resources are used on deep learning-based methods, the effect is significantly improved and slightly higher than the joint model.\nZeng et al.  introduce external resources, improving the performance of trigger classification on precision and F1. Thus, it may show that increasing external knowledge is an effective method, but it still needs to be explored to introduce external knowledge into the argument extraction.", "cites": [1680, 38, 452], "cite_extract_rate": 0.3, "origin_cites_number": 10, "insight_result": {"type": "comparative", "scores": {"synthesis": 3.0, "critical": 2.5, "abstraction": 3.0}, "insight_level": "medium", "analysis": "The section provides a comparative overview of different event extraction methods on the ACE 2005 dataset, integrating results from multiple studies. While it does compare pipeline and joint models and highlights the performance of BERT-based approaches, the synthesis is limited to performance metrics and does not deeply connect theoretical or methodological ideas across papers. The critical analysis is minimal, merely stating possible reasons for performance differences without deeper evaluation or critique of the methods."}}
{"id": "672a327e-df86-44d0-bf0b-116fb50f62bc", "title": "Event Extraction Applications", "level": "section", "subsections": ["dd3f5205-5221-4688-b9d3-d4ba98c7fc53", "55d02c85-ef8f-453b-b81f-4cd876deee1c", "b64a63db-b6f7-48fe-a477-ed977e837355"], "parent_id": "d94801ff-a764-4596-9ca6-d904958ff3d5", "prefix_titles": [["title", "A Survey on Deep Learning Event Extraction: Approaches and Applications"], ["section", "Event Extraction Applications"]], "content": "\\label{Section 9}\nIn this section, we introduce several event-related applications, which can be regarded as direct downstream tasks of event extraction.\nGenerally, the identified events can be used for event graph construction~, event evolution analysis~ and other event-based NLP applications~, such as question answering~ and reading comprehension~.\nAmong the tasks, we focus on three widely researched tasks associated with events, namely script event prediction (SEP), event factuality identification (EFI) and event relation extraction (ERE).", "cites": [7500, 1700, 7499], "cite_extract_rate": 0.5, "origin_cites_number": 6, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 1.5, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section briefly introduces event-related applications and mentions three downstream tasks but does not deeply synthesize or connect the cited papers into a coherent narrative. It lacks critical evaluation of the works and generalization to broader principles, focusing instead on a surface-level description of each application."}}
{"id": "dd3f5205-5221-4688-b9d3-d4ba98c7fc53", "title": "Event Factuality Identification", "level": "subsection", "subsections": [], "parent_id": "672a327e-df86-44d0-bf0b-116fb50f62bc", "prefix_titles": [["title", "A Survey on Deep Learning Event Extraction: Approaches and Applications"], ["section", "Event Extraction Applications"], ["subsection", "Event Factuality Identification"]], "content": "Event factuality identification (EFI) aims to identify the degree of certainty about whether events actually occur or not in the real world, which can be seen as a downstream task of EE in event knowledge graph construction~.\nGenerally, event factuality can be classified into five categories~: certain positive (certainly happening, CT+), certain negative (certainly not happening, CT-), possible positive (possibly happening, PS+), possible negative (possibly not happening, PS-) and underspecified (events’ factuality cannot be identified, Uu).\nTherefore, an EFI model ought to be able to predict the factuality of the event that is PS+.\nMost existing EFI studies focus on the sentence-level task~. The early works on this task mainly employ rule-based methods~ or machine learning methods with manually designed features~. In recent years, neural networks have been introduced into the EFI task, and achieve state-of-the-art performance~, which usually adopt generative adversarial networks~ or graph neural networks~ to capture enriched textual information.\nDespite these successful efforts, sentence-level event factuality can easily encounter expression conflicts in texts. \nTo this end, Qian et al.~ propose the document-level EFI task with adversarial neural network. \nBesides, Cao et al.~ further exploits the uncertainty of local information and the global structure within documents, and achieves significant improvements on document-level EFI task.", "cites": [1702, 1701], "cite_extract_rate": 0.1111111111111111, "origin_cites_number": 18, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.5, "critical": 2.5, "abstraction": 3.0}, "insight_level": "medium", "analysis": "The section provides a clear analytical overview of event factuality identification, integrating key concepts from the cited papers and distinguishing between sentence-level and document-level approaches. While it mentions the use of neural networks, GANs, and GNNs, and references recent contributions like Qian et al. and Cao et al., it lacks deeper comparative analysis or critique of the methods. The abstraction level is moderate, as it introduces a general classification of factuality but does not fully synthesize broader principles across the literature."}}
{"id": "55d02c85-ef8f-453b-b81f-4cd876deee1c", "title": "Event Relation Extraction", "level": "subsection", "subsections": [], "parent_id": "672a327e-df86-44d0-bf0b-116fb50f62bc", "prefix_titles": [["title", "A Survey on Deep Learning Event Extraction: Approaches and Applications"], ["section", "Event Extraction Applications"], ["subsection", "Event Relation Extraction"]], "content": "Extracting event relations is an important yet challenging task for constructing event knowledge graph~, which aims to detect the relations between the identified events, and thus can also be seen as the downstream tasks of event extraction. \nGenerally, existing event relation extraction studies (ERE) mainly focus on three event relation types, including co-referential relation, causal relation and temporal relation.\nSince the three relation types are usually investigated separately and have no consistent task formulation so far, this section will briefly introduce the above three event relation extraction problems separately as different tasks. \nFor more detailed event relation extraction reviews, we recommend the readers to Liu et al.~.\n\\myparagraph{Event Coreference Resolution}\nEvent coreference resolution (ECR) aims to identify whether the candidate events refer to the same event in the real-world, where those events may appear across several sentences.\nExisting methods~ usually formulate ECR as a classification or ranking problem, and mainly focus on the contextual features around the two events, such as syntactic features, event topic information and linguistic features~.\nTo enrich the clues for resolution, existing works also exploit document-level or topical structures~, event argument information~ and other event-related task information~, such as event detection~ and entity recognition~.\n\\myparagraph{Event Causal Relation Extraction}\nEvent causal relation extraction (ECE) aims to identify the event causal relation~ and distinguish the cause and effect between two events, which benefits to the real-world event evolution understanding and thereby promotes event detection and event prediction. \nAccording to the utilized evidence, the ECE methods can be manifested in two groups: \n1) the methods exploiting internal information, which assume that the textual contexts contain sufficient clues for causal relation extraction, where the contextual features including syntactic features, lexical features, explicit causal patterns~, statistic causal association~, and document-level structures~.\n2) the methods exploiting external information, which enhances the textual representation with external knowledge, such as pre-trained language model~, and causal-related commonsense or knowledge base~.\nThere are also studies~ employing distant supervision from knowledge base to alleviate the data sparsity issue in ECE.\n\\myparagraph{Event Temporal Relation Extraction}\nEvent temporal relation extraction (ETE) aims to understand the temporal order among events in the texts.\nMost existing studies on ETE follow the TimeML format~, which is widely used to markup events, time expressions and temporal relations.\nGenerally, existing ETE studies can be roughly divided into three groups:\n1) rules-based methods, which infers the temporal relation for events relying on temporal rules, such as syntactic analyzers~, regular expression patterns over tokens~, and other linguistic rules~.\n2) machine learning-based methods, which leverages statistical temporal contextual features and achieve the task with statistical classifiers~. \n3) neural models, which captures temporal relations with neural networks, such as CNNs and LSTMs~.\nMore external features are also considered in neural models, including dependency paths~, domain knowledge~, contextualized language models~ and so on.", "cites": [1705, 1706, 1707, 1175, 8478, 1704, 1703, 8479, 1708], "cite_extract_rate": 0.28205128205128205, "origin_cites_number": 39, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.5, "critical": 2.0, "abstraction": 2.3}, "insight_level": "medium", "analysis": "The section organizes the cited works into three distinct event relation extraction tasks and summarizes their general methodologies. However, it lacks deeper synthesis or critical evaluation of the cited papers, merely grouping them by task and describing their approaches. Some abstraction is present in the form of task-level categorization, but broader trends or principles are not clearly identified."}}
{"id": "b64a63db-b6f7-48fe-a477-ed977e837355", "title": "Script Event Prediction", "level": "subsection", "subsections": [], "parent_id": "672a327e-df86-44d0-bf0b-116fb50f62bc", "prefix_titles": [["title", "A Survey on Deep Learning Event Extraction: Approaches and Applications"], ["section", "Event Extraction Applications"], ["subsection", "Script Event Prediction"]], "content": "Script~ is a chain of ordered events describing activities about a protagonist, and Script Event Prediction (SEP) aims to predict the subsequent event of a given chain from a candidate event list.\nAs an important task to understand the evolutionary patterns among events, SEP has supported various downstream applications, including anaphora resolution~, story generation~ and finalcial analysis~.\nIn SEP, each event is represented in the form of a tuple $e=v(s, o, p)$, where $v, s, o, p$ are the event arguments respectively denoting the verb, subject, object and indirect-object of the event.\nFor example, $e = give(waiter, bob, water)$ means that ``A waiter gives bob water''.\nBy far, the most widely used benchmark for SEP is NYT dataset~, where the event chains are extracted from  the New York Times (NYT) portion of the Gigaword corpus~.\nThe dataset consists   140,331/10,000/10,000 event chains  for training/validation/test. \nEach event chain contains 8 events  and has 5 candidate events where only one is the correct subsequent event.\nNext, we introduce the details about existing SEP works.\nExisting SEP works could be categorized into two groups.\nThe \\textbf{first} line of works  mainly focus on the event co-occurrence relation to predict the subsequent from three aspects.\nSpecifically, early works~ model the \\textit{event-pair-level} semantic relation to predict the subsequent event of the given event chain.\nFurther, to alleviate semantics limitation to event chain, Lv et al.~ regard the given event chain as a combination of several \\textit{event-segments} and capture clues from diverse event segments to facilitate the  event prediction.\nIn the following, researchers encode the full \\textit{event-chain}~ to grasp semantic signals to predict subsequent  event.\nWang et al.~ and Zheng et al.~ also employ the graph structure to model the event chain.\nThe \\textbf{second} line of works integrate external knowledge to help understand the scripts, since the absence of text contexts makes the semantics in scripts more sparse than normal texts.\nSpecifically, Ding et al.~ utilize knowledge bases, Event2Mind~ and ATlas Of MachIne Commonsens (ATOMIC)~, to refine  sentiment and intention information  to enrich the semantics of the script.\nFurther, Lv et al. ~ incorporate event knowledge base ASER (Activities, States, Events and their Relations)~ to provide causal and temporal relations between events to predict the subsequent event, achieving great success in this task.", "cites": [1684, 350, 8480, 1709], "cite_extract_rate": 0.3157894736842105, "origin_cites_number": 19, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 2.5, "abstraction": 3.5}, "insight_level": "medium", "analysis": "The section synthesizes multiple SEP approaches effectively, grouping them into two main lines of work based on event co-occurrence and external knowledge integration. It abstracts these works into broader categories, showing some generalization. However, while it mentions certain advancements (e.g., graph-based methods, use of knowledge bases), it lacks deeper critical evaluation of their strengths, weaknesses, or limitations, which constrains the level of insight."}}
