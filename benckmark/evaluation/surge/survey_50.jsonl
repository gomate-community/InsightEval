{"id": "faad7f9d-9374-486c-98ae-37a7d6392f0a", "title": "Introduction", "level": "section", "subsections": [], "parent_id": "12251930-629c-43b6-96fe-1bbcd729d008", "prefix_titles": [["title", "Generative Adversarial Networks for Spatio-Temporal Data: A Survey"], ["section", "Introduction"]], "content": "Spatio-temporal (ST) properties are commonly observed in various fields, such as transportation , social science  and criminology , among which have been rapidly transformed by the proliferation of sensor and big data. However, the vast amount of ST data requires appropriate processing techniques to build effective applications. Generally, traditional data mining methods dealing with transaction data or graph data could perform poorly when applied to ST datasets. The reasons are mainly two-fold  : (1) ST data are often in continuous space while traditional data (e.g., transaction data, graph data) are usually discrete; (2) ST data usually have spatial and temporal attributes where the data correlations are more complex to be captured by traditional techniques. Moreover, ST data tend to be highly self-correlated, and data samples are usually not generated independently as in traditional data. \nWith the prevalence of deep learning, many neural networks (e.g., \\textit{Convolutional Neural Network} (CNN) , \\textit{Recurrent Neural Network} (RNN) , \\textit{Autoencoder} (AE) , \\textit{Graph Convolutional Network} (GCN) ) have been proposed and achieved remarkable success for modelling ST data, due to its demonstrated potential for hierarchical feature engineering ability. However, the traditional deep learning based ST modelling methods have some limitations. For instance, existing methods use deterministic models (e.g., RNN) and cannot capture the stochastic behaviour of ST data. Additionally, traditional deep learning approaches lack effective mechanisms to support the reasoning of the abstract data, which makes it hard to identify the factors leading to model improvements . To address the above challenges, we have explored  one of the most interesting breakthroughs in the deep learning field: \\textit{Generative Adversarial Networks} (GANs) , which can learn rich distributions over ST data implicitly and work with multi-model outputs . \nGAN is a generative model which learns to produce realistic data adversarially. It consists of two components  : the generator $G$ and discriminator $D$. $G$ captures the data distribution and produces realistic data from the latent variable $z$, and $D$ estimates the probability of the data coming from the real data space. GAN adopts the concept of the zero-sum non-cooperative game where $G$ and $D$ are trained to play against  each other until reaching a Nash equilibrium. Recently, GANs  have gained considerable attention in various fields , involving images (e.g., image translation , super-resolution , joint image generation , object detection , change facial attributes ), videos (e.g., video generation , text to video ), and natural language processing (e.g., text generation , text to image ). \nHowever, image or video generation approaches are not applicable for modelling traditional ST data (e.g., time series, trajectories, ST events, ST graphs) in real-world applications such as traffic flow, regional rainfall, and pedestrian trajectory. On the one hand, image generation usually takes the appearance between the input and output images into account, and fails to adequately handle spatial variations. On the other hand, video generation considers spatial dynamics between images, however, temporal changes are not adequately considered when the prediction of the next image is highly dependent on the previous image . Though the video can be regarded as a special type of ST data due to its  dynamic locations in spatial and temporal dimensions, the discussion of using GANs for video generation usually falls into the field of computer vision, where several papers have thoroughly reviewed the recent progress of video generation with GANs . Hence, new approaches need to be explored to successfully modelling ST data with GAN techniques.\nRecently, GANs have been applied to ST data modelling, where the applications usually include the generation of de-identified ST events , time series imputation , trajectory prediction , graph representation , etc. Despite the success of GANs in the computer vision area (e.g., image and video generation), applying GANs to ST data prediction is challenging . For instance, leveraging additional information such as \\textit{Places of Interest (PoI)} and weather information is still untouched in previous research. Besides, different from the images where researchers could rely on visual inspections of the generated instances, evaluation of GANs on ST data remains an unsolved problem. It is neither practical nor appropriate to adopt the traditional evaluation metrics for GAN on ST data .\nA few studies reviewed recent literature on ST data modelling problems or GAN based applications in different fields. For ST data modelling, Atluri et al.  reviewed the popular problems and methods for modelling ST data. A taxonomy of the different types of ST data instances has been provided to identify the relevant problems for ST data in real-world applications. Then, Wang et al.  reviewed the recent progress in applying deep learning to ST data mining tasks and proposed a pipeline of the utilisation of deep learning models for ST data modelling problems. For GAN based applications, Hong et al.  explained the GANs from various perspectives and enumerated popular GAN variants applied to multiple tasks. Recent progress of GANs was discussed in  and Wang et al.  proposed a taxonomy of GANs for the computer vision area. Particularly, Yi et al.  reviewed the recent advances of GANs in medical imaging. \nNevertheless, all the above works reviewed either ST data modelling problems or the recent progress of GANs in the computer vision area . Though many researchers  have modelled ST data with GANs, there is no related survey in this area to address the potential of using GANs for ST data applications. The lack of a comprehensive review makes it more difficult for researchers to identify the problems and choose an appropriate method (e.g., architecture, loss function, evaluation metric) when applying GAN techniques for ST applications. For the first time, this paper presents a comprehensive overview of GANs for ST data, describes promising applications of GANs, and identifies some remaining challenges needed to be solved for enabling successful applications in different ST related tasks.\nTo present a comprehensive overview of all the relevant research on GANs for ST data, we use \\textit{Google Scholar} \\footnote{https://scholar.google.com/} to conduct automated keyword-based search . According to , Google Scholar provides coverage and accessibility, and digital libraries such as \\textit{IEEE Explore} \\footnote{https://ieeexplore.ieee.org/}, \\textit{Science Direct} \\footnote{https://www.sciencedirect.com/}, \\textit{ACM Digital Library} \\footnote{https://dl.acm.org/}. \nThe search period is limited from 2014 to 2021 (inclusive) as the GAN has first appeared in 2014 . However, papers that introduce novel concepts or approaches for ST data mining can be predated 2014. To ensure that our survey covers all relevant primary literature, we have included such seminal papers regardless of their publication date.\nThe remainder of the paper is organised as follows. In Section \\ref{sec:pre}, we discuss the properties, characteristics and common research problems of ST data. We also present the popular deep learning methods with non-GAN frameworks for ST data, including the \\textit{Convolutional Neural Networks}, \\textit{Recurrent Neural Networks}, \\textit{Long Short-term Memory} and \\textit{Gated Recurrent Units}. Section \\ref{sec:gan} reviews the definition of GAN and its popular variants with different architecture and loss functions. Section \\ref{sec:st} lists the recent research progress for GANs in different categories of ST  applications. Section \\ref{sec:dis} summarises the challenges of processing ST data with GANs, including the adapted architectures, loss functions and evaluation metrics. Finally, we conclude the paper and discuss future research directions.", "cites": [986, 981, 7009, 987, 76, 983, 978, 8403, 985, 87, 988, 980, 982, 984, 896, 989, 979], "cite_extract_rate": 0.4722222222222222, "origin_cites_number": 36, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.5, "abstraction": 4.0}, "insight_level": "high", "analysis": "The introduction section synthesizes key ideas from multiple cited papers to establish a coherent narrative on the application of GANs to spatio-temporal data. It critically points out limitations of traditional deep learning and GAN-based methods in computer vision when applied to ST data. The section also abstracts the discussion to highlight broader challenges, such as the need for domain-specific adaptations and evaluation metrics, positioning the survey as filling a meaningful gap in the literature."}}
{"id": "d447d205-f296-42e7-bb99-90cbb93bf139", "title": "Properties", "level": "subsubsection", "subsections": [], "parent_id": "546dd4c0-3daf-449c-9b7e-6153f28e086a", "prefix_titles": [["title", "Generative Adversarial Networks for Spatio-Temporal Data: A Survey"], ["section", "Preliminary"], ["subsection", "Spatio-temporal Data"], ["subsubsection", "Properties"]], "content": "There are several general properties for ST data (i.e., spatial reference, time reference, auto-correlation, and heterogeneity ) described as below.\n\\textbf{Spatial Reference}. The spatial reference describes whether the objects are associated with the fixed location or dynamic locations . Traditionally, when the data is collected from stationary sensors (e.g., weather stations), we consider the spatial dimension of the data is fixed. Recently, with the boost of mobile computing and location-based services, the dynamic locations of moving objects have been recorded where the collected data comes from sensors attached to different objects, e.g., GPS trajectories from road vehicles . \n\\textbf{Temporal Reference}. The temporal reference describes to what extent the objects evolve . The simplest context includes objects that do not evolve where only the static snapshots of objects are available. In a slightly more complicated situation, objects can change status but only the most recent update snapshot remains where the full history of status is unknown. The extreme context consists of moving objects where the full history of moving is kept, therefore generating time series where all the status have been traversed. \n\\textbf{Auto-correlation}. The observations of ST data are not independent and usually have spatial and temporal correlations between near measurements. For example, in the transportation area, sensors in each parking lot with the unique spatial location can record the temporal information when a vehicle arrives or leaves . This auto-correlation of ST data results in the smoothness of temporal measurements (e.g., temperature changes over time) and consistency between the spatial measurements (e.g., temperature values are similar in adjacent locations). Thereby, the traditional GAN techniques for the computer vision field (e.g., image generation ) without considering the temporal correlation may not well suited for the ST data. \n\\textbf{Heterogeneity}. ST dataset can show heterogeneity in spatial or temporal information on different levels. For instance, traffic flow in a city can show similar patterns between different weeks. During a week, the traffic data on Monday may be different from data on Friday. There can also be inter-week changes due to public events or extreme weather, affecting the traffic patterns in a city. To deal with the heterogeneity of spatial and temporal information, it is necessary to learn different models for different spatio-temporal regions .", "cites": [983, 991, 990], "cite_extract_rate": 0.5, "origin_cites_number": 6, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 1.5, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section provides a basic description of the properties of spatio-temporal data but lacks significant synthesis of the cited papers. It does not effectively connect ideas across the works or present a cohesive analytical framework. Additionally, it offers minimal critical evaluation or abstraction beyond the specific examples mentioned."}}
{"id": "f243b06f-a5ed-4bd1-bd12-71ab06676ad0", "title": "Data Types", "level": "subsubsection", "subsections": [], "parent_id": "546dd4c0-3daf-449c-9b7e-6153f28e086a", "prefix_titles": [["title", "Generative Adversarial Networks for Spatio-Temporal Data: A Survey"], ["section", "Preliminary"], ["subsection", "Spatio-temporal Data"], ["subsubsection", "Data Types"]], "content": "There are various spatio-temporal data types in real-world applications, differing in the representation of space and time context . Hence, it is crucial to establish the available ST data types in applications to effectively use GAN methods. Here, we describe the four common types of ST data which have been studied with GANs recently: (1) time series ; (2) ST events ; (3) ST graphs ; (4) trajectory data . Among the above four types of ST data, ST events and trajectories capture the observations of discrete objects and events. At the same time, the time series and ST graphs record the information of continuous or discrete ST fields. Though there are other types of ST data available in real-world scenarios, in some cases they can be converted into another, or they can be processed with similar GAN approaches to the above four types (e.g., sequential data vs time series).  Next, we briefly discuss the properties of those data types and potential difficulties when facing with GANs. \n\\textbf{Time Series}.\nA time series can be represented as a sequence of data points $X=\\{X_1,X_2,...,X_n\\}$ listed in an order of time (i.e., sequence of discrete-time data ). Examples of time series include the values of indoor temperature during a day , the changes of accelerometer readings in the IoT devices , fluctuations of the stock price in a month , etc. Time series analysis consists of techniques to analyse time series for extracting useful statistic information and data characteristics. The common questions used for dealing with time series include but not limited to:\n\\textit{Can we predict future values for time series based on the historical values ?}\n\\textit{Can we cluster groups of time series with similar temporal and spatial patterns  ?}\n\\textit{Can we impute the missing values automatically in multi-variate time series ?}\n\\textit{Can we split time series into different segments with its characteristic properties ?} \n\\textbf{Spatio-temporal Events}.\n\\begin{figure}\n    \\centering\n    \\subfigure[Spatio-temporal events]{ \\includegraphics[width=0.35\\textwidth]{Images/STevents.png}\\label{fig:STevents}}\\hspace{0.6cm}\n    \\subfigure[Two trajectories]{\\includegraphics[width=0.43\\textwidth]{Images/Trajectory.pdf}\n    \\label{fig:Traj}}\n    \\caption{Examples of spatio-temporal events and trajectories}\n\\end{figure}\nAn spatio-temporal event represents a tuple containing temporal, spatial information as well as an additional observed value . Generally, it is denoted as $x_i = \\{m_i,t_i,l_i\\}$, where $t_i$ and $l_i$ indicates the time and location of the event, $m_i$ means the value to describe the event. Typically, the locations are recorded in three dimensions (i.e., latitude, longitude, and altitude or depth),  although sometimes only 1 or 2 spatial coordinates are available. Spatio-temporal events (see Figure ~\\ref{fig:STevents}) are frequently used in real-world applications such as the taxi demand , traffic flow , urban crimes , forest fires , etc. In some cases, spatio-temporal events may even have duration like parking or heliophysics . Usually, an ordered set of spatio-temporal events can also be considered as an trajectory where the spatial locations visited by moving objects. Some common questions that used for analysing spatio-temporal events includes: \\textit{Can we predict the future spatio-temporal events based on the previous observations ?} \\textit{How are spatio-temporal events clustered based on time and space ?} \\textit{Can we identify the anomalous spatio-temporal events that do not follow the common patters of other events ?}\n\\textbf{Trajectory data}.\nA trajectory represents the recordings of locations of a moving object at certain times and it is usually defined as a function mapped from the temporal domain to the spatial domain . Trajectories of moving points can be denoted as a sequence of tuples\n$P =\\{(x_1,y_1,t_1),(x_2,y_2,t_2),...,(x_n,y_n,t_n)\\}$, where $(x_i,y_i,t_i)$ indicates the location $(x_i,y_i)$ at time $t_i$. Several research have been conducted in the field of trajectory data mining and there are four major categories : mobility of people , mobility of transportation , mobility of natural phenomena and mobility of animals . Figure ~\\ref{fig:Traj} shows an example of two trajectories of object $A$ and object $B$. The common questions for processing trajectory data include:  \n\\textit{Can we predict the future trajectory based on the historical trajectory traces ?} \n\\textit{Can we divide a collection of trajectories into small representative groups ?}\n\\textit{Can we detect the abnormal behaviours from trajectories ? } \n\\textbf{Spatio-temporal Graph}.\n\\begin{figure}\n    \\centering\n    \\includegraphics[width=0.9\\textwidth]{Images/Graphall.pdf}\n    \\caption{Example of Spatio-temporal Graph Data}\n    \\label{fig:graph}\n\\end{figure}\nSpatio-temporal graph structure provides the representation of the relations between different nodes in different time.  A sequence of spatio-temporal graphs  can be represented as $\\mathcal{G}=(\\mathcal{G}_1, \\mathcal{G}_2,...,\\mathcal{G}_n)$ where $\\mathcal{G}_i = \\{V_i, E_i, W_i\\}$ indicates the graph snapshot at time $T_i$ ($i\\in \\{1,2,...,n\\}$). Spatio-temporal graphs have been applied in various domains such as commerce (e.g., trades between countries ), transportation (e.g., route planning algorithms , traffic forecasting ) and social science (e.g., studying geo-spatial relations of different social phenomena ). Figure~\\ref{fig:graph} is an example of spatio-temporal graphs in $T_1, T_2, T_3$. Some common questions for processing spatio-temporal graph includes:\n\\textit{Can we forecast the status of graph based on the historical graph representations ? }\n\\textit{Can we predict the links based on the previous graph networks ? }", "cites": [981, 1000, 983, 996, 989, 999, 993, 998, 994, 995, 8404, 25, 997, 979, 7320, 992], "cite_extract_rate": 0.34, "origin_cites_number": 50, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 1.5, "abstraction": 2.5}, "insight_level": "low", "analysis": "The section provides a descriptive overview of spatio-temporal data types and lists example applications and research questions. While it references several papers, it does so mainly to support definitions and examples, without substantial synthesis of their findings or methods. There is little critical evaluation or abstraction to broader principles."}}
{"id": "761a1176-7f65-46e8-ac85-1c1afba325e2", "title": "CNN", "level": "subsubsection", "subsections": [], "parent_id": "df6448fb-1ac2-4885-9808-b1f891145edd", "prefix_titles": [["title", "Generative Adversarial Networks for Spatio-Temporal Data: A Survey"], ["section", "Preliminary"], ["subsection", "Spatio-Temporal Deep Learning with Non-GAN Networks"], ["subsubsection", "CNN"]], "content": "\\iffalse\n\\begin{figure}\n    \\centering\n    \\includegraphics[width=0.85\\textwidth]{Images/CNN.pdf}\n    \\caption{Basic structure of a typical CNN model}\n    \\label{fig:cnn}\n\\end{figure}\n\\fi\n\\textit{Convolutional Neural Network} (CNN)  is a type of deep, feed-forward neural network commonly used to analyse visual imagery. A typical CNN model is composed of an input layer, an output layer and some hidden layers. \nCompared to the traditional multilayer perceptron (MLP), CNNs can develop internal representations of two-dimensional images, allowing CNNs to be used more generally on other types of data with spatial correlations. Though CNNs are not specifically developed for non-image data, it has been widely used in ST data mining problem for trajectory and ST raster data .", "cites": [990], "cite_extract_rate": 0.5, "origin_cites_number": 2, "insight_result": {"type": "descriptive", "scores": {"synthesis": 1.5, "critical": 1.0, "abstraction": 1.0}, "insight_level": "low", "analysis": "The section provides a basic, factual description of CNNs and their applicability to spatio-temporal data, but it lacks meaningful synthesis of the cited paper (Paper 1). It does not elaborate on how CNNs are used in specific spatio-temporal contexts or compare their strengths and weaknesses with other methods. There is no critical analysis or abstraction of broader patterns or principles."}}
{"id": "c4195f9a-68a2-4774-9c80-3084131b53b3", "title": "RNN, LSTM and GRU", "level": "subsubsection", "subsections": [], "parent_id": "df6448fb-1ac2-4885-9808-b1f891145edd", "prefix_titles": [["title", "Generative Adversarial Networks for Spatio-Temporal Data: A Survey"], ["section", "Preliminary"], ["subsection", "Spatio-Temporal Deep Learning with Non-GAN Networks"], ["subsubsection", "RNN, LSTM and GRU"]], "content": "\\textit{Recurrent Neural Network (RNN)}  is a type of neural networks where the previous outputs are fed as the input to the current step.\nThe advantage of RNN is the hidden state (internal memory) that captures information calculated so far in a sequence. Figure~\\ref{fig: rnn} shows the basic architecture of an RNN, where $X$ is the input data, $y$ is the output data, $h$ is the hidden state and $U, V, W$ indicates the parameters of the RNN. The current state $h_t$ is calculated by the current input $X_t$ and previous state $h_{t-1}$. \n\\iffalse\n\\begin{figure}\n    \\centering\n    \\includegraphics[width=0.4\\textwidth]{Images/LSTM.pdf}\n    \\caption{Structure of a typical LSTM unit}\n    \\label{fig:lstm}\n\\end{figure}\n\\fi\nThough the RNNs work effectively in many application domains, they may suffer from a problem called vanishing gradients . To cope with this problem, two variants of RNN have been developed: Long Short-Term Memory (LSTM)  and Gated Recurrent Units (GRU) networks . LSTM is capable of learning long-term dependencies with a special memory unit. An LSTM cell has three gates (forget gate, input gate, and output gate) to regulate the information flow. \nCompared with standard LSTM models, GRU has fewer parameters which combines the input gate and the forget gate into an 'update gate' and merges the cell state and hidden state. RNN, LSTM and GRU are widely used to learn the temporal correlations of time series and ST data.\n\\iffalse\n\\begin{figure}\n    \\centering\n    \\includegraphics[width=0.50\\textwidth]{Images/RNN.pdf}\n    \\caption{Basic structure of a typical RNN model}\n    \\label{fig:rnn}\n\\end{figure}\n\\begin{figure}\n    \\centering\n    \\includegraphics[width=0.45\\textwidth]{Images/Autoencoder.pdf}\n    \\caption{Structure of a typical Autoencoder}\n    \\label{fig:autoencoder}\n\\end{figure}\n\\fi\n\\begin{figure}\n\t\\centering\n\t\\subfigure[RNN]{\n\t\\label{fig: rnn}\n\t{\\includegraphics[height=1.1in]{Images/RNN.pdf}}\n\t}\n\t\\hspace{0.15in}\n\t\\subfigure[Autoencoder]{\n\t\\label{fig:autoencoder}\n\t\\includegraphics[height=1.1in]{Images/Autoencoder.pdf}\n    }\n    \\caption{Structure of RNN and Autoencoder }\n\\end{figure}", "cites": [7321], "cite_extract_rate": 0.25, "origin_cites_number": 4, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 2.0, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section provides a basic descriptive overview of RNN, LSTM, and GRU, mentioning their structures and purposes. It cites Paper 1 but only briefly refers to it without integrating its contributions or insights into the discussion. There is minimal synthesis, no critical evaluation of the cited work, and no abstraction to broader principles or trends in spatio-temporal deep learning."}}
{"id": "11aa9f14-0e0b-4a89-b29d-048e4b033d82", "title": "Autoencoder (AE)", "level": "subsubsection", "subsections": [], "parent_id": "df6448fb-1ac2-4885-9808-b1f891145edd", "prefix_titles": [["title", "Generative Adversarial Networks for Spatio-Temporal Data: A Survey"], ["section", "Preliminary"], ["subsection", "Spatio-Temporal Deep Learning with Non-GAN Networks"], ["subsubsection", "Autoencoder (AE)"]], "content": "AE  is a neural network that is trained to copy its input to its output by learning data codings in an unsupervised manner . The network is composed of two parts: encoder and decoder, as shown in Figure~\\ref{fig:autoencoder}. The encoder function compresses the input into a latent-space representation and the decoder reconstructs the input through the representation. \nAs a commonly used unsupervised representation learning method, AE is popular for classification and prediction tasks in trajectories , time series  and other ST data .", "cites": [166], "cite_extract_rate": 0.16666666666666666, "origin_cites_number": 6, "insight_result": {"type": "descriptive", "scores": {"synthesis": 1.5, "critical": 1.0, "abstraction": 1.5}, "insight_level": "low", "analysis": "The section provides a basic description of autoencoders and their general function without effectively synthesizing information from the cited papers. It does not critically evaluate the AE approach in the context of spatio-temporal data or compare it with other methods. The content remains concrete and lacks abstraction or identification of broader trends or principles."}}
{"id": "cb3e1cc9-6af4-469c-8de4-19707a4fc0df", "title": "Graph Convolutional Network (GCN)", "level": "subsubsection", "subsections": [], "parent_id": "df6448fb-1ac2-4885-9808-b1f891145edd", "prefix_titles": [["title", "Generative Adversarial Networks for Spatio-Temporal Data: A Survey"], ["section", "Preliminary"], ["subsection", "Spatio-Temporal Deep Learning with Non-GAN Networks"], ["subsubsection", "Graph Convolutional Network (GCN)"]], "content": "With the ability to extract representations from both local graph structure and node features, GCN  has become popular in solving learning tasks on spatio-temporal graph dataset. For instance, Yu et al. introduced Spatio-Temporal Graph Convolutional Networks (STGCN)  to solve the prediction problem in traffic networks. Other deep learning models have their issues dealing with ST forecasting tasks, such as RNN-based networks often have heavy computation in training and normal convolutional operations are limited on grid structures. STGCN differently converts traffic data into the graph-structured format and use spatio-temporal convolutional blocks to capture spatial and temporal dependencies. Furthermore, the cost of computation could be reduced by Chebyshev Polynomials Approximation or First Order Approximation. Recently, attention mechanisms have been employed with GCN models to learn the impact of the spatio-temporal factors in training, such as Graph Multi-Attention Network (GMAN)  and Attention-based Spatial-Temporal Graph Convolutional Network (ASTGCN) .", "cites": [25, 32], "cite_extract_rate": 0.5, "origin_cites_number": 4, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.5, "critical": 2.0, "abstraction": 2.3}, "insight_level": "medium", "analysis": "The section provides a basic descriptive overview of GCNs and their application in spatio-temporal data, particularly in traffic forecasting. It mentions two specific papers (STGCN and GMAN) and highlights some of their techniques, such as attention mechanisms and approximation methods. However, it lacks deeper critical analysis or comparative evaluation of these approaches and does not generalize to broader patterns or principles in the field."}}
{"id": "67ffe654-5809-431a-bde2-0c52accd6245", "title": "Basic Idea of GANs", "level": "subsection", "subsections": [], "parent_id": "32a02756-1c44-4fb8-9820-9024dd8f9120", "prefix_titles": [["title", "Generative Adversarial Networks for Spatio-Temporal Data: A Survey"], ["section", "Generative Adversarial Networks"], ["subsection", "Basic Idea of GANs"]], "content": "\\begin{figure}\n    \\centering\n    \\includegraphics[width=0.95\\textwidth]{Images/GANvariants.pdf}\n    \\caption{A view of variants of GAN. $G$ represents the generator network, $D$ is the discriminator network, $z$ represents the noise, $c$ means the class labels, $x_f$ are the generated fake images and $x_r$ are the real images}\n    \\label{fig:variants}\n\\end{figure}\nThe original concept of GANs is to create two neural networks and let them compete against each other. As shown in Figure~ \\ref{fig:variants}, the basic architecture of GANs comprises two components: a generator and a discriminator. On the one hand, the generator's task is to synthesis fake images which can fool the discriminator. On the other hand, the discriminator, as to its name, learns to distinguish if its input is a fake image or not . \nLet's left the images generation task aside. The underlying idea of generative adversarial nets is more general, which is to create one fake distribution $p_g$ and make it as close as possible to a data distribution $p_r$. The reason we use such an approach is that $p_r$ could be hard to get directly and by doing in this manner, we get a good approximation of it and then we can sample from this approximate distribution instead . The advantages of this approach are that since the generator is learning to approximate the real distribution directly, there is no need to introduce the Markov Chain and no inference is required due to the isolation between the generator and the real data distribution. Besides, its simple structure makes it easier to incorporate with other techniques .\nThe Generator $G(z;\\theta_g)$, a neural network that parameterized by theta takes a sample $z \\sim p_z$ as input and mapping that to a sample $x\\sim p_g$. And its rival, the Discriminator $D(x;\\theta_d)$ outputs a single binary value to indicate its prediction of the input's origin. During the training session, both parts are trained simultaneously and based on their opponent's result, which forms a minimax game with the overall objective function :\n\\begin{equation*}\n\\underset{G}{min}\\underset{D}{\\ max} \\ V( D,G) =\\mathbb{E}_{x\\sim p_{data}( x)}[\\log D( x)] +\\mathbb{E}_{z\\sim p_{z}( z)}[\\log( 1-D( G( z)))]\n\\end{equation*}\nDespite all the advantages above, the original generative adversarial network is still inadequate in some places. The practical results show that the training is particularly delicate and the generators may suffer from vanishing gradient for optimizing the generator .  To address all those problems that might occur, many variants of the vanilla GAN are proposed .", "cites": [148, 1001, 529, 76, 1002], "cite_extract_rate": 0.8333333333333334, "origin_cites_number": 6, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 2.0, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section provides a basic overview of GANs, including their architecture and training objective. While it mentions several GAN variants and their purposes, it does not effectively synthesize or connect these ideas across the cited papers. There is limited critical analysis of the cited works and no abstraction to broader principles or frameworks."}}
{"id": "83853cc2-25c4-47f4-abcc-88a75e025b98", "title": "Loss Function", "level": "subsection", "subsections": [], "parent_id": "32a02756-1c44-4fb8-9820-9024dd8f9120", "prefix_titles": [["title", "Generative Adversarial Networks for Spatio-Temporal Data: A Survey"], ["section", "Generative Adversarial Networks"], ["subsection", "Loss Function"]], "content": "In traditional generative modelling approaches, the performance of a model is indicated by the reverse Kullback-Leibler (KL) divergence between our desire distribution $p_r$ and our generator's distribution $p_g$ . \n\\begin{equation*}\nD_{KL}( P_{g} \\| P_{r}) =\\int _{\\chi } P_{g}( x) \\ \\log\\frac{P_{g}( x)}{P_{r}( x)}\\mathrm{d} x\n\\end{equation*}\nMinimising this term means making those two distributions closer, and it would get to zero once $p_r=p_g$. However, the generator might still generate fake-looking data due to the imbalanced nature  of this function. It could heavily penalise the generator for the part that is in the real distribution but not covered by the generator while paying less attention to the extra part covered by the generator. To avoid this weakness,  another option that is discussed in the original GANs paper is called Jensen-Shannon (JS) divergence . \n\\begin{equation*}\nD_{JS}( P_{r} \\| P_{g}) =\\frac{1}{2} D_{KL}\\left( P_{r} \\| \\tfrac{1}{2}( P_{r} +P_{g})\\right) +\\frac{1}{2} D_{KL}\\left( P_{g} \\| \\tfrac{1}{2}( P_{r} +P_{g})\\right)\n\\end{equation*}\nAlthough it shows some promising results, JS divergence is not the ultimate choice since it still suffers from issues like gradient vanishing. Some latest studies show that those can be resolved by using other types of loss function .", "cites": [148, 54, 63], "cite_extract_rate": 0.6, "origin_cites_number": 5, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.0, "critical": 3.5, "abstraction": 3.0}, "insight_level": "medium", "analysis": "The section provides a clear analytical overview of GAN loss functions by introducing the KL divergence, JS divergence, and LSGAN loss. It connects the ideas from multiple papers to explain the evolution of loss functions and the associated training challenges. While it identifies limitations (e.g., gradient vanishing), it does not offer a deep comparative or meta-level critique, keeping the abstraction moderate."}}
{"id": "fc5128eb-1a1b-492c-86a3-a5892d36c294", "title": "Architecture of GAN Variants", "level": "subsection", "subsections": [], "parent_id": "32a02756-1c44-4fb8-9820-9024dd8f9120", "prefix_titles": [["title", "Generative Adversarial Networks for Spatio-Temporal Data: A Survey"], ["section", "Generative Adversarial Networks"], ["subsection", "Architecture of GAN Variants"]], "content": "Although the vanilla GAN shows its potential for data generation , and the discriminator in this structure is proved to be effective on classification task . But it still suffers from blurry and possible mode dropping/collapse. Besides, there is no control in the generation process since its unsupervised manner . To this end, some studies introduce other machine learning techniques into the original GAN structure, and some results are promising. The architecture of those variants is shown in Figure~ \\ref{fig:variants}.\nMirza et al.  proposed CGAN (Conditional GAN), which introduces a support info vector $y$. In the generator, each input $z$ gets its corresponding $y$, and it is also available the discriminator which can help it better judge. Since this vector is a controlled parameter rather than another random sample, we gain some control of the samples generated. Chen et al. , on the other hand, is also focused on providing support info to the generator, and proposed the InfoGAN. A latent code $c$ is adding to the input of the generator, and after the images go through the discriminator, another module $Q$ is introduced to approximate the distribution of $P(c|x)$ and calculate the variational mutual information $I(c; G(z, c))$ which indicates the level of info remains after the generation process. The result generator can be controlled by maximising this regularisation term according to the latent code $c$. Odena et al.  introduced a supervised task into the original GAN and proposed ACGAN (Auxiliary Classifier GAN). Every sample from the real data belongs to a predefined class, and an expected label $c\\sim p_c$ along with noise $z \\sim p_z$ is used as input to generate a data sample of that class. Besides the real/fake discrimination task, an auxiliary classifier is created to classify every sample, enabling the generator's ability to synthesis sample for a particular class.", "cites": [1001, 1003, 529, 1002], "cite_extract_rate": 0.8, "origin_cites_number": 5, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.5, "critical": 2.0, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section provides a basic description of GAN variants (CGAN, InfoGAN, ACGAN) and their architectures, citing relevant papers. However, it lacks deeper synthesis by not connecting the underlying principles or comparing their suitability for spatio-temporal tasks. There is minimal critical analysis or abstraction to broader patterns or principles in GAN design."}}
{"id": "50381dcb-5673-417e-bf1c-f15e9c7de3ee", "title": "GANs for Spatio-temporal Events", "level": "subsection", "subsections": [], "parent_id": "18110330-2f2a-4e5b-86b6-d01be014ca94", "prefix_titles": [["title", "Generative Adversarial Networks for Spatio-Temporal Data: A Survey"], ["section", "GANs for Spatio-temporal Data Modelling"], ["subsection", "GANs for Spatio-temporal Events"]], "content": "In this subsection, we mainly introduce how GANs are applied to predict the ST events (e.g., taxi demand , crime , fluid flows , anomaly detection ) in the future based on the previous events.\n\\newgeometry{,hmargin=0.2cm,vmargin=1cm,landscape}\n\\begin{table}\n \\centering\n   \\footnotesize\n    \\setlength\\tabcolsep{3pt}\n\\caption{Review of Spatio-temporal Data and Modelling Tasks using GAN}\n\\label{tab:category}\n  \\centering\n\\begin{tabular}{@{}lllllll@{}}\n\\toprule\nST data type                   & Reference             & Year & Task            & Values in task                        & Model category     & Evaluation methods                                                             \\\\ \\midrule\n\\multirow{15}{*}{\\textit{Time series}} & C-RNN-GAN     & 2016 & Generation      & Musical data                          & GAN and LSTM       & \\begin{tabular}[c]{@{}l@{}}Domain metrics (e.g., polyphony, scale consistency,   repetitions, tone span)\\end{tabular}\\\\\n                              & RCGAN          & 2017 & Generation      & Medical data                          & GAN and RNN        & TSTR and TRTS                                                                  \\\\\n                              & SSL-GAN       & 2017 & Generation      & Electronic health records             & GAN, CNN and AE    & Prediction accuracy over multiple data combinations                            \\\\\n                              & OccuGAN        & 2018 & Generation      & Occupancy data                        & GAN and DNN        & \\begin{tabular}[c]{@{}l@{}}Domain metrics (e.g., time of first arrival, number of  occupied transitions)\\end{tabular}    \\\\\n                              & Grid-GAN    & 2018 & Generation      & Smart grid data                       & CGAN and CNN       & TSTR and TRTS                                                                  \\\\\n                              & EEG-GAN      & 2018 & Generation      & EEG brain signals                     & WGAN and CNN       & IS, FID and ED                                                                 \\\\\n                              & StockGAN         & 2018 & Generation      & Stock data                            & GAN, CNN and LSTM  & Prediction accuracy (e.g., RMSRE, DPA)                                         \\\\\n                              & GRU-GAN             & 2018 & Imputation      & Medical records, meteorologic data    & GAN and GRU        & Imputation accuracy                                                            \\\\\n                              & ForGAN        & 2019 & Generation      & Synthetic series and internet traffic & CGAN and LSTM      & KL divergence                                                                  \\\\\n                              & NAOMI         & 2019 & Imputation      & Traffic flow, movement data           & GAN and RNN        & Imputation accuracy                                                            \\\\\n                              & TimeGAN       & 2019 & Generation      & Sines, stocks, energy and events data & GAN and AE         & Diversity, fidelity and usefulness (e.g., TSTR)                                \\\\\n                              & E2GAN           & 2019 & Imputation      & Medical records, meteorologic data    & GAN and GRU        & Imputation accuracy                                                            \\\\\n                              & SimGAN         & 2020 & Generation      & Heart rate ECG signals                & GAN                & Prediction accuracy over multiple GAN methods                                  \\\\\n                              & Ad-Attack     & 2020 & Generation      & Stock prices and electricity data     & GAN                & Domain metrics (e.g, attack sucess rate, returned  of perturbed portfolio)     \\\\\n                               & AOS4Rec     & 2020 & Generation      &    Sequences of recommendation  &       GAN and GRU          &   Precision, nDCG and BLEU   \\\\\n                              \\midrule\n\\multirow{9}{*}{\\textit{Trajectory} }  & GD-GAN       & 2018 & Prediction      & Pedestrain trajectories               & GAN and LSTM       & \\begin{tabular}[c]{@{}l@{}}Average displacement error (ADE) and final  displacement error (FDE)\\end{tabular}               \\\\\n                              & SocialGAN       & 2018 & Prediction      & Socailly acceptable trajectories      & GAN and LSTM       & \\begin{tabular}[c]{@{}l@{}}Quantitative (e.g., ADE, FDE) and qualitative  (e.g., group avoiding) metrics \\end{tabular}  \\\\\n                              & SoPhie           & 2019 & Prediction      & Pedestrain trajectories               & GAN and LSTM       & ADE and FDE                                                                    \\\\\n                              & Social Ways     & 2019 & Prediction      & Pedestrain trajectories               & GAN and LSTM       & ADE and FDE                                                                    \\\\\n                              & Social-BiGAT      & 2019 & Prediction      & Pedestrain trajectories               & GAN and LSTM       & ADE and FDE                                                                    \\\\\n                              & APOIR       & 2019 & Prediction      &   Point-of-Interests             &     GAN and GRU  &               Precision, Recall, nDCG and MAP                                    \\\\\n                              & CoL-GAN        & 2020 & Prediction      & Pedestrain trajectories               & GAN, CNN and LSTM  & Average collision times (ACT), ADE and FDE                                     \\\\ \n                               & AdattTUL     & 2020 & Link prediction       &       Human mobility trajectories         &            GAN, GRU and LSTM &  Prediction accuracy over multiple models                             \\\\\n                                & MT-ASTN     & 2020 & Prediction       &       Crowd flow trajectories         &  GAN, AE &        MAE and RMSE over multiple models                     \\\\ \n                               \\midrule\n\\multirow{5}{*}{\\textit{ST events} }   & D-GAN         & 2017 & Prediction      & Taxi and bike data                    & GAN and VAE        & Prediction accuracy over multiple models                                       \\\\\n                              & Taxi-CGAN      & 2020 & Prediction      & Taxi hotspots data                    & CGAN and LSTM      & \\begin{tabular}[c]{@{}l@{}}False identification test (FIT) and the section\n                              consistency test (SCT)\\end{tabular}        \\\\\n                              & Crime-GAN      & 2017 & Prediction      & Crime data                            & DCGAN, CNN and RNN & \\begin{tabular}[c]{@{}l@{}}Prediction accuracy (e.g., JS divergence) over multiple models\\end{tabular}                   \\\\\n                              & MAD-GAN      & 2019 & Prediction      & Cyber-attacks data                    & GAN and LSTM       & DR-score                                                                       \\\\ \n                              \\midrule\n\\multirow{9}{*}{\\textit{Graphs}  }     & GraphGAN       & 2018 & Representation  & Social networks                       & GAN and DNN        & Prediction accuracy over multiple models                                       \\\\\n                              & NetGAN       & 2018 & Representation  & Citation and blogs networks           & WGAN and LSTM      & Prediction accuracy over multiple models                                       \\\\\n                              & ANE            & 2018 & Representation  & Citation and blogs networks           & GAN and DNN        & Prediction accuracy over multiple models                                       \\\\\n                              & NetRA    & 2018 & Representation  & Social and biological networks        & GAN, LSTM and AE   & Prediction accuracy over multiple models                                       \\\\\n                              & GCN-GAN      & 2019 & Link Prediction & Mobility networks                     & GAN, GCN and LSTM  & MSE, edge-wise KL divergence, mismatch rate                                    \\\\\n                              & GANE          & 2019 & Representation  & Coauthor networks                     & WGAN and DNN       & Prediction accuracy over multiple models                                       \\\\\n                              & NetworkGAN    & 2019 & Link Prediction & Social networks                       & GAN, GCN and LSTM  & RMSE, AUC, KL divergence                                                       \\\\\n                              & ProGAN         & 2019 & Representation  & Social and citation networks          & GAN and DNN        & Prediction accuracy over multiple models                                       \\\\\n                              & MEGAN         & 2019 & Representation  & Social multi-view networks            & GAN and MLP        & Prediction accuracy over multiple models    \\\\  \n                                 & GRL     & 2020 & Link Prediction       &      Relation triples and freebase entity pairs      &  GAN, LSTM and RL &        MAE, MAP and AUC over multiple models                                                   \\\\ \\bottomrule \n\\end{tabular}\n\\end{table}\n\\restoregeometry\nFor the first time, Saxena et al.  proposed a generative adversarial network \\textit{D-GAN} for accurate spatio-temporal events prediction. In the model, GAN and VAE are combined to jointly learn generation and variational inference of ST data in an unsupervised manner. They also designed a general fusion module to fuse heterogeneous multiple data sources. Figure~\\ref{fig:dgan} shows the architecture for D-GAN, consisting of four components: \\textit{Encoder}, \\textit{Generator/Decoder}, \\textit{Discriminator}, and \\textit{External feature fusion}. $G$ network is trained using the adversarial process. The decoder (i.e., generator) learns to approximate the distribution of real data, while the $D$ network discriminates between samples generated by $D$ and samples from real distributions. During the training process, D-GAN adopts a reconstruction loss and adversarial loss . In addition, \\textit{ConvLSTM}  and \\textit{3D\n-ConvNet} structures were exploited to model long-term patterns and spatial dependencies in ST data. \nRecently, Yu et al.  applied a conditional generative adversarial network with long short-term structure (LSTM-CGAN) for taxi hotspot prediction, which captures the spatial and temporal variations of hotspots simultaneously. Furthermore, Jin et al.  developed a context-based generative model \\textit{Crime-GAN} to learn the spatio-temporal dynamics of the crime situation. They aggregated Seq2Seq, VAE network and adversarial loss in the framework to study ST data representation better. Furthermore, the deep convolutional generative adversarial network (DCGAN) has been developed for spatio-temporal fluid flow prediction in a tsunami case in Japan . \nGANs have also been used for anomaly detection for ST events. Li et al.  proposed MAD-GAN, an unsupervised anomaly detection method for multivariate time series based on GAN. They trained a GAN generator and discriminator with LSTM. Then, the GAN-trained generator and discriminator are employed to detect anomalies in the testing data with a combined Discrimination and Reconstruction Anomaly Score (DR-Score).\n\\begin{figure}\n    \\centering    \\includegraphics[width=0.95\\textwidth]{Images/dgan.pdf}\n    \\caption{D-GAN architecture proposed by Seaena et al. }\n    \\label{fig:dgan}\n\\end{figure}", "cites": [981, 7009, 40, 1006, 1007, 1000, 1004, 996, 1008, 988, 8404, 989, 7320, 979, 992, 1009, 1005], "cite_extract_rate": 0.4146341463414634, "origin_cites_number": 41, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 2.0, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section primarily provides a descriptive list of papers applying GANs to spatio-temporal events, with minimal synthesis of ideas across the works. It lacks in-depth critical analysis or evaluation of the methods, and does not abstract beyond specific systems to highlight broader patterns or principles in the field."}}
{"id": "788bda59-feb9-4d0f-a421-8989914e21a3", "title": "GANs for Trajectory Prediction", "level": "subsection", "subsections": [], "parent_id": "18110330-2f2a-4e5b-86b6-d01be014ca94", "prefix_titles": [["title", "Generative Adversarial Networks for Spatio-Temporal Data: A Survey"], ["section", "GANs for Spatio-temporal Data Modelling"], ["subsection", "GANs for Trajectory Prediction"]], "content": "Trajectory prediction refers to the problem of estimating the future trajectories of various agents based on the previous observations . Gupta et al.  proposed {SocialGAN} to jointly predict trajectories avoiding collisions for all people. They introduced a variety loss encouraging the generative network of the GAN to spread its distribution and cover the space of possible paths while being consistent with the observed inputs. A new pooling mechanism was proposed to learn a 'global' pooling vector that encodes the subtle cues for all people involved in a scene. In {GD-GAN}~, Fernando et al. designed a GAN based pipeline to jointly learn features for both pedestrian trajectory prediction and social group detection. As the basic GAN structure used in SocialGAN is susceptible to mode collapsing and dropping issues, Amirian et al.~ extended the SocialGAN by incorporating the Info-GAN~ structure in their \\textit{Social Ways} trajectory prediction network.\n\\textit{SoPhie}, proposed by Sadeghian et al.~, is another GAN based trajectory prediction approach that can take both the information from the scene context and social interactions of the agents into consideration.\nTwo separate attention modules are also used to better capture the scene context and the social interactions.\nMore recently, based on BicycleGAN~ framework, Social-BiGAT~ develops the bijection function between the output trajectories and the latent space input to the trajectory generator.\nIt also uses a Graph Attention Network in combination with a VGG network~ to encode social influence from other pedestrians and semantic scene influence of the environment. For trajectories with fewer potential collisions, CoL-GAN~, proposed by Liu et al., exploits a CNN-based network as the trajectory discriminator.\nDifferent from other GAN based trajectory prediction methods such as SocialGAN~ and SoPhie~, the proposed discriminator can classify whether each segment of a trajectory is real or fake. \nRecently, Gao et al.  studied the trajectory user linking problem to identify user identities from mobility\npatterns. They combined autoencoder with GANs for jointly human mobility learning, which provides regularized latent space for mobility classification. APOIR  was developed to learn the distribution of underlying user preferences in the Point-of-interest (POI) recommendation. It consists of two components: the recommender and the discriminator. The recommender approaches users' true preference, and the discriminator distinguishes the generated POIs from the truly visited ones.", "cites": [988, 1007, 514, 9089, 1002, 1006, 979], "cite_extract_rate": 0.5833333333333334, "origin_cites_number": 12, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.5, "critical": 2.0, "abstraction": 2.0}, "insight_level": "medium", "analysis": "The section provides a descriptive overview of various GAN-based trajectory prediction methods, citing their key features and innovations. While it briefly connects papers like SocialGAN and Social Ways by mentioning improvements through Info-GAN, it lacks deeper synthesis or a structured framework. There is minimal critical evaluation of the approaches, and the abstraction remains limited to reiterating the methods without identifying broader trends or principles."}}
{"id": "a0a11f43-a150-4fcc-8f7b-e6c4e6b38925", "title": "GANs for Time Series Modelling", "level": "subsection", "subsections": ["c0263314-29fd-4cd0-a9f4-9f0c2fdf4e40", "33fedc1b-60ae-4f63-b3dc-bee7d61b9211"], "parent_id": "18110330-2f2a-4e5b-86b6-d01be014ca94", "prefix_titles": [["title", "Generative Adversarial Networks for Spatio-Temporal Data: A Survey"], ["section", "GANs for Spatio-temporal Data Modelling"], ["subsection", "GANs for Time Series Modelling"]], "content": "Specifically, time series is assumed to be a special kind of sequential data where the order matters. It is a sequence series obtained at consecutive equally spaced points at the time dimension, and not the only case of sequential data. However, processing the sequential data (e.g., musical data) may share similar GAN approaches to the time series data. Therefore, we will include several studies for modelling sequential data (e.g., musical data in ). Although natural language data can also be considered as sequential data, we will not include the NLP research with GANs (e.g., text generation , text to image ) since the natural language is not one of the ST data types and usually falls into the field of NLP. In this subsection, we will demonstrate two ST tasks for time series data: generation and imputation.", "cites": [992, 76, 8403], "cite_extract_rate": 1.0, "origin_cites_number": 3, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.5, "critical": 2.0, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section provides a basic descriptive overview of GANs applied to time series data, mentioning the distinction between time series and other sequential data types. While it references multiple papers, it does not deeply integrate or synthesize their findings into a coherent narrative. There is minimal critical analysis or abstraction to broader principles, focusing instead on categorization and brief mention of applications."}}
{"id": "c0263314-29fd-4cd0-a9f4-9f0c2fdf4e40", "title": "Generation", "level": "subsubsection", "subsections": [], "parent_id": "a0a11f43-a150-4fcc-8f7b-e6c4e6b38925", "prefix_titles": [["title", "Generative Adversarial Networks for Spatio-Temporal Data: A Survey"], ["section", "GANs for Spatio-temporal Data Modelling"], ["subsection", "GANs for Time Series Modelling"], ["subsubsection", "Generation"]], "content": "Data generation refers to creating data from the sampled data source. One of the main purposes of time series generation with GAN is to protect the privacy of sensitive data such as medical data , electroencephalographic  (EEG) data ,  heart signal electrocardiogram (ECG) data , occupancy data , electronic health records (EHR) , etc.\nRecently, GANs have been used to generate sequential data. Mogren et al.  proposed C-RNN-GAN (continuous RNN-GAN) to generate continuous-valued sequential data. They built the GAN with an LSTM generator and discriminator. The discriminator consists of a bidirectional layout which allows it to take context in both directions into account for its decisions. They trained the model on sequences of classical music and evaluated with metrics such as polyphony, scale consistency, repetitions and tone span. \nThen, Esteban et al.  proposed a regular GAN where recurrent neural networks have substituted both the generator and the discriminator. They presented the Recurrent GAN (RGAN) and Recurrent Conditional GAN (RCGAN) to generate sequences of real-valued medical data or data subject to some conditional inputs. For evaluation, they proposed to use the capability of the generated synthetic data to train supervised models, i.e., TSTR (train on synthetic, test on real). They addressed that TSTR is more effective than TRTS (train on real, test on synthetic) because TRTS performance may not degrade when GAN suffers mode collapse. \nGANs have been used for the generation of biological-physiological signals such as EEG and ECG.  Hartmann et al.  proposed EEG-GAN to generate electroencephalographic (EEG) brain signals. With the modification of the improved WGAN training, they trained a GAN to produce artificial signals in a stable fashion which strongly resembles single-channel real EEG signals in the time and frequency domain. For evaluation metrics, they showed that the combination of Frechet inception distance (FID) and sliced Wasserstein distance (SWD), Euclidean distance (ED) can give a good idea about its overall properties. Golany et al.  proposed the simulator-based GANs for ECG synthesis to improve a supervised classification. They incorporated ECG simulator equations into the generation networks, and then the generated ECG signals are used to train a deep network.\nChen et al.  proposed GAN framework for building occupancy modelling. They first learned the discriminator and generator in the vanilla GAN with the training occupancy data. Then, the learned generator is the required occupancy model, which can be used to generate occupancy data with random inputs. To evaluate, they defined five variables (i.e., mean occupancy, time of the first arrival, time of the last departure, cumulative occupied duration and the number of occupied/unoccupied transitions) with two criteria (i.e., normalised root mean squared error and total variation distance).\nChe et al.  used a modified GAN called \\textit{ehrGAN} to generate plausible labelled EHR data. The generator is a modified encoder-decoder CNN network, and the generated EHR data mimics the real patient records which augments the training dataset in a semi-supervised learning manner. In this work, they used the generative networks with the CNN prediction model to improve the performance of risk prediction.\nKoochali et al.  proposed \\textit{ForGAN} to predict the next-step time series value $X_{t+1}$ by learning the full conditional probability distribution. They applied a conditional GAN and the condition windows are the previous $t$ values  ($X_0, X_1,...,X_t$). With the input of the noise vector, the generator predicts the values at the $t+1$ step and then the discriminator compared this value to the true value at the $t+1$ step with the same condition windows. LSTM network is used in both generator and discriminator. Zhou et al.  predicted the stock price at next time step $y_{t+1}$ based on the features in previous t time step $X_1,X_2,...,X_t$ and previous stock price $y_1, y_2,...,y_t$ using generative adversarial nets. \nInstead of generating a sequence of single values, Dang et al.  developed an approach for the generation of adversarial attacks where the output is a sequence of probability distributions. The proposed approaches are demonstrated on two challenging tasks: the prediction of electricity consumption and stock market trading. Besides, AOSeRec  were proposed to generate a sequence of items consistent with user preferences rather than the next-item prediction. The model integrated the sequence-level oracle and adversarial learning into the seq2seq auto-regressive learning.\nGenerally, an excellent time-series generative model should preserve temporal dynamics, and the generated sequences should follow the original patterns between variables across time. Therefore, Yoon et al.  proposed a framework \\textit{TimeGAN} for producing realistic multivariate time-series, combining the flexibility of the unsupervised GAN approach with the control afforded by supervised learning. In addition to the traditional unsupervised adversarial loss on both real and fake data, they presented a stepwise supervised loss with the original data as supervision, which helps learn from the transition dynamics in real sequences. \n\\begin{figure}\n    \\centering\n    \\includegraphics[width=0.9\\textwidth]{Images/GANE1.pdf}\n    \\caption{An overview of the time series imputation framework proposed by Luo et al. }\n    \\label{fig:GANE1}\n\\end{figure}", "cites": [992, 996, 1008, 989, 7320], "cite_extract_rate": 0.4166666666666667, "origin_cites_number": 12, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.0, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section effectively synthesizes information from multiple papers, connecting GAN-based approaches for time series generation across diverse domains such as medical data, EEG/ECG signals, and occupancy modeling. It demonstrates critical analysis by discussing evaluation methods and pointing out limitations like mode collapse in the context of TSTR. Additionally, it abstracts broader principles, such as the importance of temporal dynamics and the integration of conditional and supervised learning for better sequence modeling."}}
{"id": "33fedc1b-60ae-4f63-b3dc-bee7d61b9211", "title": "Imputation", "level": "subsubsection", "subsections": [], "parent_id": "a0a11f43-a150-4fcc-8f7b-e6c4e6b38925", "prefix_titles": [["title", "Generative Adversarial Networks for Spatio-Temporal Data: A Survey"], ["section", "GANs for Spatio-temporal Data Modelling"], ["subsection", "GANs for Time Series Modelling"], ["subsubsection", "Imputation"]], "content": "In real-world applications, time series are usually incomplete due to various reasons, and the time intervals of observations are usually not fixed . The missing values in time series make it hard for effective analysis . One popular way to handle the missing values of time series is to impute the missing values to get the complete dataset. Generally, there are three different ways for time series imputation: case deletion methods , statistical imputation methods , and machine learning based imputation methods . However, all the existing approaches hardly consider the temporal relations between two observations. In recent years, researchers have started to take advantages of GANs to learn latent representations between observations for time series imputation .\nLuo et al.  applied the adversarial model to generate and impute the original incomplete time series. To learn the latent relationships between observations with non-fixed time lags, a novel RNN cell called GRUI was proposed, which considers the non-fixed time lags and fades the influence of the past observations determined by the time lags. They proposed a two-stage model  (see Figure~ \\ref{fig:GANE1}) for time series imputation: In the first stage, they adopted the GRUI in the discriminator and generator in GAN to learn the distribution and temporal information of the dataset. In the second stage, for each sample, they tried to optimise the 'noise' input vector and find the best-matched input vector of the generator. The noise was trained with a two-part loss function: masked reconstruction loss and discriminative loss. Masked reconstruction loss is the masked squared errors of the non-missing part between the original and generated sample. It means that the generated time series should be close enough to the original incomplete time series. The discriminative loss forces the generated sample as real as possible. However, this two-stage model needs a considerable time to find the best-matched input vector, which is not always the best, especially when the initial value of the 'noise' is not set properly. \nThen, Luo et al.  proposed an end-to-end GAN-based imputation model E$^2$GAN which not only simplifies the process of time series imputation but also generates more reasonable values for the filling of missing values. E$^2$GAN takes a compressing and reconstructing strategy to avoid the 'noise' optimisation stage in . As seen in Figure ~\\ref{fig:GANE2}, in the generator (a denoising auto-encoder), they added a random vector to the original sample and map it into a low-dimensional vector. Then they reconstructed it from the low-dimensional vector. The generator seeks to find a network structure that can best compress and reconstruct the multivariate time series and fool the discriminator. Then they used the reconstructed sample to impute the missing values.\n\\begin{figure}\n    \\centering\n    \\includegraphics[width=0.9\\textwidth]{Images/GANE2.pdf}\n    \\caption{An overview of E$^2$GAN framework proposed by Luo et al. }\n    \\label{fig:GANE2}\n\\end{figure}\nNon-Autoregressive Multiresolution Imputation (NAOMI)  is a new model for the imputation of spatio-temporal sequences like traffic flow data and movement trajectories when arbitrary missing observations are given. NAOMI imputes missing values for spatio-temporal sequences recursively from coarse to fine-grained resolutions with a non-autoregressive decoding procedure. It further employs a generative adversarial learning process to reduce variance for improving the performance.", "cites": [1005], "cite_extract_rate": 0.14285714285714285, "origin_cites_number": 7, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.5, "critical": 2.0, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section provides a descriptive overview of GAN-based methods for time series imputation, primarily summarizing the approaches of Luo et al. and NAOMI. It offers minimal synthesis by only sequentially presenting these methods without connecting them to broader themes or contrasting them meaningfully. There is limited critical analysis, as the section mentions a drawback (slow optimization in the two-stage model) but does not deeply evaluate the limitations or compare the approaches. Abstraction is weak, with no clear generalization of principles or patterns across the cited works."}}
{"id": "e27d5917-5584-4f9a-8525-2f908b6efb75", "title": "Temporal Link Prediction", "level": "subsubsection", "subsections": [], "parent_id": "537a7111-41c9-435b-aef5-8ccbd033d1ca", "prefix_titles": [["title", "Generative Adversarial Networks for Spatio-Temporal Data: A Survey"], ["section", "GANs for Spatio-temporal Data Modelling"], ["subsection", "GANs for Spatio-temporal Graph Modelling"], ["subsubsection", "Temporal Link Prediction"]], "content": "Temporal link prediction refers to the dynamics prediction problem in network systems (e.g., mobility and traffic prediction) where system behaviours are described by the abstract graphs . Given the snapshots of a graph in previous timestamps, the temporal link prediction task aims to construct the graph topology at the next timestamp. Lei et al.  proposed GCN-GAN to predict links in weighted dynamic networks. They combined graph convolutional network (GCN), long short-term memory (LSTM) as well as generative adversarial network (GAN). The generator consists of a GCN hidden layer, LSTM hidden layer and a fully connected layer. Discriminator contains a fully connected feed-forward network. For evaluation, they used edge-wise KL divergence and mismatch rate besides mean square error (MSE). Then, Yang et al.  designed an attentive GCN model for temporal link prediction in graphs using GAN. Compared to , attentive GCN allows for assigning different importance to the vertices to learn the spatial features of the dynamic network. Then, temporal matrix factorisation (TMF) LSTM was employed to capture dynamic networks' temporal dependencies and evolutionary patterns. GAN framework was then proposed to improve the performance of temporal link prediction. \nRecently, Want et al.  have designed a GAN-based reinforcement learning model (GRL) for knowledge graph completion, which employs both WGAN and LSTM to record trajectories and generate sub-graph sequences. In addition, the deep deterministic policy gradient approach (DDPG) is adopted to optimise both reward and adversarial loss and generates better policies, which leads to more stable training compared with the traditional optimization method.", "cites": [1000], "cite_extract_rate": 0.3333333333333333, "origin_cites_number": 3, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.5, "critical": 2.0, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section provides a basic descriptive overview of different GAN-based approaches for temporal link prediction but lacks deeper synthesis, critical evaluation, or abstraction. It lists models and components without comparing their strengths or weaknesses or identifying broader trends in the field."}}
{"id": "afc0ba4c-0209-4291-9a7c-de1c28b50605", "title": "Graph Representation", "level": "subsubsection", "subsections": [], "parent_id": "537a7111-41c9-435b-aef5-8ccbd033d1ca", "prefix_titles": [["title", "Generative Adversarial Networks for Spatio-Temporal Data: A Survey"], ["section", "GANs for Spatio-temporal Data Modelling"], ["subsection", "GANs for Spatio-temporal Graph Modelling"], ["subsubsection", "Graph Representation"]], "content": "Wang et al.  proposed GraphGAN unifying two types of graph representation methods: discriminative methods and generative methods via adversarial training. They found that the traditional softmax function and its variants are not suitable for the generator for two reasons: (1) softmax treats all vertices equally in the graph for a given vertex and does not consider the graph structure and proximity information; (2) the calculation of softmax involves all vertices in the\ngraph which is time-consuming and computationally inefficient. Therefore, they introduced \\textit{graph softmax} as the implementation of the generator and proved that it satisfies the desirable properties of normalisation, computational efficiency and graph structure awareness.\n\\begin{table}\n\\small\n\\setlength\\tabcolsep{2pt}\n\\caption{Summary of Datasets}\n\\label{tab:dataset}\n\\begin{tabular}{@{}llll@{}}\n\\toprule\nST data type                  & Dataset                                                                 & Data source                                       & Used references                                                       \\\\ \\midrule\n\\multirow{10}{*}{\\textit{Time series}} & Philips eICU database            & Medical data  &                                                          \\\\\n                              & MNIST                                                                    & Hand-written digit images                         &                                                          \\\\\n                              & Occupancy dataste                  & Occupancy data in the building                    &                                                      \\\\\n                              & Pecan street dataset               & Energy consumption, solar generation           &                                                    \\\\\n                              & PhysioNet dataset            & Medical data (e.g., heart rate, glucose)          &                     \\\\\n                              & KDD cup 2018 dataset                     & Air quality data                                  &                                      \\\\\n                              & A5M dataset                      & Transatlantic link data                           &                                                   \\\\\n                              & PEMS-SF traffic dataset               & Freeway occupancy rate                            &                                                       \\\\\n                              & Appliances energy dataset  & Environmental data                                &                                                           \\\\ \n                              & UCI electricity dataset          & Historical price data                             &                 \\\\ \n                              &  Yoochoose         &   Clicking events from users                         &                                                                \\\\ \n                               & MovieLens         &   Movie ratings data                          &                                                                      \\\\ \n                               \\midrule\n\\multirow{8}{*}{\\textit{Trajectory}}   & ETH                                                                     & Videos                          &                                                                       \\\\\n                              & UCY                                                                     & Videos                           &                                                                       \\\\\n                              & Stanford drone dataset                                            & Videos                    &                                                                       \\\\\n                              & Vittorio emanuele II                        & Videos                          &                                                                                    \\\\\n                              & Foursquare          &         Location-based social networks               &                                                                                  \\\\\n                               & Gowalla      & Location-based social networks                         &                                                                                  \\\\\n                               & Brightkite         &      Location-based social networks                   &                                                                                  \\\\\n                               & Yelp        &  Location-based social networks                       &                                                                                  \\\\\n                              \\midrule\n\\multirow{3}{*}{\\textit{ST events}}    & Yellow taxi dataset                      & Taxi demand data                                  &                                                        \\\\\n                              & CitiBike trip dataset                   & Bike demand data                                  &                                                        \\\\\n                              & SWaT dataset                      & Attacked data in water system                     &                                             \\\\ \\midrule\n\\multirow{8}{*}{\\textit{Graphs}}       & ArXiv-AstroPh                               & Scientific collaborations data                    &                                                     \\\\\n                              & Wikipedia             & Network of words                                  &\n                                             \\\\\n                              & CORA                                & Citation networks of publications                 &                      \\\\\n                              & CiteSeer               & Citation networks of publications                 &                        \\\\\n                              & DBLP                          & Collaboration graph of authors                    &   \\\\\n                              & Blogcatalog                   & Social network for bloggers                       &                   \\\\\n                              & UCI message dataset                   & Message communication networks                    & \n                                                             \\\\\n                              & Flickr                                & Social networks                                   &                                        \\\\ \\bottomrule\n\\end{tabular}\n\\end{table}\nAiming at better capturing the essential properties and preserving the patterns of real graphs, Bojchevski et al. introduced NetGAN  to learn a distribution of network via the random walks. The merits of using random walks are their invariance under node reordering and efficiency in exploring the sparse graphs by merely traversing the nonzero entries. The results confirmed that the combination of longer random walks and LSTM is advantageous for the model to learn the topology and general patterns in the data. \nAdversarial Network Embedding (ANE)  also considers the random walk mechanism to learn network representation with the adversarial learning principle. It consisted of two components: (1) the structure-preserving component is developed to extract network structural properties via either Inductive DeepWalk or Denoising Autoencoder; (2) the adversarial learning component contributes to learning network representations by matching the posterior distribution of the latent representations to given priors. However, using DeepWalk for learning graph embedding could lead to an overfitting issue due to sparsity is common in networks or increasing computational burden when more sampled walks are considered . Therefore, NetRA  was proposed to further minimise network locality-preserving loss and global reconstruction error with a discrete LSTM Autoencoder and continuous space generator, such that the mapping from input sequences into vertex representations could be improved.\nMost recently, GAN embedding (GANE)  tries to gain the underlying graph distribution based on the probability distribution of edge existence which is similar to GraphGAN. The difference is that this model applies Wasserstein-1 distance as the overall objective function and intends to achieve link prediction and network embedding extraction simultaneously. As a novel network embedding method, the proximity generative adversarial network (ProGAN)  is proposed to capture the underlying proximity between different nodes by approximating the generated distribution of nodes in a triplet format to the underlying proximity in the model of GAN. Specifically, a triplet can encode the relationship among three nodes, including similarity and dissimilarity. After the training of the generator and discriminator, the underlying proximities discovered are then used to build network embedding with an encoder.\nThe works mentioned above primarily focus on the single-view network in learning network embedding. However, numerous real-world data are represented by multi-view networks whose nodes have different types of relations. Sun et al.  introduced a new framework for multi-view network embedding called MEGAN, which can preserve the information from individual network views, while considering nodes connectivity within one relation and complex correlations among different views. During the training of MEGAN, a pair of nodes are chosen from the generator based on the fake connectivity pattern across views produced by multi-layer perceptron (MLP), and the discriminator is then executed to differentiate the real pair of nodes from the generated one.", "cites": [7009, 8405, 1007, 1004, 1008, 988, 652, 8404, 1010, 989, 7320, 979, 1009, 1006, 1005], "cite_extract_rate": 0.24193548387096775, "origin_cites_number": 62, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.5, "critical": 2.0, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section provides a descriptive overview of selected papers on graph representation using GANs, but it lacks a deeper synthesis of ideas or a coherent narrative connecting them. While it mentions some limitations (e.g., computational inefficiency of softmax, overfitting with DeepWalk), the analysis remains superficial without substantial evaluation or comparison of approaches. There is minimal abstraction beyond individual papers, and the table of datasets appears to be more for listing than for analytical use."}}
{"id": "b5137191-acb7-40ac-b088-b3ff2bf8a01a", "title": "Architectures and loss functions of GANs", "level": "subsubsection", "subsections": [], "parent_id": "4f2e9bda-6ba6-4650-9895-7996a4f3651f", "prefix_titles": [["title", "Generative Adversarial Networks for Spatio-Temporal Data: A Survey"], ["section", "Discussion"], ["subsection", "Challenges and Future Directions"], ["subsubsection", "Architectures and loss functions of GANs"]], "content": "In the computer vision area, fully connected layers were initially used as building blocks in vanilla GAN, but later on were replaced by convolutional layers in DCGAN . Compared with images with only spatial relations, modelling ST data is more complex due to the constraints from both spatial and temporal dimensions. Therefore, adapting architectures and loss functions of GANs for specific ST applications have become the mainstream recently.\nGenerally, original or adapted RNN   , LSTM , VAE , CNN , GNN  are usually used as the base model (i.e., the discriminator and generator) in the vanilla GAN , WGAN  or CGAN , which captures the spatio-temporal relations for ST data. What's more, some new loss functions have been proposed to dealing with specific ST tasks, such as the stepwised supervised loss in TimeGAN , masked reconstruction loss in GRU-GAN , the variety loss in SocialGAN . \nThe architecture of the generator and discriminator is of significant importance since it strongly influences the performance and stability of the GANs on ST data. Though GAN models have achieved remarkable success in ST applications , the unstable training process still remains unresolved and hinders further development for GAN on ST tasks, especially considering the heterogeneity and auto-correlation of ST data. For instance, Saxena et al.  concatenated the latent code and data space in the discriminator for faster convergence, better learning and higher training stability. Although many previous studies discussed how to enable the stable training process , the problems of instability of GANs still need further research, especially on the ST data modelling. With further developments of GANs, new architectures and loss functions can be designed based on the characteristics of ST tasks.", "cites": [117, 7009, 1003, 981, 1007, 1000, 8317, 996, 8404, 989, 7320, 992, 1011], "cite_extract_rate": 0.6190476190476191, "origin_cites_number": 21, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.5, "critical": 3.0, "abstraction": 3.0}, "insight_level": "medium", "analysis": "The section synthesizes information from multiple papers to highlight architectural adaptations and loss functions used in GANs for spatio-temporal data. It connects these ideas to the broader challenges of instability in training and the complexity of ST data, but the analysis remains somewhat high-level without deep comparative or evaluative insights into individual methods. The section begins to generalize by pointing out common trends, such as the use of RNNs, VAEs, and GNNs, but stops short of offering a meta-level abstraction or a novel framework."}}
{"id": "006ef4e7-f555-4db3-8831-5ad14b879263", "title": "Evaluation Metrics", "level": "subsubsection", "subsections": [], "parent_id": "4f2e9bda-6ba6-4650-9895-7996a4f3651f", "prefix_titles": [["title", "Generative Adversarial Networks for Spatio-Temporal Data: A Survey"], ["section", "Discussion"], ["subsection", "Challenges and Future Directions"], ["subsubsection", "Evaluation Metrics"]], "content": "Though GANs have gained huge success in various fields, evaluating the performance of GANs is still an open question. As illustrated in  and , both quantitatively measures (e.g., \\textit{Log-likelihood with Parzen Window Estimation} , \\textit{Frchet Inception Distance} , \\textit{Maximum Mean Discrepancy} , \\textit{Root Mean Square Error} , \\textit{Histogram} , \\textit{Stepwise Method} ) and qualitative measures (e.g., \\textit{Preference Judgement} , Analysing \\textit{Internals of Models} ) have strengths and limitations. The nebulous notion of quality can be best assessed by a human judge, which is neither practical nor appropriate for different types of ST data. \nIn most cases, it is not easy or even possible to visually evaluate the generated ST data. For instance, the \\textit{Intense Care Unit} (ICU) time series  or heart rate \\textit{Electrocardiogram} (ECG)  signals could look completely random to a non-medical expert. Usually, the evaluation of generated ST samples requires domain knowledge. For example, Mogren et al.  evaluated the generated music sequences using metrics in the field of music such as polyphony, repetitions, tone span and scale consistency. For future ST applications with GANs, some novel metrics based on domain knowledge could be considered to evaluate the generated ST data. \nEspecially, some researchers have proposed the general approach to evaluate the generated ST-data. Esteban et al.  developed a general method called \\textit{Train on Synthetic, Test on Real} (TSTR) to evaluate the generated samples of GANs when a supervised task defined on the training data. They used a dataset generated by GANs to train a classification model, then tested on a held-out set of true samples. This evaluation metric is ideal when employing GANs to share synthetic de-identified data because it demonstrates the ability of the generated synthetic data to be used for real applications. In the future, more practical metrics should be developed to evaluate the performance of generated ST samples.", "cites": [60, 1013, 117, 992, 1003, 980, 1014, 1012, 989], "cite_extract_rate": 0.6923076923076923, "origin_cites_number": 13, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.5, "critical": 3.0, "abstraction": 3.0}, "insight_level": "medium", "analysis": "The section synthesizes multiple evaluation approaches from the cited works, connecting them to the challenge of assessing GANs on spatio-temporal data. It provides a critical perspective by pointing out the limitations of human judgment and visual inspection in certain domains. While it identifies the need for domain-specific metrics, it stops short of proposing a novel framework or deep abstraction of overarching principles."}}
