{"id": "f5301377-4bcf-46f3-b564-af3aaeae11aa", "title": "Introduction", "level": "section", "subsections": [], "parent_id": "d7064ba6-829e-4acb-8323-ddbd20c53d89", "prefix_titles": [["title", "D'ya like DAGs? A Survey on Structure Learning and Causal Discovery"], ["section", "Introduction"]], "content": "Causal understanding has been described as `part of the bedrock of intelligence' , and is one of the fundamental goals of science . It is important for a broad range of applications, including policy making , medical imaging , advertisement , the development of medical treatments , the evaluation of evidence within legal frameworks , social science , biology , and many others. It is also a burgeoning topic in machine learning and artificial intelligence , where it has been argued that a consideration for causality is crucial for reasoning about the world. In order to discover causal relations, and thereby gain causal understanding, one may perform interventions and manipulations as part of a randomized experiment. These experiments may not only allow researchers or agents to identify causal relationships, but also to estimate the magnitude of these relationships.\nUnfortunately, in many cases, it may not be possible to undertake such experiments due to prohibitive cost, ethical concerns, or impracticality. For example, to understand the impact of smoking, it would be necessary to force different individuals to smoke or not-smoke. Researchers are therefore often left with non-experimental, observational data. In the absence of intervention and manipulation, observational data leave researchers facing a number of challenges: Firstly, observational datasets may not contain all relevant variables - there may exist unobserved/hidden/latent factors (this is sometimes referred to as the third variable problem). Secondly, observational data may exhibit selection bias - for example, younger patients may in general prefer to opt for surgery, whereas older patients may prefer medication. Thirdly, the causal relationships underlying these data may not be known \\textit{a priori} - for example, are genetic factors independent causes of a particular outcome, or do they mediate or moderate an outcome? These three challenges affect the discovery and estimation of causal relationships. \nTo address these challenges, researchers in the fields of statistics and machine learning have developed numerous methods for uncovering causal relations (causal discovery) and estimating the magnitude of these effects (causal inference) from observational data, or from a mixture of observational and experimental data. Under various (often strong) assumptions, these methods are able to take advantage of the relative abundance of observational data in order to infer causal structure and causal effects. Indeed, observational data may, in spite of the three challenges listed above, provide improved statistical power and generalizability compared with experimental data . \nIn this paper we review relevant background theory and provide a survey of methods which perform structure discovery (sometimes called causal induction ) with observational data or with a mixture of observational and experimental data. A number of reviews, surveys and guides are already available (see \\textit{e.g.} ), however, these reviews cover combinatoric approaches to causal discovery, whereas we primarily focus on the recent flurry of developments in continuous optimization approaches. Furthermore, the existing reviews are relatively short, and we attempt to provide a more scoping introduction to the necessary background material. We also seek to provide more extensive coverage of continuous optimization approaches than other current reviews, which focus on combinatoric approaches. Finally, we provide references to further useful resources including datasets and openly available software packages.\nThe structure of this survey is as follows: Following an overview of relevant background information in Section \\ref{sec:background}, we provide an overview of approaches to structure discovery in Section \\ref{sec:discovery}, including a list of common evaluation metrics. In Section \\ref{sec:comb} we briefly outline a range of combinatoric approaches, before focusing on continuous optimization approaches in Section \\ref{sec:cont}. We begin \\ref{sec:summary} by referencing several additional resources including reviews, guides, datasets, and software packages. We also provide a summary and discussion of the methods covered in Section \\ref{sec:summary}, and note various opportunities for future work and future direction. Many of the methods we review in this survey seek to discover and interpret the learned structure \\textit{causally}. Whilst this is a laudable aim, we are reminded of important commentaries (\\textit{e.g.},) which argue for appropriate skepticism and care when making the leap from observation to causality via causal discovery methods. We therefore conclude Section \\ref{sec:summary}, as well as this survey as a whole, by providing a discussion on these issues.", "cites": [4388, 4387, 4391, 4389, 4390, 8772], "cite_extract_rate": 0.2, "origin_cites_number": 30, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 2.0, "abstraction": 2.0}, "insight_level": "low", "analysis": "The introduction section provides a general overview of causal discovery and its importance in machine learning and science, citing relevant papers. However, it does not deeply synthesize the ideas from the cited works into a coherent narrative, nor does it critically evaluate the methods or limitations. The abstraction is limited to high-level applications and challenges without identifying overarching principles or trends in the literature."}}
{"id": "e080023e-65af-4830-ae5c-a4ad41eab570", "title": "Causality and SCMs", "level": "subsection", "subsections": [], "parent_id": "0455708a-79fb-42a9-bb72-7ed94894d9c2", "prefix_titles": [["title", "D'ya like DAGs? A Survey on Structure Learning and Causal Discovery"], ["section", "Background - Definitions and Assumptions"], ["subsection", "Causality and SCMs"]], "content": "In spite of some notable reluctance to treat graphs learned from observational data as causal , we acknowledge that it is a common and worthwhile aim, and begin by presenting a working definition of causality and its popular systematization in Structural Causal Models (SCMs). Causality eludes straightforward definition , and is often characterized intuitively with examples involving fires and houses , firing squads , and bottles and rocks . One definition of what is known as \\textit{counterfactual causality} is given by by Lewis (1973)  as follows:\\footnote{See discussion in Menzies \\& Beebee (2020) } \n\\begin{displayquote}\"We think of a cause as something that makes a difference, and the difference it makes must be a difference from what would have happened without it. Had it been absent, its effects – some of them, at least, and usually all – would have been absent as well\".\n\\end{displayquote}\nLewis' definition is counterfactual in the sense that he effectively describes `what would have happened if the cause had been A*, given that the effect was B when the cause was A'. Seemingly, this definition is compatible with the \\textit{Pearlian} school of causal reasoning. Specifically, in the context of what are known as SCMs:\n\\begin{displayquote}\n\"Given two disjoint sets of variables $X$ and $Y$, the causal effect of $X$ on $Y$, denoted as... $P(y|do(x))$, is a function from $X$ to the space of probability distributions on $Y$. For each realization of $x$ of $X$, $P(y|do(x))$ gives the probability of $Y=y$ induced by deleting from the model [$x_i = f_i(pa_i,u_i), i=1...,n,$] all equations corresponding to variables in $X$ and substituting $X=x$ in the remaining equations.\"\n\\end{displayquote}\nThis definition \\cite[p.70]{Pearl2009} requires further examination. Firstly, the model $x_i = f_i(pa_i,u_i), i=1...,n,$ is a Structural Equation/Causal Model (SEM/SCM) which indicates assignment of the value $x_i$ in the space of $X$ to a function of its structural parents $pa_i$ and exogenous noise $u_i$. We elaborate on what parents are (as well as children, descendants etc.) below. Secondly, the $do$ notation  indicates \\textit{intervention}, where the value of $x$ is set to a specific quantity. The structure (including attributes such as \\textit{parents}) can be represented graphically using various types of graphical models (\\textit{e.g.}, Directed Acyclic Graphs). Figure \\ref{fig:sem} shows the relationship between a DAG and a general Structural Equation Model. Sometimes this SEM is also called a Functional Causal Model (FCM), where the functions are assumed to represent the causal mechanisms . The use of the assignment operator `$:=$' makes explicit the asymmetric nature of these equations. In other words, they are not to be rearranged to solve for their inputs. To transform these relationships from mathematical relationships to causal relations, the Causal Markov Condition is imposed, which simply assumes that arrows (and their entailed conditional independencies) represent causal dependencies \\cite[p.105-6]{Peters2017}. \nThe ultimate benefit of the graphical and structural model frameworks is that they, at least in principle and under some strong assumptions, enable us to use observational data to answer scientific questions such as `how?', `why?', and `what if?' .\n\\begin{figure}[t!]\n\\centering\n\\includegraphics[width=0.5\\linewidth]{SEM.pdf}\n\\caption{Transitioning from a typical DAG representation (left) to a structural equation model (right). Grey vertices are unobserved/latent random variables.}\n\\label{fig:sem}\n\\end{figure}", "cites": [8773], "cite_extract_rate": 0.09090909090909091, "origin_cites_number": 11, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.5, "critical": 2.5, "abstraction": 3.5}, "insight_level": "medium", "analysis": "The section integrates foundational concepts of causality and SCMs by connecting counterfactual definitions (Lewis) with Pearlian causal reasoning and SEMs, indicating some synthesis. It abstracts the role of graphical models and the Causal Markov Condition in enabling causal inference from observational data. However, it lacks deeper critical analysis of the cited works and does not compare or contrast different causal modeling approaches in detail."}}
{"id": "0f330c17-d8ea-4921-9848-245f5405df2f", "title": "Graphical Models", "level": "subsection", "subsections": [], "parent_id": "0455708a-79fb-42a9-bb72-7ed94894d9c2", "prefix_titles": [["title", "D'ya like DAGs? A Survey on Structure Learning and Causal Discovery"], ["section", "Background - Definitions and Assumptions"], ["subsection", "Graphical Models"]], "content": "For background on graphical models, see work by Koller and Friedman (2009) . We follow a similar formalism to Peters et al. (2017)  and Strobl (2018) . A graph $\\mathcal{G}(\\mathbf{X}, \\mathcal{E})$ represents a joint distribution $P_{\\mathbf{X}}$ as a factorization of $d$ variables $\\mathbf{X} = \\{X_1, ..., X_d\\}$ using $d$ corresponding \\textit{nodes/vertices} $v \\in \\mathbf{V}$ and connecting edges $(i, j) \\in \\mathcal{E}$, where $(i, j)$ indicates an edge between $v_i$ and $v_j$. If two vertices $i$ and $j$ are connected by an edge we call them \\textit{adjacent}, and, can also denote this in terms of the corresponding variables $\\mathbf{X}$ as $X_i \\rightarrow X_j$ or $X_i \\leftarrow X_j$ (directed), $X_i$ --- $X_j$ (undirected), $X_i \\leftrightarrow X_j$ (bidirected), $X_i \\LineCirc X_j$ or $X_i \\CircLine X_j$ (partially undirected), $X_i \\CircRightarrow X_j$ or $X_i \\CircLeftarrow X_j$ (partially directed), or $X_i \\CircCirc X_j$ (nondirected). A graph comprising entirely undirected edges forms a \\textit{skeleton}. It is also possible to have self-loops, although these occur relatively infrequently in the structure discovery literature. These different edge types allow us to define a range of graph types and relationships.\nAn \\textit{undirected path} exists if there are edges connecting two vertices regardless of the edge types between them. In contrast, a \\textit{directed path} constitutes directed edges with consistent arrowhead directions. We can define a \\textit{parent} $pa_j$ as a vertex $v_i$ with \\textit{child} $v_j$ connected by a directed edge $X_i \\rightarrow X_j$ such that $(i,j) \\in \\mathcal{E}$ but $(j,i) \\notin \\mathcal{E}$. Further upstream parents are \\textit{ancestors} of downstream \\textit{descendants} if there exists a directed path constituting $i_{k} \\rightarrow j_{k+1}$ for all $k$ in a sequence of vertices. An \\textit{immorality} or \\textit{v-structure} describes when two non-adjacent vertices are parents of a common child. A \\textit{collider} is a vertex where incoming directed arrows converge.\nIt is possible for \\textit{directed cycles} to occur when following a directed path results in the visitation of a vertex more than once (\\textit{e.g.}, $X_i \\rightarrow X_j \\rightarrow X_k \\rightarrow X_i$). Many phenomena in nature exhibit cyclic properties and feedback, and ignoring this possibility has the potential to induce bias . If all edges are directed, and there are no cycles, we have the well-known class of \\textit{Directed Acyclic Graphs} (DAGs). On the other hand, if all edges are directed but there is no restriction preventing cycles, we have a \\textit{Directed Graph} (DG).", "cites": [4392], "cite_extract_rate": 0.2, "origin_cites_number": 5, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 1.5, "abstraction": 2.5}, "insight_level": "low", "analysis": "The section provides a descriptive overview of graphical models, including definitions of various edge types, paths, and graph classes like DAGs and DGs. It cites one paper (doc_id: 4392) to highlight the importance of handling cycles, but does not synthesize or connect ideas across multiple sources. There is minimal critical analysis or abstraction beyond the specific content of the cited paper, with the focus primarily on defining concepts rather than evaluating or generalizing them."}}
{"id": "321d1b02-aed7-4f99-afac-a8686da2929c", "title": "Markov Equivalence Class (MEC) and Completed Partially Directed Acyclic Graphs (CPDAGs)", "level": "subsection", "subsections": [], "parent_id": "0455708a-79fb-42a9-bb72-7ed94894d9c2", "prefix_titles": [["title", "D'ya like DAGs? A Survey on Structure Learning and Causal Discovery"], ["section", "Background - Definitions and Assumptions"], ["subsection", "Markov Equivalence Class (MEC) and Completed Partially Directed Acyclic Graphs (CPDAGs)"]], "content": "The conditional independence constraints implied by a graph's $d$-separation properties are not always enough to uniquely identify it. Whether a graph can be uniquely identified is known as the problem of \\textit{identifiability}, and a significant body of work has been devoted to identifying scenarios for which the true graph is identifiable (\\textit{e.g.}, linear functional form with non-Gaussian errors , or nonlinear functional forms with additive noise ).\\footnote{One may define an SEM defined on a DAG as identifiable if there are no other SEMs that induce the same joint distribution with a different DAG .} As such, there are situations in which multiple graphs satisfy the same conditional independencies. For example, conditional independence implied by $X_i \\indep X_k | X_j$ is present in the graph $X_i \\rightarrow X_j \\rightarrow X_k$ as well as the graphs $X_i \\leftarrow X_j \\leftarrow X_k$ and $X_i \\leftarrow X_j \\rightarrow X_k$, in spite of the fact that these graphs have drastically different causal implications. The class of graphs which represent the same set of conditional independencies together constitute the \\textit{Markov Equivalence Class} (MEC). Graphs belong to the same equivalence class when they have the same skeleton and the same immoralities . \n\\begin{figure}[t!]\n\\centering\n\\includegraphics[width=0.8\\linewidth]{cpdag.pdf}\n\\caption{Showing a skeleton, a CPDAG, and the Markov Equivalence set of graphs. Variable C is a collider, and so the direction of incoming arrows can be identified from conditional independencies.}\n\\label{fig:cpdag}\n\\end{figure}\n\\textit{Completed Partially Directed Acyclic Graphs} (CPDAGs) can be used to represent an MEC. In CPDAGs, an edge is only directed if there is only one graph in the MEC with an edge in that direction, otherwise, if there is uncertainty about the direction, it is left `non-directed' using $\\CircCirc$. One might wonder whether there are any MECs without undirected edges, and indeed there are. A collider or v-structure forms an MEC with only one valid DAG: $X_i \\rightarrow X_j \\leftarrow X_k$. This is because conditioning on $X_j$ makes $X_i$ and $X_k$ $d$-connected. An example of a skeleton graph, a CPDAG, and corresponding MEC graphs are shown in Figure \\ref{fig:cpdag}.", "cites": [4393], "cite_extract_rate": 0.25, "origin_cites_number": 4, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.5, "critical": 2.5, "abstraction": 3.0}, "insight_level": "medium", "analysis": "The section provides a clear explanation of Markov Equivalence Classes and CPDAGs, integrating foundational concepts from causal graph theory. It connects the idea of identifiability to the limitations of conditional independence in uniquely determining causal structure, referencing relevant literature. However, the critical analysis is limited, as it does not evaluate the cited paper's methodology or limitations in detail, and the abstraction remains at a moderate level, identifying general principles without deep meta-level insights."}}
{"id": "1824ba95-8a64-4061-af26-97ff9b37c619", "title": "Assumption: Sufficiency", "level": "subsection", "subsections": [], "parent_id": "0455708a-79fb-42a9-bb72-7ed94894d9c2", "prefix_titles": [["title", "D'ya like DAGs? A Survey on Structure Learning and Causal Discovery"], ["section", "Background - Definitions and Assumptions"], ["subsection", "Assumption: Sufficiency"]], "content": "One of the challenges with using observational data is the assumption that all relevant data have been collected/observed. This is less problematic in the case of Randomized Controlled Trials (RCTs) because the randomization itself helps mitigate the effect of confounding which would otherwise imbalance the treatment and control groups.\\footnote{In reality, limited sample sizes (which are often encountered with expensive RCTs) can still render this issue problematic .} In observational settings, unobserved confounding can significantly bias effect estimates (even reversing their direction). Whilst it is possible to try to infer hidden confounders from observational data using latent variable models (see \\textit{e.g.} , a large number of causal discovery methods assume \\textit{sufficiency}, which is the assumption that there are no unobserved confounders. The assumption of sufficiency is strong and may often be inappropriate or overly restrictive. If the assumption does not hold, the set of observed variables is (causally) \\textit{insufficient}  and a DAG comprising only the observed variables can not be used (and the DAG is said to not be closed under marginalization) .", "cites": [4394, 4396, 4395], "cite_extract_rate": 0.5, "origin_cites_number": 6, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.5, "critical": 3.0, "abstraction": 3.0}, "insight_level": "medium", "analysis": "The section synthesizes information from the three cited papers to discuss the assumption of sufficiency, linking them to the broader issue of unobserved confounding in causal discovery. It provides a critical perspective by acknowledging the strength and potential inappropriateness of the assumption, though the critique is not deeply nuanced. The abstraction is moderate, as it generalizes the idea of sufficiency but does not offer a meta-level framework or deeper theoretical synthesis."}}
{"id": "6283eb8d-4d1c-407f-a42e-5993f5ffa87b", "title": "Acyclic Directed Mixed Graphs (AGMGs) and Maximal Ancestral Graphs (MAGs) and $m$-separation", "level": "subsection", "subsections": [], "parent_id": "0455708a-79fb-42a9-bb72-7ed94894d9c2", "prefix_titles": [["title", "D'ya like DAGs? A Survey on Structure Learning and Causal Discovery"], ["section", "Background - Definitions and Assumptions"], ["subsection", "Acyclic Directed Mixed Graphs (AGMGs) and Maximal Ancestral Graphs (MAGs) and $m$-separation"]], "content": "In the presence of unobserved confounding, an \\textit{Acyclic Directed Mixed Graph} (ADMG) may be used. ADMGs represent hidden confounding as bidirected edges. For example, the confounding relationship given by $X_i \\leftarrow H \\rightarrow X_j \\rightarrow X_k$ can, in the absence of $H$, be represented in an ADMG as $X_i \\leftrightarrow X_j \\rightarrow X_k$. \n\\textit{Maximal Ancestral Graph} (MAG) can also be used to represent hidden confounding, and have the further capacity of representing selection bias (\\textit{i.e.} as might occur when a certain sub-population is sampled). MAGs satisfy the following three properties : (1) there are no directed cycles (acyclicity); (2) if an edge $X_i \\leftrightarrow X_j$ exists (which implies $X_i$ is the \\textit{spouse} of $X_j$) then there are no directed paths between $X_i$ and $X_j$; (3) if an edge $X_i$ --- $X_j$ exists (which implies $X_i$ is the \\textit{neighbour} $X_j$) then $X_i$ and $X_j$ have no spouses or parents. This edge is used to represent selection bias (\\textit{i.e.} where a subpopulation has been sampled according to some condition). \nThe definitions of ancestor and descendent translate naturally from DAGs (see above) to MAGs, as does the definition for $d$-separation, which becomes $m$\\textit{-separation}. In the latter case, the conditions for $d$-separation in Equations \\ref{eq:dsep1} and \\ref{eq:dsep2} hold, substituting any confounding variable relationships (\\textit{e.g.}, $X_i \\leftarrow H \\rightarrow X_j$) with a bidirected arrow (\\textit{e.g.}, $X_i \\leftrightarrow  X_j$). In the presence of selection bias, a $X_i$ --- $X_j$ edge can be used. Readers are directed to  for a more detailed and formal exposition. \n\\begin{figure}[t!]\n\\centering\n\\includegraphics[width=0.65\\linewidth]{dagmagpag.pdf}\n\\caption{Showing the relationship between the true DAG and its representation using a MAG and a PAG. Shaded vertex is a hidden/unobserved confounding variable. Adapted from \\cite[p.179]{Peters2017}.}\n\\label{fig:magdagpag}\n\\end{figure}\nThe assumption of $m$-faithfulness translates naturally from $d$-faithfulness for DAGs (see above) to MAGs, according to the conditional independencies implied by $m$-separation.", "cites": [8774], "cite_extract_rate": 0.3333333333333333, "origin_cites_number": 3, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.5, "critical": 2.0, "abstraction": 2.5}, "insight_level": "medium", "analysis": "The section provides a clear and factual description of ADMGs and MAGs, including their properties and the concept of $m$-separation. While it references a paper on Markov equivalence for ancestral graphs, it does not deeply synthesize or integrate multiple sources to form a broader narrative. There is limited critical analysis or abstraction to overarching principles, as the focus remains primarily on definitions and relationships."}}
{"id": "6f1ba755-5344-4273-a6e5-6511fcdb262e", "title": "Other Definitions and Assumptions", "level": "subsection", "subsections": [], "parent_id": "0455708a-79fb-42a9-bb72-7ed94894d9c2", "prefix_titles": [["title", "D'ya like DAGs? A Survey on Structure Learning and Causal Discovery"], ["section", "Background - Definitions and Assumptions"], ["subsection", "Other Definitions and Assumptions"]], "content": "Other types of graph used to represent causal structure include Partially Oriented Induced Path Graphs (POIPGs) , Single World Intervention Graphs (SWIGs) , $\\sigma$-connection graphs , undirected graphs , interaction and component graphs for dynamic systems , Maximal Almost Ancestral Graphs (MAAGs) , psi-ECs , Patterns , and arid, bow-free, and ancestral ADMGs . There are also other types of assumptions relating to the functional form of the structural relationships (\\textit{e.g.}, linear or non-linear) as well as the parametric form of the marginals and the errors (\\textit{e.g.}, Gaussian or non-Gaussian). In the interests of brevity, we have not discussed these additional graph-types and assumptions here, but encourage interested readers to consult the listed references.", "cites": [4392, 208, 4395], "cite_extract_rate": 0.25, "origin_cites_number": 12, "insight_result": {"type": "descriptive", "scores": {"synthesis": 1.5, "critical": 1.0, "abstraction": 1.5}, "insight_level": "low", "analysis": "The section lists various types of causal graphs and assumptions without synthesizing or connecting the ideas from the cited papers. It lacks critical analysis and does not evaluate or contrast the strengths and limitations of these approaches. The content remains at a surface level with minimal abstraction or generalization."}}
{"id": "c7f163ba-b2ce-4453-a39e-0f6f6c4181ff", "title": "Constraint-Based and Score-Based Approaches", "level": "subsection", "subsections": [], "parent_id": "f54fa638-8d60-45e7-b02a-a85a1d51a9e3", "prefix_titles": [["title", "D'ya like DAGs? A Survey on Structure Learning and Causal Discovery"], ["section", "Structure Discovery Methods"], ["subsection", "Constraint-Based and Score-Based Approaches"]], "content": "Most constraint-based approaches test for conditional independencies in the empirical joint distribution in order to construct a graph that reflects these conditional independencies.\\footnote{Other constraints exist, such as Verma constraints .} According to the discussion above, there are often multiple graphs that fulfil a given set of conditional independencies, and so it is common for constraint-based approaches to output a graph representing some MEC (\\textit{e.g.}, a PAG). Unfortunately, conditional independence tests require large sample sizes to be reliable, and Shah and Peters (2020)  discuss further challenges to controlling Type I errors.\\footnote{Examples of flexible conditional independence testing include GAN-based  and Kernel based  methods.}\nScore-based approaches test the validity of a candidate graph $\\mathcal{G}$ according to some scoring function $S$. The goal is therefore stated as :\n\\vspace{-1mm}\n\\begin{equation}\n    \\hat{\\mathcal{G}} = \\mbox{argmax}_{\\mathcal{G} \\mbox{ over } \\mathbf{X}} S(\\mathcal{D}, \\mathcal{G})\n\\end{equation}\nwhere $\\mathcal{D}$ represents the empirical data for variables $\\mathbf{X}$. Common scoring functions include the Bayesian Information Criterion (BIC) , the Minimum Description Length (as an approximation of Kolmogorov Complexity) , the Bayesian Gaussian equivalent (BGe) score , the Bayesian Dirichlet equivalence (BDe) score , the Bayesian Dirichlet equivalence uniform (BDeu) score , and others .", "cites": [4397, 4398, 4399, 8775], "cite_extract_rate": 0.25, "origin_cites_number": 16, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.5, "critical": 2.0, "abstraction": 2.0}, "insight_level": "medium", "analysis": "The section provides a basic description of constraint-based and score-based approaches, with a brief mention of conditional independence testing challenges and some examples of methods, including those from the cited GAN and kernel-based papers. However, it lacks deeper synthesis or comparison of these methods and does not critically evaluate their strengths or limitations. The abstraction level is minimal, focusing on surface-level generalization rather than deeper principles or trends in the field."}}
{"id": "a3032350-63f8-47e7-b069-559b73550171", "title": "Exploiting Structural Asymmetries", "level": "subsection", "subsections": ["6a867c77-23ab-4016-bfd8-733be5b0ea3a", "6e1b1381-522a-4604-b2c3-116698ae1ec1"], "parent_id": "f54fa638-8d60-45e7-b02a-a85a1d51a9e3", "prefix_titles": [["title", "D'ya like DAGs? A Survey on Structure Learning and Causal Discovery"], ["section", "Structure Discovery Methods"], ["subsection", "Exploiting Structural Asymmetries"]], "content": "There is no way to rule out scenarios whereby a joint distribution admits SCMs indicating either of the structural directions $X_i \\rightarrow X_j$ or $X_i \\leftarrow X_j$, thereby making the induction of causal directionality from observation alone, impossible. However, if some additional assumptions are made about the functional and/or parametric forms of the underlying true data-generating structure, then one can exploit asymmetries in order to identify the direction of a structural relationship. These asymmetries manifest in various ways, including non-independent errors, measures of complexity, and dependencies between marginals and cumulative distribution functions. Methods which exploit such asymmetries are typically \\textit{local} methods, as they are only able to test edges one at a time (pairwise/bivariate causal directionality), or to test triples (with the third variable being an unobserved confounder) . They may, of course, be extended to construct full-graphs by iteratively testing pairwise relationships (see \\textit{e.g.} the Information-Geometric Causal Inference algorithm ). We now briefly provide some examples of structural asymmetries, and direct interested readers to Mooij et al. (2016)  for a detailed review.", "cites": [4400], "cite_extract_rate": 0.3333333333333333, "origin_cites_number": 3, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.5, "critical": 2.5, "abstraction": 3.0}, "insight_level": "medium", "analysis": "The section provides an analytical overview of structural asymmetries in causal discovery, integrating key concepts from the cited paper and placing them within a broader theoretical context. It synthesizes ideas about how assumptions on functional forms enable directionality inference and highlights the local nature of such methods. While it offers some abstraction by generalizing the role of asymmetries, it lacks deeper critical analysis or nuanced comparison of different approaches."}}
{"id": "8a4f598c-3bca-44cc-8a67-e556a533b13f", "title": "Interventions and Adjustment Sets", "level": "subsection", "subsections": [], "parent_id": "f54fa638-8d60-45e7-b02a-a85a1d51a9e3", "prefix_titles": [["title", "D'ya like DAGs? A Survey on Structure Learning and Causal Discovery"], ["section", "Structure Discovery Methods"], ["subsection", "Interventions and Adjustment Sets"]], "content": "If interventional data are available, we are able to reduce the number of graphs in our MEC. An intervention can be denoted using Pearl's \\textit{do} operator  such that, \"for each realization of $x$ of $X$, $P(y|do(x))$ gives the probability of $Y=y$ induced by deleting from the model [$x_i = f_i(pa_i,u_i), i=1...,n,$] all equations corresponding to variables in $X$ and substituting $X=x$ in the remaining equations.\" Such interventions can be hard/perfect/structural/atomic/deterministic, or soft/imperfect/parametric, depending on whether a variable is set to a specific value, or whether the variable and its relationship to its neighbours is modified in some way (\\textit{e.g.}, by changing the noise distribution $u$). Graphically, a hard intervention can be represented by removing all incoming arrows (from parents) to a vertex, and setting that vertex to the value $x$ \\cite[p.88-91]{Peters2017}. For a structural equation model $X = U_X$, $Y=f(X) + U_Y$ and $Z = g(X) + h(Y) + U_Z$, an intervention $Y=4$ would entail $X = U_X$ (unmodified), $Y=4$ (modified), and $Z = g(X) + h(4) + U_Z$ (modified). Thus it can be seen that only $Y$ and its descendants have been affected by the intervention, leaving $X$ unchanged. In contrast to hard interventions, a parametric intervention preserves the structure of the intervention itself, introducing an additional vertex and affecting the conditional distribution of the intervened variable. Parametric interventions also preserve any correlations deriving from unobserved/hidden confounders . This difference is illustrated in Figure \\ref{fig:intervention}.\nIn order to demonstrate how interventions can be used to narrow the equivalence set (and in some cases make the true graph identifiable), consider the graphs in Figure \\ref{fig:intervention2}. Starting with the CPDAG on the left, where the edge from A to C is undirected because the direction of the edge cannot be ascertained from conditional independencies alone. Intervening (hard) on B allows us to orient this edge by comparing the resulting distribution under intervention. If the edge is oriented $A \\rightarrow B$ then the intervention has the effect of `removing' this edge. Conversely, if the edge is oriented $B \\rightarrow A$ then the intervention does nothing to remove this arrow, and the downstream variable $A$ should change accordingly.\nAnother way to view interventions from the perspective of independencies is to consider their formulation in terms of \\textit{adjustment sets}. Following : $p(y|do(X=x)) = p(y)$ if  $Y$ is a parent of $X$ (\\textit{i.e.}, $Y \\in pa_X$). In words, intervening on $X$ does not change $y$ because $X$ is `downstream' of $Y$. Secondly, if $Y \\not \\in pa_X$, then:\n\\vspace{-1mm}\n\\begin{equation}\n    p(y|do(X=x)) = \\sum_{pa_X}p(y|x, pa_X)p(pa_X)\n\\end{equation}\nHere, the marginalized interventional distribution $p(y|do(X=x))$ is being computed using the \\textit{adjustment} set (in this case $pa_X$ is a valid adjustment set). More generally, the interventional distribution can be calculated as:\n\\vspace{-1mm}\n\\begin{equation}\n    p(y|do(X=x)) = \\sum_\\mathbf{z} p(y|x, \\mathbf{z})p(\\mathbf{z})\n\\end{equation}\nwhen $\\mathbf{z}$ is a valid adjustment set for this particular interventional distribution. Note that sets including mediators and descendants of mediators (where $B$ in the graph $A \\rightarrow B \\rightarrow C$ is a mediator) are \\textit{not} valid adjustment sets for finding $C | do(A)$. See Cinelli et al. (2020)  for a \"Crash course in good and bad controls\". \nFor a detailed review of different types of interventions and their implications, readers are directed to Eberhardt \\& Scheines (2006) . Suffice to say there are many ways to leverage different types of intervention, including multiple interventions on different vertices, or single interventions applied to multiple nodes. Finally, there is work investigating the use of data representing unknown or uncertain interventions, whereby it is not known which variables have been intervened on . The use of intervention also yields what is known as an Interventional Equivalence Class (IEC), representing the set of graphs compatible with a given intervention(s).", "cites": [8776], "cite_extract_rate": 0.125, "origin_cites_number": 8, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.0, "critical": 2.0, "abstraction": 3.0}, "insight_level": "medium", "analysis": "The section provides an analytical overview of interventions and adjustment sets in causal discovery, integrating concepts from Peters (2017) and Cinelli et al. (2020) to explain how interventions can influence graph identifiability and adjustment sets. While it connects ideas to form a coherent narrative, the critical evaluation remains limited—primarily descriptive with minimal critique or comparison of approaches. Some level of abstraction is present, particularly in defining general adjustment set formulations and their implications."}}
{"id": "59ba57dd-a897-4543-b1fc-dbcd95f62bdb", "title": "Combinatoric/Search Based Approaches", "level": "section", "subsections": [], "parent_id": "d7064ba6-829e-4acb-8323-ddbd20c53d89", "prefix_titles": [["title", "D'ya like DAGs? A Survey on Structure Learning and Causal Discovery"], ["section", "Combinatoric/Search Based Approaches"]], "content": "\\label{sec:comb}\nThe number of possible DAGs increases super-exponentially with the number of variables . As noted by Peters et al. (2017) , the number of possible DAGs for 10 variables is $> 4\\times10^{18}$. As such, the search problem is NP-hard , and this will later motivate the use of continuous optimization approaches to graph learning.\n\\begin{table}[hb!]\n\\centering\n\\fontsize{5.6}{6.6}\\selectfont\n\\begin{tabular}{llllllll}\n\\toprule\n\\textbf{Method}  & \\textbf{Year} & \\textbf{Type} & \\textbf{Suff.} & \\textbf{Faith.} & \\textbf{Acycl.} & \\textbf{Interv.} & \\textbf{Output} \\\\ \\midrule\nPC \t &\t1993 &\tconstraint\t& yes\t& yes &\tyes &\tno &\tCPDAG \\\\\nCCD\t \t & 1996\t & constraint &\tyes\t & yes\t& both\t& no &\tPAG \\\\\nFCI \t\t & 2000\t & constraint & \tno & \tyes & \tyes\t & no & \tPAG \\\\\nTPDA  \t & \t2002\t & constraint & \tyes & \tyes\t & yes & \tno\t & CPDAG \\\\\nCPC\t   & \t2006\t & constraint & \tyes & \trelaxed\t & yes & \tno & \tCPDAG \\\\\nKCL   \t\t & 2007\t & constraint & \tyes\t & yes\t & yes & \tno & \tCPDAG \\\\\nION\t   & \t2008 & \tconstraint\t & no & \tyes\t & yes\t & no & \tPAG \\\\\nIDA  \t\t & 2009 & \tconstraint & \tyes\t & yes & \tyes\t & yes & \tDAG \\\\\ncSAT+  \t & \t2010 & \tconstraint & \tno & \tyes & \tyes & \tno & \tPCG \\\\\nKCI-test  & 2012 & constraint & yes\t& yes &\tyes &\tno &\tCPDAG \\\\\nRFCI  \t\t & 2012 & \tconstraint & \tno\t & yes & \tyes & \tno\t & PAG \\\\\nCHC\t   & \t2012 & \tconstraint & \tyes & \tyes & \tyes & \tno & \tPDAG \\\\\nSAT \t\t & 2013 & \tconstraint & \tno\t & yes & \tno & \tyes & \tDG \\\\\nParallel-PC\t   & \t2014 & \tconstraint & \tyes\t & yes & \tyes\t & no & \tCPDAG \\\\\nRPC   \t & \t2013 & \tconstraint\t & yes & \tyes\t & yes & \tno\t & CPDAG \\\\\nPC-stable  \t & \t2014 & \tconstraint\t & both\t & yes & \tboth & \tno\t & CPDAG \\\\\nCOmbINE\t  \t & 2015\t & constraint & \tno & \tyes & \tyes & \tyes\t & summary SMCMs \\\\\nbackshift  \t & \t2015 & \t- & \tno\t & no & \tno & \tyes\t & DG \\\\\nIGSP\t &\t2018\t &  constraint & yes & relaxed & yes & yes & I-MEC \\\\\t\n$\\sigma$-CG  \t & \t2018 & \tconstraint & \tno\t & yes & \tno & \tyes & \t$\\sigma$-connection graphs \\\\\nCCI\t   & \t2018 & \tconstraint\t & no & \tyes\t & no & \tno & \tMAAG \\\\\nFCI-soft  \t & \t2019 & \tconstraint & \tno\t & relaxed\t & yes & \tyes\t & I-MEC \\\\\nIBSSI  \t & \t2020 & \tconstraint\t & no & \tyes\t & yes\t & yes\t & DAG \\\\\nCD-NOD\t \t & 2020\t & constraint & \tno & \tyes & \tboth & \tyes\t & ----- \\\\\npsi-FCI\t  \t & 2020\t & constraint & \tno & \trelaxed\t & yes\t & yes & \tPsi-EC \\\\\nLCDI\t  \t & 2020\t & constraint & \tno & \tyes\t & yes\t & yes & Pattern \\\\\nEG  \t & \t2009 & \tscore & \tyes\t & yes & \tyes\t & no & \tBT-DAG \\\\\nTWILP  \t & \t2014 & \tscore & \tyes\t & yes\t & yes & \tno\t & BT-DAG \\\\\nK2 \t & \t1992\t & score & \tno\t & yes & \tyes\t & no & \tCPDAG \\\\\nLB-MDL  \t\t & 1994\t & score & \tyes\t & yes & \tyes\t & no & \tDAG \\\\\nHGC\t   & \t1995 & \tscore & \tyes\t & yes & \tyes & \tno & \tCPDAG \\\\\nGES\t   & \t2002 & \tscore & \tyes\t & yes\t & yes\t & no & \tCPDAG \\\\\nOS\t   & \t2005 & \tscore & \tyes\t & yes\t & yes & \tno & \tDAG \\\\\nHGL\t   & \t2005 & \tscore\t & yes & \tyes\t & yes & \tyes\t & CPDAG \\\\\nMeinshausen  \t & \t2006 & \tscore & yes\t & \t- & \tno & \tno & \tUG \\\\\nGraphical Lasso\t   & \t2008 & \tscore\t & yes & \t- & \tno & \tno & \tUG \\\\\nBC  \t\t & 2008\t & score & \tyes\t & - & \tno & \tno & \tUG \\\\\nTC  \t & \t2008 & \tscore & yes\t & \tyes\t & yes & \tno & \tCPDAG \\\\\nHG\t   & \t2008 & \tscore & \tyes\t & yes & \tyes & \tyes\t & DAG \\\\\nAdaptive Lasso  \t & \t2010 & \tscore & \tyes\t & yes & \tyes & \tno & \tDAG \\\\\nGIES  \t & \t2012 & \tscore\t & yes & \tyes\t & yes\t & yes & \tPDAG \\\\\nCD  \t & \t2013 & \tscore\t & yes & \tyes & \tyes  & \tyes\t & DAG \\\\\nGBN learner  \t\t & 2013 & \tscore & \tyes & \tno & \tyes & \tno\t & CPDAG \\\\\nGES-mod\t   & \t2013 & \tscore & \tyes & \tyes\t & yes & \tno & \tCPDAG \\\\\nPen-PC\t   & \t2015\t & score & \tyes\t & yes\t & yes & \tno & \tCPDAG \\\\\nScalable GBN  \t & \t2015 & \tscore & \tyes\t & no & \tyes & \tno\t & DAG \\\\\nK-A*   \t & \t2016 & \tscore\t & yes\t & yes & \tyes & \tno & \tDAG \\\\\nNS-DIST\t   & \t2016 & \tscore\t & yes & \tno & \tyes & \tyes\t & DAG \\\\\nMIP-GD\t  \t & 2017 & \tscore & \tyes & \tyes & \tyes\t & no & \tCPDAG \\\\\nCD2\t   & \t2018 & \tscore\t & yes & \tyes & \tyes & \tyes\t & DAG \\\\\nSP  \t\t & 2018\t & score & \tyes\t & relaxed & \tyes\t & no & \tCPDAG \\\\\nVAR\t  \t & 2018\t & score & \tyes\t & yes & \tboth & \tno & \tDG \\\\\nGSF   \t & \t2018 & \tscore & \tyes\t & yes & \tyes & \tno & \tCPDAG \\\\\nbQCD  \t & \t2020 & \tscore\t & yes\t & yes & \tyes\t & no & \tBi \\\\\nGCL \t & \t2020 & \tscore & \tno & \t- & \tno\t & no & \tGCLM \\\\\nGGIM  \t & \t2020 & \tscore\t & yes & \tno & \tno & \tno & \tGGIM  \\\\\nGYKZ  \t & \t2020 & \tscore & \tyes\t & yes & \tboth & \tno\t & DG \\\\\nSLARAC etc.\t   & \t2020 & \tscore\t & Granger\t & - & \t- & \tno & \tBi \\\\\nOrder-MCMC\t   & \t2003 & \tsampling\t & yes & \tyes\t & yes & \tno & \tDAG \\\\\nOG\t  \t & 2008\t & sampling\t & yes & \tyes & \tyes\t & yes\t & DAG \\\\\nEE-DAG\t  \t & 2011 & \tsampling & \tyes\t & yes & \tyes\t & yes & \tDAG \\\\\nZIPBN  \t & \t2020 & \tsampling & \tyes\t & no\t & yes & \tno\t & DAG \\\\\nLiNGAM\t  \t & 2006\t & asymmetries & \tyes\t & no & \tyes & \tno & \tDAG \\\\\nLV LiNGAM  \t & \t2008\t & asymmetries & \tno & \tyes\t & yes & \tno & \tDAG \\\\\nnon-linear ANM  \t & \t2008 & \tasymmetries & \tyes\t & yes & \tyes\t & no & \tDAG \\\\\nCAN\t   & \t2009 & \tasymmetries\t & no & \tyes & \tyes & \tno & \tBi/tri \\\\\nCCM  & 2012 & asymmetries & - & - & no & no &Bi\\\\\nIGCI\t & \t2012 & \tasymmetries\t & yes & \tyes & \tyes\t & no & \tBi \\\\\nKCDC\t\t & 2018\t & asymmetries & \tyes & \tyes\t & yes & \tno & \tBi \\\\\nMMHC\t & \t2006 & \thybrid\t & yes\t & yes\t & yes & \tno\t & DAG \\\\\nARGES\t & \t2018 & \thybrid & \tyes\t & yes\t & yes & \tno & \tCPDAG \\\\ \\bottomrule\n\\end{tabular}\n\\caption{This table comprises a list of non-continuous optimization based approaches to causal discovery (\\textit{i.e.}, combinatoric, search-based, SAT-solver). Provides indication of assumptions of sufficiency (`Suff.'), faithfulness (`Faith.'), acyclicity (`Acycl.'), as well as whether the method leverages forms of intervention (`Interv.'). `Bi' indicates bivariate cause-effect pairs (possibly multivariate). N.B. If the output is `DAG' this does not necessarily imply that the method identifies the \\textit{true} DAG.}\n\\label{tab:combtable}\n\\end{table}\nTable \\ref{tab:combtable} presents a non-exhaustive list of methods which do not use continuous optimization. In other words, they include primarily combinatoric/search-based approaches to structure discovery. The table presents the type of approach used: constraint-based, score-based, asymmetry-based, hybrid, and sampling-based (which measure belief in a proposed graph structure by sampling from a posterior). In addition, the table provides the associated assumptions: Sufficiency (\\textit{i.e.}, whether it assumes there are no hidden variables), Faithfulness (some methods achieve a less severe/relaxed form of faithfulness); and Acyclicity (some methods can learn feedback loops and cycles). Finally, the table indicates whether the method leverages interventions, and indicates the method's output (CPDAG, PAG, etc.).", "cites": [4392, 4402, 4399, 8777, 4406, 8779, 4404, 4403, 4407, 4401, 7807, 8778, 4405, 9128, 4408, 8781, 8780], "cite_extract_rate": 0.2328767123287671, "origin_cites_number": 73, "insight_result": {"type": "comparative", "scores": {"synthesis": 3.0, "critical": 2.5, "abstraction": 2.0}, "insight_level": "medium", "analysis": "The section provides a structured, comparative overview of combinatoric/search-based causal discovery methods through a detailed table, which organizes them by type, assumptions, and output. It synthesizes key methodological aspects (e.g., acyclicity, faithfulness) and connects them to broader challenges like the NP-hard nature of the problem. However, it lacks deeper critical analysis of trade-offs between methods or evaluation of their relative strengths and weaknesses, and offers minimal abstraction beyond the categorization of properties."}}
{"id": "e3f99f06-d65d-4b95-8b55-0b44c70b2761", "title": "Continuous Optimization Based Approaches", "level": "section", "subsections": ["be5edbc5-64da-4965-9e61-8b91afbe6137", "57b8cba2-5515-4be3-b553-21e84bde0b9f", "1f33f466-a955-4d63-bd6c-a91dd141fd8f", "6c3c5181-4556-4079-89e7-a38fc977cf6c", "41fb3958-62af-452b-92b6-1df7f638aa05", "f155b2c4-f043-4e63-8ad6-47c837569f8c", "38cfca9f-ced1-455a-959d-1d8ce511cf12", "a83c1447-dc1e-4031-b980-0681ae445438", "2188f180-19b4-4113-a9da-2f0f098f7fcd", "b690b915-d3f1-45b9-8e98-e15e983e8281", "8a9e8699-72b1-41d5-be79-e0fa419b159d", "fa9031f1-f536-43fe-83f6-366410a7045f", "db61edbd-5557-4c25-b41c-41943ce70929", "51b3e956-242c-4969-98bf-80eb55b0964f", "866d25d5-07bb-4377-bb80-0ced84497836", "c45ac5d1-934f-4e69-8023-fdb97f686ba6", "d13a6d5b-8a64-45f3-bf0f-b26b73f96182", "458256af-3567-4413-9a54-9a6a43b2bed4", "310fc173-a27a-44f5-80e0-762a7977bf43", "a14e43ae-3134-4b05-827e-843c456b7091", "55452ade-c642-4cdb-8268-9f520d60f376", "148e58f6-a688-4178-b841-4e1582efdbfc", "92ffbe6d-c427-4deb-b422-8d966e7a0e4c", "3ec98074-0004-4d32-9e46-09897e42fd16", "2043fc45-87ba-4221-9f2d-e9f53c69e365", "c70e0772-d561-4088-a023-a0d37f39a0f3", "f667b5e4-6d67-40e4-837e-1e606b360314", "73ce1a21-9e47-4620-b74d-5dd63fe72bae", "0262bee5-a9a2-400f-a690-3b01a5aa1df0", "be4bcd32-1f8c-4942-a274-6feaf503d7ad"], "parent_id": "d7064ba6-829e-4acb-8323-ddbd20c53d89", "prefix_titles": [["title", "D'ya like DAGs? A Survey on Structure Learning and Causal Discovery"], ["section", "Continuous Optimization Based Approaches"]], "content": "\\label{sec:cont}\nThe primary focus of this survey is to review continuous optimization based methods for structure discovery. Continuous optimizaion methods are pervasive in the field of deep learning, whereby highly parameterized networks are optimized using variations on gradient descent . Increased compute (particularly with the advent of GPUs) make the task of learning from large, high-dimensional datasets feasible. Recently, there have been an increasing number of methods which seek to learn structure from data, whilst leveraging the advantages of continuous optimization. This has resulted in the confluence of black-box deep learning approaches, and structure discovery. These continuous optimization approaches recast the combinatoric graph-search problem into a continuous optimization problem (specifically, an Equality Constrained Program) . In Equation~\\ref{eq:notears}, the left hand side represents the traditional approach, which seeks the adjacency matrix $\\mathbf{A}$ that minimizes some score function $S(\\mathbf{A})$, subject to the implied $d$-vertex graph $\\mathcal{G}(A)$ being in the set of valid DAGs. The right hand side represents a characterization of the continuous optimization problem which, again, seeks the adjacency matrix $\\mathbf{A}$ that minimizes some score function $S(\\mathbf{A})$, but this time subject to the constraint $h(\\mathbf{A}) = 0 $. Here, $h$ is the function used to enforce acyclicity in the inferred graph. \n\\vspace{-2mm}\n\\begin{equation}\n\\begin{array}{cl}\n\\min _{\\mathbf{A} \\in \\mathbb{R}^{d \\times d}} S(\\mathbf{A}) & \\; \\; \\; \\; \\; \\; \\min _{\\mathbf{A} \\in \\mathbb{R}^{d \\times d}} S(\\mathbf{A}) \\\\ \\text { subject to } \\mathcal{G}(\\mathbf{A}) \\in \\mathrm{DAGs} & \\;\\;\\;\\;\\;\\text { subject to } h(\\mathbf{A})=0\n\\end{array}\n\\label{eq:notears}\n\\end{equation}\n\\vspace{-1mm}\nThe increased popularity of structure discovery in deep learning is not without sound motivation, with arguments that disentangled, structured, and symbolic representations are key to the next generation of AI, as well as robust cross-domain performance, transfer learning, and interpretability . Researchers have noted three primary approaches to learning representations of the world: (1) distributed, (2) structured and symbolic, and (3) a hybrid of (1) and (2). Most basic neural networks perform distributed learning and there is no clear separation of high-level semantics.. \n\\begin{table}[hb!]\n\\centering\n\\scriptsize\n\\begin{tabular}{llllll}\n\\toprule\n\\textbf{Method}  & \\textbf{Year} & \\textbf{Data} & \\textbf{Acycl.} & \\textbf{Interv.} & \\textbf{Output} \\\\ \\midrule\nCMS  & 2014 & low & - & no &Bi \\\\\nNO TEARS\t&\t2018 &\tlow &\tyes &\tno &\tDAG \\\\\nCGNN\t&\t2018 & low &  yes & no & DAG \\\\\t\t\t\t\nGraphite\t&\t2019 &  low/medium & no & no & UG \\\\\t\tSAM\t&\t2019 & low/medium & yes & no & DAG \\\\\t\nDAG-GNN\t&\t2019\t & low & yes &  no & DAG \\\\\t\nGAE\t&\t2019\t\t & low &  yes& no & DAG\\\\\t\t\t\nNO BEARS\t&\t2019\t & low/medium/high & yes & no & DAG \\\\\t\nMeta-Transfer\t&\t2019\t &Bi& yes & yes &Bi\\\\\t\nDEAR\t\t&2020\t\t\t & high & yes & no & - \\\\\t\t\nCAN\t\t&2020 &\tlow/medium/high\t& yes &\tno &\tDAG \\\\\nNO FEARS\t\t&2020\t\t\t\t &  low & yes & no & DAG\\\\\t\nGOLEM\t&\t2020\t\t & low & yes & no  & DAG\\\\\t\t\t\nABIC\t\t&2020\t\t & low & yes & no & ADMG/PAG \\\\\t\t\t\nDYNOTEARS\t\t&2020\t\t & low & yes & no & SVAR \\\\\t\t\t\nSDI\t\t&2020\t\t\t\t & low & yes & yes & DAG \\\\\t\nAEQ\t&\t2020\t\t\t &Bi& - & no & direction\\\\\t\t\nRL-BIC\t&\t2020\t\t & low & yes & no & DAG \\\\\t\t\t\nCRN\t&\t2020\t\t\t & low & yes  &  yes & DAG\\\\\t\t\nACD\t\t&2020\t\t & low & Granger & no & time-series DAG\\\\\t\t\t\nV-CDN\t\t&2020\t\t & high & Granger & no  & time-series DAG\\\\\t\t\t\nCASTLE (reg.)\t\t&2020\t\t & low/medium & yes & no & DAG\\\\\t\t\t\nGranDAG\t\t&2020\t\t & low &yes & no  & DAG\\\\\t\t\t\nMaskedNN\t\t&2020\t & low & yes & no & DAG\\\\\t    \t\t\t\nCausalVAE\t\t&2020\t\t\t & high & yes & yes & DAG\\\\\t\t\nCAREFL\t&\t2020\t & low & yes & no & DAG / Bi\\\\\t\t\t\t\nVarando\t&\t2020\t\t & low & yes& no& DAG \\\\\t\t\t\nNO TEARS+\t&\t2020\t & low& yes& no& DAG \\\\\t\t\t\t\nICL\t\t&2020\t\t\t\t & low  & yes & no & DAG\\\\\t\nLEAST\t\t&2020 & low/medium/high & yes & no & DAG \t\\\\ \\bottomrule\n\\end{tabular}\n\\caption{This table comprises a list of continuous optimization based approaches to causal discovery. `Data' indicates the dimensionality of the data the method has been demonstrated to handle. `Bi' indicates bivariate cause-effect pairs (possibly multivariate), `low' indicates <100 vertices, `medium' indicates >100, and `high' indicates either dimensionality >10,000 or data which are not already projected into a causal/semantic space (\\textit{e.g.}, image data). `Acycl.' indicates whether the method enforces acyclicity, and `Interv.' indicates the use of interventions during learning. Please consult the main test for further details of each method. N.B. If the output is `DAG' this is not meant to necessarily imply the method identifies the \\textit{true} DAG.}\n\\label{tab:conttable}\n\\end{table}\nConversely, DAGs are highly structured and facilitate causal reasoning. However, such reasoning is only possible if one already has access to variables which represent high-level semantic concepts, which is not the case when learning from raw video data, for example. Hence the motivation for hybrids which can be used to `learn' or infer high-level representations as well as the structured relations between them. Examples of hybrid approaches include methods such as Recurrent Independent Mechanisms , graph networks , and a large body of work on scene understanding . The debate as to how much structural inductive bias / constraint is required for an algorithm to reason effectively is ongoing . Indeed, finding a DAG to represent complex phenomena (such as natural language) is non-trivial and potentially impossible.\nIn this section we review the recent evolution of continuous optimization based approaches to structure learning, and Table \\ref{tab:conttable} presents a non-exhaustive list of such methods.", "cites": [7809, 4416, 4414, 318, 4417, 7814, 4415, 4419, 4420, 7812, 166, 8782, 4418, 7815, 7813, 4413, 4410, 7807, 4409, 4412, 4395, 7810, 208, 4411, 8773, 7811, 4390, 7808, 4393], "cite_extract_rate": 0.6444444444444445, "origin_cites_number": 45, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.5, "critical": 2.0, "abstraction": 2.5}, "insight_level": "medium", "analysis": "The section provides a descriptive overview of continuous optimization-based approaches for DAG structure learning and includes a table summarizing multiple methods. While it references several key papers, it largely functions as a catalog without deep synthesis or critical evaluation of the methods. Some abstract ideas, such as the role of structured vs. distributed representations, are introduced, but the section lacks a nuanced discussion of trade-offs or broader theoretical implications."}}
{"id": "57b8cba2-5515-4be3-b553-21e84bde0b9f", "title": "DAGs with NO TEARS (2018)", "level": "subsection", "subsections": [], "parent_id": "e3f99f06-d65d-4b95-8b55-0b44c70b2761", "prefix_titles": [["title", "D'ya like DAGs? A Survey on Structure Learning and Causal Discovery"], ["section", "Continuous Optimization Based Approaches"], ["subsection", "DAGs with NO TEARS (2018)"]], "content": "The recent (2018) method DAGs with NO TEARS (Non-combinatoric Optimization via Trace Exponential Augmented lagRangian Structure learning)  is generally considered as the first to recast the combinatoric graph search problem as a continuous optimization problem (see Equation \\ref{eq:notears}). The function $h$ for enforcing acyclicity is derived to be:\n\\vspace{-1mm}\n\\begin{equation}\n    h(\\mathbf{A}) = tr(e^{\\mathbf{A}\\odot \\mathbf{A}}) - d = 0\n    \\label{eq:notearsacyclicity}\n\\end{equation}\n\\vspace{-5mm}\nIn practice, $h(A)$ may be small but non-zero, and edges may require some thresholding. One of the disadvantages of this acyclicity constraint is that the matrix exponential requires $\\mathcal{O}(d^3)$ computations, and subsequent methods seek to improve on this. The structural model learnt is linear such that $X_j = a_j^T \\mathbf{X} + U_j$, where $a_j$ is the weight in the adjacency matrix corresponding with the edges into $X_j$, (the noise variables are not assumed to be Gaussian). NO TEARS uses a least-squares loss with an $l1$ penalty to encourage sparsity, and their objective is optimized using the Augmented Lagrangian method  with L-BFGS . As well as synthetic data, NO TEARS is also evaluated on the proteins and phospholipid dataset by Sachs et al. (2005) . Despite the fact that the formulated optimization problem does not guarantee an optimal solution, their results demonstrate close-to-optimal results on the chosen datasets.", "cites": [7810], "cite_extract_rate": 0.25, "origin_cites_number": 4, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.0, "abstraction": 3.5}, "insight_level": "medium", "analysis": "The section provides a clear synthesis of the NO TEARS method, integrating the theoretical formulation of the acyclicity constraint with its practical implementation and evaluation. It critically mentions the computational cost of the matrix exponential and the lack of guaranteed optimality, which are important limitations. While it offers some abstraction by highlighting the shift from combinatorial to continuous optimization, it could further contextualize this within broader trends in causal discovery."}}
{"id": "1f33f466-a955-4d63-bd6c-a91dd141fd8f", "title": "Causal Generative Neural Network (CGNN, 2018)", "level": "subsection", "subsections": [], "parent_id": "e3f99f06-d65d-4b95-8b55-0b44c70b2761", "prefix_titles": [["title", "D'ya like DAGs? A Survey on Structure Learning and Causal Discovery"], ["section", "Continuous Optimization Based Approaches"], ["subsection", "Causal Generative Neural Network (CGNN, 2018)"]], "content": "CGNN  combines graph learning with continuous optimization, neural networks, and hill-climbing or Tabu search. The neural networks are used to learn the functions mapping variables (\\textit{e.g.} see the SEM breakdown in Figure \\ref{fig:sem}), where the variables themselves are selected according to the output of a greedy-search  algorithm. The motivation for the neural network is that they do not impose restrictions on the functional form \\textit{a priori} and therefore \"let the data speak\" . The networks are trained using the Adam  optimizer with a Maximum Mean Discrepancy (MMD)  score function. During training, the edges are directed in order to minimize this discrepancy, and following training, the graph is adjusted to remove cycles. CGNN incorporates a hill-climbing search algorithm to optimize the structure of the DAG, and then the network optimization resumes. This training cycle is repeated to convergence, and each edge has an associated score representing its contribution to the global fit. They use a thresholding function to regularize the number of edges in the graph. Finally, their method includes a means to identify possible hidden confounding, by leveraging the fact that confounding can be modelled as correlations/associations between the (otherwise) exogenous latent random variables.", "cites": [8773], "cite_extract_rate": 0.25, "origin_cites_number": 4, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.5, "critical": 2.0, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section provides a factual summary of the CGNN approach, describing its components, training process, and handling of hidden confounding. While it mentions connections to concepts like SEM and MMD, it does not synthesize these ideas into a broader framework or compare CGNN to other methods in depth. There is little critical evaluation or abstraction to higher-level principles."}}
{"id": "6c3c5181-4556-4079-89e7-a38fc977cf6c", "title": "Graphite (2019)", "level": "subsection", "subsections": [], "parent_id": "e3f99f06-d65d-4b95-8b55-0b44c70b2761", "prefix_titles": [["title", "D'ya like DAGs? A Survey on Structure Learning and Causal Discovery"], ["section", "Continuous Optimization Based Approaches"], ["subsection", "Graphite (2019)"]], "content": "Graphite  is a generative neural network model incorporating a graph neural network  encoder, where latent variables are inferred using black-box variational inference . Graphite takes in graphical/network data, and infers a posterior latent distribution over these data. The network is trained to reconstruct the graph which is parameterized using a symmetric, weighted adjacency matrix (\\textit{i.e.} the graph is undirected). The method is shown to perform well on data with as many as 19,717 vertices.", "cites": [5680, 8783, 2073, 4421], "cite_extract_rate": 0.6666666666666666, "origin_cites_number": 6, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 1.5, "abstraction": 1.5}, "insight_level": "low", "analysis": "The section provides a straightforward description of the Graphite method, referencing foundational papers on variational inference. However, it lacks synthesis by failing to connect these ideas to broader themes in structure learning, offers minimal critical analysis of the approach or its limitations, and does not abstract to general principles or trends in the field."}}
{"id": "41fb3958-62af-452b-92b6-1df7f638aa05", "title": "Structural Agnostic Modeling (SAM, 2019)", "level": "subsection", "subsections": [], "parent_id": "e3f99f06-d65d-4b95-8b55-0b44c70b2761", "prefix_titles": [["title", "D'ya like DAGs? A Survey on Structure Learning and Causal Discovery"], ["section", "Continuous Optimization Based Approaches"], ["subsection", "Structural Agnostic Modeling (SAM, 2019)"]], "content": "SAM  is a neural network approach that is intended to address the limitations of CGNN. These limitations are CGNN's quadratic complexity (due to the calculation of the MMD), and the scalability issues that arise due to CGNNs use of a greedy-search. SAM addresses these two limitations with the use of adversarial training , and by making the mechanism which optimizes the DAG part of end-to-end training. Their score function is a log-likelihood loss with two model complexity regularizers: One that penalizes the model, on a per-vertex basis, by an amount proportional to the number of vertex parents; and one which acts as neural network parameter/weight decay. It uses an acyclicity constraint which is similar to the one in NO TEARS  to encourage DAG-ness:\n\\vspace{-2mm}\n\\begin{equation}\n    \\sum_{k=1}^{d}\\frac{tr(A_j)}{k!} = 0\n\\end{equation}\nHere, $A$ is what they call a structural gate, which performs the same function as an adjacency matrix. The neural network parameterization of the structural equation model is $X_j = L_{j,H+1}\\circ \\sigma \\circ ...L_{j,1}([\\mathbf{a}_j \\odot \\mathbf{X}, U_j]$. In words, the stack of $H$ neural network layers $L_H$ and non-linearities $\\sigma$ for each variable $j$ is used as the function over the Hadamard product between the data $\\mathbf{X}$ and a binary vector form of the adjacency matrix $A$, s.t. $a_{i,j} = 1$ iff there is an edge $X_i \\rightarrow X_j$. They provide a detailed theoretical analysis of their method, showing how the global training objective constitues a combination of a structural component (which seeks the CPDAG) and a functional component (which exploits asymmetries). They assume both faithfulness and sufficiency, and evaluate on a range of low to medium dimensionality datasets (the highest number of dimensions is approximately 6000 (DREAM5 ).", "cites": [7810], "cite_extract_rate": 0.2, "origin_cites_number": 5, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.5, "critical": 3.0, "abstraction": 3.0}, "insight_level": "medium", "analysis": "The section provides an analytical overview of SAM by highlighting its motivations (addressing CGNN's limitations) and innovations (adversarial training, end-to-end optimization). It integrates the acyclicity constraint from NO TEARS, showing synthesis with another key paper. However, the critical analysis is moderate, focusing more on features than on limitations or trade-offs. Abstraction is limited to identifying the general use of continuous optimization and neural network parameterization."}}
{"id": "f155b2c4-f043-4e63-8ad6-47c837569f8c", "title": "DAG Graph Neural Network (DAG-GNN, 2019)", "level": "subsection", "subsections": [], "parent_id": "e3f99f06-d65d-4b95-8b55-0b44c70b2761", "prefix_titles": [["title", "D'ya like DAGs? A Survey on Structure Learning and Causal Discovery"], ["section", "Continuous Optimization Based Approaches"], ["subsection", "DAG Graph Neural Network (DAG-GNN, 2019)"]], "content": "DAG-GNN  extends NO TEARS by incorporating neural network functions $f$ and black-box variational inference such that the score function is the Evidence Lower BOund (ELBO) . The method assumes faithfulness, and infers a latent posterior $\\mathbf{Z}$: \n\\vspace{-1mm}\n\\begin{equation}\n    \\mathbf{Z} = f_4((\\mathbf{I}-\\mathbf{A}^T)f_3(\\mathbf{X})\n    \\label{eq:daggnn1}\n\\end{equation}\nwhere $A$ is a weighted adjacency matrix, and $\\mathbf{X}$ may comprise vector-valued variables. DAG-GNN recovers the observations with a decoder:\n\\vspace{-1mm}\n\\begin{equation}\n\\mathbf{X} = f_2((\\mathbf{I} - \\mathbf{A}^T)^{-1}f_1(\\mathbf{Z}))\n\\label{eq:daggnn2}\n\\end{equation}\nTogether, Equations \\ref{eq:daggnn1} and \\ref{eq:daggnn2} constitute a variational autoencoder . Noting that if $f_2$ is invertible, then:\n\\vspace{-1mm}\n\\begin{equation}\n    f_2^{-1}(\\mathbf{X}) = \\mathbf{A}^Tf_2^{-1}(\\mathbf{X}) + f_1(\\mathbf{Z})\n\\end{equation}\nwhich is a generalization of the linear SEM model $\\mathbf{X} = \\mathbf{A}^T\\mathbf{X}+\\mathbf{Z}$. Acyclicity is enforced using a constraint derived from the one employed in NO TEARS  as:\n\\vspace{-1mm}\n\\begin{equation}\n    tr[(\\mathbf{I} + \\alpha \\mathbf{A} \\odot \\mathbf{A})^d] - d = 0\n\\end{equation}\nwhere $\\alpha$ acts as a hyperparameter on this constraint. This formulation of the acyclicity constraint is justified on the basis of that it is preferred over a calculation that involves the matrix exponential (as appears in Equation \\ref{eq:notearsacyclicity}). Similarly to NO TEARS, they also use the augmented Lagriangian approach to optimization. They evaluate on low-dimensional data such as the proteins and phospholipid dataset by Sachs et al. (2005) .", "cites": [5680, 8783, 7810, 4413, 2073, 4421], "cite_extract_rate": 0.8571428571428571, "origin_cites_number": 7, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.5, "critical": 2.0, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section provides a descriptive overview of DAG-GNN, explaining its formulation, the use of variational autoencoders, and the acyclicity constraint. While it references related work (e.g., NO TEARS and variational inference methods), it lacks deeper synthesis of how these components interrelate or contribute to broader themes in causal discovery. There is minimal critical analysis or abstraction beyond the specific method."}}
{"id": "38cfca9f-ced1-455a-959d-1d8ce511cf12", "title": "Graph AutoEncoder (GAE, 2019)", "level": "subsection", "subsections": [], "parent_id": "e3f99f06-d65d-4b95-8b55-0b44c70b2761", "prefix_titles": [["title", "D'ya like DAGs? A Survey on Structure Learning and Causal Discovery"], ["section", "Continuous Optimization Based Approaches"], ["subsection", "Graph AutoEncoder (GAE, 2019)"]], "content": "GAE  extends NO TEARS and DAG-GNN formulations for structure learning into a graph autoencoder model, facilitating non-linear structural relationships and vector-valued variables. They model structure in the same way as DAG-GNN, and draw a connection to graph convolutional neural networks :\n\\vspace{-1mm}\n\\begin{equation}\n    f(X_j, \\mathbf{A}) = f_2(\\mathbf{A}^T f_1(X_j))\n\\end{equation}\nwhere $f_1$ and $f_2$ are multilayer perceptrons (MLPs). Similarly to NO TEARS, and DAG-GNN, they also use the augmented Lagrangian method with Adam  for constrained optimization. Their acyclicity constraint is identical to the one used in NO TEARS (Equation \\ref{eq:notearsacyclicity}). They demonstrate that GAE performs significantly better than NO TEARS and DAG-GNN, particularly as the number of vertices in the graph increases, and also highlight that training time is much shorter.", "cites": [4418], "cite_extract_rate": 0.3333333333333333, "origin_cites_number": 3, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.5, "critical": 2.0, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section briefly describes the GAE method and its relation to NO TEARS and DAG-GNN, but it largely summarizes the approach without synthesizing ideas across the cited works. There is minimal critical evaluation or abstraction of broader principles, focusing mainly on factual reporting of the model formulation and performance."}}
{"id": "a83c1447-dc1e-4031-b980-0681ae445438", "title": "Meta-Transfer Objectives (2019)", "level": "subsection", "subsections": [], "parent_id": "e3f99f06-d65d-4b95-8b55-0b44c70b2761", "prefix_titles": [["title", "D'ya like DAGs? A Survey on Structure Learning and Causal Discovery"], ["section", "Continuous Optimization Based Approaches"], ["subsection", "Meta-Transfer Objectives (2019)"]], "content": "Bengio et al.  identify that if the correct causal direction is known, then learning algorithms adapt faster under distributional shift (\\textit{i.e.} intervention), than they do if it makes the incorrect assumptions about the direction. This is demonstrated by comparing the adaptation rates, and formulating a meta-learning objective that accounts for the rates of learning under different directional assumptions.", "cites": [4415], "cite_extract_rate": 1.0, "origin_cites_number": 1, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.0, "critical": 2.0, "abstraction": 3.0}, "insight_level": "medium", "analysis": "The section provides an analytical overview by highlighting the key idea from Bengio et al. (2019) that correct causal direction leads to faster adaptation under distributional shifts. It synthesizes the paper’s meta-learning objective into a concise explanation but does not integrate broader literature or compare it with other approaches in depth. While it offers some level of abstraction by framing the concept in terms of adaptation rates, it lacks deeper critical evaluation or discussion of limitations."}}
{"id": "b690b915-d3f1-45b9-8e98-e15e983e8281", "title": "Disentangled gEnerative cAusal Representation Learning (DEAR 2020)", "level": "subsection", "subsections": [], "parent_id": "e3f99f06-d65d-4b95-8b55-0b44c70b2761", "prefix_titles": [["title", "D'ya like DAGs? A Survey on Structure Learning and Causal Discovery"], ["section", "Continuous Optimization Based Approaches"], ["subsection", "Disentangled gEnerative cAusal Representation Learning (DEAR 2020)"]], "content": "DEAR  combines a Variational AutoEncoder (VAE)  with an adversarial loss  in order to infer a latent space with \"causal\" structure. Strictly, this is not a causal discovery method, because they assume the `super-graph' is given, and they learn the associated weights and parameters. The latent space is given supervision in the form of labels for the generative factors. The latent structure is defined as:\n \\vspace{-1mm}\n\\begin{equation}\n    z = f((\\mathbf{I} - \\mathbf{A}^T)^{-1}h(\\epsilon))\n\\end{equation}\nHere, $A$ is a weighted adjacency matrix, $f$ and $h$ are neural networks, and $\\epsilon$ is noise sampled from a prior distribution. DEAR is notable for its use of high-dimensional data with semantic labels. It maps from image data to the structured latent space, where the labels provide a form of supervision.", "cites": [2073, 5680], "cite_extract_rate": 0.5, "origin_cites_number": 4, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 2.0, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section provides a basic description of the DEAR method, integrating some background from the cited VAE papers but without connecting it to broader trends in causal discovery. It mentions that DEAR is not a causal discovery method in the strict sense and highlights its use of supervision and high-dimensional data, but lacks deeper critical analysis or abstraction into general principles."}}
{"id": "8a9e8699-72b1-41d5-be79-e0fa419b159d", "title": "Causal Adversarial Network (CAN 2020)", "level": "subsection", "subsections": [], "parent_id": "e3f99f06-d65d-4b95-8b55-0b44c70b2761", "prefix_titles": [["title", "D'ya like DAGs? A Survey on Structure Learning and Causal Discovery"], ["section", "Continuous Optimization Based Approaches"], ["subsection", "Causal Adversarial Network (CAN 2020)"]], "content": "CAN  is a Generative Adversarial Network (GAN)  that facilitates interventional sampling from a structural graph (which the authors refer to as a causal graph) at inference time. It comprises a Label Generation Network, which learns a graph from the dataset labels, and a Conditional Image Generation Network, which generates the images conditioned on the interventional distribution specified by the user at inference time. Their generator is a function of an adjacency matrix applied to the noise vectors as $\\mathbf{X} = G((\\mathbf{I} - \\mathbf{A}^T)^{-1}\\mathbf{Z})$ where $X$ is a sample from the join distribution, $\\mathbf{Z}$ is random noise, $A$ is a weighted adjacency matrix, $\\mathbf{I}$ is the identity matrix, and $G$ is the non-linear generator function. In order to impose acyclicity they leverage an equality constraint , such that acyclicity occurs if:\n\\vspace{-1mm}\n\\begin{equation}\n    tr[(\\mathbf{I} + \\beta \\mathbf{A} \\odot \\mathbf{A})^d] - d = 0\n\\end{equation}\nwhere  $d$ is the number of vertices in the graph, `$tr$' is the trace operator, $\\odot$ is the Hadamard product, and $\\beta$ is a non-zero hyperparameter.\nAs well as evaluating CAN on CelebA  image data (including the generation of interventional samples), they also evaluate it on the more traditional CHILD  and Alarm  datasets showing performance competitive with state-of-the-art.", "cites": [4413, 4409, 485], "cite_extract_rate": 0.5, "origin_cites_number": 6, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 1.5, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section provides a factual description of the Causal Adversarial Network (CAN 2020) method, including its components and mathematical formulation. While it references related works such as DAG-GNN and the broader context of DAG structure learning, it lacks deeper synthesis or connection of ideas across these works. There is minimal critical evaluation or identification of broader patterns or principles."}}
{"id": "fa9031f1-f536-43fe-83f6-366410a7045f", "title": "DAGs with NO FEARS", "level": "subsection", "subsections": [], "parent_id": "e3f99f06-d65d-4b95-8b55-0b44c70b2761", "prefix_titles": [["title", "D'ya like DAGs? A Survey on Structure Learning and Causal Discovery"], ["section", "Continuous Optimization Based Approaches"], ["subsection", "DAGs with NO FEARS"]], "content": "NO FEARS  revisits and updates aspects of DAG-GNN and NO TEARS. They provide a detailed analysis of the acyclicity constraint of NO TEARS (see Equation \\ref{eq:notearsacyclicity}) and show that, following the augmented Lagrangian optimization, it is not guaranteed to converge to a feasible solution of the intend constraint (\\textit{i.e.}, when $h(\\mathbf{A}) = 0$). Instead of a constraint that depends on $\\mathbf{A}\\odot \\mathbf{A}$, they propose one that depends only on the absolute value $|\\mathbf{A}|$, on the basis that there is a connection with the $l1$ penalty and sparsity. Following some modifications to make the absolute value function differentiable, the authors modify existing algorithms with knowledge derived through theoretic analysis, and show their proposal to improve all baselines (including combinatoric approaches).", "cites": [7813], "cite_extract_rate": 1.0, "origin_cites_number": 1, "insight_result": {"error": "Failed to parse LLM response", "raw_response": "{\n    \"type\": \"analytical\",\n    \"scores\": {\"synthesis\": 4.0, \"critical\": 4.0, \"abstraction\": 3.5},\n    \"insight_level\": \"high\",\n    \"analysis\": \"The section provides a clear synthesis of the NO FEARS paper by highlighting its theoretical contributions and improvements over prior methods like DAG-GNN and NO TEARS. It offers critical analysis by pointing out limitations of the NO TEARS acyclicity constraint and explaining the motivation behind the proposed changes. The abstraction is strong in ide"}}
{"id": "db61edbd-5557-4c25-b41c-41943ce70929", "title": "Gradient-based Optimization of dag-penalized Likelihood for learning linEar dag Models (GOLEM, 2020)", "level": "subsection", "subsections": [], "parent_id": "e3f99f06-d65d-4b95-8b55-0b44c70b2761", "prefix_titles": [["title", "D'ya like DAGs? A Survey on Structure Learning and Causal Discovery"], ["section", "Continuous Optimization Based Approaches"], ["subsection", "Gradient-based Optimization of dag-penalized Likelihood for learning linEar dag Models (GOLEM, 2020)"]], "content": "Following in a similar vain to other works such as NO BEARS, DAG-GNN, and NO FEARS, GOLEM  examines the acyclicity constraint of NO FEARS. They also note that NO TEARS uses a least-squares score function, and improve on this by proposing a score function that directly maximizes the data likelihood. The authors show that in the linear Gaussian case and under mild assumptions (such as faithfulness), a likelihood-based objective with `soft' sparsity regularization is sufficient to asymptotically identify a quasi-equivalent (see original paper for definition) DAG and that a hard acyclicity constraint is not required. Further, in the linear non-Gaussian scenario, they explain how an acyclicity constraint is not needed in the asymptotic regime, although it may be necessary with finite samples. Finally, they explain how it is sufficient to have a `soft' acyclicity penalty, instead of a hard constraint, which greatly reduces the complexity of the optimization problem. They propose their own objective, including a likelihood based score with an $l1$ regularizer and soft acyclicity constraint, which they optimize using Adam . Some post-processing is undertaken to threshold edges in order to guarantee acyclicity. The primary distinctions from NO TEARS are, therefore, (a) the likelihood based score function, and (b) the use of a soft (rather than hard) aycyclicity penalty.", "cites": [7808], "cite_extract_rate": 0.5, "origin_cites_number": 2, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.5, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section effectively synthesizes GOLEM with related works like NO BEARS, DAG-GNN, and NO TEARS, linking them through their treatment of acyclicity constraints. It provides a critical analysis by discussing the trade-offs between hard and soft constraints and the role of sparsity and likelihood in DAG recovery. The abstraction level is high as it generalizes about the optimization formulation and its implications for causal discovery."}}
{"id": "51b3e956-242c-4969-98bf-80eb55b0964f", "title": "Approximate Bayesian Information Criterion for Differentiable Causal Discovery Under Unmeasured Confounding (ABIC, 2020)", "level": "subsection", "subsections": [], "parent_id": "e3f99f06-d65d-4b95-8b55-0b44c70b2761", "prefix_titles": [["title", "D'ya like DAGs? A Survey on Structure Learning and Causal Discovery"], ["section", "Continuous Optimization Based Approaches"], ["subsection", "Approximate Bayesian Information Criterion for Differentiable Causal Discovery Under Unmeasured Confounding (ABIC, 2020)"]], "content": "ABIC  extends the continuous optimization paradigm to discover various types (ancestral, arid, bow-free) of ADMGs which account for unmeasured confounding. In the linear SEM case, unmeasured confounders manifest as correlated errors, which are represented in a \\textit{second} adjacency matrix. They present three differentiable constraints which can be used to discover a particular type of ADMG. They use the BIC criterion as the primary objective/score function. The parameters are optimized using a Residual Iterative Conditional Fitting algorithm .", "cites": [8784, 4395], "cite_extract_rate": 1.0, "origin_cites_number": 2, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 1.5, "abstraction": 1.5}, "insight_level": "low", "analysis": "The section provides a basic description of the ABIC method and its approach to differentiable causal discovery under unmeasured confounding. It mentions how the method extends continuous optimization to ADMGs, the use of BIC as a score function, and the optimization algorithm employed. However, there is minimal synthesis of the cited papers, no critical evaluation or comparison with other methods, and no abstraction to broader principles or frameworks in causal discovery."}}
{"id": "866d25d5-07bb-4377-bb80-0ced84497836", "title": "DYNOTEARS (2020)", "level": "subsection", "subsections": [], "parent_id": "e3f99f06-d65d-4b95-8b55-0b44c70b2761", "prefix_titles": [["title", "D'ya like DAGs? A Survey on Structure Learning and Causal Discovery"], ["section", "Continuous Optimization Based Approaches"], ["subsection", "DYNOTEARS (2020)"]], "content": "DYNOTEARS  seeks to discover structure in time series data, which is a topic we have not covered in Section 2 of this work. By using second order optimization, DYNOTEARS seeks to learn a Structural Vector AutoRegressive (SVAR) model, which is also a form of dynamic Bayesian network. This is argued to be important on the basis that temporal dynamics are an essential part of real-world systems, which cannot be captured using a static graph model. They assume that variables potentially affect each other both contemporaneously, and in a time-lagged manner. DYNOTEARS is, therefore, not Granger causal, because it accounts for contemporaneous effects \\cite[p.203-208]{Peters2017}. They model two adjacency matrices, $\\mathbf{W}$ and $\\mathbf{A}$, for the intra-slice and inter-slice graph edges, respectively. Because the edges represented in $\\mathbf{A}$ only go forward in time, only $\\mathbf{W}$ needs an acyclicity constraint. They use the same constraint as NO TEARS (see Equation \\ref{eq:notearsacyclicity}, and incorporate it into an augmented Lagrangian problem which is optimized using L-BFGS-B . Following optimization, and similarly to other methods using acyclicity constraints, they threshold edges with weights close to 0. DYNOTEARS is evaluated on S\\&P 500 returns data with 97 vertices, and on DREAM4 with 100 vertices .", "cites": [7811], "cite_extract_rate": 0.3333333333333333, "origin_cites_number": 3, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 1.5, "abstraction": 1.5}, "insight_level": "low", "analysis": "The section provides a basic description of the DYNOTEARS method, including its objective, key assumptions, and technical details such as adjacency matrices and optimization techniques. It integrates minimal context from the cited paper but does not connect DYNOTEARS to broader themes or compare it with other time-series structure learning approaches. There is little critical evaluation or abstraction of principles beyond the specific method."}}
{"id": "c45ac5d1-934f-4e69-8023-fdb97f686ba6", "title": "Structural Discovery from Intervention (SDI, 2020)", "level": "subsection", "subsections": [], "parent_id": "e3f99f06-d65d-4b95-8b55-0b44c70b2761", "prefix_titles": [["title", "D'ya like DAGs? A Survey on Structure Learning and Causal Discovery"], ["section", "Continuous Optimization Based Approaches"], ["subsection", "Structural Discovery from Intervention (SDI, 2020)"]], "content": "SDI  is a neural network method that assumes faithfulness and sufficiency, and which attempts to discover structure using data which have been subject to unknown interventions. SDI is restricted to discrete, categorical variables with no missingness; it assumes the available interventions are sparse and only effect a single (possibly unknown) variable; the interventions may be soft; and there are no compounding interventions (\\textit{i.e.}, only one or less interventions occur in the data). \nThe method is trained in three stages which repeat until convergence. The first stage is concerned with updating the functional parameters (those which map between vertices). The procedure involves randomly drawing data samples and graph configurations, and optimizing the functional parameters using the log-likelihood as a score function. In the second stage the structural parameters are updated (those which model the edges between vertices), and interventional (unknown) data are sampled. The variable subject to intervention is predicted using a simple heuristic; namely, that the variable exhibiting the greatest reduction in log-likelihood is predicted on the basis that it is a poor fit to the observational distribution. Given a new set of interventional data and sampled graphs, these graphs can be scored whilst masking the intervened variable. In the third stage, and following , the REINFORCE algorithm  is used to update the discrete structural parameters. \nThey apply an acyclicity constraint which is derived from Equation \\ref{eq:notearsacyclicity} as: $\\sum_{i\\neq j} \\mbox{cosh}(\\sigma(a_{ij})\\sigma(a_{ji})) $, where $a_{ij}$ is the structural parameter linking variable $i$ to $j$, and $\\sigma$ is the sigmoid function. The method is evaluated on low-dimensional data ($d < 100$), and is shown to exceed state-of-the-art on a number of benchmark datasets.", "cites": [4415], "cite_extract_rate": 0.3333333333333333, "origin_cites_number": 3, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 2.0, "abstraction": 2.0}, "insight_level": "medium", "analysis": "The section provides a clear and factual description of the SDI method, outlining its assumptions, training stages, and evaluation results. It cites one relevant paper but does not integrate or synthesize ideas across multiple sources. There is minimal critical analysis or abstraction, as the section primarily summarizes the method without comparing it to others or discussing its broader implications or limitations."}}
{"id": "d13a6d5b-8a64-45f3-bf0f-b26b73f96182", "title": "AutoEncoder Complexity (AEQ, 2020)", "level": "subsection", "subsections": [], "parent_id": "e3f99f06-d65d-4b95-8b55-0b44c70b2761", "prefix_titles": [["title", "D'ya like DAGs? A Survey on Structure Learning and Causal Discovery"], ["section", "Continuous Optimization Based Approaches"], ["subsection", "AutoEncoder Complexity (AEQ, 2020)"]], "content": "The authors of the AEQ method  develop a score function based on autoencoder reconstruction error for discovering the directionality of vector valued cause-effect pairs. Their key result is that the SEM $Y = g(f(X), U)$ only holds in one direction if $X$ and $Y$ are vectors and $g$ and $f$ are neural network functions. They extend this result to univariate $X$ by creating multivariate versions of the variable based on a sorted concatenation of slices of the original. The complexity of this multivariate surrogate is then measured using an autoencoder reconstruction error (they use an $l2$ loss). For a cause-effect pair, the variable with the higher loss is likely to be the cause. In the case where the original variables are multivariate, they propose an adversarial conditional independence method that discriminates between joint distributions and the product of the marginals (resembling a mutual information proxy).", "cites": [7809], "cite_extract_rate": 1.0, "origin_cites_number": 1, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 2.0, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section provides a factual description of the AEQ method and its use of autoencoder reconstruction error for causal discovery. It integrates only one cited paper and does not connect it to other approaches or theories. There is minimal critical evaluation or abstraction beyond the specific method."}}
{"id": "458256af-3567-4413-9a54-9a6a43b2bed4", "title": "Causal Discovery with Reinforcement Learning (RL-BIC, 2020)", "level": "subsection", "subsections": [], "parent_id": "e3f99f06-d65d-4b95-8b55-0b44c70b2761", "prefix_titles": [["title", "D'ya like DAGs? A Survey on Structure Learning and Causal Discovery"], ["section", "Continuous Optimization Based Approaches"], ["subsection", "Causal Discovery with Reinforcement Learning (RL-BIC, 2020)"]], "content": "The authors of RL-BIC  take a reinforcement learning approach to causal discovery. They generate directed graphs using an encoder-decoder neural network model, which forms the `actor'. The output of the encoder-decoder is the proposed graph, which is scored using the BIC in order to generate a reward signal. A critic is used to update the proposed graphs and therefore also to drive the optimization of the neural network parameters. They assume an additive noise model $X_i = f_i(pa_i) + U_i$ as well as faithfulness and causal sufficiency. Their output graph is represented using a binary adjacency matrix. They mask out $(i,i)$ edges to prevent self-loops, and incorporate an adapted form of the NO TEARS acyclicity penalty:\n\\begin{equation}\n    h(\\mathbf{A}) = tr(e^{\\mathbf{A}})- d = 0\n\\end{equation}\nIn order to guarantee acyclicity (in the event that $h(\\mathbf{A})$ is small but non-zero), they augment it with a hard indicator function penalty that acts on whether the graph is a valid DAG or not. All generated graphs are stored during training, and the one with the best score is chosen, and this graph is finally pruned to reduce false discovery. The method is trained using poly-gradient method and REINFORCE  with Adam , and evaluated on relatively small graphs ($\\leq 30$ nodes).", "cites": [4416], "cite_extract_rate": 0.3333333333333333, "origin_cites_number": 3, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 2.0, "abstraction": 1.5}, "insight_level": "low", "analysis": "The section provides a straightforward description of the RL-BIC method and its components without synthesizing broader themes or connecting it to other methods in the field. There is minimal critical analysis of its strengths or limitations, and no abstraction to higher-level concepts or trends in causal discovery. The content remains focused on the specific paper and method."}}
{"id": "310fc173-a27a-44f5-80e0-762a7977bf43", "title": "Meta-Learning Neural Causal Representations (CRN, 2020)", "level": "subsection", "subsections": [], "parent_id": "e3f99f06-d65d-4b95-8b55-0b44c70b2761", "prefix_titles": [["title", "D'ya like DAGs? A Survey on Structure Learning and Causal Discovery"], ["section", "Continuous Optimization Based Approaches"], ["subsection", "Meta-Learning Neural Causal Representations (CRN, 2020)"]], "content": "Ke et al. (2020)  propose a meta-learning neural network method that leverages continuous representations of graphs and which assumes causal sufficiency. Training is split into episodes where, for each episode, a graph is proposed and used to generate data for the duration of the episode. The episode is further split into $k$ time points, and for each time point a random intervention is undertaken on the graph and data is generated. The model is then asked to predict the outcome of the intervention, and thereby ends up `learning' the causal relationships between the variables in the graph. They also propose a Causal Relational Network (CRN), which accumulates information about the interventions and graphs over time (similar to an LSTM ). They use a graph decoder (the gradients from which are not backpropagated to the rest of the network) in order to validate the graph's continuous representation against the ground truth graph. It is shown that CRNs learn new causal models quickly and efficiently. Interestingly, there is no discussion about (a)cyclicity, but nonetheless their intention is to learn DAGs.", "cites": [4412], "cite_extract_rate": 0.5, "origin_cites_number": 2, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 2.0, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section provides a basic descriptive summary of the CRN (2020) paper, outlining its method, training process, and results. It mentions the use of a graph decoder and notes the absence of discussion on (a)cyclicity, but does not integrate this work with others in the field or place it within a broader framework. There is limited critical evaluation or abstraction beyond the specific method described."}}
{"id": "a14e43ae-3134-4b05-827e-843c456b7091", "title": "Amortized Causal Discovery (ACD, 2020)", "level": "subsection", "subsections": [], "parent_id": "e3f99f06-d65d-4b95-8b55-0b44c70b2761", "prefix_titles": [["title", "D'ya like DAGs? A Survey on Structure Learning and Causal Discovery"], ["section", "Continuous Optimization Based Approaches"], ["subsection", "Amortized Causal Discovery (ACD, 2020)"]], "content": "ACD  is a Granger-causality non-linear time-series method which leverages black-box variational inference  to infer a latent posterior graph. Granger causality assumes there are no contemporaneous effects \\cite[p.203-208]{Peters2017}. The method is demonstrated to perform well under hidden confounding (and so does not assume causal sufficiency). \nACD learns from samples with different causal relationships but shared dynamics. This is motivated using an example from neuroscience. They use the encoder to infer the causal graph from a particular sample, and a decoder which models the dynamics and takes past samples and the inferred graph in order to predict the future. Specifically, for sample $\\mathbf{X}_s$ with graph encoder $f$ and decoder dynamics model $g$, the future is predicted as $\\mathbf{X}_s^{t+1} = g(\\mathbf{X}_s^{\\leq t}, f(\\mathbf{X}_s))$. The graph is inferred from the entire sample, and the dynamics model $g$ is used to predict the future given the inferred graph and a portion of the past.", "cites": [5680, 8783, 2073, 4421, 4411], "cite_extract_rate": 1.0, "origin_cites_number": 5, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 1.5, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section provides a basic description of the Amortized Causal Discovery (ACD) method and its components, such as the encoder and decoder, but does not effectively synthesize insights from the cited variational inference papers. There is minimal critical analysis or evaluation of the approach's strengths and weaknesses relative to other methods. The content remains largely concrete and does not abstract to broader principles or patterns in causal discovery."}}
{"id": "55452ade-c642-4cdb-8268-9f520d60f376", "title": "Causal Discovery from Video (V-CDN, 2020)", "level": "subsection", "subsections": [], "parent_id": "e3f99f06-d65d-4b95-8b55-0b44c70b2761", "prefix_titles": [["title", "D'ya like DAGs? A Survey on Structure Learning and Causal Discovery"], ["section", "Continuous Optimization Based Approaches"], ["subsection", "Causal Discovery from Video (V-CDN, 2020)"]], "content": "The authors of V-CDN  use unsupervised key-point detection on video data in order to build a causal representation of these points. It is a Granger-causal non-linear time-series method which leverages black-box variational inference  and deep neural networks to infer a latent graph which explains the structural relationships between the deteceted keypoints. They integrate a dynamics module to facilitate future prediction.", "cites": [5680, 8783, 2073, 4421, 4390], "cite_extract_rate": 1.0, "origin_cites_number": 5, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 1.5, "abstraction": 1.5}, "insight_level": "low", "analysis": "The section provides a brief description of the V-CDN method and mentions the use of variational inference and deep neural networks, but it does not synthesize or connect these ideas meaningfully with the cited papers. There is minimal critical evaluation of the method or its limitations, and no abstraction or generalization to broader trends or principles in causal discovery or continuous optimization."}}
{"id": "148e58f6-a688-4178-b841-4e1582efdbfc", "title": "Causal Structure Learning (CASTLE, 2020)", "level": "subsection", "subsections": [], "parent_id": "e3f99f06-d65d-4b95-8b55-0b44c70b2761", "prefix_titles": [["title", "D'ya like DAGs? A Survey on Structure Learning and Causal Discovery"], ["section", "Continuous Optimization Based Approaches"], ["subsection", "Causal Structure Learning (CASTLE, 2020)"]], "content": "The authors of CASTLE  propose causal discovery as an auxiliary task which helps to regularize a supervised predictive model. The motivation is that, by identifying key causal factors, the model avoids overfitting to potential confounders which hurt model robustness and generalizability. Specifically, a neural network model attempts to identify the DAG that explains the structural relationships between the observed variables, and this task is built into an autoencoder  framework. Their structural model is non-parametric, following the form $X_i = f_i(pa_i, U_i)$ and using an acyclicity constraint:\n\\vspace{-2mm}\n\\begin{equation}\n    h(\\mathbf{A}) = (tr(e^{\\mathbf{A}\\odot \\mathbf{A}}) - d - 1)^2\n\\end{equation}\nwhich, they explain, also forces the autoencoder to reconstruct only the input variables which have neighbours.", "cites": [7812], "cite_extract_rate": 0.5, "origin_cites_number": 2, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 1.5, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section provides a factual summary of the CASTLE method, describing its framework and acyclicity constraint. It integrates minimal context from the cited paper but does not connect it to broader themes or other works in the field. There is little critical evaluation or abstraction, focusing mainly on what the method does rather than its implications, limitations, or how it fits into the wider landscape of causal discovery."}}
{"id": "92ffbe6d-c427-4deb-b422-8d966e7a0e4c", "title": "Gradient Based Neural DAG Learning (GranDAG, 2020)", "level": "subsection", "subsections": [], "parent_id": "e3f99f06-d65d-4b95-8b55-0b44c70b2761", "prefix_titles": [["title", "D'ya like DAGs? A Survey on Structure Learning and Causal Discovery"], ["section", "Continuous Optimization Based Approaches"], ["subsection", "Gradient Based Neural DAG Learning (GranDAG, 2020)"]], "content": "In a similar vain to other methods, GranDAG  seeks to expand upon NO TEARS in order to deal with non-linear relationships through the use of neural networks. They follow the non-linear additive noise structural model of the form $X_j = f_j(pa_j) + U_j$, where each function $f_j$ is parameterized as a fully-connected neural network. In order to maintain an independence of mechanisms which corresponds with the independence implied by an adjacency matrix, they formulate \\textit{neural network paths} and a  \\textit{connectivity matrix}, resembling previous work by Germain et al. (2015) . The connectivity matrix $\\mathbf{C}_j$ is essentially the matrix product of all neural network weights in a single neural network (\\textit{i.e.}, parameterizing one $f_j$). This product results in $\\mathbf{C}_j \\in \\mathbb{R}^{m \\times d}$ where $m$ is the number of parameters needed to specify a chosen distribution for $X_j$ (\\textit{e.g.}, a Gaussian has two parameters), and $d$ is the number of variables.  If $\\mathbf{C}_{j,ki}= 0$ then the input $i$ is independent of output $k$ for variable $X_j$. Note that $f_j$ takes as input $X_{-j}$ (where the variable of interest $j$ is masked to zero). The connectivity matrix is then used to define their weighted adjacency matrix, such that the adjacency matrix $\\mathbf{A} \\in \\mathbb{R}^{d\\times d}$ depends on all neural network weights from all neural networks. They define the weighted adjacency matrix and substitute it into the NO TEARS acyclicity constraint as:\n\\vspace{-1mm}\n\\begin{equation}\n    h(\\mathbf{A}) = tr(e^{\\mathbf{A}}) - d = 0\n\\end{equation}\nFor learning they employ the augmented Lagrangian formulation, using a log-likelihood score function, and threshold the resulting edges for $h(\\mathbf{A}){ij})$ close to zero. They demonstrate that their continuous optimization based approach exceeds the performance of combinatoric approaches such as PC , as well as other continuous optimization based approaches e.g. NO TEARS and DAG-GNN.", "cites": [7816], "cite_extract_rate": 0.3333333333333333, "origin_cites_number": 3, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 2.0, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section provides a factual description of GranDAG, its model structure, and optimization approach, with a reference to prior work by Germain et al. (2015) and MADE. However, it lacks deeper synthesis of these works into a broader context, critical evaluation of their limitations or trade-offs, and abstraction to general principles. It primarily summarizes the method rather than offering insightful analysis."}}
{"id": "3ec98074-0004-4d32-9e46-09897e42fd16", "title": "Masked Gradient Based Structure Learning (MaskedNN, 2020)", "level": "subsection", "subsections": [], "parent_id": "e3f99f06-d65d-4b95-8b55-0b44c70b2761", "prefix_titles": [["title", "D'ya like DAGs? A Survey on Structure Learning and Causal Discovery"], ["section", "Continuous Optimization Based Approaches"], ["subsection", "Masked Gradient Based Structure Learning (MaskedNN, 2020)"]], "content": "The researchers behind  attempt to improve on NO TEARS  using neural networks. They assume an additive noise SEM of the form $X_j = f_j(pa_j) + U_j$, and explain how their method can be directly extended from handling scalar variables to vector valued variables. They provide a discussion on identifiability (something which a number of methods in both the combinatoric and continuous optimization literature tend to omit). They provide an overview of the gradual evolution from NO TEARS (which assumes linear SEMs), via DAG-GNN , GAE  and GraNDAG  (which handle non-linear SEMs), but highlight that these methods do not provide an in depth discussion about identifiability. They also highlight that the use of non-linear transformations on the adjacency matrices in DAG-GNN and GAE may affect their causal interpretability.\nMaskedNN uses a binary adjacency matrix  $\\mathbf{A}$ (rather than weighted), which is integrated into their SEM as: $X_j = h_j(\\mathbf{A}_j \\odot \\mathbf{X}) + U_j$ and refer to this as an Augmented SEM (ASEM). Their discussion on identifiability states that their method can learn a Super-graph of the true graph, and further utilize thresholding and Causal Additive Model  based pruning to remove spurious edges under mild conditions. They leverage the Gumbel-softmax trick  to incorporate discrete learning (in view of the binary adjacency matrix) into an augmented Lagrangian 1st order continuous optimization based approach with an Adam optimizer ).", "cites": [4422, 7810, 4418, 4413, 782, 4393], "cite_extract_rate": 0.6666666666666666, "origin_cites_number": 9, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.5, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section effectively synthesizes MaskedNN and related works, placing it in the broader context of continuous optimization-based DAG learning methods like NO TEARS, DAG-GNN, GAE, and GraNDAG. It offers critical insights by pointing out the lack of identifiability discussion in earlier methods and how MaskedNN addresses it using thresholding and pruning. It abstracts the discussion by highlighting the transition from linear to non-linear SEMs and the implications of discrete vs. continuous optimization."}}
{"id": "2043fc45-87ba-4221-9f2d-e9f53c69e365", "title": "Causal Variational AutoEncoder (CausalVAE, 2020)", "level": "subsection", "subsections": [], "parent_id": "e3f99f06-d65d-4b95-8b55-0b44c70b2761", "prefix_titles": [["title", "D'ya like DAGs? A Survey on Structure Learning and Causal Discovery"], ["section", "Continuous Optimization Based Approaches"], ["subsection", "Causal Variational AutoEncoder (CausalVAE, 2020)"]], "content": "The creators of CausalVAE  argue that whilst many disentangled representation learning methods assume independence between latent factors , most latent factors behind real-world phenomena exhibit causal dependencies. They propose the use of a Variational AutoEncoder . The latent space of a VAE is usually parameterized by a set of exogeneous factors (often modelled as a multivariate, isotropic Gaussian). CausalVAE integrates a \\textit{Causal Layer} which transforms these exogenous latent factors into endogenous factors which reflect the causal semantics of the data. They assume a linear SEM following the form $\\mathbf{Z} = \\mathbf{A}^T \\mathbf{Z} + \\mathbf{U}$ where $\\mathbf{Z}$ are the inferred latent factors following the application of the adjacency matrix $\\mathbf{A}$. They integrate supervision in the form of semantic labels $\\mathbf{Y}$ to condition the posterior $p(\\mathbf{Z}|\\mathbf{Y})$, which forces identifiability.\nThese factors (which now reflect semantic quantities according to the provided supervision) are then passed to a masking layer, similar to the one used in MaskedNN. They then apply $Z_j = g_j(\\mathbf{A}_j \\odot \\mathbf{Z}) + U_j $ where $g$ are nonlinear and invertible functions. $\\mathbf{A}_j \\odot \\mathbf{Z}$ yields a vector only containing parental information, because the adjacency matrix effectively masks non-parents. The authors explain how this masking layer facilitates interventional queries. In order to learn the causal structure, they incorporate the structural inductive prior into the supervised loss function:\n\\vspace{-1mm}\n\\begin{equation}\n    l_y = \\mathbb{E}_q || \\mathbf{Y} - \\sigma (\\mathbf{A}^T\\mathbf{Y})||^2_2\n\\end{equation}\nwhere $q$ is the approx posterior distribution. They incorporate the NO TEARS acyclicity constraint:\n\\vspace{-2mm}\n\\begin{equation}\n    h(\\mathbf{A}) = tr((\\mathbf{I}+ \\mathbf{A}\\odot \\mathbf{A})^d)-d = 0\n\\end{equation}\nThe method is evaluated on the CelebA  dataset, as well as a synthetic data of a pendulum casting a shadow from a light. The second dataset is used to demonstrate the interventions - they intervene (for example) on the position of the light in order to demonstrate the independence of the position of the pendulum as well as the dependence with the shadow.", "cites": [4424, 5680, 2073, 4423, 485], "cite_extract_rate": 0.7142857142857143, "origin_cites_number": 7, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.5, "critical": 2.5, "abstraction": 3.0}, "insight_level": "medium", "analysis": "The section provides an analytical overview of CausalVAE by explaining its design, assumptions, and evaluation. It synthesizes ideas from multiple VAE-related papers to contextualize the method within the broader field of disentangled representation learning. However, it lacks deeper critical evaluation of the method's limitations and broader comparisons with other approaches. The abstraction level is moderate, as it connects the method to general concepts like causal dependencies and identifiability but does not elevate the discussion to overarching principles in causal discovery."}}
{"id": "c70e0772-d561-4088-a023-a0d37f39a0f3", "title": "Causal AutoRegressive Flows (CAREFL, 2020)", "level": "subsection", "subsections": [], "parent_id": "e3f99f06-d65d-4b95-8b55-0b44c70b2761", "prefix_titles": [["title", "D'ya like DAGs? A Survey on Structure Learning and Causal Discovery"], ["section", "Continuous Optimization Based Approaches"], ["subsection", "Causal AutoRegressive Flows (CAREFL, 2020)"]], "content": "In CAREFL , the authors combine causal discovery with the deep learning framework known as normalizing flows . Normalizing flows provide a means to construct generative models which have the capacity to model complex densities using invertible transformations of a basic and tractable density. They enable the exact computation of the log-likelihood (which constitute their learning objective) via the use of the change of variables formula and inverse log Jacobian determinant. Specifically, they use autoregressive flows, which are a form of normalizing flow for which the transformations are affine and have simple, lower-triangular Jacobians .\nThe authors consider an SEM in terms of a \\textit{causal ordering}, whereby, according to the SEM/DAG, there exists a permutation of the vertices that corresponds to the order of specified dependencies. For example, a parent vertex precedes a child vertex in the causal ordering. The generic additive noise SEM $X_j = f_j(pa_j)+ U_j$ can be written in terms of a causal ordering $\\pi$ as $X_j = f_j(\\mathbf{X}_{<\\pi(j)}) + U_j$ (which is assumed for CAREFL), where $X_{<\\pi(j)}$ represents variables that precede $X_j$ in the causal order (including its parents). This latter form is shown to bear resemblance to the autoregressive flow model with a few constraints. The CAREFL method is shown to be flexible enough to answer both counterfactual and interventional queries. As well as outputting a DAG, the method can also be used to judge causal direction by using the log-likelihood to score different directions.", "cites": [3329, 3292, 4417, 4425], "cite_extract_rate": 0.8, "origin_cites_number": 5, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 2.5, "abstraction": 3.5}, "insight_level": "medium", "analysis": "The section synthesizes key ideas from multiple papers to explain how CAREFL connects causal discovery and normalizing flows, particularly autoregressive ones. It integrates concepts like causal ordering and log-likelihood scoring effectively. However, it lacks deeper critical evaluation of the method's limitations or broader comparisons with alternative approaches, and while it identifies a conceptual link, it does not fully abstract to a meta-level principle of causal modeling."}}
{"id": "f667b5e4-6d67-40e4-837e-1e606b360314", "title": "DAGs without Imposing Acyclicity (NODAG, 2020)", "level": "subsection", "subsections": [], "parent_id": "e3f99f06-d65d-4b95-8b55-0b44c70b2761", "prefix_titles": [["title", "D'ya like DAGs? A Survey on Structure Learning and Causal Discovery"], ["section", "Continuous Optimization Based Approaches"], ["subsection", "DAGs without Imposing Acyclicity (NODAG, 2020)"]], "content": "Varando (2020)  proposes a proximal gradient  optimization objective that yields a linear SEM and corresponding DAG without requiring an acyclicity constraint. The method derives the novel objective by framing the learning problem in terms of sparse matrix factorization, and the resulting method NODAG is shown to be both effective and efficient.", "cites": [7807], "cite_extract_rate": 0.5, "origin_cites_number": 2, "insight_result": {"type": "descriptive", "scores": {"synthesis": 1.5, "critical": 1.5, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section provides a minimal description of the NODAG method from Varando (2020), paraphrasing the paper's approach without meaningful synthesis or broader context. It lacks critical evaluation or comparison with other methods, and offers little abstraction beyond the specific technique."}}
{"id": "73ce1a21-9e47-4620-b74d-5dd63fe72bae", "title": "NO TEARS+ (2020)", "level": "subsection", "subsections": [], "parent_id": "e3f99f06-d65d-4b95-8b55-0b44c70b2761", "prefix_titles": [["title", "D'ya like DAGs? A Survey on Structure Learning and Causal Discovery"], ["section", "Continuous Optimization Based Approaches"], ["subsection", "NO TEARS+ (2020)"]], "content": "A number of the same authors from NO TEARS revisit their original work and update it. We refer to this later work as NO TEARS+ , which seeks to extend NO TEARS acyclicity constraint to handle nonparametric, general models of the form $g_j(f_j(X))$ (which subsumes additive noise models, linear models, and generalized linear models). This model does not utilize an adjacency matrix, and thus they frame acyclicity in terms of partial derivatives (an idea they attribute to Rosasco et al. (2013) ) such that $[\\mathbf{W}(f)]_{kj} := ||\\partial_k f_j||_2$. This states that the dependency structure between variable $k$ and the function $f_j$ (which is described by the DAG represented in matrix $\\mathbf{W}$) is the $l2$ norm of the partial derivative of $f_j$ with respect to $X_k$. They integrate a multi-layer perceptron into their derived framework (as well as a number of other variations) and demonstrate it's effective performance and efficiency.", "cites": [4426], "cite_extract_rate": 0.5, "origin_cites_number": 2, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 1.5, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section provides a factual summary of NO TEARS+ and its relation to Rosasco et al. (2013), but lacks deeper synthesis of how these ideas connect to broader themes in causal discovery. There is no critical evaluation of the method's strengths or limitations, nor is there abstraction to higher-level patterns or principles in structure learning."}}
{"id": "0262bee5-a9a2-400f-a690-3b01a5aa1df0", "title": "Imputated Causal Learning (ICL, 2020)", "level": "subsection", "subsections": [], "parent_id": "e3f99f06-d65d-4b95-8b55-0b44c70b2761", "prefix_titles": [["title", "D'ya like DAGs? A Survey on Structure Learning and Causal Discovery"], ["section", "Continuous Optimization Based Approaches"], ["subsection", "Imputated Causal Learning (ICL, 2020)"]], "content": "The authors of ICL  focus on the problem of structure discovery under the missing-data setting, and provide definitions and examples of three types of missingness: Missing At Random (MAR), Missing Completely At Random (MCAR), and Missing Not At Random (MNAR). They propose the use of Generative Adversarial Networks (GANs)  and Variational AutoEncoders (VAEs) . ICL takes incomplete data and simultaneously imputes the missing data using the GAN, in order to match the generated distribution to the empirical distribution. The task of the discriminator in the GAN is to differentiate between observed versus generated data. The skeleton graph is estimated using a method following DAG-GNN . Following this, the edges in the skeleton are oriented following a method proposed by Cai et al. (2019)  which is based on the additive noise model for causal direction identification.\n\\begin{table}[h!]\n\\centering\n\\scriptsize\n\\begin{tabular}{ll}\n\\hline\n\\textbf{Method}  & \\textbf{Keywords \\& Software}  \\\\ \\hline\ncausaleffect  & general causality, R\\\\\ndaggity &  general causality, R\\\\\ndosearch  &causal effect identification, R\\\\\nCausal Discovery Toolbox  &causal discovery, Python\\\\\npcalg  &causal discovery, R\\\\\nbnlearn  &causal discovery, R\\\\\nrEDM  & dynamic modeling and convergent cross mapping, R \\\\\nDoWhy   & general causality, Python\\\\\nCausalImpact  &intervention, time series, R\\\\\ncausal-cmd  & general causality, Python (py-causal) \\& JAVA + CLI \\\\\n\\hline \\hline\n\\end{tabular}\n\\caption{This table comprises a list of Python and R packages for general causal inference and structure discovery. CLI = command line interface}\n\\label{tab:packages}\n\\end{table}\n\\vspace{-1.0cm}", "cites": [8782, 7817, 5680, 4413, 2073], "cite_extract_rate": 0.3125, "origin_cites_number": 16, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.5, "critical": 2.0, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section provides a basic description of ICL (2020), citing relevant papers and outlining its approach to handling missing data in causal structure learning. While it integrates a few concepts (e.g., using GANs and DAG-GNN), it lacks deeper synthesis, critical evaluation of the methods, or broader abstraction. The inclusion of a table of tools is factual but not discussed in relation to the method or its limitations."}}
{"id": "be4bcd32-1f8c-4942-a274-6feaf503d7ad", "title": "Scalable Learning for Bayesian Networks (LEAST, 2020)", "level": "subsection", "subsections": [], "parent_id": "e3f99f06-d65d-4b95-8b55-0b44c70b2761", "prefix_titles": [["title", "D'ya like DAGs? A Survey on Structure Learning and Causal Discovery"], ["section", "Continuous Optimization Based Approaches"], ["subsection", "Scalable Learning for Bayesian Networks (LEAST, 2020)"]], "content": "The authors of LEAST  propose a new acyclicity constraint, which improves upon the $\\mathcal{O}(d^3)$ cost of NO TEARS . To do this, they first consider:\n\\begin{equation}\n    h(\\mathbf{S}) = tr(e^\\mathbf{S}) - d = 0\n\\end{equation}\nto be the NO TEARS constraint, where $\\mathbf{S} = \\mathbf{A}\\odot \\mathbf{A}$. This was subsequently altered by  to:\n\\vspace{-1mm}\n\\begin{equation}\n    g(\\mathbf{S}) = tr((\\mathbf{I} + \\mathbf{S})^d) - d = tr(\\sum_{k=1}^d\\frac{d}{k}\\mathbf{S}^k) =0 \n\\end{equation}\n\\vspace{-3mm}\n on the basis that $e^\\mathbf{S} = \\sum_{i=0}^{\\inf} \\frac{\\mathbf{S}^k}{k!}$, where $k$ is the length of a cycle. The authors of LEAST argue that both of these have drawbacks relating to $\\mathcal{O}(d^3)$ complexity, as well as storage of  $e^S$. They note that NO BEARS  framed the problem in terms of a spectral radius (the absolute value of the largest Eigenvalue of $S$). However, this also requires $\\mathcal{O}(d^3)$ computation, so they derive an upper bound $\\bar{\\delta}$ on this spectral radius as:\n \\vspace{-1mm}\n \\begin{equation}\n \\begin{split}\n     \\bar{\\delta}^{(k)} = \\sum_{i=1}^db^{(k)}[i] \\; \\; \\; \\mbox{where} \\\\\n     b^{(k)} = (r(\\mathbf{S}^{(k)}))^\\alpha \\odot (c(\\mathbf{S}^{(k)}))^{1-\\alpha} \\; \\; \\; \\mbox{and} \\\\\n     \\mathbf{S}^{(k+1)} = (D^{(k)})^{-1}\\mathbf{S}^{(k)}D^{(k)} \\;\\;\\;\\; \\mbox{and} \\\\\n     D^{(k)} = \\mbox{Diag}(b^{(k)})\n     \\end{split}\n \\end{equation}\n\\vspace{-1mm}\nCombining a computable form for this upper bound with the least squares objective and $l1$ regularization, they show that this new objective is nearer to $\\mathcal{O}(d)$, and trains between 5 and 15 times faster than NO TEARS. Note that edge thresholding is still required. They demonstrate the benefits of this speedup by evaluating on both small graphs, as well as graphs with as many as 160,000 vertices.\n\\begin{table}[hb!]\n\\centering\n\\scriptsize\n\\begin{tabular}{lll}\n\\toprule\n\\textbf{Dataset}  & \\textbf{Vertices} & \\textbf{Notes}  \\\\ \\midrule\nMulti-body Interaction  &  - & up to 5 moving balls with physical interactions/relations \\\\\nFabric deformation  &  - &applying forces to different fabrics \\\\\nCause-effect pairs  & 2 & bivariate distributions\\\\\nCause-effect pairs  & 2 & bivariate distributions \\\\\nCause-effect pairs (Tuebingen)  & 2 & bivariate  distributions \\\\\nSynTReN  & user specified & synthetic gene expression data\\\\\nSachs  &  11 & proteins and phospholipids in human cells \\\\\nScale-Free Graphs  & user specified & preferential attachment graph generation law \\\\\nErdos-R\\'{e}nyi Graphs (\\textit{e.g.} ) & user specified & adds edges with probability $p=\\frac{2e}{d^2-d}$ \\\\\nLinear, GP Add, GP Mix, Sigmoid Add and Sigmoid Mix & - & mixed graph data \\\\\nCausalWorld  & - & comprehensive robotics dataset\\\\\nMPI3D  & - & visual disentanglement dataset \\\\\nPendulum-light-shadow  & - & image data \\\\\nPhase coupled oscillator  & - & physical relations \\\\\nNetSim  & user specified & fMRI data simulation\\\\\nTemperature  & & \\\\\nBnLearn   & -  & Repository \\\\\nDREAM series  & up to 6000 & simulated and in-vivo gene regulation networks \\\\\nCausality 4 Climate  & - & climate change time series competition data \\\\\nArchaeology  & 8 & archaeology data \\\\ \nS\\&P500 & 500 & time series / stock returns\\\\\n\\bottomrule\n\\end{tabular}\n\\caption{This table comprises a list of datasets that have been used for testing structure discovery methods.}\n\\label{tab:data}\n\\end{table}\n\\vspace{-1cm}", "cites": [8779, 4400, 7815, 4413, 4427, 7818, 7810, 9145, 4411, 4390], "cite_extract_rate": 0.4166666666666667, "origin_cites_number": 24, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.5, "critical": 2.0, "abstraction": 2.0}, "insight_level": "medium", "analysis": "The section primarily describes the LEAST method and its acyclicity constraint, referencing NO TEARS and NO BEARS for context. It synthesizes a limited amount of information from the cited papers to highlight the method's computational improvements but does not deeply connect or integrate ideas from multiple sources. There is minimal critical analysis or abstraction to broader principles, with the focus largely on factual description."}}
{"id": "f54e2ad6-7a62-4a87-9c56-5285a7c27d6b", "title": "Summary and Discussion", "level": "section", "subsections": ["596577d6-b9e1-4559-985a-5619ff7d52b1", "ab961f1d-f44e-4b96-9c10-ac46f6613ff1"], "parent_id": "d7064ba6-829e-4acb-8323-ddbd20c53d89", "prefix_titles": [["title", "D'ya like DAGs? A Survey on Structure Learning and Causal Discovery"], ["section", "Summary and Discussion"]], "content": "\\label{sec:summary}\nWe have attempted to present the relevant background, definitions, assumptions, approaches to causal discovery, common evaluation metrics, as well as providing a brief review of combinatoric methods, and a detailed review of continuous optimization based methods. In terms of additional resources, a range of software packages exist for undertaking causal inference and structure discovery and we have provided a list in Table \\ref{tab:packages} for convenience. Also, in Table \\ref{tab:data} we provide a list of datasets used for causal discovery. Note that not all of these datasets are readily available.\n Finally, we encourage readers to explore various additional references and commentaries. These include: A discussion of the relevance of causality to machine learning ; Commentaries on the nature of causality ; alternative reviews on causal inference and causal discovery ; reviews with a focus on time-series causal inference and discovery ; frameworks for dynamical SCMs with ODEs ; guides on the foundations for causal discovery ; some example applications ; textbooks on causal inference and causal discovery .", "cites": [8786, 4431, 4416, 4430, 4388, 8785, 4428, 4429], "cite_extract_rate": 0.36363636363636365, "origin_cites_number": 22, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.5, "critical": 2.0, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section provides a general overview of the survey's contents and lists additional resources, including the cited papers, but does not synthesize or integrate their specific contributions into a cohesive narrative. There is minimal critical analysis of the cited works, and the discussion remains at a high level without abstracting broader principles or trends in the field."}}
{"id": "596577d6-b9e1-4559-985a-5619ff7d52b1", "title": "Opportunities and Future Directions", "level": "subsection", "subsections": [], "parent_id": "f54e2ad6-7a62-4a87-9c56-5285a7c27d6b", "prefix_titles": [["title", "D'ya like DAGs? A Survey on Structure Learning and Causal Discovery"], ["section", "Summary and Discussion"], ["subsection", "Opportunities and Future Directions"]], "content": "One of the main advantages to combinatoric approaches to structure discovery relates to the provision of guarantees for identifying the true graph, or at least the true equivalence class. This advantage comes at a significant cost, however, because such approaches are limited to low-dimensional problems (or low-cardinality graphs) due to the super-exponential search space. One might expect, then, that even though the continuous optimization approaches are confronted with a non-trivial, non-convex solution space, they might at least scale to larger problems. Unfortunately, and as can be seen from Table \\ref{tab:conttable}, most continuous optimization approaches have only been evaluated on low-dimensional problems. This seems to be due to the fact that the most common acyclicity constraint, namely the one in Equation \\ref{eq:notearsacyclicity} from NO TEARS , contains a term that requires $\\mathcal{O}({d^3})$ computations. This has motivated the development of higher-efficiency acyclicity constraints for continuous optimization approaches to structure discovery, such as the one in LEAST . One further way to alleviate the issues when confronted with high-dimensional problems is to encode the data into a lower-dimensional representation. This was undertaken in CausalVAE , who applied the NO TEARS constraint to a graph operating in low-dimensional representation space. Whilst this approach works well for non-semantic data (such as pixel data from images), it might not be useful in situations whereby the data are both high-dimensional \\textit{and} semantic (as with gene regulation data in the DREAM5 dataset ). In the latter case, encoding semantic data into a new subspace may or may not be meaningful, and will likely depend on the domain of application.\nIn terms of what we consider to present the most opportunity for future work, we note that there are relatively few continuous optimization approaches which seek to learn structured, semantic representations from non-semantic, high-dimensional data such as video or image data (exceptions include CausalVAE  and DEAR , and related works on scene understanding include ). Interestingly, the field of reinforcement learning, which involves the interaction of learning agents with each other and their environment, has been relatively slow on the uptake of causal perspectives . Ashton (2020)  even notes that one of the seminal texts on reinforcement learning  makes no explicit reference to causality throughout the entire text. As such, the application of causal discovery to reinforcement learning presents significant opportunity.\\footnote{Some exceptions include .} Finally, whilst there were numerous combinatoric methods which are designed to handle unobserved confounding and/or cyclicity (\\textit{e.g.}, CCD , backshift , CCI ), there are relatively few such continuous optimization approaches. Given the complexity of time-varying real-world phenomena and the potential for cycles, we note the opportunity to develop continuous optimization methods which can operate in a broader class of scenarios.", "cites": [4392, 4433, 4402, 7821, 7820, 4434, 8787, 4439, 4432, 4438, 4436, 7815, 7810, 4435, 4437, 4429, 7819], "cite_extract_rate": 0.7083333333333334, "origin_cites_number": 24, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.5, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section effectively synthesizes key concepts from multiple cited papers to identify coherent trends and open challenges in the field of causal discovery and its intersections with reinforcement learning and high-dimensional data. It provides critical analysis by pointing out limitations in current continuous optimization methods and their scalability issues. Furthermore, the section abstracts from individual papers to highlight broader opportunities, such as the need for structured semantic representations and the underutilization of causal perspectives in reinforcement learning."}}
{"id": "ab961f1d-f44e-4b96-9c10-ac46f6613ff1", "title": "The Causal Leap", "level": "subsection", "subsections": [], "parent_id": "f54e2ad6-7a62-4a87-9c56-5285a7c27d6b", "prefix_titles": [["title", "D'ya like DAGs? A Survey on Structure Learning and Causal Discovery"], ["section", "Summary and Discussion"], ["subsection", "The Causal Leap"]], "content": "It was mentioned in Section 1, that a causal perspective is crucial to the empirical sciences as well as for improving machine learning methods. More fundamentally, as humans we are interested in how to reason about and interact in a world full of causal interactions. In general, the pursuit of causality is essential to understanding the world and our universe. However, it is fraught with difficulty, and below we finish with a discussion on some of the criticisms and warnings relating to this otherwise laudable pursuit. \nWe now take the time to discuss how structure discovery methods take us from a structural association (albeit, an association which may exhibit directional asymmetry) to that of a causal association. What is there to suggest that learning or identifying such a graphical or structural model is equivalent to learning or identifying causes and generative structure in reality? In order to interpret graphical models causally, the the Causal Markov Condition (CMC)  is often assumed. However, in our view (and see also ) the CMC simply represents an uninformative re-branding of the regular Markov condition (which describes the conditional independence properties of the graph), with the additional and rather audacious interpretation of the arrows as directed causal dependencies. As Dawid (2008) \\cite[p.83]{Dawid2008} argues, \"there is no reason to believe [the causal implications of the CMC] hold in complete generality\". It should be clear that the conditional independence properties of DAGs play a foundational r\\^{o}le in causal discovery. However, as Dawid (2008) states in his work \\textit{Beware of the DAG!}: \"...for conditional independence the arrows are nothing but incidental construction features supporting the $d$-separation semantics.\" It may be interesting, then, to observe just how many structure discovery methods, particularly those which rely exclusively on conditional independencies (rather than, say, interventional data and rigorous identifiability), uncritically label themselves as causal... \nThe use of structural equations gets us somewhat closer to where we want to be when seeking to represent causality, than do graphical models alone. This is because the structural equation formalism  can be more specific and informative than its simpler (yet intuitive) graphical counterpart \\cite[p.106]{Peters2017}. Nonetheless, as with graphical models, the interpretation of structural equations as structural causal models cannot be made without strong and often untestable assumptions. Applying these strong assumptions to structural or graphical models incites some harsh criticism. Indeed, Korb \\& Wallace (1997) caricature research into causal discovery as \"a glorious perversion\" akin to the \"search for the philosopher's stone\" \\cite[p.551]{Korb1997}. \nSuch criticisms are important to assimilate, and they remind us to be careful when using statistical/causal models to draw inference about the nature of reality. In particular, even if a graphical model bears resemblance to our own conception of a phenomenon, it may not be an appropriate or fair way to represent complex social constructs (\\textit{e.g.}, gender or race), representing what Freidman described as a biased attempt to \"quantify the qualitative, make discrete the continuous, or formalize the nonformal\" . For instance, it is not clear what it means to be able to manipulate/intervene on someone's race, independently of their other attributes, or indeed at all. In general, we need a thorough understanding of what a variable is \\textit{supposed} to represent, and whether it actually represents it at all (both a problem of ontology and epistemology) before we perform meaningful inference. However, a sufficiently clear understanding may be slippery and, in some cases, impossible to attain. \nThe prevalence of reports of systemic bias arising from automated decision processes is increasing, and an awareness for sources of bias is critical in undertaking fair and equitable machine learning . Just because causal discovery methods define themselves as `causal', does not mean there are not significant problems with taking the leap from data to reality. Indeed, blindly interpreting structured models as robustly representing causal quantities can be immensely problematic. We appreciate Dawid's  reference to Bourdieu who warns of \"sliding from the model of reality to the reality of the model\" .\nIn spite of the notable criticisms, causal discovery methods may still be used productively, particularly for exploratory purposes (\\textit{e.g.}, in providing candidate causal links for further investigation and validation) . Furthermore, the combination of observational and interventional/experimental data may provide us with opportunities to uniquely \\textit{identify} models which, at least under various assumptions, correspond with some true external cause-effect relationships. More broadly, shifting from naive associational and purely predictive machine learning models to models informed by causal structure, may bring concomitant improvements in model robustness and generalizability. So long as researchers maintain a cautious approach when making the leap from modelling structure to inferring causality, structure discovery methods can still be used in support of the endeavour to further human understanding.\n\\bibliographystyle{ACM-Reference-Format}\n\\bibliography{NN.bib}\n\\appendix\n\\end{document}\n\\endinput", "cites": [4440, 7822], "cite_extract_rate": 0.2222222222222222, "origin_cites_number": 9, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.5, "critical": 4.2, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section offers a nuanced and critical analysis of the assumptions behind causal discovery methods, particularly the Causal Markov Condition and structural equations. It synthesizes perspectives from multiple sources and abstracts to broader philosophical and practical concerns about the leap from data to causality. While it does not deeply integrate the cited papers, it contextualizes their relevance to a larger critique of causal modeling."}}
