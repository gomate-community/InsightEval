{"id": "2e5fc9e6-1214-40d0-8d87-a4789cbd05ad", "title": "Introduction", "level": "section", "subsections": [], "parent_id": "c7a3c574-b9a2-41d9-8a41-220c3546317c", "prefix_titles": [["title", "Generalized Out-of-Distribution Detection: A Survey \n"], ["section", "Introduction"]], "content": "\\label{sec:introduction}\nA trustworthy visual recognition system should not only produce accurate predictions on known context, but also detect unknown examples and reject them (or hand them over to human users for safe handling)~. \nFor instance, a well-trained food classifier should be able to detect non-food images such as selfies uploaded by users, and reject such input instead of blindly classifying them into existing food categories. \nIn safety-critical applications such as autonomous driving, the driving system must issue a warning and hand over the control to drivers when it detects unusual scenes or objects it has never seen during training.\n\\begin{figure}[h]\n\\vspace{-8mm}\n    \\centering\n    \\includegraphics[width=\\linewidth]{figures/taxonomy.pdf}\n    \\caption{Taxonomy of generalized OOD detection framework, illustrated by classification tasks.\n    Four bases are used for the task taxonomy: \n    \\textbf{1)} Distribution shift to detect: the task focuses on detecting covariate shift or semantic shift; \n    \\textbf{2)} ID data type: the ID data contains one single class or multiple classes; \n    \\textbf{3)} Whether the task requires ID classification;\n    \\textbf{4)} Transductive learning task requires all observations;  inductive tasks follow the train-test scheme.\n    Note that ND is often interchangeable with AD, but ND is more concerned with semantic anomalies. \n    OOD detection is generally interchangeable with OSR for classification tasks.}\n    \\vspace{-3mm}\n    \\label{fig:taxonomy}\n\\end{figure}\n\\begin{figure*}[t]\n    \\centering\n    \\includegraphics[width=\\textwidth]{figures/benchmark.pdf}\n    \\caption{Illustration of sub-tasks under generalized OOD detection framework with vision tasks.\n    Tags on test images refer to model's expected predictions.\n    \\textbf{(a)}~In \\emph{sensory anomaly detection}, test images with covariate shift will be considered as OOD. No semantic shift occurs in this setting.\n    \\textbf{(b)}~In \\emph{one-class novelty detection}, normal/ID images belong to one class. Test images with semantic shift will be considered as OOD.\n    \\textbf{(c)}~In \\emph{multi-class novelty detection}, ID images belong to multiple classes. Test images with semantic shift will be considered as OOD.\n    Note that \\textbf{(b)} and \\textbf{(c)} compose novelty detection, which is identical to the topic of semantic anomaly detection.\n    \\textbf{(d)}~\\emph{Open set recognition} is identical to multi-class novelty detection in the task of detection, with the only difference that open set recognition further requires ID classification.\n    \\emph{Out-of-distribution detection} solves the same problem as open-set recognition. It canonically aims to detect test samples with semantic shift without losing the ID classification accuracy.\n    However, OOD Detection encompasses a broader spectrum of learning tasks and solution space.\n    \\textbf{(e)} \\emph{Outlier detection} does not follow a train-test scheme. All observations are provided. It fits in the generalized OOD detection framework by defining the majority distribution as ID. Outliers can have any distribution shift from the majority.\n    }\n    \\label{fig:benchmark}\n\\end{figure*}\nMost existing machine learning models are trained based on the closed-world assumption~, where the test data is assumed to be drawn \\emph{i.i.d.} from the same distribution as the training data, known as in-distribution (ID). However, when models are deployed in an \\emph{open-world} scenario~, test samples can be out-of-distribution (OOD) and therefore should be handled with caution. \nThe distributional shifts can be caused by semantic shift (\\eg OOD samples are drawn from different classes)~, or covariate shift (\\eg OOD samples from a different domain)~.\nThe detection of semantic distribution shift (\\eg due to the occurrence of new classes) is the focal point of OOD detection tasks, where the label space $\\mathcal{Y}$ can be different between ID and OOD data and hence the model should not make any prediction. In addition to OOD detection, several problems adopt the ``open-world'' assumption and have a similar goal of identifying OOD examples. These include outlier detection~(OD)~, anomaly detection~(AD)~, novelty detection~(ND)~, and open set recognition~(OSR)~. \nWhile all these problems are related to each other by sharing similar motivations, subtle differences exist among the \\emph{sub-topics} in terms of the specific definition. \nHowever, the lack of a comprehensive understanding of the relationship between the different sub-topics leads to confusion for both researchers and practitioners. Even worse, these sub-topics, which are supposed to be compared and learned from each other, are developing in isolation.\nIn this survey, we for the first time clarify the similarities and differences between these problems, and present a unified framework termed \\emph{generalized OOD detection}.\nUnder this framework, the five problems (\\ie AD, ND, OSR, OOD detection, and OD) can be viewed as special cases or sub-topics. \nWhile other sub-topics have been extensively surveyed, the summarization of OOD detection methods is still inadequate and requires further exploration. This paper fills this gap by focusing specifically on recent technical developments in OOD detection, analyzing fair experimental comparisons among classical methods on common benchmarks. Our survey concludes by highlighting open challenges and outlining potential avenues for future research.\nWe further conduct a literature review for each sub-topic, with a special focus on the OOD detection task. To sum up, we make three contributions to the research community:\n\\begin{enumerate}\n\\item \\textbf{A Unified Framework}:\nFor the first time, we systematically review five closely related topics of AD, ND, OSR, OOD detection, and OD, and present a unified framework of \\emph{generalized OOD detection}. Under this framework, the similarities and differences of the five sub-topics can be systematically compared and analyzed. We hope our unification helps the community better understand these problems and correctly position their research in the literature.\n\\item \\textbf{A Comprehensive Survey for OOD Detection}:\nNoticing the existence of comprehensive surveys on AD, ND, OSR, and OD methodologies in recent years~, this survey provides a comprehensive overview of OOD detection methods and thus complements existing surveys.\nBy connecting with methodologies of other sub-topics that are also briefly reviewed, as well as sharing the insights from a fair comparison on a standard benchmark, we hope to provide readers with a more holistic understanding of the developments for each problem and their interconnections, especially for OOD detection.\n\\item \\textbf{Future Research Directions}:\nWe draw readers' attention to some problems or limitations that remain in the current generalized OOD detection field. We conclude this survey with discussions on open challenges and opportunities for future research.\n\\end{enumerate}", "cites": [3203, 3208, 7700, 3207, 3206, 3204, 1356, 3205, 2684, 1624, 328, 3202, 1611], "cite_extract_rate": 0.5, "origin_cites_number": 26, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.2, "critical": 3.5, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section synthesizes information from multiple papers on OOD detection and related fields to present a novel, unified framework termed 'generalized OOD detection.' It integrates concepts from anomaly, novelty, open set, and outlier detection, offering a coherent structure. While it identifies gaps in OOD detection research, the critical analysis is moderate, and the abstraction level is strong, highlighting broader patterns and the need for a unified perspective."}}
{"id": "0be73434-94f5-4280-a6f9-60270c71e0df", "title": "Generalized OOD Detection", "level": "section", "subsections": ["b8ce7df1-b0bf-4b79-a6b8-eaa102b6c421", "e8a24116-d732-4ec4-b6cb-f7b156fa67f9", "86620575-4ab7-4415-bae8-58a076550e6e", "9cfc6670-eede-4d23-8141-3ad4a7ccc55c", "7abc2b75-fdc3-4e2c-aebb-316acddac5bb", "3ebe9f16-79b4-4a57-975c-3760c1e59a53", "1ab857c0-0154-484b-8f40-75b1cc9315a2"], "parent_id": "c7a3c574-b9a2-41d9-8a41-220c3546317c", "prefix_titles": [["title", "Generalized Out-of-Distribution Detection: A Survey \n"], ["section", "Generalized OOD Detection"]], "content": "\\label{sec:general-ood}\n\\keypoint{Framework Overview} In this section, we introduce a unified framework termed \\emph{generalized OOD detection}, which encapsulates five related sub-topics: anomaly detection~(AD), novelty detection~(ND), open set recognition~(OSR), out-of-distribution~(OOD) detection, and outlier detection~(OD).\nThese sub-topics can be similar in the sense that they all define a certain \\emph{in-distribution}, with the common goal of detecting \\emph{out-of-distribution} samples under the open-world assumption.\nHowever, subtle differences exist among the sub-topics in terms of the specific definition and properties of ID and OOD data---which are often overlooked by the research community. To this end, we provide a clear introduction and description of each sub-topic in respective subsections (from Section~\\ref{sec:tax_anomaly} to \\ref{sec:tax_od}). Each subsection details the motivation, background, formal definition, as well as relative position within the unified framework. \nApplications and benchmarks are also introduced, with concrete examples that facilitate understanding.\nFig.~\\ref{fig:benchmark} illustrates the settings for each sub-topic.\nIn the end, we conclude this section by introducing the neighborhood topics to clarify the scope of the generalized OOD detection framework. (Section~\\ref{sec:related_topics}).\n\\keypoint{Preliminary: Distribution Shift} \n\\revise{\nIn our framework, we recognize the complexity and interconnectedness of distribution shifts, which are central to understanding various OOD scenarios. Distribution shifts can be broadly categorized into \\textit{covariate shift} and \\textit{semantic (label) shift}, but it's important to clarify their interdependence.\nFirstly, let's define the input space as $\\mathcal{X}$ (sensory observations) and the label space as $\\mathcal{Y}$ (semantic categories). The data distribution is represented by the joint distribution $P(X, Y)$ over the space $\\mathcal{X} \\times \\mathcal{Y}$.\nDistribution shift can occur in either the marginal distribution $P(X)$, or both $P(Y)$ and $P(X)$. Note that shift in $P(Y)$ naturally triggers shift in $P(X)$.\n\\keypoint{Covariate Shift:} This occurs when there is a change in the marginal distribution $P(X)$, affecting the input space, while the label space $\\mathcal{Y}$ remains constant. \nExamples of covariate distribution shift on $P(X)$ include adversarial examples~, domain shift~, and style changes~.\n\\keypoint{Semantic Shift:} This involves changes in both $P(Y)$ and indirectly $P(X)$. A shift in the label space $P(Y)$ implies the introduction of new categories or the alteration of existing ones. This change naturally affects the input space $P(X)$ since the nature of the data being observed or collected is now different. \n\\keypoint{Remark:} Given the interdependence between $P(X)$ and $P(Y)$, it's crucial to distinguish the intentions behind different types of distribution shifts. We define \\textit{Covariate Shift} as scenarios where changes are intended in the input space ($P(X)$) without any deliberate alteration to the label space ($P(Y)$). On the other hand, \\textit{Semantic Shift} specifically aims to modify the semantic content, directly impacting the label space ($P(Y)$) and, consequently, the input space ($P(X)$).\nImportantly, we note that covariate shift is more commonly used to evaluate model \\emph{generalization} and robustness performance, where the label space $\\mathcal{Y}$ remains the same during test time. On the other hand, the detection of semantic distribution shift (\\eg due to the occurrence of new classes) is the focal point of many \\emph{detection} tasks considered in this framework, where the label space $\\mathcal{Y}$ can be different between ID and OOD data and hence the model should not make any prediction.\n}\nWith the concept of distribution shift in mind, readers can get a general idea of the differences and connections among sub-topics/tasks in Fig.~\\ref{fig:taxonomy}. \nNotice that different sub-tasks can be easily identified with the following four dichotomies: \n1) covariate/semantic shift dichotomy; \n2) single/multiple class dichotomy; \n3) ID classification needed/non-needed dichotomy; \n4) inductive/transductive dichotomy.\nNext, we proceed with elaborating on each sub-topic.", "cites": [892, 917], "cite_extract_rate": 0.5, "origin_cites_number": 4, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 2.5, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section synthesizes concepts from multiple papers by integrating the idea of distribution shifts into a unified framework for OOD detection. It abstracts these concepts through the formalization of input and label spaces, offering a meta-level view of covariate and semantic shifts. However, while the synthesis is strong, the critical analysis is limited to identifying intentions and applications of different shifts rather than evaluating specific methodological limitations of the cited works."}}
{"id": "b8ce7df1-b0bf-4b79-a6b8-eaa102b6c421", "title": "Anomaly Detection", "level": "subsection", "subsections": [], "parent_id": "0be73434-94f5-4280-a6f9-60270c71e0df", "prefix_titles": [["title", "Generalized Out-of-Distribution Detection: A Survey \n"], ["section", "Generalized OOD Detection"], ["subsection", "Anomaly Detection"]], "content": "\\label{sec:tax_anomaly}\n\\keypoint{Background}\nThe notion of ``anomaly'' stands in contrast with the ``normal'' defined in advance.\nThe concept of ``normal'' should be clear and reflect the real task.\nFor example, to create a ``not-hotdog detector\", the concept of the normal should be clearly defined as the hotdog class, \\ie a food category, so that objects that violate this definition are identified as anomalies, which include steaks, rice, and non-food objects like cats and dogs.\nIdeally, ``hotdog'' would be regarded as a homogeneous concept, regardless of the sub-classes of French or American hotdog.\nCurrent anomaly detection settings often restrict the environment of interest to some specific scenarios.\nFor example, the ``not-hotdog detector'' only focuses on realistic images,\nassuming the nonexistence of images from other domains such as sketches.\nAnother realistic example is industrial defect detection, which is based on only one set of assembly lines for a specific product.\nIn other words, the ``open-world'' assumption is usually not completely ``open\".\nNevertheless, ``not-hotdog'' or ``defects'' can form a large unknown space that breaks the ``closed-world'' assumption.\nIn summary, the key to anomaly detection is to define normal clearly (usually without sub-classes) and detect all possible anomalous samples under some specific scenarios.\n\\smallskip\n\\keypoint{Definition}\nAnomaly detection (AD)~ aims to detect any anomalous samples that deviate from the predefined normality during testing. The deviation can happen due to either covariate shift or semantic shift, which leads to two sub-tasks: sensory AD and semantic AD, respectively~.\nSensory AD detects test samples with covariate shift, under the assumption that normalities come from the same covariate distribution. No semantic shift takes place in sensory AD settings.\nOn the other hand, semantic AD detects test samples with label shift, assuming that normalities come from the same semantic distribution (category), \\ie normalities should belong to only one class.\nFormally, in sensory AD, normalities are from in-distribution $P(X)$ while anomalies encountered at test time are from out-of-distribution $P'(X)$, where $P(X) \\neq P'(X)$ --- only covariate shift occurs.\nThe goal in sensory AD is to detect samples from $P'(X)$.\nNo semantic shift occurs in this setting, \\ie $P(Y)=P'(Y)$. Conversely, for semantic AD, only semantic shift occurs (\\ie $P(Y) \\neq P'(Y)$) and the goal is to detect samples that belong to novel classes.\n\\smallskip\n\\keypoint{Remark: Sensory/Semantic Dichotomy}\nOur sensory/semantic dichotomy for the AD sub-task definition comes from the low-level sensory anomalies and high-level semantic anomalies that are introduced in ~ and highlighted in the recent AD survey~, to reflect the rise of deep learning. Note that although most sensory and semantic AD methods are shown to be mutually inclusive due to the common shift on $P(X)$, some approaches are specialized in one of the sub-tasks (ref.~Section~\\ref{sec:anomaly}).\nRecent research communities are also trending on subdividing types of anomalies to develop targeted methods, so that practitioners can select the optimal solution for their own practical problem~.\n\\smallskip\n\\keypoint{Position in Framework}\nUnder the generalized OOD detection framework, the definition of ``normality'' seamlessly connects to the notion of ``in-distribution\", and ``anomaly'' corresponds to ``out-of-distribution\".\nImportantly, AD treats ID samples as a whole, which means that regardless of the number of classes (or statistical modalities) in ID data, AD does not require differentiation in the ID samples. This feature is an important distinction between AD and other sub-topics such as OSR and OOD detection.\n\\smallskip\n\\keypoint{Application and Benchmark}\nSensory AD only focuses on objects with the same or similar semantics, and identifies the observational differences on their surface. Samples with sensory differences are recognized as sensory anomalies. \nExample applications include adversarial defense~, forgery recognition of biometrics and artworks~, image forensics~, industrial inspection~, \\etc.\nThe most popular academic AD benchmark is MVTec-AD~ for industrial inspection.\nIn contrast to sensory AD, semantic AD only focuses on the semantic shift. \nAn example of real-world applications is crime surveillance~.\nActive image crawlers for a specific category also need semantic AD methods to ensure the purity of the collected images~.\nAn example of the academic benchmarks is to recursively use one class from MNIST as ID during training, and ask the model to distinguish it from the rest of the 9 classes during testing.\n\\smallskip\n\\keypoint{Evaluation}\nIn the AD benchmarks, test samples are annotated to be either normal or abnormal. \nThe deployed anomaly detector will produce a confidence score for a test sample, indicating how confident the model considers the sample as normality.\nSamples below the predefined confidence threshold are considered abnormal.\nBy viewing the anomalies as positive and\ntrue normalities as negative\\footnote{Align with MSP~. Check \\href{https://github.com/Jingkang50/OpenOOD/issues/206}{this issue} in OpenOOD}, different thresholds will produce a series of true positive rates (TPR) and false-positive rates (FPR)---from which we can calculate the area under the receiver operating characteristic curve (AUROC)~. Similarly, the precision and recall values can be used to compute metrics of F-scores and the area under the precision-recall curve (AUPR)~.\nNote that there can be two variants of AUPR values: one treating ``normal'' as the positive class, and the other treating ``abnormal'' as the positive class. For AUROC and AUPR, a higher value indicates better detection performance.\n\\smallskip\n\\keypoint{Remark: Alternative Taxonomy on Anomalies}\nSome previous literature considers anomalies types to be three-fold: point anomalies, conditional or contextural anomalies, and group or collective anomalies~.\nIn this survey, we mainly focus on point anomalies detection for its popularity in practical applications and its adequacy to elucidate the similarities and differences between sub-tasks.\nDetails of the other two kinds of anomalies, \\ie contextural anomalies that often occur in time-series tasks, and collective anomalies that are common in the data mining field, are not covered in this survey. We recommend readers to the recent AD survey papers~ for an in-depth discussion on them.\n\\smallskip\n\\keypoint{Remark: Taxonomy based on Supervision}\nWe use sensory/semantic dichotomy to subdivide AD at the task level. From the perspective of methodologies, some literature categorizes AD techniques into unsupervised and (semi-) supervised settings. Note that these two taxonomies are orthogonal as they focus on tasks and methods respectively.", "cites": [7701, 3208, 3207, 3210, 3206, 7074, 3211, 3212, 1624, 3209, 313], "cite_extract_rate": 0.4782608695652174, "origin_cites_number": 23, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.5, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section demonstrates strong synthesis by integrating multiple sources to clearly define and contextualize anomaly detection within the broader framework of OOD detection. It provides abstraction by highlighting key distinctions such as the sensory/semantic dichotomy and connects these ideas to practical applications and benchmarks. Critical analysis is evident in the discussion of assumptions and limitations (e.g., restricted environments and biases in evaluation metrics), though it could be more explicitly comparative."}}
{"id": "e8a24116-d732-4ec4-b6cb-f7b156fa67f9", "title": "Novelty Detection", "level": "subsection", "subsections": [], "parent_id": "0be73434-94f5-4280-a6f9-60270c71e0df", "prefix_titles": [["title", "Generalized Out-of-Distribution Detection: A Survey \n"], ["section", "Generalized OOD Detection"], ["subsection", "Novelty Detection"]], "content": "\\label{sec:tax_novelty}\n\\keypoint{Background}\nThe word ``novel'' generally refers to the unknown, new, and something interesting.\nWhile novelty detection (ND) is often interchangeable with AD in the community, strictly speaking, their subtle difference is worth noticing.\nIn terms of motivation, novelty detection usually does not perceive ``novel'' test samples as erroneous, fraudulent, or malicious as AD does, but cherishes them as learning resources for potential future use with a positive learning attitude~. In fact, novelty detection is also known as ``novel class detection''~, indicating that it is primarily focusing on detecting semantic shift.\n\\smallskip\n\\keypoint{Definition}\nNovelty detection aims to detect any test samples that do not fall into any training category.\nThe detected novel samples are usually prepared for future constructive procedures, such as more specialized analysis, or incremental learning of the model itself.\nBased on the number of training classes, ND contains two different settings:\n1) one-class novelty detection~(\\emph{one-class ND}): only one class exists in the training set;\n2) multi-class novelty detection~(\\emph{multi-class ND}): multiple classes exist in the training set. It is worth noting that despite having many ID classes, the goal of multi-class ND is only to distinguish novel samples from ID. Both one-class and multi-class ND are formulated as binary classification problems.\n\\smallskip\n\\keypoint{Position in Framework}\nUnder the generalized OOD detection framework, ND deals with the setting where OOD samples have semantic shift, without the need for classification in the ID set even if possible.\nTherefore, ND shares the same problem definition with semantic AD.\n\\smallskip\n\\keypoint{Application and Benchmark}\nReal-world ND application includes video surveillance~, planetary exploration~ and incremental learning~.\nFor one-class ND, an example academic benchmark can be identical to that of semantic AD, which considers one class from MNIST as ID and the rest as the novel.\nThe corresponding MNIST benchmark for multi-class ND may use the first 6 classes during training, and test on the remaining 4 classes as OOD.\n\\smallskip\n\\keypoint{Evaluation}\nThe evaluation of ND is identical to AD, which is based on AUROC, AUPR, or F-scores (see details in Section~\\ref{sec:tax_anomaly}). \n\\smallskip\n\\keypoint{Remark: One-Class/Multi-Class Dichotomy} Although the ND models do not require the ID classification even with multi-class annotations, the method on multi-class ND can be different from one-class ND, as multi-class ND can make use of the multi-class classifier while one-class ND cannot.\nAlso note that semantic AD can be further split into one-class semantic AD and multi-class semantic AD that matches ND, as semantic AD is equivalent to ND.\n\\smallskip\n\\keypoint{Remark: Nuance between AD and ND}\nApart from the special interest in semantics, some literature~ also point out that ND is supposed to be fully unsupervised (no novel data in training), while AD might have some abnormal training samples. \\revise{It's important to note that neither AD nor ND necessitates the classification of ID data. This is a key distinction between OSR and OOD detection, which we will discuss in subsequent sections.}", "cites": [3206, 3208, 3211, 3213, 8445], "cite_extract_rate": 0.45454545454545453, "origin_cites_number": 11, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 2.5, "abstraction": 3.5}, "insight_level": "medium", "analysis": "The section synthesizes information well by connecting the concepts of novelty detection with anomaly detection, highlighting subtle differences in motivation and methodology across the cited literature. It abstracts the problem into settings (one-class vs. multi-class) and positions ND within the broader generalized OOD framework. However, critical analysis is limitedâ€”there is little discussion of methodological trade-offs or limitations in the reviewed works."}}
{"id": "86620575-4ab7-4415-bae8-58a076550e6e", "title": "Open Set Recognition", "level": "subsection", "subsections": [], "parent_id": "0be73434-94f5-4280-a6f9-60270c71e0df", "prefix_titles": [["title", "Generalized Out-of-Distribution Detection: A Survey \n"], ["section", "Generalized OOD Detection"], ["subsection", "Open Set Recognition"]], "content": "\\label{sec:tax_osr}\n\\keypoint{Background}\nMachine learning models trained in the closed-world setting can incorrectly classify test samples from unknown classes as one of the known categories with high confidence~.\nSome literature refers to this notorious overconfident behavior of the model as ``arrogance\", or ``agnostophobia\"~.\nOpen set recognition (OSR) is proposed to address this problem, with their own terminology of ``known known classes'' to represent the categories that exist at training, and ``unknown unknown classes'' for test categories that do not fall into any training category. Some other terms, such as open category detection~ and open set learning~, are simply different expressions for OSR.\n\\smallskip\n\\keypoint{Definition}\nOpen set recognition requires the multi-class classifier to simultaneously: 1) accurately classify test samples from ``known known classes\", and 2) detect test samples from ``unknown unknown classes\".\n\\smallskip\n\\keypoint{Position in Framework}\nOSR well aligns with our generalized OOD detection framework, where ``known known classes'' and ``unknown unknown classes'' correspond to ID and OOD respectively.\nFormally, OSR deals with the case where OOD samples during testing have semantic shift, \\ie $P(Y)\\neq P'(Y)$.\nThe goal of OSR is largely shared with that of multi-class ND---the only difference is that OSR additionally requires accurate classification of ID samples from $P(Y)$.\n\\smallskip\n\\keypoint{Application and Benchmark}\nOSR supports the robust deployment of real-world image classifiers in general, which can reject unknown samples in the open world~.\nAn example academic benchmark on MNIST can be identical to multi-class ND, which considers the first 6 classes as ID and the remaining 4 classes as OOD. In addition, OSR further requires a good classifier on the 6 ID classes.\n\\smallskip\n\\keypoint{Evaluation}\nSimilar to AD and ND, the metrics for OSR include F-scores, AUROC, and AUPR. Beyond them, the classification performance is also evaluated by standard ID accuracy. While the above metrics evaluate the novelty detection and ID classification capabilities independently, some works raise some evaluation criteria for joint evaluation, such as CCR@FPR$x$~, which calculates the class-wise recall when a certain FPR equal to $x$ (\\eg $10^{-1}$) is achieved.", "cites": [3214, 3215], "cite_extract_rate": 0.3333333333333333, "origin_cites_number": 6, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 2.5, "abstraction": 3.5}, "insight_level": "medium", "analysis": "The section effectively synthesizes the key ideas from the cited papers, such as the notion of 'agnostophobia' and 'open category detection,' and integrates them into the broader generalized OOD detection framework. It abstracts these concepts by linking OSR to the taxonomy of OOD detection, distinguishing between known and unknown classes. However, it lacks deeper critical analysis of the cited works, such as evaluating their effectiveness or limitations."}}
{"id": "9cfc6670-eede-4d23-8141-3ad4a7ccc55c", "title": "Out-of-Distribution Detection", "level": "subsection", "subsections": [], "parent_id": "0be73434-94f5-4280-a6f9-60270c71e0df", "prefix_titles": [["title", "Generalized Out-of-Distribution Detection: A Survey \n"], ["section", "Generalized OOD Detection"], ["subsection", "Out-of-Distribution Detection"]], "content": "\\label{sec:tax_ood}\n\\keypoint{Background}\nWith the observation that deep learning models are often inappropriate but in fact overconfident in classifying samples from different semantic distributions in the image classification task and text categorization~, the field of out-of-distribution detection emerges, requiring the model to reject inputs that are semantically different from the training distribution and therefore should not be predicted by the model.\n\\smallskip\n\\keypoint{Definition}\nOut-of-distribution detection, or OOD detection, aims to detect test samples drawn from a distribution that is different from the training distribution, with the definition of distribution to be well-defined according to the application in the target.\nFor most machine learning tasks, the distribution should refer to ``label distribution'', which means that OOD samples should not have overlapping labels \\wrt training data.\nFormally, in the OOD detection, the test samples come from a distribution whose semantics are shifted from ID, \\ie $P(Y)\\neq P'(Y)$.\nNote that the training set usually contains multiple classes, and OOD detection should NOT harm the ID classification capability.\n\\smallskip\n\\keypoint{Position in Framework}\nOut-of-distribution detection can be canonical to OSR in common machine learning tasks like multi-class classification---keeping the classification performance on test samples from ID class space $\\mathcal{Y}$, and reject OOD test samples with semantics outside the support of $\\mathcal{Y}$. Also, the multi-class setting and the requirement of ID classification distinguish the task from AD and ND.\n\\smallskip\n\\keypoint{Application and Benchmark}\nThe application of OOD detection usually falls into safety-critical situations, such as autonomous driving~.\nAn example academic benchmark is to use CIFAR-10 as ID during training and to distinguish CIFAR images from other datasets such as SVHN, \\etc. \nResearchers should pay attention that OOD datasets should NOT have label overlapping with ID datasets when building the benchmark.\n\\smallskip\n\\keypoint{Evaluation}\nApart from F-scores, AUROC, and AUPR, another commonly-used metric is FPR@TPR$x$, which measures the FPR  when the TPR is $x$ (\\eg 0.95). Some works also use an alternative metric, TNR@TPR$x$, which is equivalent to 1-FPR@TPR$x$. OOD detection also concerns the performance of ID classification.\n\\smallskip\n\\keypoint{Remark: OSR \\vs OOD Detection}\nThe difference between OSR and OOD detection tasks is three-fold.\n\\noindent\\textbf{1) Different benchmark setup:} OSR benchmarks usually split one multi-class classification dataset into ID and OOD parts according to classes, while OOD detection takes one dataset as ID and finds several other datasets as OOD with the guarantee of non-overlapping categories between ID/OOD datasets. \nHowever, despite the different benchmark traditions of the two sub-tasks, they are in fact tackling the same problem of semantic shift detection.\n\\noindent\\textbf{2) No additional data in OSR:} Due to the requirement of theoretical open-risk bound guarantee, OSR discourages the usage of additional data during training by design~. This restriction precludes methods that are more focused on effective performance improvements (\\eg outlier exposures~) but may violate OSR constraints.\n\\noindent\\textbf{3) Broadness of OOD detection:} Compare to OSR, OOD detection encompasses a broader spectrum of learning tasks (\\eg multi-label classification~), wider solution space (to be discussed in Section~\\ref{sec:ood}).\n\\smallskip\n\\keypoint{Remark: Mainstream OOD Detection Focuses on Semantics}\nWhile most works in the current community interpret the keyword ``out-of-distribution'' as ``out-of-label/semantic-distribution'', some OOD detection works also consider detecting covariate shifts~, which claim that covariate shift usually leads to a significant drop in model performance and therefore needs to be identified and rejected.\nHowever, although detecting covariate shift is reasonable on some specific tasks (usually due to high-risk or privacy reasons) that are to be discussed in the following paragraph, research on this topic remains a controversial task \\emph{w.r.t} OOD generalization tasks (\\cf Section~\\ref{sec:related_topics} and Section~\\ref{sec:future_direction}). Detecting semantic shift has been the mainstream of OOD detection tasks.\n\\smallskip\n\\keypoint{Remark: To Generalize, or To Detect?}\nWe provide another definition from the perspective of generalization:\nOut-of-distribution detection, or OOD detection, aims to detect test samples to which the model cannot or does not want to generalize~.\nIn most of the machine learning tasks, such as image classification, the models are expected to generalize their prediction capability to samples with covariate shift, and they are only unable to generalize when semantic shift occurs.\nHowever, for applications where models are by-design nontransferable to other domain, such as many deep reinforcement learning tasks like game AI~, the key term ``distribution'' should refer to ``data/input distribution'', so that the model should refuse to decide the environment that is not the same as the training environment, \\ie $P(X)\\neq P'(X)$. \nSimilar applications are those high-risk tasks such as medical image classification~ or in privacy-sensitive scenario~, where the models are expected to be very conservative and only make predictions for samples exactly from the training distribution, rejecting any samples that deviate from it.\nRecent studies~ also highlight a model-specific view: a robust model should generalize to examples with covariate shift; a weak model should reject them.\nUltimately, an OOD detection task is considered valid when it successfully balances the aspects of ``detection\" and ``generalization\", taking into account factors such as meaningfulness and the inherent challenges presented by the task. Nonetheless, detecting semantic shift remains the primary focus of OOD detection tasks and is central to this survey.", "cites": [3216, 1629, 3219, 7130, 3218, 3217, 1624, 7129], "cite_extract_rate": 0.5714285714285714, "origin_cites_number": 14, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.5, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section synthesizes concepts from multiple papers to provide a coherent framework of OOD detection, including its relation to OSR, AD, and ND. It critically evaluates methodological constraints (e.g., no additional data in OSR) and identifies broader patterns, such as the distinction between semantic and covariate shifts. The abstraction into a model-specific and application-driven understanding of OOD detection demonstrates a high level of insight."}}
{"id": "7abc2b75-fdc3-4e2c-aebb-316acddac5bb", "title": "Outlier Detection", "level": "subsection", "subsections": [], "parent_id": "0be73434-94f5-4280-a6f9-60270c71e0df", "prefix_titles": [["title", "Generalized Out-of-Distribution Detection: A Survey \n"], ["section", "Generalized OOD Detection"], ["subsection", "Outlier Detection"]], "content": "\\label{sec:tax_od}\n\\keypoint{Background}\nAccording to~\\emph{Wikipedia} , an outlier is a data point that differs significantly from other observations.\nRecall that the problem settings in AD, ND, OSR, and OOD detect unseen test samples that are different from the training data distribution.\nIn contrast, outlier detection directly processes all observations and aims to select outliers from the contaminated dataset~. Since outlier detection does not follow the train-test procedure but has access to all observations, approaches to this problem are usually transductive rather than inductive~.\n\\smallskip\n\\keypoint{Definition}\nOutlier detection aims to detect samples that are markedly different from the others in the given observation set, due to either covariate or semantic shift.\n\\smallskip\n\\keypoint{Position in Framework}\nDifferent from all previous sub-tasks, whose in-distribution is defined during training, the ``in-distribution'' for outlier detection refers to the majority of the observations. Outliers may exist due to semantic shift on $P(Y)$, or covariate shift on $P(X)$.\n\\smallskip\n\\keypoint{Application and Benchmark}\nWhile mostly applied in data mining tasks~, outlier detection is also used in real-world computer vision applications such as video surveillance~ and dataset cleaning~.\nFor the application of dataset cleaning, outlier detection is usually used as a pre-processing step for the main tasks such as learning from open-set noisy labels~, webly supervised learning~, and open-set semi-supervised learning~.\nTo construct an outlier detection benchmark on MNIST, one class should be chosen so that all samples that belong to this class are considered as inliers. A small fraction of samples from other classes are introduced as outliers to be detected. \n\\smallskip\n\\keypoint{Evaluation}\nApart from F-scores, AUROC, and AUPR, the evaluation of outlier detectors can be also evaluated by the performance of the main task it supports. For example, if an outlier detector is used to purify a dataset with noisy labels, the performance of a classifier that is trained on the cleaned dataset can indicate the quality of the outlier detector.\n\\smallskip\n\\keypoint{Remark: On Inclusion of Outlier Detection} \nInterestingly, the outlier detection task can be considered as an outlier in the generalized OOD detection framework, since outlier detectors are operated on the scenario when all observations are given, rather than following the training-test scheme. Also, publications exactly on this topic are rarely seen in the recent deep learning venues. However, we still include outlier detection in our framework, because intuitively speaking, outliers also belong to one type of out-of-distribution, and introducing it can help familiarize readers more with various terms~(\\eg OD, AD, ND, OOD) that have confused the community for a long while.", "cites": [8630, 2277, 7702, 71, 3220], "cite_extract_rate": 0.35714285714285715, "origin_cites_number": 14, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.5, "critical": 2.5, "abstraction": 3.0}, "insight_level": "medium", "analysis": "The section provides a clear definition and contextual placement of outlier detection within the generalized OOD framework, synthesizing the concept with related tasks like AD, ND, and OSR. It integrates several cited papers to show how outlier detection supports tasks such as dataset cleaning and semi-supervised learning. However, the critical analysis is limited to a brief remark on the low presence in deep learning venues, without deeper evaluation of methodological strengths or weaknesses. The abstraction is moderate, as it generalizes outlier detection as a form of OOD but stops short of offering a meta-level framework."}}
{"id": "3ebe9f16-79b4-4a57-975c-3760c1e59a53", "title": "Related Topics", "level": "subsection", "subsections": [], "parent_id": "0be73434-94f5-4280-a6f9-60270c71e0df", "prefix_titles": [["title", "Generalized Out-of-Distribution Detection: A Survey \n"], ["section", "Generalized OOD Detection"], ["subsection", "Related Topics"]], "content": "\\label{sec:related_topics}\nApart from the five sub-topics that are described in our \\emph{generalized OOD detection} framework (shown in Figure~\\ref{fig:taxonomy}), we further briefly discuss five related topics below, which help clarify the scope of this survey.\n\\smallskip\n\\keypoint{Learning with Rejection (LWR)}\nLWR~ can date back to early works on abstention~, which considered simple model families such as SVMs~.\nThe phenomenon of neural networks' overconfidence in OOD data is first revealed by~. Despite methodologies differences, subsequent works developed on OOD detection and OSR share the underlying spirit of classification with the rejection option. \n\\smallskip\n\\keypoint{Domain Adaptation/Generalization}\nDomain Adaptation (DA)~ and Domain Generalization (DG)~ also follow ``open-world'' assumption. Different from generalized OOD detection settings, DA/DG expects the existence of covariate shift during testing without any semantic shift and requires classifiers to make accurate predictions into the same set of classes~.\nNoticing that OOD detection commonly concerns detecting the semantic shift, which is complementary to DA/DG. In the case when both covariate and semantic shift take place, the model should be able to detect semantic shift while being robust to covariate shift. More discussion on relations between DA/DG and OOD detection is in Section~\\ref{sec:future_direction}. \nThe difference between DA and DG is that while the former requires extra but few training samples from the target domain, the latter does not.\n\\smallskip\n\\keypoint{Novelty Discovery} \nNovelty discovery~ requires all observations to be given in advance as outlier detection does. The observations are provided in a semi-supervised manner, and the goal is to explore and discover the new categories and classes in the unlabeled set. Different from outlier detection where outliers are sparse, the unlabeled set in novelty discovery setting can mostly consist of, and even be overwhelmed by unknown classes.\n\\smallskip\n\\keypoint{Zero-shot Learning}\nZero-shot learning~ has a similar goal of novelty discovery but follows the training-testing scheme. The test set is under the ``open-world'' assumption with unknown classes, which expects classifiers trained only on the known classes to perform classification on unknown testing samples with the help of extra information such as label relationships.\n\\smallskip\n\\keypoint{Open-world Recognition}\nOpen-world recognition~ aims to build a lifelong learning machine that can actively detect novel images~, label them as new classes, and perform continuous learning. It can be viewed as a combination of novelty detection (or open-set recognition) and incremental learning. \n\\revise{More specifically, open-world recognition extends the concept of OSR by adding the ability to incrementally learn new classes over time. In open-world scenarios, the system not only identifies unknown instances but also can update its model to include these new classes as part of the known set. This approach is more dynamic and suited for real-world applications where the environment is not static, and new categories can emerge after the initial training phase~.}\n\\smallskip\n\\keypoint{Conformal Prediction}\n\\revise{Conformal prediction (CP) stands as a robust statistical framework in machine learning, primarily designed to provide confidence measures for predictions~. Distinctively, it yields prediction intervals with specified confidence levels, transcending the limitations of mere point estimates.\nIn scenarios of OOD detection, the conformal prediction framework becomes particularly insightful: wider prediction intervals or lower confidence levels generated by conformal prediction methods can serve as indicators of such OOD data.\nAlthough research at the intersection of CP and OOD detection is still emerging~, the potential of applying the conformal prediction framework in this domain is significant and warrants further exploration.}", "cites": [3221, 8632, 7131, 3228, 8631, 3225, 3226, 7057, 3230, 3223, 328, 3229, 3224, 3227, 3222], "cite_extract_rate": 0.6818181818181818, "origin_cites_number": 22, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.5, "critical": 3.0, "abstraction": 3.5}, "insight_level": "medium", "analysis": "The section synthesizes related topics by connecting them to generalized OOD detection, highlighting distinctions and commonalities between concepts such as open-world recognition and conformal prediction. It provides a critical perspective by pointing out limitations, such as the isolation of related fields and the need for further exploration of CP in OOD detection. The section abstracts patterns by discussing overarching assumptions (e.g., open-world, covariate vs semantic shift) and broader implications for real-world applications."}}
{"id": "1ab857c0-0154-484b-8f40-75b1cc9315a2", "title": "Organization of Remaining Sections", "level": "subsection", "subsections": [], "parent_id": "0be73434-94f5-4280-a6f9-60270c71e0df", "prefix_titles": [["title", "Generalized Out-of-Distribution Detection: A Survey \n"], ["section", "Generalized OOD Detection"], ["subsection", "Organization of Remaining Sections"]], "content": "In this paper, we focus on the methodologies of OOD detection in Section~\\ref{sec:ood}, providing a comprehensive overview of the different approaches that have been proposed in the literature. We also briefly introduce methodologies for other sub-tasks including AD, ND, OSR, and OD in Section~\\ref{sec:others}, to provide readers with a broader understanding of OOD-related problems and inspire the development of more effective methods.\nFor each sub-task, we categorize and introduce the methodologies into four groups: \n\\textbf{1) classification-based methods:} methods that largely rely on classifiers;\n\\textbf{2) density-based methods:} detecting OOD by modeling data density;\n\\textbf{3) distance-based methods:} using distance metrics (usually in the feature space) to identify OODs;\nand \\textbf{4) reconstruction-based methods:} methods featured by reconstruction techniques.\nTo offer readers further insights from an empirical perspective, we conduct a thorough analysis that provides a fair comparison between representative OOD detection methods and methods from other sub-tasks.\nAdditionally, we highlight some of the remaining problems and limitations that exist in the current generalized OOD detection field. We conclude this survey with a discussion on the open challenges and opportunities for future research. It is worth noting that a concurrent survey~ provides a detailed explanation of OOD-related methods, which greatly complements our work.\n\\begin{figure*}[!t]\n    \\centering\n    \\includegraphics[width=\\linewidth]{figures/timeline.pdf}\n    \\vspace{-0.5cm}\n    \\caption{Timeline for representative OOD detection methodologies.\n    Different colors indicate different categories of methodologies.\n    Each method has its corresponding reference (inconspicuous white) in the lower right corner. Methods with high citations and open-source code are prioritized for inclusion in this figure.}\n    \\label{fig:timeline}\n\\end{figure*}\n\\begin{table*}[]\n\\caption{Paper list for out-of-distribution detection.}\n\\label{tab:method}\n\\centering\n\\begin{tabular}{@{}c|c|l|p{8cm}<{\\centering}@{}}\n\\toprule\n\\multicolumn{3}{c|}{Sections} & References \\\\ \\midrule\n\\midrule\n\\multicolumn{1}{c|}{\\multirow{15}{*}{\\begin{tabular}[c]{@{}c@{}} \\textcolor{red}{$\\S~$}\\ref{sec:ood_classification} \\\\ Classification \\end{tabular}}} &\n\\multicolumn{1}{c|}{\\multirow{5}{*}{{\\begin{tabular}[c]{@{}c@{}} \\textcolor{red}{$\\S~$}\\ref{sec:ood_confcal} \\\\ Output-based \\\\ Methods \\end{tabular}}}} &\n\\multirow{2}{*}{\\begin{tabular}[c]{@{}c@{}} \\textcolor{red}{a}:~Training-free\n\\end{tabular}}\n&  \\\\  \\cmidrule(l){3-4} \n&\n\\multicolumn{1}{l|}{}                              &\n\\multirow{3}{*}{\\begin{tabular}[c]{@{}c@{}} \\textcolor{red}{b}:~Training-based \\end{tabular}}\n&  \\\\ \\cmidrule(l){2-4} \n&\n\\multicolumn{1}{l|}{\\multirow{3}{*}{{\\begin{tabular}[c]{@{}c@{}} \\textcolor{red}{$\\S~$}\\ref{sec:ood_confcal} \\\\ Outlier Exposure \\\\ \\end{tabular}}}} &\n\\multirow{2}{*}{\\begin{tabular}[c]{@{}c@{}} \\textcolor{red}{a}:~Real Outliers\n\\end{tabular}}\n&  \\\\  \\cmidrule(l){3-4} \n&\n\\multicolumn{1}{l|}{}                              &\n\\multirow{1}{*}{\\begin{tabular}[c]{@{}c@{}} \\textcolor{red}{b}:~Data Generation \\end{tabular}}\n&  \\\\ \\cmidrule(l){2-4} \n&\n\\multicolumn{2}{l|}{\n\\textcolor{red}{$\\S~$}\\ref{sec:ood_gradient}:~Gradient-based Methods} &           \\\\\n\\cmidrule(l){2-4} \n&\n\\multicolumn{2}{l|}{\n\\textcolor{red}{$\\S~$\\ref{sec:ood_bayesian}}:~Bayesian Models}         \n&  \\\\\n\\cmidrule(l){2-4} \n&\n\\multicolumn{2}{l|}{\n\\textcolor{red}{$\\S~$}\\ref{sec:ood_foundation}:~OOD for Foundation Models}  &  \\\\\n\\cmidrule(l){1-4} \n\\multicolumn{3}{c|}{\n\\multirow{2}{*}{\\begin{tabular}[c]{@{}c@{}}\n\\textcolor{red}{$\\S~$}\\ref{sec:ood_density}:~Density-based Methods\n\\end{tabular}}}  \n&  \\\\\n\\cmidrule(l){1-4} \n\\multicolumn{3}{c|}{\\textcolor{red}{$\\S~$}\\ref{sec:ood_distance}:~Distance-based Methods}               &  \\\\ \n\\cmidrule(l){1-4} \n\\multicolumn{3}{c|}{\\textcolor{red}{$\\S~$}\\ref{sec:ood_reconstruction}:~Reconstruction-based Methods}               & \\\\ \n\\cmidrule(l){1-4} \n\\multicolumn{3}{c|}{\\textcolor{red}{$\\S~$}\\ref{sec:theoretical}:~Theoretical Analysis}               & \\\\ \n\\bottomrule\n\\end{tabular}\n\\end{table*}", "cites": [3273, 7704, 8634, 7132, 3252, 3246, 6982, 3256, 3237, 3293, 3232, 7705, 3286, 3253, 3231, 3238, 3290, 3298, 3292, 3260, 1624, 3277, 3247, 3274, 3242, 7706, 3287, 8638, 3264, 3291, 3219, 3269, 3299, 3279, 3214, 3294, 8636, 3284, 7130, 3283, 3245, 3278, 3268, 6981, 3258, 3235, 3261, 3297, 3239, 7707, 3267, 8640, 3241, 3251, 3276, 3240, 8319, 3249, 3270, 3295, 8637, 7703, 8639, 3233, 8633, 3265, 107, 3266, 3216, 3285, 3209, 3255, 3257, 7494, 203, 7133, 3263, 3281, 3243, 3280, 3250, 3234, 1252, 3282, 3296, 3259, 3248, 3288, 3272, 3262, 3254, 3275, 3215, 8635, 3236, 3244, 3271, 1630, 3289], "cite_extract_rate": 0.8048780487804879, "origin_cites_number": 123, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.5, "critical": 2.0, "abstraction": 2.3}, "insight_level": "medium", "analysis": "The section provides a structured overview of OOD detection methodologies, categorizing them into four groups and listing relevant papers under each category. While it offers a clear taxonomy, it lacks deeper synthesis of ideas across the cited works and does not critically evaluate or contrast them. There is some abstraction in the categorization, but the analysis remains largely descriptive and surface-level."}}
{"id": "4aa3467c-8e06-49ec-85df-b8c720f347b8", "title": "Classification-based Methods", "level": "subsection", "subsections": ["ae8ddd40-6675-4841-a907-898f3924646a", "c2359d6e-5106-4598-9b78-918e091cc729", "3c7a045c-7ff3-4985-8762-45095f226bcd", "145bb2d5-973d-48d4-82f5-177b3b47aa2c", "932f5926-9908-41df-9ae2-9a2d539317ee"], "parent_id": "b64f4212-2221-489a-89da-4c3cd93853fc", "prefix_titles": [["title", "Generalized Out-of-Distribution Detection: A Survey \n"], ["section", "OOD Detection: Methodology"], ["subsection", "Classification-based Methods"]], "content": "\\label{sec:ood_classification}\nResearch on OOD detection originated from a simple baseline, that is, using the maximum softmax probability as the indicator score of ID-ness~. Early OOD detection methods focus on deriving improved OOD scores based on the output of neural networks.", "cites": [1624], "cite_extract_rate": 1.0, "origin_cites_number": 1, "insight_result": {"type": "descriptive", "scores": {"synthesis": 1.5, "critical": 1.0, "abstraction": 1.5}, "insight_level": "low", "analysis": "The section is primarily descriptive, summarizing the origin of OOD detection and introducing a basic method from one cited paper. It lacks synthesis of multiple sources, critical evaluation of the methods, and abstraction to broader principles or trends."}}
{"id": "ae8ddd40-6675-4841-a907-898f3924646a", "title": "Output-based Methods", "level": "subsubsection", "subsections": [], "parent_id": "4aa3467c-8e06-49ec-85df-b8c720f347b8", "prefix_titles": [["title", "Generalized Out-of-Distribution Detection: A Survey \n"], ["section", "OOD Detection: Methodology"], ["subsection", "Classification-based Methods"], ["subsubsection", "Output-based Methods"]], "content": "\\label{sec:ood_confcal}\n\\keypoint{a.~Post-hoc Detection}\nPost-hoc methods have the advantage of being easy to use without modifying the training procedure and objective. The property can be important for the adoption of OOD detection methods in real-world production environments, where the overhead cost of retraining can be prohibitive. Early work ODIN~ is a post-hoc method that uses temperature scaling and input perturbation to amplify the ID/OOD separability. Key to the method, a sufficiently large temperature has a strong smoothing effect that transforms the softmax score back to the logit space---which effectively distinguishes ID vs. OOD. Note that this is different from confidence calibration, where a much milder $T$ is employed. While calibration focuses on representing the true correctness likelihood of {ID data only}, the ODIN score is designed to maximize the gap between ID and OOD data and may no longer be meaningful from a predictive confidence standpoint. \nBuilt on the insights, recent work~ proposed using an energy score for OOD detection, which enjoys theoretical interpretation from a likelihood perspective~. Test samples with lower energy are considered ID and vice versa. \nJointEnergy score~ is then proposed to perform OOD detection for multi-label classification networks. The most recent work SHE~ uses stored patterns that represent classes to measure the discrepancy of unseen data for OOD detection, which is hyperparameter-free and computationally efficient compared to classic energy methods.\nTechniques such as layer-wise Mahalanobis distance~ and Gram Matrix~ are implemented for better-hidden feature quality to perform density estimation.\nRecently, one fundamental cause of the overconfidence issue on OOD data has been revealed that using mismatched BatchNorm statistics---that are estimated on ID data yet blindly applied to the OOD data in testing---can trigger abnormally high unit activations and model output accordingly~. Therefore, ReAct~ proposes truncating the high activations, which establishes strong post-hoc detection performance and further boosts the performance of existing scoring functions. \nSimilarly, NMD~ uses the activation means from BatchNorm layers for ID/OOD discrepancy.\nWhile {ReAct} considers activation space,  proposes a weight sparsification-based OOD detection framework termed DICE. DICE ranks weights based on a measure of contribution and selectively uses the most salient weights to derive the output for OOD detection. By pruning away noisy signals, DICE provably reduces the output variance for OOD data, resulting in a sharper output distribution and stronger separability from ID data. \n\\revise{In a similar vein, ASH~ also targets the activation space but adopts a different strategy. It removes a significant portion (e.g., 90\\%) of an input's feature representations from a late layer based on a top-K criterion, followed by adjusting the remaining activations (e.g., 10\\%) either by scaling or assigning constant values, yielding surprisingly effective results.}\n\\keypoint{b.~Training-based Methods}\nWith the training phase, confidence can be developed via designing a confidence-estimating branch~ or class~, ensembling with leaving-out strategy~, adversarial training~, stronger data augmentation~, pretext training~, better uncertainty modeling~, input-level manipulation~, and utilizing feature or statistics from the intermediate-layer features~. Especially, to enhance the sensitivity to covariate shift, some methods focus on the hidden representations in the middle layers of neural networks. Generalized ODIN, or G-ODIN~ extended ODIN~ by using a specialized training objective termed DeConf-C and choosing hyperparameters such as perturbation magnitude on ID data. Note that we do not categorize G-ODIN as post-hoc method as it requires model retraining. Recent work~ shows that the overconfidence issue can be mitigated through Logit Normalization (LogitNorm), a simple fix to the common cross-entropy loss by enforcing a constant vector norm on the logits in training. Trained with LogitNorm, neural networks produce highly distinguishable confidence scores between in- and out-of-distribution data.\nSome works redesign the label space to achieve good OOD detection performance. While commonly used to encode categorical information for classification, the one-hot encoding ignores the inherent relationship among labels. For example, it is unreasonable to have a uniform distance between \\texttt{dog} and \\texttt{cat} vs. \\texttt{dog} and \\texttt{car}.\nTo this end, several works attempt to use information in the label space for OOD detection.\nSome works arrange the large semantic space into a hierarchical taxonomy of known classes~.\nUnder the redesigned label architecture, top-down classification strategy~ and group softmax training~ are demonstrated effective. \nAnother set of works uses word embeddings to automatically construct the label space.\nIn , the sparse one-hot labels are replaced with several dense word embeddings from different NLP models, forming multiple regression heads for robust training. When testing, the label, which has the minimal distance to all the embedding vectors from different heads, will be considered as the prediction. If the minimal distance crosses above the threshold, the sample would be classified as ``novel''.\nRecent works further take the image features from language-image pre-training models~ to better detect novel classes, where the image encoding space also contains rich information from the language space~.", "cites": [8319, 3291, 3249, 7132, 3281, 3246, 3256, 7130, 3295, 3296, 3237, 3293, 3248, 7705, 3239, 3262, 3254, 3290, 3265, 107, 3260, 3277, 7707, 3274, 3242, 3267, 3285, 1639, 3255, 7494, 3251, 3276], "cite_extract_rate": 0.8421052631578947, "origin_cites_number": 38, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.2, "critical": 3.3, "abstraction": 3.8}, "insight_level": "high", "analysis": "The section demonstrates strong synthesis by connecting multiple post-hoc and training-based methods into a structured overview, emphasizing their design choices and effectiveness. It provides critical insights by contrasting goals such as confidence calibration versus OOD separability and pointing out limitations like overconfidence due to mismatched BatchNorm statistics. The abstraction level is moderate, identifying trends like the use of activation space and sparsification, but could offer more meta-level principles to elevate further."}}
{"id": "c2359d6e-5106-4598-9b78-918e091cc729", "title": "Methods with Outlier Exposure", "level": "subsubsection", "subsections": [], "parent_id": "4aa3467c-8e06-49ec-85df-b8c720f347b8", "prefix_titles": [["title", "Generalized Out-of-Distribution Detection: A Survey \n"], ["section", "OOD Detection: Methodology"], ["subsection", "Classification-based Methods"], ["subsubsection", "Methods with Outlier Exposure"]], "content": "\\label{sec:ood_classification_oe}\n\\keypoint{a.~Real Outliers}\nAnother branch of OOD detection methods makes use of a set of collected OOD samples, or ``outlier'', during training to help models learn ID/OOD discrepancy.\nStarting from the concurrent baselines that encourage a flat/high-entropic prediction on given OOD samples~ and suppressing OOD feature magnitudes~, a follow-up work, MCD~ uses a network with two branches, between which entropy discrepancy is enlarged for OOD training data. Another straightforward approach with outlier exposure spares an extra abstention (or rejection class) and considers all the given OOD samples in this class~.\nA later work OECC~ noticed that an extra regularization for confidence calibration introduces additional improvement for OE.\nTo effectively utilize the given, usually massive, OOD samples, some work use outlier mining~ and adversarial resampling~ approaches to obtain a compact yet representative set.\n\\revise{In cases where the meaningful ``near''-OOD images are not available, MixOE  proposes to interpolate between ID and ``far''-OOD images to obtain informative outliers for better regularization.} \nOther works consider a more practical scenario where given OOD samples contain ID samples, therefore using pseudo-labeling~ or ID filtering methods~ with optimal transport scheme~ to reduce the interference of ID data.\nIn general, OOD detection with outlier exposure can reach a much better performance. \nHowever, research shows that the performance can be largely affected by the correlations between given and real OOD samples~. To address the issue, recent work~ proposes a novel framework that enables effectively exploiting unlabeled in-the-wild data for OOD detection. Unlabeled wild data is frequently available since it is produced essentially for free whenever deploying an existing classifier in a real-world system. This setting can be viewed as training OOD detectors in their \\emph{natural habitats}, which provide a much better match to the true test time distribution than data collected offline.\n\\keypoint{b.~Outlier Data Generation}\nThe outlier exposure approaches impose a strong assumption on the availability of OOD training data, which can be infeasible in practice. \nWhen no OOD sample is available, some methods attempt to synthesize OOD samples to enable ID/OOD separability.\nExisting works leverage GANs to generate OOD training samples and force the model predictions to be uniform~, generate boundary samples in the low-density region~, or similarly, high-confidence OOD samples~, or using meta-learning the update sample generation~.\nHowever, synthesizing images in the high-dimensional pixel space can be difficult to\noptimize. \nRecent work VOS~ proposed synthesizing virtual outliers from the low-likelihood region in the feature space, which is more tractable given lower dimensionality. \nWhile VOS~ is a parametric approach that models the feature space as a class-conditional Gaussian distribution, NPOS~ also generates outlier ID data but in a non-parametric approach. \\revise{Noticing the generated OOD data could be incorrect or irrelevant, DOE~ synthesizes hard OOD data that leads to worst judgments to train the OOD detector with a min-max learning scheme, and ATOL~ uses auxiliary task to relieve the mistaken OOD generation.}\nIn object detection,  proposes synthesizing unknown objects from videos in the wild using spatial-temporal unknown distillation.", "cites": [3219, 3269, 3299, 3214, 3294, 3280, 3234, 6982, 3245, 8637, 6981, 3258, 3238, 3216, 3264, 3241, 3244, 3271, 1630], "cite_extract_rate": 0.8260869565217391, "origin_cites_number": 23, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.5, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section effectively synthesizes multiple outlier exposure methods, connecting them under the broader theme of using real or synthetic outliers to improve OOD detection. It provides critical analysis by highlighting limitations such as the correlation between training and real OOD samples and the difficulty of generating meaningful outliers. The abstraction is strong as it identifies overarching principles like the benefits of natural habitat training and the trade-offs between parametric and non-parametric outlier synthesis."}}
{"id": "3c7a045c-7ff3-4985-8762-45095f226bcd", "title": "Gradient-based Methods", "level": "subsubsection", "subsections": [], "parent_id": "4aa3467c-8e06-49ec-85df-b8c720f347b8", "prefix_titles": [["title", "Generalized Out-of-Distribution Detection: A Survey \n"], ["section", "OOD Detection: Methodology"], ["subsection", "Classification-based Methods"], ["subsubsection", "Gradient-based Methods"]], "content": "\\label{sec:ood_gradient}\nExisting OOD detection approaches primarily rely on the output (Section~\\ref{sec:ood_classification}) or feature space for deriving OOD scores, while overlooking information from the gradient space. ODIN~ first explored using gradient information for OOD detection. In particular, ODIN proposed using input pre-processing by adding small perturbations obtained from the input gradients. The goal of ODIN perturbations is to increase the softmax score of any given input by reinforcing the model's belief in the predicted label. Ultimately the perturbations have been found to create a greater gap between the softmax scores of ID and OOD inputs, thus making them more separable and improving the performance of OOD detection. While ODIN only uses gradients {implicitly} through input perturbation, recent work proposed GradNorm~ which explicitly derives a scoring function from the {gradient space}. GradNorm employs the vector norm of gradients, backpropagated from the KL divergence between the softmax output and a uniform probability distribution.\n\\revise{A recent research~ demonstrates that while gradient-based methods are effective, their success does not necessarily depend on gradients, but rather on the magnitude of learned feature embeddings and predicted output distribution.}", "cites": [3247, 3251, 3270], "cite_extract_rate": 1.0, "origin_cites_number": 3, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.5, "critical": 4.0, "abstraction": 3.0}, "insight_level": "medium", "analysis": "The section synthesizes the key contributions of ODIN and GradNorm, linking them under the theme of gradient-based OOD detection. It provides a critical perspective by highlighting a recent finding that challenges the assumption of gradients being the core reason for success, indicating a nuanced evaluation. The abstraction is moderate, identifying a broader pattern of reliance on feature embeddings and output distributions rather than gradients themselves, but does not offer a meta-level framework."}}
{"id": "145bb2d5-973d-48d4-82f5-177b3b47aa2c", "title": "Bayesian Models", "level": "subsubsection", "subsections": [], "parent_id": "4aa3467c-8e06-49ec-85df-b8c720f347b8", "prefix_titles": [["title", "Generalized Out-of-Distribution Detection: A Survey \n"], ["section", "OOD Detection: Methodology"], ["subsection", "Classification-based Methods"], ["subsubsection", "Bayesian Models"]], "content": "\\label{sec:ood_bayesian}\nA Bayesian model is a statistical model that implements Bayes' rule to infer all uncertainty within the model~.\nThe most representative method is the Bayesian neural network~, which draws samples from the posterior distribution of the model via MCMC~, Laplace methods~ and variational inference~, forming the epistemic uncertainty of the model prediction.\nHowever, their obvious shortcomings of inaccurate predictions~ and high computational costs~ prevent them from wide adoption in practice.\nRecent works attempt several less principled approximations including MC-dropout~ and deep ensembles~ for faster and better estimates of uncertainty. These methods are less competitive for OOD uncertainty estimation. \nFurther exploration takes natural-gradient variational inference and enables practical and affordable modern deep learning training while preserving the benefits of Bayesian principles~.\nDirichlet Prior Network (DPN) is also used for OOD detection with an uncertainty modeling of three different sources of uncertainty: model uncertainty, data uncertainty, and distributional uncertainty, and form a line of works~.\nRecently, the Bayesian hypothesis test has been used to formulate OOD detection, with upweighting method and Hessian approximation for scalability~.", "cites": [7703, 8639, 3300, 3301, 3302, 3288, 8633, 3278], "cite_extract_rate": 0.47058823529411764, "origin_cites_number": 17, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.5, "critical": 3.0, "abstraction": 3.0}, "insight_level": "medium", "analysis": "The section synthesizes multiple papers on Bayesian models for OOD detection, connecting ideas such as different types of uncertainty, training approaches (e.g., natural-gradient variational inference), and limitations of existing methods. It provides some critical evaluation by mentioning shortcomings like inaccuracy and computational cost. However, the abstraction remains limited to known concepts without a deeper meta-level analysis of overarching principles in Bayesian OOD detection."}}
{"id": "932f5926-9908-41df-9ae2-9a2d539317ee", "title": "OOD Detection for Foundation Models", "level": "subsubsection", "subsections": [], "parent_id": "4aa3467c-8e06-49ec-85df-b8c720f347b8", "prefix_titles": [["title", "Generalized Out-of-Distribution Detection: A Survey \n"], ["section", "OOD Detection: Methodology"], ["subsection", "Classification-based Methods"], ["subsubsection", "OOD Detection for Foundation Models"]], "content": "\\label{sec:ood_foundation}\n\\revise{\nFoundation models~, notably large-scale vision-language models~, have demonstrated exceptional performance in a variety of downstream tasks. Their success is largely attributed to extensive pre-training on large-scale datasets. Several works~ reveal that well-pretrained models can significantly enhance OOD detection, particularly in challenging scenarios.\nHowever, adapting (tuning) these models for downstream tasks with specific semantic (label) space in the training data remains a challenge, as simple approaches such as linear probing, prompt tuning~, and adaptor-style fine-tuning methods~ do not have good results on OOD detection.\nTo advance the problem, a thorough investigation~ examines how fine-tuned vision-language models are performed. Additionally, recent research~ highlights the impact of large-scale pretraining data and provides a systematic study on pretraining strategies on OOD detection performance.\nOn a technical front, LoCoOp~ introduces OOD regularization to a subset of CLIP's local features identified as OOD, enhancing prompt learning for better ID and OOD differentiation, and LSA~ uses a bidirectional prompt customization mechanism to enhance the image-text alignment.\nThe strong zero-shot learning capabilities of models like CLIP~ also open avenues for zero-shot OOD detection. This new setting aims to categorize known class samples and detect samples that do not belong to any of the known classes, where known classes are represented solely through textual descriptions or class names, eliminating the need for explicit training on these classes.\nAddressing this, ZOC~ trains a decoder based on CLIP's visual encoder to create candidate labels for OOD detection. While ZOC is computationally intensive and data-demanding, MCM~ opts for softmax scaling to align visual features with textual concepts for OOD detection.\nA recent advancement, CLIPN~, innovatively integrates a ``no'' logic in OOD detection. Utilizing new prompts and a text encoder, along with novel opposite loss functions, CLIPN effectively tackles the challenge of identifying hard-to-distinguish OOD samples. This development marks a significant stride in enhancing the precision of OOD detection in complex scenarios.\n}", "cites": [3305, 1550, 3287, 203, 1639, 3235, 3306, 7133, 3263, 3243, 3298, 3266, 7494, 3303, 3304], "cite_extract_rate": 0.9375, "origin_cites_number": 16, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.5, "abstraction": 3.5}, "insight_level": "high", "analysis": "The section effectively synthesizes multiple papers to build a narrative around OOD detection in foundation models, particularly CLIP-based systems. It highlights key methods (e.g., LoCoOp, LSA, CLIPN) and their technical contributions, showing how they address specific limitations. The critical perspective is evident in the evaluation of tuning approaches and the challenges they face, though deeper comparative analysis is limited. The section abstracts the general idea that foundation models can enhance OOD detection but struggle with adaptation, pointing to broader trends in vision-language learning."}}
{"id": "bd7529a3-f231-4faa-ba94-1425a45e32ce", "title": "Density-based Methods", "level": "subsection", "subsections": [], "parent_id": "b64f4212-2221-489a-89da-4c3cd93853fc", "prefix_titles": [["title", "Generalized Out-of-Distribution Detection: A Survey \n"], ["section", "OOD Detection: Methodology"], ["subsection", "Density-based Methods"]], "content": "\\label{sec:ood_density}\nDensity-based methods in OOD detection explicitly model the in-distribution with some probabilistic models, and flag test data in low-density regions as OOD.\nAlthough OOD detection can be different from AD in that multiple classes exist in the in-distribution, density estimation methods used for AD in Section~\\ref{sec:anomaly} can be directly adapted to OOD detection by unifying the ID data as a whole~.\nWhen the ID contains multiple classes, class-conditional Gaussian distribution can explicitly model the in-distribution so that the OOD samples can be identified based on their likelihoods~.\nFlow-based methods~ can also be used for probabilistic modeling.\nWhile directly estimating the likelihood seems like a natural approach, some  works~ find that probabilistic models sometimes assign a higher likelihood for the OOD sample.\nSeveral works attempt to solve the problems using likelihood ratio~.\n~ finds that the likelihood exhibits a strong bias towards the input complexity and proposes a likelihood ratio-based method to compensate for the influence of input complexity.\nRecent methods turn to new scores such as likelihood regret~ or an ensemble of multiple density models~. \nTo directly model the density of semantic space, SEM score is used with a simple combination of density estimation in the low-level and high-level space~.\nOverall, generative models can be prohibitively challenging to train and optimize, and the performance can often lag behind the classification-based approaches (Section~\\ref{sec:ood_classification}).", "cites": [7708, 3267, 3284, 1252, 3232, 3286, 8636, 3282, 3283, 3236, 3297, 3231, 3292, 3250, 8635], "cite_extract_rate": 0.8333333333333334, "origin_cites_number": 18, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.8, "critical": 3.5, "abstraction": 3.3}, "insight_level": "medium", "analysis": "The section effectively synthesizes density-based OOD detection approaches by integrating several papers, linking concepts such as Gaussian modeling, generative flows, and likelihood-based scores. It also critically addresses the limitations of likelihood estimation for OOD detection and highlights proposed solutions like likelihood ratios and regret-based scores. While it identifies broader patterns in the challenges and trends of generative models for OOD detection, the abstraction remains somewhat constrained to the density-based domain without reaching a fully meta-level perspective."}}
{"id": "7727623d-6ffc-445c-81c1-35dab3093771", "title": "Distance-based Methods", "level": "subsection", "subsections": [], "parent_id": "b64f4212-2221-489a-89da-4c3cd93853fc", "prefix_titles": [["title", "Generalized Out-of-Distribution Detection: A Survey \n"], ["section", "OOD Detection: Methodology"], ["subsection", "Distance-based Methods"]], "content": "\\label{sec:ood_distance}\nThe basic idea of distance-based methods is that the testing OOD samples should be relatively far away from the centroids or prototypes of in-distribution classes. \n~ uses the minimum Mahalanobis distance to all class centroids for detection. A subsequent work splits the images into foreground and background and then calculates the Mahalanobis distance ratio between the two spaces~. In contrast to the parametric approach, recent work~ shows strong promise of non-parametric nearest-neighbor distance for OOD detection. Unlike Mahalanobis, the non-parametric approach does not impose any distributional assumption about the underlying\nfeature space, hence providing stronger simplicity, flexibility, and generality.\nFor distance functions, some works use cosine similarity between test sample features and class features to determine OOD samples~.\nThe one-dimensional subspace spanned by the first singular vector of the training features is shown to be more suitable for cosine similarity-based detection~. \nMoreover, other works leverage distances with radial basis function kernel~, Euclidean distance~, and geodesic distance~ between the inputâ€™s embedding and the class centroids.\nApart from calculating the distance between samples and class centroids, the feature norm in the orthogonal complement space of the principal space is shown effective on OOD detection~. Recent work CIDER~ explores the usability of the embeddings in the hyperspherical space, where inter-class dispersion and inner-class compactness can be encouraged.", "cites": [3273, 7706, 3267, 8640, 3279, 8641, 3268, 3289], "cite_extract_rate": 0.7272727272727273, "origin_cites_number": 11, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.5, "critical": 2.0, "abstraction": 2.3}, "insight_level": "medium", "analysis": "The section provides a factual overview of distance-based methods for OOD detection and briefly mentions several techniques and papers. It connects some ideas (e.g., comparing parametric vs. non-parametric methods), but lacks deeper synthesis or a unifying framework. Critical analysis is minimal, with no clear evaluation of trade-offs or limitations of the approaches. Some pattern recognition is present, such as the use of different distance metrics, but the section remains largely at a concrete level."}}
{"id": "4a32d3f4-6df2-4062-8b1c-c1e22341d22e", "title": "Reconstruction-based Methods", "level": "subsection", "subsections": [], "parent_id": "b64f4212-2221-489a-89da-4c3cd93853fc", "prefix_titles": [["title", "Generalized Out-of-Distribution Detection: A Survey \n"], ["section", "OOD Detection: Methodology"], ["subsection", "Reconstruction-based Methods"]], "content": "\\label{sec:ood_reconstruction}\nThe core idea of reconstruction-based methods is that the encoder-decoder framework trained on the ID data usually yields different outcomes for ID and OOD samples. The difference in model performance can be utilized as an indicator for detecting anomalies.\nFor example, reconstruction models that are only trained by ID data cannot well recover the OOD data~, and therefore the OOD can be identified. While reconstruction-based models with pixel-level comparison seem not a popular solution in OOD detection for its expensive training cost, reconstructing with hidden features is shown as a promising alternative~.\nRather than reconstructing the entire image, recent work MoodCat~ masks a random portion of the input image and identifies OOD samples using the quality of the classification-based reconstruction results. READ~ combines inconsistencies from a classifier and an autoencoder by transforming the reconstruction error of raw pixels to the latent space of the classifier. \\revise{MOOD~ shows that masked image modeling for pretraining is beneficial to OOD detection tasks compared to contrastive training and classic classifier training.}", "cites": [3253, 8634, 8638, 3272, 3259], "cite_extract_rate": 1.0, "origin_cites_number": 5, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.5, "critical": 3.0, "abstraction": 3.0}, "insight_level": "medium", "analysis": "The section provides an analytical overview of reconstruction-based OOD detection methods, connecting the core concept across multiple papers. It synthesizes the idea that reconstruction errors can serve as indicators of OOD samples and highlights different approaches (e.g., pixel-level vs. latent space reconstruction). However, it lacks deeper critical evaluation of the methods' trade-offs or limitations and stops short of presenting broader meta-level principles."}}
{"id": "d3ee04e4-adfe-42d6-8efa-28298b3496f0", "title": "Theoretical Analysis", "level": "subsection", "subsections": [], "parent_id": "b64f4212-2221-489a-89da-4c3cd93853fc", "prefix_titles": [["title", "Generalized Out-of-Distribution Detection: A Survey \n"], ["section", "OOD Detection: Methodology"], ["subsection", "Theoretical Analysis"]], "content": "\\label{sec:theoretical}\n\\revise{\nEarly theoretical research on OOD detection~ delves into the limitations of Deep Generative Models (DGMs) in OOD contexts. This work uncovers a critical flaw where DGMs frequently assign greater probabilities to OOD data compared to training data, attributing this issue primarily to model misestimation rather than the typical set hypothesis. This hypothesis posits that relevant out-distributions might be located in high-likelihood areas of the data distribution. The study concludes that any generalized OOD task must restrict the set of distributions that are considered out-of-distribution, as without any restrictions, the task is impossible.\nLater work~ advances the field by developing a comprehensive analytical framework aimed at enhancing theoretical understanding and practical performance of OOD detection methods in neural networks. Their innovative approach culminates in a novel OOD detection method that surpasses existing techniques in both theoretical robustness and empirical performance.\nAnother series of studies has been focused on Open-Set Learning (OSL). The seminal work in this domain~ conceptualizes open-space risk for recognizing samples from unknown classes. The following research applies extreme value theory to OSL~.\nWhile probably approximately correct (PAC) theory is applied for OSR~, their method required test samples during training. Therefore, an investigation of the generalization error bound is conducted and proves the existence of a low-error OSL algorithm under certain assumptions~.\nStill, under the PAC theory, a later study establishes necessary and sufficient conditions for the learnability of OOD detection in various scenarios~, including cases with overlapping and non-overlapping ID and OOD data. Their work also offers theoretical support for existing OOD detection algorithms and suggests that OOD detection is possible under certain practical conditions.\nDespite these theoretical advancements, the field eagerly anticipates further research addressing aspects such as generalization in OOD detection, the explainability of these models, the integration of deep learning theory specific to OOD detection, and the exploration of foundation model theories pertinent to this area.\n}", "cites": [7704, 3209, 3257, 3290, 3215], "cite_extract_rate": 0.625, "origin_cites_number": 8, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.5, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section effectively synthesizes multiple theoretical works to build a cohesive narrative around the limitations and possibilities of OOD detection. It critically analyzes the assumptions and shortcomings of the cited methods, especially in terms of generalization and the necessity of distributional constraints. The section also abstracts the findings to highlight broader theoretical principles and identifies key open research directions."}}
{"id": "84b25b27-0b63-4872-8f10-5798f847b12b", "title": "Discussion", "level": "subsection", "subsections": [], "parent_id": "b64f4212-2221-489a-89da-4c3cd93853fc", "prefix_titles": [["title", "Generalized Out-of-Distribution Detection: A Survey \n"], ["section", "OOD Detection: Methodology"], ["subsection", "Discussion"]], "content": "\\label{sec:ood_discussion}\nThe field of OOD detection has enjoyed rapid development since its emergence, with a large space of solutions. \nIn the multi-class setting, the problem can be canonical to OSR (Section~\\ref{sec:osr})---accurately classify test samples from ID within the class space $\\mathcal{Y}$, and reject test samples with semantics outside the support of $\\mathcal{Y}$. The difference often lies in the evaluation protocol. OSR splits a dataset into two halves: one set as ID and another set as OOD. In contrast, OOD allows a more general and flexible evaluation by considering test samples from different datasets or domains. \nMoreover, OOD detection encompasses a broader spectrum of learning tasks (\\eg multi-label classification~, object detection~) and solution space. Apart from the methodology development, theoretical understanding has also received attention in the community~, providing provable guarantees and empirical analysis to understand how OOD detection performance changes with respect to data distributions.", "cites": [6981, 6982, 3290, 3246], "cite_extract_rate": 1.0, "origin_cites_number": 4, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.0, "critical": 2.5, "abstraction": 3.5}, "insight_level": "medium", "analysis": "The section provides some synthesis by connecting OOD detection with related tasks like OSR and highlighting the flexibility of OOD evaluation protocols. It also generalizes to multi-label and object detection tasks, showing abstraction. However, it lacks deep critical analysis of the cited papers, merely acknowledging their contributions without evaluating their strengths or limitations. The analytical nature is present but not fully developed."}}
{"id": "2f438838-65b0-473c-9c97-5435d293f43e", "title": "Open Set Recognition", "level": "subsection", "subsections": [], "parent_id": "ebbb5685-66d1-4ac0-b51f-470112eac8f2", "prefix_titles": [["title", "Generalized Out-of-Distribution Detection: A Survey \n"], ["section", "Methodologies from Other Sub-tasks"], ["subsection", "Open Set Recognition"]], "content": "\\label{sec:osr}\nThe concept of OSR was first introduced in~, which showed the validity of 1-class SVM and binary SVM for solving the OSR problem. In particular,  proposes the 1-vs-Set SVM to manage the open-set risk by solving a two-plane optimization problem instead of the classic half-space of a binary linear classifier. This paper highlighted that the open-set space should also be bounded, in addition to bounding the ID risk.\n\\smallskip\n\\keypoint{Classification-based Methods}\n\\label{sec:osr_classification}\nEarly works focused on logits redistribution using the compact abating probability (CAP)~ and extreme value theory (EVT)~.\nIn particular, classic probabilistic models lack the consideration of open-set space. CAP explicitly models the probability of class membership abating from ID points to OOD points, and EVT focuses on modeling the tail distribution with extreme high/low values.\nIn the context of deep learning, OpenMax~ first implements EVT for neural networks. OpenMax replaces the softmax layer with an OpenMax layer, which calibrates the logits with a per-class EVT probabilistic model such as Weibull distribution.\nTo bypass open-set risk construction, some works attained good results without EVT. For example, some work uses a membership loss to encourage high activations for known classes, and uses large-scale external datasets to learn globally negative filters that can reduce the activations of novel images~.\nApart from explicitly forcing discrepancy between known/unknown classes, \nother methods extract stronger features through an auxiliary task of transformation classification~, or mutual information maximization between the input image and its latent features~, \\etc.\nImage generation techniques have been utilized to synthesize unknown samples from known classes, which helps distinguish between known vs. unknown samples~.\nWhile these methods are promising on simple images such as handwritten characters, they do not scale to complex natural image datasets due to the difficulty in generating high-quality images in high-dimensional space.\nAnother solution is to successively choose random categories in the training set and treat them as unknown, which helps the classifier to shrink the boundaries and gain the ability to identify unknown classes~.\nMoreover,  splits the training data into typical and atypical subsets, which also helps learn compact classification boundaries.\n\\smallskip\n\\keypoint{Distance-based Methods}\n\\label{sec:osr_distance}\nDistance-based methods for OSR require the prototypes to be class-conditional, which allows maintaining the ID classification performance.\nCategory-based clustering and prototyping are performed based on the visual features extracted from the classifiers. OOD samples can be detected by computing the distance \\emph{w.r.t.} clusters~.\nSome methods also leveraged contrastive learning to learn more compact clusters for known classes~, which enlarge the distance between ID and OOD.\nCROSR~ enhances the features by concatenating visual embeddings from both the classifier and reconstruction model for distance computation in the extended feature space.\nBesides using features from classifiers, GMVAE~ extracts features using a reconstruction VAE, and models the embeddings of the training set as a Gaussian mixture with multiple centroids for the following distance-based operations.\nClassifiers using nearest neighbors are also adapted for OSR problem~. By storing the training samples, the nearest neighbor distance ratio is used for identifying unknown samples in testing.\n\\smallskip\n\\keypoint{Reconstruction-based Methods}\n\\label{sec:osr_reconstruction}\nWith similar motivations as Section~\\ref{sec:ood_reconstruction},\nreconstruction-based methods expect different reconstruction behavior for ID vs. OOD samples. The difference can be captured in the latent feature space or the pixel space of reconstructed images. \nBy sparsely encoding images from the known classes, open-set samples can be identified based on their dense representation. Techniques such as sparsity concentration index~ and kernel null space methods~ are used for sparse encoding.\nBy fixing the visual encoder obtained from standard multi-class training to maintain ID classification performance, C2AE trains a decoder conditioned on label vectors and estimates the reconstructed images using EVT to distinguish unknown classes~.\nSubsequent works use conditional Gaussian distributions by forcing different latent features to approximate class-wise Gaussian models, which enables classifying known samples as well as rejecting unknown samples~.\nOther methods generate counterfactual images, which help the model focus more on semantics~.\nAdversarial defense is also considered in~ to enhance model robustness.\n\\smallskip\n\\keypoint{Discussion}\n\\label{sec:osr_hybrid}\nAlthough there is not an independent section for density-based methods, these methods can play an important role and are fused as a critical step in some classification-based methods such as OpenMax~. The density estimation on visual embeddings can effectively detect unknown classes without influencing the classification performance. A hybrid model also uses a flow-based density estimator to detect unknown samples~.\nAs introduced in Section~\\ref{sec:tax_ood}, the general goal of OSR and OOD detection is aligned, that is to detect semantic shift from the training data. Therefore, we encourage methods from these two field should learn more from each other.\nFor example, apart from novel methods, OSR research also shows that a good classifier~ in the close-set is critical to OSR performance, which should also applicable to OOD detection tasks.", "cites": [3319, 3309, 3316, 3322, 3321, 3318, 3310, 3325, 3313, 3307, 3311, 8642, 3323, 3308, 3312, 3315, 3320, 3314, 3324, 3317, 7134], "cite_extract_rate": 0.65625, "origin_cites_number": 32, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.0, "abstraction": 3.5}, "insight_level": "medium", "analysis": "The section effectively synthesizes key OSR methodologies from multiple papers into a structured narrative, grouping them into classification-based, distance-based, and reconstruction-based approaches. It provides some critical analysis, such as noting limitations in scalability and the over-demanding nature of pixel-level reconstruction. While it identifies patterns (e.g., use of EVT, clustering, and feature extraction), it stops short of offering a meta-level theoretical abstraction or deep comparative critique."}}
{"id": "3dd1298a-927c-4c14-a463-60605b3be96b", "title": "Anomaly Detection \\& Novelty Detection", "level": "subsection", "subsections": [], "parent_id": "ebbb5685-66d1-4ac0-b51f-470112eac8f2", "prefix_titles": [["title", "Generalized Out-of-Distribution Detection: A Survey \n"], ["section", "Methodologies from Other Sub-tasks"], ["subsection", "Anomaly Detection \\& Novelty Detection"]], "content": "\\label{sec:anomaly}\nThis section reviews methodologies for sensory and semantic AD and one-class ND. Notice that multi-classes ND is covered in the previous. \nGiven homogeneous in-distribution data, approaches include density-based, reconstruction-based, distance-based, and hybrid methods. We also discuss theoretical works.\n\\smallskip\n\\keypoint{Density-based Methods}\n\\label{sec:ad_density}\nDensity-based methods model normal data (ID) distributions, assuming anomalous test data has low likelihood while normal data has higher likelihood. Techniques include classic density estimation, density estimation with deep generative models, energy-based models, and frequency-based methods.\nParametric density estimation assumes pre-defined distributions~. Methods involve multivariate Gaussian distribution~, mixed Gaussian distribution~, and Poisson distribution~. Non-parametric density estimation handles more complex scenarios~ with histograms~ and kernel density estimation (KDE)~.\nNeural networks generate high-quality features to enhance classic density estimation. Techniques include autoencoder (AE)~ and variational autoencoder (VAE)~-based models, generative adversarial networks (GANs)~, flow-based models~, and representation enhancement strategies.\nEBMs use scalar energy scores to express probability density~ and provide a solution for AD~. Training EBMs can be computationally expensive, but score matching~ and stochastic gradient Langevin dynamics~ enable efficient training.\nFrequency domain analysis for AD includes methods like CNN kernel smoothing~, spectrum-oriented data augmentation~, and phase spectrum targeting~. These mainly focus on sensory AD.\n\\smallskip\n\\keypoint{Reconstruction-based Methods}\n\\label{sec:ad_reconstruction}\nThese AD methods leverage model performance differences on normal and abnormal data in feature space or by reconstruction error.\nSparse reconstruction assumes normal samples can be accurately reconstructed using a limited set of basis functions, while anomalies have larger reconstruction costs and a dense representation~. Techniques include $L_1$ norm-based kernel PCA~ and low-rank embedded networks~.\nReconstruction-error methods assume a model trained on normal data will produce better reconstructions for normal test samples than anomalies. Deep models include AEs~, VAEs~, GANs~, and U-Net~.\nAE/VAE-based models combine reconstruction-error with AE/VAE models~ and use strategies like reconstructing by memorized normality~, adapting model architectures~, and partial/conditional reconstruction~. In semi-supervised AD, CoRA~ trains two AEs on inliers and outliers, using reconstruction errors for anomaly detection.\nReconstruction-error methods using GANs leverage the discriminator to calculate reconstruction error for anomaly detection~. Variants like denoising GANs~, class-conditional GANs~, and ensembling~ further improve performance.\nGradient-based methods observe different patterns on training gradient between normalities and anomalies in a reconstruction task, using gradient-based representation to characterize anomalies~.\n\\smallskip\n\\keypoint{Distance-based Methods}\n\\label{sec:ad_distance}\nThese methods detect anomalies by calculating the distance between samples and prototypes~, requiring training data in memory. Methods include K-nearest Neighbors~ and prototype-based methods~.\n\\smallskip\n\\keypoint{Classification-based Methods}\n\\label{sec:ad_classification}\nAD and one-class ND are often formulated as unsupervised learning problems, but there are some supervised and semi-supervised methods as well. One-class classification (OCC) directly learns a decision boundary that corresponds to a desired density level set of the normal data distribution~. DeepSVDD~ introduced classic OCC to the deep learning community. PU learning~ is proposed for the semi-supervised AD setting where unlabeled data is available in addition to the normal data. Self-supervised learning methods use pretext tasks such as contrastive learning~, image transformation prediction~, and future frame prediction~, where anomalies are more likely to make mistakes on the designed task.\nOne-class classification learns a decision boundary that corresponds to a desired density level set of the normal data distribution, which DeepSVDD~ introduced to the deep learning community. PU learning~ is a popular method for the semi-supervised AD setting. Self-supervised learning methods use pretext tasks such as contrastive learning~, image transformation prediction~, and future frame prediction~, where anomalies are more likely to make mistakes on the designed task.\n\\smallskip\n\\keypoint{Discussion: Sensory \\emph{vs} Semantic AD}\nSensory and semantic AD approaches assume the normal data as homogeneous, despite the presence of multiple categories within it. While semantic AD methods are mainly applicable to sensory AD problems, the latter can benefit from techniques that focus on lower-level features (e.g., flow-based and hidden feature-based), local representations, and frequency-based methods. Although current OOD detection tasks mostly focus on semantic shift, the method for Sensory AD might be especially helpful for far OOD detection, like ImageNet \\vs Texture dataset.\n\\smallskip\n\\keypoint{Discussion: Theoretical Analysis}\nIn addition to algorithmic development, theoretical analysis of AD and one-class ND has also been provided in some works. For instance,  constructs a clean set of ID and a mixed set of ID/OOD with identical sample sizes, achieving a PAC-style finite sample guarantee for detecting a certain portion of anomalies with the minimum number of false alarms. All these works could be beneficial to the theoretical works of OOD detection.", "cites": [3337, 3328, 3331, 3336, 8643, 3332, 3256, 3283, 3329, 5680, 3333, 3335, 3213, 3334, 8644, 6980, 3231, 3292, 3215, 3327, 3339, 3330, 3338, 3326], "cite_extract_rate": 0.39344262295081966, "origin_cites_number": 61, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.0, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section synthesizes multiple methods from cited papers into a coherent categorization (density-based, reconstruction-based, etc.), demonstrating strong integration. It also includes critical elements such as limitations of reconstruction-based methods (e.g., threshold selection) and challenges in training generative models. Additionally, it abstracts broader themes like the use of frequency-based techniques in sensory AD and contrasts between semi-supervised and unsupervised approaches."}}
{"id": "4d845bb1-dde4-47f7-8f92-20409c56b094", "title": "Outlier Detection", "level": "subsection", "subsections": [], "parent_id": "ebbb5685-66d1-4ac0-b51f-470112eac8f2", "prefix_titles": [["title", "Generalized Out-of-Distribution Detection: A Survey \n"], ["section", "Methodologies from Other Sub-tasks"], ["subsection", "Outlier Detection"]], "content": "\\label{sec:outlier}\nOutlier detection (OD) observes all samples to identify significant deviations from the majority distribution. Though mostly studied in data mining, deep learning-based OD methods are used for data cleaning in open-set noisy data~ and open-set semi-supervised learning~.\n\\smallskip\n\\keypoint{Density-based Methods}\n\\label{sec:od_density}\nOD methods include Gaussian distribution~, Mahalanobis distance~, Gaussian mixtures~, and Local outlier factor (LOF)~. RANSAC~ estimates parameters for a mathematical model. Classic density methods and NN-based density methods can also be applied.\n\\smallskip\n\\keypoint{Distance-based Methods}\n\\label{sec:od_distance}\nOutliers can be detected by neighbor counting~, DBSCAN clustering~, and graph-based methods~.\n\\smallskip\n\\keypoint{Classification-based Methods}\n\\label{sec:od_classification}\nAD methods like Isolation Forest~ and OC-SVM~ can be applied to OD. Deep learning models can identify outliers~. Techniques for robustness and feature generalizability include ensembling~, co-training~, and distillation~.\n\\smallskip\n\\keypoint{Discussion}\nOD techniques are valuable for open-set semi-supervised learning, learning with open-set noisy labels, and novelty discovery. All these solutions can be applied especially when OOD samples are exposed during the training stage~.\n\\begin{figure}[!t]\n    \\centering\n    \\includegraphics[width=0.9\\linewidth]{figures/cifar10.pdf}\n    \\caption{The illustration of CIFAR-10 benchmark that is used in Section~\\ref{sec:benchmark}. The CIFAR-100 benchmark simply swaps the position of CIFAR-10 and CIFAR-100 in the figure.}\n    \\label{fig:benchmark}\n\\end{figure}\n\\begin{figure*}[!t]\n    \\centering\n    \\includegraphics[width=\\linewidth]{figures/exp.pdf}\n    \\vspace{-0.7cm}\n\\caption{Comparison between different methodologies under generalized OOD detection framework on the CIFAR-10/100 benchmarks. Results are from OpenOOD~. Different colors denote the method categories. Each method reports near-OOD (left-bar) and far-OOD (right-bar) AUROC scores, as introduced in Section~\\ref{sec:exp_metrics}. Method names in black originated for OOD detection, while in red are AD methods, blue for OSR methods, and pink for models from model uncertainty works.}\n    \\label{fig:exp}\n\\end{figure*}", "cites": [3341, 3340, 8630, 3342, 1630, 3345, 7709, 3343, 2277, 3344, 7702], "cite_extract_rate": 0.36666666666666664, "origin_cites_number": 30, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 2.0, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section provides a descriptive overview of outlier detection methods and mentions several papers, but lacks synthesis of their contributions into a cohesive narrative. It offers minimal critical analysis and does not delve into broader patterns or principles across the cited works. The discussion is brief and primarily serves to list applications and techniques without deeper insight."}}
{"id": "7bbd7bb5-e6a4-435c-8172-62a17141e85e", "title": "Benchmarks and Experiments", "level": "section", "subsections": ["ed2d5bd6-71a9-45dc-bbfa-1aa5dbd6df1f", "8272bdd0-f42a-44f1-909b-cf46f330e4f1", "60dd48c0-f483-4389-bb89-1e41980e9e69", "41171fad-6e49-4793-a9ac-7189b675196e"], "parent_id": "c7a3c574-b9a2-41d9-8a41-220c3546317c", "prefix_titles": [["title", "Generalized Out-of-Distribution Detection: A Survey \n"], ["section", "Benchmarks and Experiments"]], "content": "\\label{sec:benchmark}\nIn this section, we report the fair comparison of methodologies that from different categories on the CIFAR~ benchmark. The report originated from OpenOOD benchmarks~. We selected several popular AD methods, OOD detection methods (post-hot, training-required, and extra-data-required), and model robustness methods.", "cites": [7709], "cite_extract_rate": 0.5, "origin_cites_number": 2, "insight_result": {"type": "descriptive", "scores": {"synthesis": 1.5, "critical": 1.5, "abstraction": 1.5}, "insight_level": "low", "analysis": "The section provides a basic description of the benchmarking setup and the types of methods included, but it lacks synthesis of ideas from the cited papers. There is minimal critical analysis of the methods or the benchmark itself, and no abstraction or generalization of patterns or principles across the surveyed works."}}
{"id": "ed2d5bd6-71a9-45dc-bbfa-1aa5dbd6df1f", "title": "Benchmarks and Metrics", "level": "subsection", "subsections": [], "parent_id": "7bbd7bb5-e6a4-435c-8172-62a17141e85e", "prefix_titles": [["title", "Generalized Out-of-Distribution Detection: A Survey \n"], ["section", "Benchmarks and Experiments"], ["subsection", "Benchmarks and Metrics"]], "content": "\\label{sec:exp_metrics}\nThe common practice for building OOD detection benchmarks is to consider an entire dataset as in-distribution (ID), and then collect several datasets that are disconnected from any ID categories as OOD datasets. In this part, we show the results from two popular OOD benchmarks with ID datasets of CIFAR-10~, CIFAR-100~ from OpenOOD (\\cf Figure~\\ref{fig:benchmark}), with each benchmark designing near-OOD and far-OOD datasets to facilitate detailed analysis of the OOD detectors. Near-OOD datasets only have semantic shift compared with ID datasets, while far-OOD further contains obvious covariate (domain) shift.\n\\noindent\\textbf{CIFAR-10}\\qquad\nCIFAR-10~ is a 10-class dataset for general object classification, which contains 50k training images and 10k test images. As for the OOD dataset, we construct near-OOD with CIFAR-100~ and TinyImageNet~.\nNotice that 1,207 images are removed from TinyImageNet since they actually belong to CIFAR-10 classes~.\nFar-OOD is built by MNIST~, SVHN~, Texture~, and Places365~ with 1,305 images are removed due to semantic overlaps.\n\\noindent\\textbf{CIFAR-100}\\qquad\nAnother OOD detection benchmark uses CIFAR-100~ as an in-distribution, which contains 50k training images and 10k test images with 100 classes. \nFor OOD dataset, near-OOD includes CIFAR-10~ and TinyImageNet~. \nSimilar to the CIFAR-10 benchmark, 2,502 images are removed from TinyImageNet due to the overlapping semantics with CIFAR-100 classes~.\nFar-OOD consists of MNIST~, SVHN~, Texture~, and Places365~ with 1,305 images removed.\n\\noindent\\textbf{Metrics}\\qquad\nWe only report the AUROC scores, which measure the area under the Receiver Operating Characteristic (ROC) curve.", "cites": [1630], "cite_extract_rate": 0.1111111111111111, "origin_cites_number": 9, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 2.0, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section provides a factual description of how OOD benchmarks are constructed, specifically using CIFAR-10 and CIFAR-100 with corresponding near-OOD and far-OOD datasets. It mentions the semantic and covariate shifts but does not synthesize this information with the cited paper in a meaningful way. There is minimal critical evaluation or abstraction to broader principles, limiting its insight quality."}}
{"id": "8272bdd0-f42a-44f1-909b-cf46f330e4f1", "title": "Experimental Setup", "level": "subsection", "subsections": [], "parent_id": "7bbd7bb5-e6a4-435c-8172-62a17141e85e", "prefix_titles": [["title", "Generalized Out-of-Distribution Detection: A Survey \n"], ["section", "Benchmarks and Experiments"], ["subsection", "Experimental Setup"]], "content": "To ensure a fair comparison across methods that originate from different fields and have different implementations, unified settings with common hyperparameters and architecture choices are implemented. ResNet-18~ is used as the backbone network. If the implemented method requires training, the widely accepted setting with SGD optimizer, a learning rate of 0.1, momentum of 0.9, and weight decay of 0.0005 for 100 epochs, is used. For further details, please refer to OpenOOD~.", "cites": [8645, 7709, 97], "cite_extract_rate": 1.0, "origin_cites_number": 3, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 1.5, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section provides a basic description of the experimental setup used for comparing OOD detection methods, citing relevant papers for the benchmark (OpenOOD) and the backbone network (ResNet-18). However, it lacks deeper synthesis or integration of the cited works' contributions, and offers minimal critical analysis or abstraction beyond the specific setup."}}
{"id": "60dd48c0-f483-4389-bb89-1e41980e9e69", "title": "Experimental Results and Findings", "level": "subsection", "subsections": [], "parent_id": "7bbd7bb5-e6a4-435c-8172-62a17141e85e", "prefix_titles": [["title", "Generalized Out-of-Distribution Detection: A Survey \n"], ["section", "Benchmarks and Experiments"], ["subsection", "Experimental Results and Findings"]], "content": "\\keypoint{Data Augmentation Methods are the Most Effective}\nWe split Figure~\\ref{fig:exp} into several sections based on the method type. Generally, the most effective methods are those that use model uncertainty works with data augmentation techniques. This group mainly includes simple and effective methods such as preprocessing methods like PixMix~ and CutMix~. PixMix achieves 93.1\\% on Near-OOD in CIFAR-10, the best performance among all the methods in this benchmark. These methods also perform well in most of the other benchmarks. Similarly, other simple and effective methods to enhance model uncertainty estimation such as Ensemble~ and Mixup~ also demonstrate excellent performance.\n\\keypoint{Extra Data Seems Not Necessary?}\nComparing UDG~ (the best from the extra-data part) with KNN~ (the best from the extra data-free part), we found that UDG's advantage is only in CIFAR-10 near-OOD, which is not satisfactory since a large quantity of real outlier data is required. In this benchmark, we use the entire TinyImageNet training set as the extra data, the choice of training outliers could greatly affect the performance of OOD detectors, so further exploration is needed.\n\\keypoint{Post-Hoc Methods Outperform Training in General}\nSurprisingly, methods that require training do not necessarily perform better. In general, inference-only methods outperform trained methods. Nevertheless, the trained models can be generally used in conjunction with post-hoc methods, which could potentially further increase their performance.\n\\keypoint{Post-Hoc Methods are Making Progress}\nIn general, recent post-hoc methods have had better performance than previous methods since 2021, indicating that the direction of inference-only methods is promising and making progress. Recent methods show improvements in performance on more realistic datasets than previous methods, which focused on toy datasets. For example, the classic MDS performs well on MNIST but poorly on CIFAR-10 and CIFAR-100, while the recent KNN maintains good performance on MNIST, CIFAR-10, CIFAR-100, and also shows outstanding performance on ImageNet~.\n\\keypoint{Some AD Methods are Good at Far-OOD}\nAlthough anomaly detection (AD) methods were originally designed to detect pixel-level appearance differences on the MVTec-AD dataset, they have shown potency in far-OOD detection, such as with DRAEM and CutPaste. Both methods achieved high performance on far-OOD detection, especially when using CIFAR-100 as the in-distribution dataset.\n\\keypoint{Explore OpenOOD for More Experimental Findings}\n\\revise{Accompanying our survey, we lead the development of OpenOOD~, an open-source codebase that provides a unified framework and benchmarking platform for conducting fair comparisons of various model architectures and OOD detection methods. OpenOOD is continuously updated and includes two comprehensive experimental reports~ that delve into extensive analysis and discovery\\footnote{We also provide a \\href{https://zjysteven.github.io/OpenOOD/}{leaderboard} to track SOTA methods.}. We encourage readers to explore OpenOOD's resources for a deeper understanding of key aspects such as selecting model architectures, utilizing pre-trained models, practical applications, and detailed implementation insights.}", "cites": [3268, 7709, 3255, 8645, 3254, 107, 1630], "cite_extract_rate": 0.875, "origin_cites_number": 8, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.5, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section synthesizes findings from multiple cited papers to form a coherent narrative on the effectiveness of different OOD detection strategies. It offers critical evaluation by highlighting limitations, such as the data requirements of UDG and the impracticality of certain benchmarks. Furthermore, it abstracts results into broader patterns, such as the growing promise of post-hoc and data augmentation methods, and the relevance of AD techniques to far-OOD scenarios."}}
{"id": "41171fad-6e49-4793-a9ac-7189b675196e", "title": "Exclusion of Covariate-Shift Detection", "level": "subsection", "subsections": [], "parent_id": "7bbd7bb5-e6a4-435c-8172-62a17141e85e", "prefix_titles": [["title", "Generalized Out-of-Distribution Detection: A Survey \n"], ["section", "Benchmarks and Experiments"], ["subsection", "Exclusion of Covariate-Shift Detection"]], "content": "\\revise{While OpenOOD does not include settings for pure covariate shift, this was a deliberate choice. The primary focus is on semantic shifts, which are fundamental to OOD detection. By not separately analyzing covariate shifts, we aim to avoid potential misinterpretations and prevent the overemphasis on covariate shift detection. Experiments in~ highlight a key finding: most current OOD detectors are more sensitive to covariate shifts than semantic shifts and lead to the concept of ``full-spectrum OOD detection'', advocating for models that \\textbf{effectively generalize to handle covariate shifts} while \\textbf{simultaneously detecting samples with semantic shifts}. More experimental evaluations can be found in OpenOOD v1.5~.}", "cites": [8645, 7708], "cite_extract_rate": 1.0, "origin_cites_number": 2, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.5, "critical": 3.0, "abstraction": 3.5}, "insight_level": "medium", "analysis": "The section integrates the key ideas from both cited papers, connecting the concept of 'full-spectrum OOD detection' from Paper 2 with the benchmarking improvements in OpenOOD v1.5 from Paper 1. It provides some critical reasoning by highlighting the deliberate choice to exclude covariate shift and the potential misinterpretations that may arise. However, it stops short of deeper comparative or evaluative analysis of the approaches and limitations, offering moderate abstraction by discussing broader implications such as generalization versus detection."}}
{"id": "318e4c59-d478-4932-a736-04a04a3dddf7", "title": "Challenges", "level": "subsection", "subsections": [], "parent_id": "6a080ea2-3a75-4289-92f3-fb1228d6bb7a", "prefix_titles": [["title", "Generalized Out-of-Distribution Detection: A Survey \n"], ["section", "Challenges and Future Directions"], ["subsection", "Challenges"]], "content": "\\keypoint{a.~Proper Evaluation and Benchmarking}\nWe hope this survey can clarify the distinctions and connections of various sub-tasks, and help future works properly identify the target problem and benchmarks within the framework. The mainstream OOD detection works primarily focus on detecting semantic shifts.\nAdmittedly, the field of OOD detection can be very broad due to the diverse nature of distribution shifts. \nSuch a broad OOD definition also leads to some challenges and concerns~, which advocate a clear specification of OOD type in consideration (\\eg semantic OOD, adversarial OOD, \\etc) so that proposed solutions can be more specialized.\nBesides, the motivation of detecting a certain distribution shift also requires clarification. While rejecting classifying samples with semantic shift is apparent, detecting sensory OOD should be specified to some meaningful scenarios to contextualize the necessity and practical relevance of the task. \nWe also urge the community to carefully construct the benchmarks and evaluations. It is noticed that early work~ ignored the fact that some OOD datasets may contain images with ID categories, causing inaccurate performance evaluation. \nFortunately, recent OOD detection works~\nhave realized this flaw and pay special attention to removing ID classes from OOD samples to ensure proper evaluation. \n\\keypoint{b.~Outlier-free OOD Detection}\nThe outlier exposure approach~ imposes a strong assumption of the availability of  OOD  training data,  which can be difficult to obtain in practice. Moreover, one needs to perform careful de-duplication to ensure that the outlier training data does not contain ID data. These restrictions may lead to inflexible solutions and prevent the adoption of methods in the real world. Going forward, a major challenge for the field is to devise outlier-free learning objectives that are less dependent on auxiliary outlier dataset. \n\\keypoint{c.~Tradeoff Between Classification and OOD Detection}\nIn OSR and OOD detection, it is important to achieve the dual objectives simultaneously: one for the ID task (\\eg image classification), another for the OOD detection task. For a shared network, an inherent trade-off may exist between the two tasks. Promising solutions should strive for both. These two tasks may or may not contradict each other, depending on the methodologies. For example, ~ advocated the integration of image classification and open-set recognition so that the model will possess the capability of discriminative recognition on known classes and sensitivity to novel classes at the same time.\n~ also showed that the ability of detecting novel classes can be highly correlated with its accuracy on the closed-set classes.\n~ demonstrated that optimizing for the cluster compactness of ID classes may facilitate both improved classification and distance-based OOD detection performance. Such solutions may be more desirable than ND, which develops a binary OOD detector separately from the classification model, and requires deploying two models. \n\\keypoint{d.~Real-world Benchmarks and Evaluations}\nCurrent methods in OOD detection are predominantly evaluated on smaller datasets like CIFAR. However, it has been observed that strategies effective on CIFAR may not perform as well on larger datasets like ImageNet, which has a more extensive semantic space. This discrepancy underscores the importance of conducting OOD detection evaluations in large-scale, real-world settings. Consequently, we recommend future research to focus on benchmarks based on ImageNet for OOD detection~ and to explore large-scale Open Set Recognition (OSR) benchmarks~ to fully test the effectiveness of these methods. \\revise{Additionally, recent research~ highlights the presence of erroneous samples in ImageNet OOD benchmarks and introduces the corrected NINCO dataset for more accurate evaluations. Furthermore, expanding the scope of benchmarks to encompass real-world scenarios, such as more realistic datasets~, and object-level OOD detection~, can provide valuable insights, especially in safety-critical applications like autonomous driving.}", "cites": [6981, 6982, 3242, 3225, 2769, 3219, 1624, 3210, 3346, 1630, 3318], "cite_extract_rate": 0.8461538461538461, "origin_cites_number": 13, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.5, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section synthesizes multiple papers to form a coherent narrative around the key challenges in OOD detection, particularly in evaluation, outlier-free detection, and the classification-OOD tradeoff. It critically evaluates the limitations of existing methods and benchmarks, and abstracts these insights to broader issues such as the need for real-world relevance, semantic coherence, and integrated system design. The synthesis is strong, showing how different works address similar themes, and it offers a nuanced perspective on the field's development."}}
{"id": "7943d3a2-86a5-494b-83dc-293f03ecbaa5", "title": "Future Directions", "level": "subsection", "subsections": [], "parent_id": "6a080ea2-3a75-4289-92f3-fb1228d6bb7a", "prefix_titles": [["title", "Generalized Out-of-Distribution Detection: A Survey \n"], ["section", "Challenges and Future Directions"], ["subsection", "Future Directions"]], "content": "\\label{sec:future_direction}\n\\keypoint{a.~Methodologies across Sub-tasks}\nDue to the inherent connections among different sub-tasks, their solution space can be shared and inspired by each other. For example, the recent emerging density-based OOD detection research (\\cf Section~\\ref{sec:ood_density}) can draw insights from the density-based AD methods (\\cf Section~\\ref{sec:ad_density}) that have been around for a long time.\n\\keypoint{b.~OOD Detection \\& Generalization}\nAn open-world classifier should consider two tasks,\n\\ie being robust to covariate shift while being aware of the semantic shift. Existing works pursue these two goals independently. Recent work proposes a semantically coherent OOD detection framework~ that encourages detecting semantic OOD samples while being robust to negligible covariate shift. \nGiven the vague definition of OOD,  proposed a formalization of OOD detection by explicitly taking into account the separation\nbetween invariant features (semantically related) and environmental features (non-semantic). The work highlighted that spurious environmental features in the training set can significantly impact\nOOD detection, especially when the semantic OOD data contains the spurious feature. \nFurther, full-spectrum OOD detection~ highlights the effects of ``covariate-shifted in-distribution'', and show that most of the previous OOD detectors are unfortunately sensitive to covariate shift rather than semantic shift. This setting explicitly promotes the generalization ability of OOD detectors.\nRecent works on open long-tailed recognition~, open compound domain adaptation~, open-set domain adaptation~ and open-set domain generalization~ consider the potential existence of open-class samples.\nLooking ahead, we envision great research opportunities on how OOD detection and OOD generalization can better enable each other~, in terms of both algorithmic design and comprehensive performance evaluation.\n\\keypoint{c.~OOD Detection \\& Open-Set Noisy Labels}\nExisting methods of learning from open-set noisy labels focus on suppressing the negative effects of noise~. However,\nthe open-set noisy samples can be useful for outlier exposure (\\cf ~Section \\ref{sec:ood_classification_oe})~ and potentially benefit OOD detection.\nWith a similar idea, the setting of open-set semi-supervised learning can be promising for OOD detection.\nWe believe the combination of OOD detection and the previous two fields can provide more insights and possibilities.\n\\keypoint{d.~OOD Detection For Broader Learning Tasks}\nAs mentioned in Section~\\ref{sec:ood_discussion}, OOD detection encompasses a broader spectrum of learning tasks, including multi-label classification~, object detection~, image segmentation~, time-series prediction~, and LiDAR-based 3D object detection~.\nFor the classification task itself, the researchers also extended the OOD detection technique to improve the reliability of zero-shot pretrained models~ (\\eg CLIP).\nFurthermore, some studies focus on applying OOD detection methods to produce reliable image captions~. \n\\revise{Recent advancements extend OOD detection to continuously adaptive or online learning environments~. Additionally, OOD detection shows promise in addressing model reliability issues in broader applications, like mitigating hallucination problems in large language models~. The integration of OOD detection methods promises to enhance the reliability and practicality of models across various fields, and insights from these fields could, in turn, further refine OOD detection techniques.}\n\\keypoint{e.~OOD Detection with World Models}\n\\revise{The existing works utilizing foundation models, particularly multi-modal ones such as CLIP~, have significantly enhanced OOD detection performance, as discussed in Section~\\ref{sec:ood_foundation}.\nStarting from this, recent advancements have further focused on leveraging the extensive world knowledge encapsulated in Large Language Models~. This approach aligns with the rapid development in multi-modal world models~, presenting burgeoning opportunities for further innovation within the OOD detection community.\n}", "cites": [7708, 1629, 8630, 3350, 3246, 6982, 3225, 2232, 3343, 2344, 6981, 2238, 3352, 2237, 3349, 3351, 3347, 3348, 1639, 3229, 2711, 3222, 1630], "cite_extract_rate": 0.92, "origin_cites_number": 25, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.5, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section synthesizes multiple cited papers to highlight how OOD detection intersects with related sub-tasks, noisy labels, and broader learning tasks, creating a coherent narrative. It critically examines limitations, such as sensitivity to covariate shift and the need for semantic coherence. The discussion abstracts these ideas into general research directions, including the integration of OOD detection with open-world models and multi-modal learning."}}
