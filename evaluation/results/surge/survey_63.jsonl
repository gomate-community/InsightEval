{"id": "6799dc21-761f-45e7-aaef-27acbc8cbc80", "title": "Deep Learning Models of Attention: the beginning", "level": "subsection", "subsections": [], "parent_id": "4f96ee17-8c70-472d-b042-28031c34fcbc", "prefix_titles": [["title", "Attention, please! A survey of Neural Attention Models in Deep Learning"], ["section", "Introduction"], ["subsection", "Deep Learning Models of Attention: the beginning"]], "content": "By 2014, the DL community noticed attention as a fundamental concept for advancing deep neural networks. Currently, the state-of-the-art in the field uses neural attention models. As shown in figure~\\ref{fig:hist_works}, the number of published works grows each year significantly in the leading repositories. In neural networks, attention mechanisms dynamically manage the flow of information, the features, and the resources available, improving learning. These mechanisms filter out irrelevant stimuli for the task and help the network to deal with long-time dependencies simply. Many neural attentional models are simple, scalable, flexible, and with promising results in several application domains~~~. Given the current research extent, interesting questions related to neural attention models arise in the literature: \\textbf{how these mechanisms help improve neural networks' performance}, \\textbf{which classes of problems benefit from this approach}, and \\textbf{how these benefits arise}. \n\\begin{figure}[htb]\n    \\centering\n    \\includegraphics[width=0.55\\linewidth]{img/trabalhos_pubicados_ano.pdf}\n    \\caption{Works published by year between 01/01/2014 to 15/02/2021. The main sources collected are ArXiv, CVPR, ICCV, ICLR, IJCNN, NIPS, and AAAI. The other category refers mainly to the following publishing vehicles: ICML, ACL, ACM, EMNLP, ICRA, ICPR, ACCV, CORR, ECCV, ICASSP, ICLR, IEEE ACCESS, Neurocomputing, and several other magazines.}\n    \\label{fig:hist_works}\n\\end{figure}\nTo the best of our knowledge, most surveys available in the literature do not address all of these questions or are more specific to some domain.\nWang et al.~ propose a review on recurrent networks and applications in computer vision, Hu~, and Galassi et al.~ offer surveys on attention in natural language processing (NLP). Lee et al.~ present a review on attention in graph neural networks, and Chaudhari et al.~ presented a more general, yet short, review.", "cites": [180, 2635, 9093, 1515, 2633, 2634, 2636, 728], "cite_extract_rate": 1.0, "origin_cites_number": 8, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 2.0, "abstraction": 2.0}, "insight_level": "medium", "analysis": "The section provides a basic overview of existing attention-related surveys and lists several works, but it does not deeply synthesize or integrate their findings into a unified narrative. It briefly mentions the domains and contributions of the cited papers but lacks critical evaluation or comparison of their approaches. The abstraction is minimal, focusing on surface-level observations rather than broader conceptual trends."}}
{"id": "e9f7f711-5e86-4799-ab32-58a1b7898f77", "title": "Overview", "level": "section", "subsections": ["744f8d2e-a25d-43d2-8d16-940b34a51075", "e3210eac-3771-4fd4-8636-d1ae7effe940", "f3bfdaf7-a4b9-4b08-81ed-a6b0d8c695c2", "06967c24-144e-447f-869e-42b2365f50c1", "5f570775-8b1f-4791-80cb-cd8884392f1d"], "parent_id": "25aabc07-c583-4f10-8638-f4d1afc51cb2", "prefix_titles": [["title", "Attention, please! A survey of Neural Attention Models in Deep Learning"], ["section", "Overview"]], "content": "\\label{sub:attention_overview}\nHistorically, research in computational attention systems has existed since the 1980s. Only in mid-2014, the Neural Attentional Networks (NANs) emerged in Natural Language Processing (NLP), where attention provided significant advances, bringing promising results through scalable and straightforward networks. Attention allowed us to move towards the complex tasks of conversational machine comprehension, sentiment analysis, machine translation, question-answering, and transfer learning, previously challenging. Subsequently, NANs appeared in other fields equally important for artificial intelligence, such as computer vision, reinforcement learning, and robotics. There are currently numerous attentional architectures, but few of them have a significantly higher impact, as shown in Figure~\\ref{fig:main_architectures_field}. In this image, we depict the most relevant group of works organized according to citation levels and innovations where RNNSearch~, Transformer~, Memory Networks~, ``show, attend and tell''~, and RAM~ stand out as key developments.\n\\begin{figure*}[h]\n    \\centering\n    \\includegraphics[width=0.95\\linewidth]{img/principais_arquiteturas_ok_2.pdf}\n    \\caption{Main Neural Attention Networks (NAN). Each circle corresponds to an architecture. The radius of the circles is defined based on the impact of the NAN on the field. The impact was defined by the citation number and the architecture innovation level. The greater the radius of the circle, the more significant the impact of architecture, and vice versa. Architectures labels are color-coded as follows: orange - natural language processing, red - computer vision, dark brown - computer vision and natural language processing, dark yellow - reinforcement learning and computer vision, light yellow - reinforcement learning and natural language processing, blue - imitation learning and robotics, and purple - others.}\n    \\label{fig:main_architectures_field}\n\\end{figure*}\nThe \\textit{bottleneck problem} in the classic encoder-decoder framework worked as the initial motivation for attention research in Deep Learning. In this framework, the encoder encodes a source sentence into a fixed-length vector from which a decoder generates the translation. The main issue is that a neural network needs to compress all the necessary information from a source sentence into a fixed-length vector. Cho et al. ~ showed that the performance of the classic encoder-decoder deteriorates rapidly as the size of the input sentence increases. To minimize this bottleneck, Bahdanau et al.~ proposed \\textbf{RNNSearch}, an extension to the encoder-decoder model that learns to align and translate together. RNNSearch generates a translated word at each time-step, looking for a set of positions in the source sentence with the most relevant words. The model predicts a target word based on the context vectors associated with those source positions and all previously generated target words. The main advantage is that RNNSearch does not encode an entire input sentence into a single fixed-length vector. Instead, it encodes the input sentence into a sequence of vectors, choosing a subset of these vectors adaptively while generating the translation. The attention mechanism allows extra information to be propagated through the network, eliminating the fixed-size context vector's information bottleneck. This approach demonstrated that the attentive model outperforms classic encoder-decoder frameworks for long sentences for the first time.\nRNNSearch was instrumental in introducing the first attention mechanism, \\textbf{soft attention} (Section~\\ref{sub:attention_mechanisms}). This mechanism has the main characteristic of smoothly selecting the network's most relevant elements. Based on RNNSearch, there have been numerous attempts to augment neural networks with new properties. Two research directions stand out as particularly interesting - \\textbf{attentional interfaces} and \\textbf{end-to-end attention}. Attentional interfaces treat attention as a module or set of elective modules, easily plugged into classic Deep Learning neural networks, just like RNNSearch. So far, this is the most explored research direction in the area, mainly for simplicity, general use, and the good results of generalization that the attentional interfaces bring. End-to-end attention is a younger research direction, where the attention block covers the entire neural network. High and low-level attentional layers act recursively or cascaded at all network abstraction levels to produce the desired output in these models. End-to-end attention models introduce a new class of neural networks in Deep Learning. End-to-end attention research makes sense since no isolated attention center exists in the human brain, and its mechanisms are used in different cognitive processes.", "cites": [180, 168, 9093, 303, 2637, 746], "cite_extract_rate": 1.0, "origin_cites_number": 6, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.0, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section synthesizes key developments in neural attention models across multiple domains, integrating insights from foundational papers like Bahdanau et al. and Cho et al. to explain the motivation and evolution of attention. It abstracts these ideas into broader concepts such as soft attention, attentional interfaces, and end-to-end attention, and offers some critical analysis by highlighting the limitations of the encoder-decoder framework and the innovation of attention in addressing them."}}
{"id": "744f8d2e-a25d-43d2-8d16-940b34a51075", "title": "Attentional interfaces", "level": "subsection", "subsections": [], "parent_id": "e9f7f711-5e86-4799-ab32-58a1b7898f77", "prefix_titles": [["title", "Attention, please! A survey of Neural Attention Models in Deep Learning"], ["section", "Overview"], ["subsection", "Attentional interfaces"]], "content": "\\label{sub:attentional_interfaces}\nRNNSearch is the basis for research on attentional interfaces. The attentional module of this architecture is widely used in several other applications. In voice recognition~, allowing one RNN to process the audio while another examines it focusing on the relevant parts as it generates a description. In-text analysis~, it allows a model to look at the words as it generates an analysis tree. In conversational modeling~, it allows the model to focus on the last parts of the conversation as it generates its response. There are also important extensions to deal with other information bottlenecks in addition to the classic encoder-decoder problem. \\textbf{BiDAF}~ proposes a multi-stage hierarchical process to question-answering. It uses the bidirectional attention flow to build a multi-stage hierarchical network with context paragraph representations at different granularity levels. The attention layer does not summarize the context paragraph in a fixed-length vector. Instead, attention is calculated for each step, and the vector assisted at each step, along with representations of previous layers, can flow to the subsequent modeling layer. This reduces the loss of information caused by the early summary. At each stage of time, attention is only a function of the query and the paragraph of the context in the current stage and does not depend directly on the previous stage's attention. The hypothesis is that this simplification leads to a work division between the attention layer and the modeling layer, forcing the attention layer to focus on learning attention between the query and the context.\nYang et al.~ proposed the \\textbf{Hierarchical Attention Network (HAN)} to capture two essential insights about document structure. Documents have a hierarchical structure: words form sentences, sentences form a document. Humans, likewise, construct a document representation by first building representations of sentences and then aggregating them into a document representation. Different words and sentences in a document are differentially informative. Moreover, the importance of words and sentences is highly context-dependent, i.e., the same word or sentence may have different importance in different contexts. To include sensitivity to this fact, HAN consists of two levels of attention mechanisms - one at the word level and one at the sentence level - that let the model pay more or less attention to individual words and sentences when constructing the document's representation. Xiong et al.~ created a coattentive encoder that captures the interactions between the question and the document with a dynamic pointing decoder that alternates between estimating the start and end of the answer span. To learn approximate solutions to computationally intractable problems, \\textbf{Ptr-Net}~ modifies the RNNSearch's attentional mechanism to represent variable-length dictionaries. It uses the attention mechanism as a pointer.\nSee et. al.~ used a hybrid  between classic sequence-to-sequence attentional models and a Ptr-Net~ to abstractive text summarization. The hybrid pointer-generator~ copies words from the source text via pointing, which aids accurate reproduction of information while retaining the ability to produce novel words through the generator. Finally, it uses a mechanism to keep track of what has been summarized, which discourages repetition. FusionNet~ presents a novel concept of \"history-of-word\" to characterize attention information from the lowest word-embedding level up to the highest semantic-level representation. This concept considers that data input is gradually transformed into a more abstract representation, forming each word's history in human mental flow. FusionNet employs a fully-aware multi-level attention mechanism and an attention score-function that takes advantage of the history-of-word. Rocktäschel et al.~ introduce two-away attention for  recognizing textual entailment (RTE). The mechanism allows the model to attend over past output vectors, solving the LSTM's cell state bottleneck. The LSTM with attention does not need to capture the premise's whole semantics in the LSTM cell state. Instead, attention generates output vectors while reading the premise and accumulating a representation in the cell state that informs the second LSTM which of the premises' output vectors to attend to determine the RTE class. Luong, et al.~, proposed global and local attention in machine translation. Global attention is similar to soft attention, while local is an improvement to make hard attention differentiable - the model first provides for a single position aligned to the current target word, and a window centered around the position is used to calculate a vector of context. \nAttentional interfaces have also emerged in architectures for computer vision tasks. Initially, they are based on human saccadic movements and robustness to change. The human visual attention mechanism can explore local differences in an image while highlighting the relevant parts. One person focuses attention on parts of the image simultaneously, glimpsing to quickly scan the entire image to find the main areas during the recognition process. In this process, the different regions' internal relationship guides the eyes' movement to find the next area to focus. Ignoring the irrelevant parts makes it easier to learn in the presence of disorder. Another advantage of glimpse and visual attention is its robustness. Our eyes can see an object in a real-world scene but ignore irrelevant parts. Convolutional neural networks (CNNs) are extremely different. CNNs are rigid, and the number of parameters grows linearly with the size of the image. Also, for the network to capture long-distance dependencies between pixels, the architecture needs to have many layers, compromising the model's convergence. Besides, the network treats all pixels in the same way. This process does not resemble the human visual system that contains visual attention mechanisms and a glimpse structure that provides unmatched performance in object recognition.\nRAM~ and STN are pioneering architectures with attentional interfaces based on human visual attention. \\textbf{RAM}~ can extract information from an image or video by adaptively selecting a sequence of regions, glimpses, only processing the selected areas at high resolution. The model is a Recurrent Neural Network that processes different parts of the images (or video frames) at each instant of time \\textit{t}, building a dynamic internal representation of the scene via Reinforcement Learning training. The main model advantages are the reduced number of parameters and the architecture's independence to the input image size, which does not occur in convolutional neural networks. This approach is generic. It can use static images, videos, or a perceptual module of an agent that interacts with the environment. \\textbf{STN (Spatial Transformer Network)}~ is a module robust to spatial transformation changes. In STN, if the input is transformed, the model must generate the correct classification label, even if it is distorted in unusual ways. STN works as an attentional module attachable -- with few modifications -- to any neural network to actively spatially transform feature maps. STN learns transformation during the training process. Unlike pooling layers, where receptive fields are fixed and local, a Spatial Transformer is a dynamic mechanism that can spatially transform an image, or feature map, producing the appropriate transformation for each input sample. The transformation is performed across the map and may include changes in scale, cut, rotations, and non-rigid body deformations. This approach allows the network to select the most relevant image regions (attention) and transform them into a desired canonical position by simplifying recognition in the following layers.\nFollowing the RAM approach, the \\textbf{Deep Recurrent Attentive Writer (DRAW)}~ represents a change to a more natural way of constructing the image in which parts of a scene are created independently of the others. This process is how human beings draw a scene by recreating a visual scene sequentially, refining all parts of the drawing for several iterations, and reevaluating their work after each modification. Although natural to humans, most approaches to automatic image generation aim to generate complete scenes at once. This means that all pixels are conditioned in a single latent distribution, making it challenging to scale large image approaches. DRAW belongs to the family of variational autoencoders. It has an encoder that compresses the images presented during training and a decoder that reconstructs the images. Unlike other generative models, DRAW iteratively constructs the scenes by accumulating modifications emitted by the decoder, each observed by the encoder. DRAW uses RAM attention mechanisms to attend to parts of the scene while ignoring others selectively. This mechanism's main challenge is to learn where to look, which is usually addressed by reinforcement learning techniques. However, at DRAW, the attention mechanism is differentiable, making it possible to use backpropagation.", "cites": [2643, 167, 1877, 2640, 2639, 1141, 2641, 2634, 7186, 2638, 746, 2642], "cite_extract_rate": 0.8571428571428571, "origin_cites_number": 14, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.0, "abstraction": 3.5}, "insight_level": "medium", "analysis": "The section demonstrates strong synthesis by connecting multiple attention-based models (e.g., BiDAF, HAN, Ptr-Net, FusionNet, STN, RAM) and their applications in NLP and computer vision, forming a cohesive narrative on attentional interfaces. It provides some critical analysis by discussing limitations of prior approaches (e.g., LSTM cell state bottlenecks, CNN rigidity) and how attentional mechanisms improve them. Abstraction is moderate, as it identifies patterns like hierarchical attention and dynamic interactions but does not elevate the discussion to a fully meta-level theoretical framework."}}
{"id": "e3210eac-3771-4fd4-8636-d1ae7effe940", "title": "Multimodality", "level": "subsection", "subsections": [], "parent_id": "e9f7f711-5e86-4799-ab32-58a1b7898f77", "prefix_titles": [["title", "Attention, please! A survey of Neural Attention Models in Deep Learning"], ["section", "Overview"], ["subsection", "Multimodality"]], "content": "\\label{sub:multimodality}\nThe first attention interfaces' use in DL were limited to  NLP and computer vision domains to solve isolated tasks. Currently, attentional interfaces are studied in multimodal learning. Sensory multimodality in neural networks is a historical problem widely discussed by the scientific community~~. Multimodal data improves the robustness of perception through complementarity and redundancy. The human brain continually deals with multimodal data and integrates it into a coherent representation of the world. However, employing different sensors present a series of challenges computationally, such as incomplete or spurious data, different properties (i.e. dimensionality or range of values), and the need for data alignment association. The integration of multiple sensors depends on a reasoning structure over the data to build a common representation, which does not exist in classical neural networks. Attentional interfaces adapted for multimodal perception are an efficient alternative for reasoning about misaligned data from different sensory sources.\nThe first widespread use of attention for multimodality occurs with the attentional interface between a convolutional neural network and an LSTM in image captioning~. In this model, a CNN processes the image, extracting high-level features, whereas the LSTM consumes the features to produce descriptive words, one by one. The attention mechanism guides the LSTM to relevant image information for each word's generation, equivalent to the human visual attention mechanism. The visualization of attention weights in multimodal tasks improved the understanding of how architecture works. This approach derived from countless other works with attentional interfaces that deal with video-text data~~~, image-text data~~, monocular/RGB-D images~~~, RADAR~, remote sensing data~~~~, audio-video~~, and diverse sensors~~~, as shown in Figure~\\ref{fig:modalities}.   \nZhang et al.~ used an adaptive attention mechanism to learn to emphasize different visual and textual sources for dialogue systems for fashion retail. An adaptive attention scheme\nautomatically decided the evidence source for tracking dialogue states\nbased on visual and textual context. \\textbf{Dual Attention Networks}~ presented attention mechanisms to capture the fine-grained interplay between images and textual information. The mechanism allows visual and textual attention to guide each other during collaborative inference. \\textbf{HATT}~ presented a new attention-based hierarchical fusion to explore the complementary features of multimodal features progressively, fusing temporal, motion, audio, and semantic label features for video representation. The model consists of three attention layers. First, the low-level attention layer deals with temporal, motion, and audio features inside each modality and across modalities. Second, high-level attention selectively focuses on semantic label features. Finally, the sequential attention layer incorporates hidden information generated by encoded low-level attention and high-level attention. Hori et. al.~ extended simple attention multimodal fusion. Unlike the simple multimodal fusion method, the feature-level attention weights can change according to the decoder state and the context vectors, enabling the decoder network to pay attention to a different set of features or modalities when predicting each subsequent word in the description. Memory Fusion Network~ presented the Delta-memory Attention module for multi-view sequential learning. First, an LSTM system, one for each of the modalities, encodes the modality-specific dynamics and interactions. Delta-memory attention discovers both cross-modality and temporal interactions in different memory dimensions of LSTMs. Finally, Multi-view Gated Memory (unifying memory) stores the cross-modality interactions over time.\nHuang et al.~ investigated the problem of matching image-text by exploiting the bi-directional attention with fine-granularity correlations between visual regions and textual words. \\textbf{Bi-directional attention} connects the word to regions and objects to words for learning mage-text matching. Li et. al.~ introduced \\textbf{Long Short-Term Memory with Pointing} (LSTM-P) inspired by humans pointing behavior~, and Pointer Networks~. The pointing mechanism encapsulates dynamic contextual information (current input word and LSTM cell output) to deal with the image captioning scenario's novel objects. Liu et. al.~ proposed a cross-modal attention-guided erasing approach for referring expressions. Previous attention models focus on only the most dominant features of both modalities and neglect textual-visual correspondences between images and referring expressions. To tackle this issue, cross-modal attention discards the most dominant information from either textual or visual domains to generate difficult training samples and drive the model to discover complementary textual-visual correspondences. Abolghasemi et al.~ demonstrated an approach for augmenting a deep visuomotor policy trained through demonstrations with \\textbf{Task Focused Visual Attention} (TFA). Attention receives as input a manipulation task specified in natural language text, an image with the environment, and returns as output the area with an object that the robot needs to manipulate. TFA allows the policy to be significantly more robust from the baseline policy, i.e., no visual attention. Pu et al.~ adaptively select features from the multiple CNN layers for video captioning. Previous models often use the output from a specific layer of a CNN as video features. However, this attention model adaptively and sequentially focuses on different layers of CNN features.\n\\begin{figure}[htb]\n    \\centering\n    \\includegraphics[clip, trim=0.3cm 6cm 0.5cm 6cm, width=1.00\\textwidth]{img/modalidades_ultimo_editado.pdf}\n    \\caption{A diagram showing sensory modalities of neural attention models. Radial segments correspond to attention architectures, and each track corresponds to a modality. Modalities are: (A) audio, (B) biomedical signals, (I) image, (O) other sensors, (L) LiDAR, (R) remote sensing data, (T) text, and (V) video. The following coloring convention is used for the individual segments: white (the modality is not implemented), light yellow (CNN), light orange (RNN), orange (Self-attentive networks), red (Memory networks), dark red (framework), and brown (GNN). This diagram emphasizes multimodal architectures so that only the most representative single modality (i.e., text or image) architectures are shown. Most multimodal architectures use the image/text or video/text modalities.}\n    \\label{fig:modalities}\n\\end{figure}", "cites": [7194, 2643, 2650, 167, 2649, 2644, 2645, 2648, 862, 2637, 2646, 7599, 2647], "cite_extract_rate": 0.5, "origin_cites_number": 26, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.0, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section synthesizes multiple multimodal attention models effectively, connecting their functionalities to a broader narrative about how attention interfaces facilitate cross-modality reasoning. It provides critical evaluations, such as pointing out limitations of previous models in handling dominant features or misalignment. The section abstracts from specific models to highlight general principles in multimodal attention, such as the importance of dynamic feature selection and interplay between modalities."}}
{"id": "f3bfdaf7-a4b9-4b08-81ed-a6b0d8c695c2", "title": "Attention-augmented memory", "level": "subsection", "subsections": [], "parent_id": "e9f7f711-5e86-4799-ab32-58a1b7898f77", "prefix_titles": [["title", "Attention, please! A survey of Neural Attention Models in Deep Learning"], ["section", "Overview"], ["subsection", "Attention-augmented memory"]], "content": "\\label{sub:attention_memory}\nAttentional interfaces also allow the neural network iteration with other cognitive elements (i.e., memories, working memory). Memory control and logic flow are essential for learning. However, they are elements that do not exist in classical architectures. The memory of classic RNNs, encoded by hidden states and weights, is usually minimal and is not sufficient to remember facts from the past accurately. Most Deep Learning models do not have a simple way to read and write data to an external memory component. The \\textbf{Neural Turing Machine} (NTM)~ and Memory Networks (MemNN)~ - a new class of neural networks - introduced the possibility for a neural network dealing with addressable memory. NTM is a differentiable approach that can be trained with gradient descent algorithms, producing a practical learning program mechanism. NTM memory is a short-term storage space for information with its rules-based manipulation. Computationally, these rules are simple programs, where data are those programs' arguments. Therefore, an NTM resembles a working memory designed to solve tasks that require rules, where variables are quickly linked to memory slots. NTMs use an attentive process to read and write elements to memory selectively. This attentional mechanism makes the network learn to use working memory instead of implementing a fixed set of symbolic data rules.\n\\textbf{Memory Networks}~ are a relatively new framework of models designed to alleviate the problem of learning long-term dependencies in sequential data by providing an explicit memory representation for each token in the sequence. Instead of forgetting the past, Memory Networks explicitly consider the input history, with a dedicated vector representation for each history element, effectively removing the chance to forget. The limit on memory size becomes a hyper-parameter to tune, rather than an intrinsic limitation of the model itself. This model was used in question-answering tasks where the long-term memory effectively acts as a (dynamic) knowledge base, and the output is a textual response. Large-scale question-answer tests were performed, and the reasoning power of memory networks that answer questions that require an in-depth analysis of verb intent was demonstrated. Mainly due to the success of MemNN, networks with external memory are a growing research direction in DL, with several branches under development as shown in figure~\\ref{fig:memory_networks_family}.\n\\begin{figure}[htb]\n  \\centering\n  \\includegraphics[width=0.80\\textwidth]{img/memory_networks_family.pdf}\n  \\caption{Memory-based neural networks (MemNN). Architectures labels are color-coded as follows: orange - natural language processing, red - computer vision, purple - others. The end-to-End Memory networks is the first end-to-end differentiable version of MemNN. GMN~ and MemGNN~ are the first graph networks with memory. DMN~, MemGNN~, Episodic graph memory networks~, Episodic CAMN~, are the first instances of the episodic memory framework.}\n  \\label{fig:memory_networks_family}\n\\end{figure}\n\\textbf{End-to-end Memory Networks}~ is the first version of MemNN applicable to realistic, trainable end-to-end scenarios, which requires low supervision during training. Aug Oh. et al.~ extends Memory Networks to suit the task of semi-supervised segmentation of video objects. Frames with object masks are placed in memory, and a frame to be segmented acts as a query. The memory is updated with the new masks provided and faces challenges such as changes, occlusions, and accumulations of errors without online learning. The algorithm acts as an attentional space-time system calculating when and where to meet each query pixel to decide whether the pixel belongs to a foreground object or not. Kumar et al.~ propose the first network with episodic memory - a type of memory extremely relevant to humans - to iterate over representations emitted by the input module updating its internal state through an attentional interface. In~, an episodic memory with a key-value retrieval mechanism chooses which parts of the input to focus on thorough attention. The module then produces a summary representation of the memory, taking into account the query and the stored memory. Finally, the latest research has invested in Graph Memory Networks (GMN), which are memories in GNNs~, to better handle unstructured data using key-value structured memories~~~~.", "cites": [2652, 2651, 9093, 2637, 9109, 7600, 553, 2653, 1966, 2634], "cite_extract_rate": 0.8333333333333334, "origin_cites_number": 12, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.0, "abstraction": 3.5}, "insight_level": "medium", "analysis": "The section effectively synthesizes multiple papers by connecting the concept of attention-augmented memory across different models (e.g., NTM, MemNN, GMN) and applications (e.g., NLP, computer vision). It provides a coherent narrative of the evolution and use of memory in neural networks. While it includes some critical analysis (e.g., limitations of memory size and error accumulation), the critique is not deeply developed. The abstraction level is moderate, with the section identifying patterns in how attention enables memory access but not fully articulating overarching principles."}}
{"id": "06967c24-144e-447f-869e-42b2365f50c1", "title": "End-to-end attention models", "level": "subsection", "subsections": [], "parent_id": "e9f7f711-5e86-4799-ab32-58a1b7898f77", "prefix_titles": [["title", "Attention, please! A survey of Neural Attention Models in Deep Learning"], ["section", "Overview"], ["subsection", "End-to-end attention models"]], "content": "\\label{sub:end_to_end_attention_models}\nIn mid-2017, research aiming at end-to-end attention models appeared in the area. The Neural Transformer (NT)~ and Graph Attention Networks~ - purely attentional architectures - demonstrated to the scientific community that attention is a key element for the future development in Deep Learning. The Transformer's goal is to use self-attention (Section~\\ref{sub:attention_mechanisms}) to minimize traditional recurrent neural networks' difficulties. The \\textbf{Neural Transformer} is the first neural architecture that uses only attentional modules and fully-connected neural networks to process sequential data successfully. It dispenses recurrences and convolutions, capturing the relationship between the sequence elements regardless of their distance. Attention allows the Transformer to be simple, parallelizable, and low training cost~. \\textbf{Graph Attention Networks} (GATs) are an end-to-end attention version of GNNs~. They have stacks of attentional layers that help the model focus on the unstructured data's most relevant parts to make decisions. The main purpose of attention is to avoid noisy parts of the graph by improving the signal-to-noise ratio (SNR) while also reducing the structure's complexity. Furthermore, they provide a more interpretable structure for solving the problem. For example, when analyzing the Attention of a model under different components in a graph, it is possible to identify the main factors contributing to achieving a particular response condition.\n\\begin{figure}[H]\n  \\centering\n  \\includegraphics[width=\\textwidth]{img/Transformer_family.pdf}\n  \\caption{Transformer-based neural networks. Architectures labels are color-coded as follows: orange - natural language processing, red - computer vision, purple - others.}\n  \\label{fig:transformer_family}\n\\end{figure}\nThere is a growing interest in NT and GATs, and some extensions have been proposed~~~~, with numerous Transformer-based architectures as shown figure~\\ref{fig:transformer_family}. These architectures and all that use self-attention belong to a new category of neural networks, called Self-Attentive Neural Networks. They aim to explore self-attention in various tasks and improve the following drawbacks: 1) a Large number of parameters and training iterations to converge; 2) High memory cost per layer and quadratic growth of memory according to sequence length; 3) Auto-regressive model; 4) Low parallelization in the decoder layers. Specifically, Weighted Transformer~ proposes modifications in the attention layers achieving a 40 \\% faster convergence. The multi-head attention modules are replaced by modules called branched attention that the model learns to match during the training process. The Star-transformer~ proposes a lightweight alternative to reduce the model's complexity with a star-shaped topology. To reduce the cost of memory, Music Transformer~, and Sparse Transformer~ introduces relative self-attention and factored self-attention, respectively. Lee et al.~ also features an attention mechanism that reduces self-attention from quadratic to linear, allowing scaling for high inputs and data sets.\nSome approaches adapt the Transformer to new applications and areas. In natural language processing, several new architectures have emerged, mainly in multimodal learning. Doubly Attentive Transformer~ proposes a multimodal machine-translation method, incorporating visual information. It modifies the attentional decoder, allowing textual features from a pre-trained CNN encoder and visual features. The Multi-source Transformer~ explores four different strategies for combining input into the multi-head attention decoder layer for multimodal translation. Style Transformer~, Hierarchical Transformer~, HighWay Recurrent Transformer~\\cite {highway_transformer}, Lattice-Based Transformer~\\cite {lattice_transformer}, Transformer TTS Network~\\cite {li2019neural}, Phrase-Based Attention~ are some important architectures in style transfer, document summarization and machine translation. Transfer Learning in NLP is one of Transformer's major contribution areas. BERT~, GPT-2~, and GPT-3~ based NT architecture to solve the problem of Transfer Learning in NLP because current techniques restrict the power of pre-trained representations. In computer vision, the generation of images is one of the Transformer's great news. Image Transformer~, SAGAN~, and Image GPT~ uses self-attention mechanism to attend the local neighborhoods. The size of the images that the model can process in practice significantly increases, despite maintaining significantly larger receptive fields per layer than the typical convolutional neural networks. Recently, at the beginning of 2021, OpenAi introduced the scientific community to DALL·E~, the Newest language model based on Transformer and GPT-3, capable of generating images from texts extending the knowledge of GPT-3 for viewing with only 12 billions of parameters.", "cites": [679, 2654, 1515, 2657, 2643, 248, 553, 180, 2655, 2656, 2658, 7194, 252, 7371, 793], "cite_extract_rate": 0.6521739130434783, "origin_cites_number": 23, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.2, "critical": 3.5, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section synthesizes a wide range of papers to provide a coherent narrative on end-to-end attention models, particularly focusing on the Transformer and GATs. It abstracts key challenges and innovations, such as memory cost and scalability improvements, and links these to broader applications in NLP and computer vision. While it offers some critical insights into limitations and proposed solutions, the critique is not as deep or nuanced as it could be."}}
{"id": "5f570775-8b1f-4791-80cb-cd8884392f1d", "title": "Attention today", "level": "subsection", "subsections": [], "parent_id": "e9f7f711-5e86-4799-ab32-58a1b7898f77", "prefix_titles": [["title", "Attention, please! A survey of Neural Attention Models in Deep Learning"], ["section", "Overview"], ["subsection", "Attention today"]], "content": "\\label{sub:attention_today}\nCurrently, hybrid models that employ the main key developments in attention's use in Deep Learning (Figure~\\ref{fig:timeline}) have aroused the scientific community's interest. Mainly, hybrid models based on Transformer, GATs, and Memory Networks have emerged for multimodal learning and several other application domains. Hyperbolic Attention Networks (HAN)~, Hyperbolic Graph Attention Networks (GHN)~, Temporal Graph Networks (TGN)~ and Memory-based Graph Networks (MGN)~ are some of the most promising developments. Hyperbolic networks are a new class of architecture that combine the benefits of self-attention, memory, graphs, and hyperbolic geometry in activating neural networks to reason with high capacity over embeddings produced by deep neural networks. Since 2019 these networks have stood out as a new research branch because they represent state-of-the-art generalization on neural machine\ntranslation, learning on graphs, and visual question answering tasks while keeping the neural representations compact. Since 2019, GATs have also received much attention due to their ability to learn complex relationships or interactions in a wide spectrum of problems ranging from biology, particle physics, social networks to recommendation systems. To improve the representation of nodes and expand the capacity of GATs to deal with data of a dynamic nature (i.e. evolving features or connectivity over time), architectures that combine memory modules and the temporal dimension, like MGNs and TGNs, were proposed.\n\\begin{figure*}[ht]\n \\centering\n \\includegraphics[width=\\textwidth]{img/main_architecture.pdf}\n \\caption{Key developments in Attention in DL Timeline. RNNSearch presented the first attention mechanism. Neural Turing machine and Memory networks introduced memory and dynamic flow control. RAM and DRAW learned to combine multi-glimpse, visual attention, and sequential processing. Spatial Transformer introduced a module to increase the robustness of CNNs to variations in spatial transformations. Show, attend and tell created attention for multimodality. The Pointer network used attention as a pointer. BiDAF, HAN, and DCN presented attentional techniques to align data with different hierarchical levels. ACT introduced the computation time topic. Transformer~ was the first self-attentive neural network with an end-to-end attention approach. GATs introduced attention in GNNs. BERT~, GPT-2~, GPT-3~, and DALL·E~ are the state-of-the-art in language models and text-to-image generation. Finally, BRIMs~ learned to combine bottom-up and top-down signals.}\n \\label{fig:timeline}\n\\end{figure*}\nAt the end of 2020, two research branches still little explored in the literature were strengthened: 1) explicit combination of bottom-up and top-down stimuli in bidirectional recurrent neural networks and 2) adaptive computation time. Classic recurrent neural networks perform recurring iteration within a particular level of representation instead of using a top-down iteration, in which higher levels act at lower levels. However, Mittal et al.~ revisited the bidirectional recurrent layers with attentional mechanisms to explicitly route the flow of bottom-up and top-down information, promoting selection iteration between the two levels of stimuli. The approach separates the hidden state into several modules so that upward iterations between bottom-up and top-down signals can be appropriately focused. The layer structure has concurrent modules so that each hierarchical layer can send information both in the bottom-up and top-down directions.\nThe adaptive computation time is an interesting little-explored topic in the literature that began to expand only in 2020 despite initial studies emerging in 2017. ACT applies to different neural networks (e.g. RNNs, CNNs, LSTMs, Transformers). The general idea is that complex data might require more computation to produce a final result, while some unimportant or straightforward data might require less. The attention mechanism dynamically decides how long to process network training data. The seminal approach by Graves et al.~ made minor modifications to an RNN, allowing the network to perform a variable number of state transitions and a variable number of outputs at each stage of the input. The resulting output is a weighted sum of the intermediate outputs, i.e., soft attention. A halting unit decides when the network should stop or continue. To limit computation time, attention adds a time penalty to the cost function by preventing the network from processing data for unnecessary amounts of time. This approach has recently been updated and expanded to other architectures. Spatially Adaptive Computation Time (SACT)~ adapts ACT to adjust the per-position amount of computation to each spatial position of the block in convolutional layers, learning to focus computing on the regions of interest and to stop when the features maps are \"good enough\". Finally, Differentiable Adaptive Computation Time (DACT)~ introduced the first differentiable end-to-end approach to computation time on recurring networks.", "cites": [180, 679, 2661, 7600, 2659, 7107, 2634, 676, 2660], "cite_extract_rate": 0.6923076923076923, "origin_cites_number": 13, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.2, "critical": 3.3, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section effectively synthesizes information from multiple cited papers, connecting key developments in attention mechanisms (e.g., GATs, HANs, TGNs) and their integration with memory, graphs, and hyperbolic geometry. It also identifies underexplored research directions such as bidirectional attention and adaptive computation time, demonstrating some critical insight. The section abstracts broader trends in attention research, such as the move toward dynamic and hierarchical modeling, though deeper evaluation of specific limitations or trade-offs is somewhat limited."}}
{"id": "d2f635e2-e10f-4b16-805f-07a5b18afa1b", "title": "End-To-End Attention models", "level": "subsection", "subsections": [], "parent_id": "75e63f10-91ba-40b8-88f1-78f077a10310", "prefix_titles": [["title", "Attention, please! A survey of Neural Attention Models in Deep Learning"], ["section", "Trends and Opportunities"], ["subsection", "End-To-End Attention models"]], "content": "Over the past eight years, most of the papers published in the literature have involved attentional mechanisms. Models that are state of the art in DL use attention. Specifically, we note that end-to-end attention networks, such as Transformers~ and Graph Attention Networks~, have been expanding significantly and have been used successfully in tasks across multiple domains (Section~\\ref{sub:attention_overview}). In particular, Transformer has introduced a new form of computing in which the neural network's core is fully attentional. Transformer-based language models like BERT~, GPT2~, and GPT3~ are the most advanced language models in NLP. Image GPT~ has recently revolutionized the results of unsupervised learning in imaging. It is already a trend to propose Transfomer based models with sparse attentional mechanisms to reduce the Transformer's complexity from quadratic to linear and use attentional mechanisms to deal with multimodality in GATs. However, Transformer is still an autoregressive architecture in the decoder and does not use other cognitive mechanisms such as memory. As research in attention and DL is still at early stages, there is still plenty of space in the literature for new attentional mechanisms, and we believe that end-to-end attention architectures might be very influential in Deep Learning's future models.", "cites": [180, 679], "cite_extract_rate": 0.4, "origin_cites_number": 5, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.5, "critical": 3.0, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section synthesizes information from cited papers by connecting the development of end-to-end attention models like Transformers and GATs to broader trends in deep learning. It abstracts from specific models to discuss architectural implications and future directions, such as reducing computational complexity and handling multimodality. While it offers some critical observations (e.g., Transformer's autoregressive nature and lack of memory mechanisms), the critique is not deeply nuanced and could be expanded for higher depth."}}
{"id": "f7e3dbb5-fa11-4416-a83a-e65df3c40dc5", "title": "Learning Multimodality", "level": "subsection", "subsections": [], "parent_id": "75e63f10-91ba-40b8-88f1-78f077a10310", "prefix_titles": [["title", "Attention, please! A survey of Neural Attention Models in Deep Learning"], ["section", "Trends and Opportunities"], ["subsection", "Learning Multimodality"]], "content": "Attention has played a crucial role in the growth of learning from multimodal data. Multimodality is extremely important for learning complex tasks. Human beings use different sensory signals all the time to interpret situations and decide which action to take. For example, while recognizing emotions, humans use visual data, gestures, and voice tones to analyze feelings. Attention allowed models to learn the synergistic relationship between the different sensory data, even if they are not synchronized, allowing the development of increasingly complex applications mainly in emotion recognition,~, feelings~, and language-based image generation~. We note that multimodal applications are continually growing in recent years. However, most research efforts are still focused on relating a pair of sensory data, mostly visual and textual data. Architectures that can scale easily to handle more than one pair of sensors are not yet widely explored. Multimodal learning exploring voice data, RGBD images, images from monocular cameras, data from various sensors, such as accelerometers, gyroscopes, GPS, RADAR, biomedical sensors, are still scarce in the literature.", "cites": [2662], "cite_extract_rate": 0.3333333333333333, "origin_cites_number": 3, "insight_result": {"type": "analytical", "scores": {"synthesis": 2.5, "critical": 3.0, "abstraction": 3.0}, "insight_level": "medium", "analysis": "The section provides an analytical overview of attention in multimodal learning, identifying key trends and current limitations. It integrates the role of attention in bridging different sensory data, but does not deeply synthesize ideas from multiple papers. It critiques the scarcity of scalable multimodal architectures and highlights underexplored sensor types, showing some critical and abstract thinking but remains grounded in surface-level observations."}}
{"id": "bfa7d747-25dc-439a-af6c-2d9f08240eb3", "title": "Cognitive Elements", "level": "subsection", "subsections": [], "parent_id": "75e63f10-91ba-40b8-88f1-78f077a10310", "prefix_titles": [["title", "Attention, please! A survey of Neural Attention Models in Deep Learning"], ["section", "Trends and Opportunities"], ["subsection", "Cognitive Elements"]], "content": "Attention proposed a new way of thinking about the architecture of neural networks. For many years, the scientific community neglected using other cognitive elements in neural network architectures, such as memory and logic flow control. Attention has made possible including in neural networks other elements that are widely important in human cognition. Memory Networks~, and Neural Turing Machine~ are essential approaches in which attention makes updates and recoveries in external memory. However, research on this topic is at an early stage. The Neural Turing Machine has not yet been explored in several application domains, being used only in simple datasets for algorithmic tasks, with a slow and unstable convergence. We believe that there is plenty of room to explore the advantages of NTM in a wide range of problems and develop more stable and efficient models. Still, Memory Networks~ presents some developments (Section~\\ref{sub:attention_overview}), but few studies explore the use of attention to managing complex and hierarchical structures of memory. Attention to managing different memory types simultaneously (i.e., working memory, declarative, non-declarative, semantic, and long and short term) is still absent in the literature. To the best of our knowledge, the most significant advances have been made in Dynamic Memory Networks~ with the use of episodic memory. Another open challenge is how to use attention to plug external knowledge into memory and make training faster. Finally, undoubtedly one of the biggest challenges still lies in including other human cognition elements such as imagination, reasoning, creativity, and consciousness working in harmony with attentional structures.", "cites": [2653, 2634, 9093], "cite_extract_rate": 1.0, "origin_cites_number": 3, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 4.0, "abstraction": 3.5}, "insight_level": "high", "analysis": "The section synthesizes ideas from multiple cited papers to present a coherent narrative on the integration of cognitive elements in neural networks via attention. It critically evaluates current research, pointing out limitations in stability, applicability, and the lack of exploration for complex memory structures and other cognitive components. While it generalizes beyond individual systems, it could offer slightly more meta-level insights to elevate abstraction further."}}
{"id": "4f44a650-fd02-4169-b323-49b6535b7666", "title": "Computer Vision", "level": "subsection", "subsections": [], "parent_id": "75e63f10-91ba-40b8-88f1-78f077a10310", "prefix_titles": [["title", "Attention, please! A survey of Neural Attention Models in Deep Learning"], ["section", "Trends and Opportunities"], ["subsection", "Computer Vision"]], "content": "Recurrent Attention Models (RAM)~ introduced a new form of image computing using glimpses and hard attention. The architecture is simple, scalable, and flexible. Spatial Transformer (STN)~ presented a simple module for learning image transformations that can be easily plugged into different architectures. We note that RAM has a high potential for many tasks in which convolutional neural networks have difficulties, such as large, high-resolution images. However, currently, RAM has been explored with simple datasets. We believe that it is interesting to validate RAM in complex classification and regression tasks. Another proposal is to add new modules to the architecture, such as memory, multimodal glimpses, and scaling. It is interesting to explore STN in conjunction with RAM in classification tasks or use STN to predict transformations between sets of images. RAM aligned with STN can help address robostusnees to spatial transformation, learn the system dynamics in Visual Odometry tasks, enhance multiple-instance learning, addressing multiple view-points.", "cites": [2639, 746], "cite_extract_rate": 1.0, "origin_cites_number": 2, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.5, "critical": 3.0, "abstraction": 3.0}, "insight_level": "medium", "analysis": "The section integrates two key papers (RAM and STN) and discusses their potential applications and limitations, showing some synthesis of their ideas. It provides a critical perspective by noting that RAM has been tested on simple datasets and suggests validation on more complex tasks. However, the analysis remains somewhat focused on specific models rather than developing broader theoretical abstractions or a novel framework."}}
{"id": "ae5327bc-c6b3-4d92-bd10-1bd4a85c3c06", "title": "Capsule Neural Network", "level": "subsection", "subsections": [], "parent_id": "75e63f10-91ba-40b8-88f1-78f077a10310", "prefix_titles": [["title", "Attention, please! A survey of Neural Attention Models in Deep Learning"], ["section", "Trends and Opportunities"], ["subsection", "Capsule Neural Network"]], "content": "Capsule networks (CapsNets), a new class of deep neural network architectures proposed recently by Hinton et al.~, have shown excellent performance in many fields, particularly in image recognition and natural language processing. However, few studies in the literature implement attention in capsule networks. AR CapsNet~ implements a dynamic routing algorithm where routing between capsules is made through\nan attention module. The attention routing is a fast forward-pass while keeping spatial information. DA-CapsNet~ proposes a dual attention mechanism, the first layer is added after the convolution layer, and the second layer is added after the primary caps. SACN~ is the first model that incorporates the self-attention mechanism as an integral layer. Recently, Tsai. et al.~ introduced a new attentional routing mechanism in which a daughter capsule is routed to a parent capsule-based between the father's state and the daughter's vote. We particularly believe that attention is essential to improve the relational and hierarchical nature that CapsNets propose. The development of works aiming at the dynamic attentional routing of the capsules and incorporating attentional capsules of self-attention, soft and hard attention can bring significant results to current models.", "cites": [2663, 2664, 306], "cite_extract_rate": 0.6, "origin_cites_number": 5, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.5, "critical": 3.0, "abstraction": 3.0}, "insight_level": "medium", "analysis": "The section synthesizes information about attention in capsule networks by integrating several approaches from the cited papers, including AR CapsNet, DA-CapsNet, SACN, and Tsai et al. It begins with a general statement about the potential of attention in enhancing the relational and hierarchical nature of CapsNets, which shows some abstraction. However, the critical analysis is limited, as it does not deeply evaluate the strengths or weaknesses of each method or provide a nuanced critique. While it connects different attention mechanisms to the broader goal of routing in CapsNets, it does not offer a novel or meta-level framework."}}
{"id": "b0e48451-b816-4293-956a-91ab69f219b4", "title": "Neural-Symbolic Learning and Reasoning", "level": "subsection", "subsections": [], "parent_id": "75e63f10-91ba-40b8-88f1-78f077a10310", "prefix_titles": [["title", "Attention, please! A survey of Neural Attention Models in Deep Learning"], ["section", "Trends and Opportunities"], ["subsection", "Neural-Symbolic Learning and Reasoning"]], "content": "According to LeCun~ one of the great challenges of artificial intelligence is to combine the robustness of connectionist systems (i.e., neural networks) with symbolic representation to perform complex reasoning tasks. While symbolic representation is highly recursive and declarative, neural networks encode knowledge implicitly by adjusting weights. For many decades exploring the fusion between connectionist and symbolic systems has been overlooked by the scientific community. Only over the past decade, research with hybrid approaches using the two families of AI methodologies has grown again. Approaches such as statistical relational learning (SRL)~ and neural-symbolic learning~ were proposed. Recently, attention mechanisms have been integrated into some neural-symbolic models, the development of which is still at an early stage. Memory Networks~ (Section~\\ref{sub:attention_overview}) and Neural Turing Machine~ (Section~\\ref{sub:attention_overview}) were the first initiatives to include reasoning in deep connectionist models.\nIn the context of neural logic programming, attention has been exploited to reason about knowledge graphs or memory structures to combine the learning of parameters and structures of logical rules. Neural Logic Programming~ uses attention on a neural controller that learns to select a subset of operations and memory content to execute first-order rules. Logic Attention Networks~ facilitates inductive KG embedding and uses attention to aggregate information coming from graph neighbors with rules and attention weights. A pGAT~ uses attention to knowledge base completion, which involves the prediction of missing relations between entities in a knowledge graph. While producing remarkable advances, recent approaches to reasoning with deep networks do not adequately address the task of symbolic reasoning. Current efforts are only about using attention to ensure efficient memory management. We believe that attention can be better explored to understand which pieces of knowledge are relevant to formulate a hypothesis to provide a correct answer, which are rarely present in current neural systems of reasoning.", "cites": [166, 2665, 9093, 1086, 7601, 2634], "cite_extract_rate": 0.75, "origin_cites_number": 8, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.5, "abstraction": 3.5}, "insight_level": "medium", "analysis": "The section synthesizes multiple papers to present a coherent narrative on the integration of attention mechanisms in neural-symbolic models. It highlights the role of attention in memory and rule-based reasoning while pointing out the current limitations in symbolic reasoning. The analysis generalizes the trend of using attention for efficient memory management but falls short of offering a novel framework or deep critique of the field."}}
{"id": "f1e2932c-68ee-4008-a710-0876a562c5b1", "title": "Incremental Learning", "level": "subsection", "subsections": [], "parent_id": "75e63f10-91ba-40b8-88f1-78f077a10310", "prefix_titles": [["title", "Attention, please! A survey of Neural Attention Models in Deep Learning"], ["section", "Trends and Opportunities"], ["subsection", "Incremental Learning"]], "content": "Incremental learning is one of the challenges for the DL community in the coming years. Machine learning classifiers are trained to recognize a fixed set of classes. However, it is desirable to have the flexibility to learn additional classes with limited data without re-training in the complete training set. Attention can significantly contribute to advances in the area and has been little explored. Ren et al.~ were the first to introduce seminal work in the area. They use Attention Attractor Networks to regularize the learning of new classes. In each episode, a set of new weights is trained to recognize new classes until they converge. Attention Attractor Networks helps recognize new classes while remembering the classes beforehand without revising the original training set.", "cites": [2666], "cite_extract_rate": 1.0, "origin_cites_number": 1, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 1.5, "abstraction": 1.5}, "insight_level": "low", "analysis": "The section provides a basic description of incremental learning and introduces the Attention Attractor Networks method by Ren et al., but lacks synthesis of multiple sources or a broader framework. It does not compare different approaches or critically evaluate their strengths and limitations, nor does it abstract beyond the specific paper to identify general trends or principles in the field."}}
{"id": "f0681cc5-f1e8-4d84-911c-f7d8c0f09488", "title": "Credit Assignment Problem (CAP)", "level": "subsection", "subsections": [], "parent_id": "75e63f10-91ba-40b8-88f1-78f077a10310", "prefix_titles": [["title", "Attention, please! A survey of Neural Attention Models in Deep Learning"], ["section", "Trends and Opportunities"], ["subsection", "Credit Assignment Problem (CAP)"]], "content": "In Reinforcement Learning (RL), an action that leads to a higher final cumulative reward should have more value. Therefore, more \"credit\" should be assigned to it than an action that leads to a lower final reward. However, measuring the individual contribution of actions to future rewards is not simple and has been studied by the RL community for years. There are at least three variations of the CAP problem that have been explored. The temporal CAP refers to identifying which actions were useful or useless in obtaining the final feedback. The structural CAP seeks to find the set of sensory situations in which a given sequence of actions will produce the same result. Transfer CAP refers to learning how to generalize a sequence of actions in tasks. Few works in the literature explore attention to the CAP problem. We believe that attention will be fundamental to advance credit assignment research. Recently, Ferret et al.~ started the first research in the area by proposing a seminal work with attention to learn how to assign credit through a separate supervised problem and transfer credit assignment capabilities to new environments.", "cites": [2667], "cite_extract_rate": 1.0, "origin_cites_number": 1, "insight_result": {"type": "analytical", "scores": {"synthesis": 2.5, "critical": 2.5, "abstraction": 3.0}, "insight_level": "medium", "analysis": "The section introduces the Credit Assignment Problem in RL and briefly mentions three variations, but only cites one paper (Ferret et al.) to illustrate a specific approach. While it positions attention as a promising tool for advancing CAP research, it lacks deeper synthesis of multiple works or a comparative framework. The abstraction is moderate as it identifies the general importance of attention in CAP, but the analysis remains limited in scope and depth."}}
{"id": "8776b886-f174-4e1e-9608-b972d9c48dca", "title": "Attention and Interpretability", "level": "subsection", "subsections": [], "parent_id": "75e63f10-91ba-40b8-88f1-78f077a10310", "prefix_titles": [["title", "Attention, please! A survey of Neural Attention Models in Deep Learning"], ["section", "Trends and Opportunities"], ["subsection", "Attention and Interpretability"]], "content": "There are investigations to verify attention as an interpretability tool. Some recent studies suggest that attention can be considered reliable for this purpose. However, other researchers criticize the use of attention weights as an analytical tool. Jain and Wallace~ proved that attention is not consistent with other explainability metrics and that it is easy to create distributions similar to those of the trained model but to produce a different result. Their conclusion is that changing attention weights does not significantly affect the model's prediction, contrary to research by Rudin~ and Riedl~ (Section~\\ref{sec:applications_interpretability}). On the other hand, some studies have found how attention in neural models captures various notions of syntax and co-reference~~~. Amid such confusion, Vashishth et al.~ investigated attention more systematically. They attempted to justify the two types of observation (that is, when attention is interpretable and not), employing various experiments on various NLP tasks. The conclusion was that attention weights are interpretable and are correlated with metrics of the importance of features. However, this is only valid for cases where weights are essential for predicting models and cannot simply be reduced to a gating unit. Despite the existing studies, there are numerous research opportunities to develop systematic methodologies to analyze attention as an interpretability tool. The current conclusions are based on experiments with few architectures in a specific set of applications in NLP.", "cites": [8575, 8574, 180, 2639, 2668, 1877], "cite_extract_rate": 0.8571428571428571, "origin_cites_number": 7, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.5, "critical": 4.0, "abstraction": 3.0}, "insight_level": "high", "analysis": "The section provides a balanced and analytical overview of attention as an interpretability tool, contrasting supportive and critical viewpoints (e.g., Jain and Wallace vs. Rudin and Riedl). It synthesizes key findings from various NLP applications and abstracts the debate into broader research opportunities. However, it could offer more explicit generalization about the underlying principles of attention-based interpretability."}}
{"id": "5e5d9264-172a-425e-bfb5-f9a3916595e0", "title": "Unsupervised Learning", "level": "subsection", "subsections": [], "parent_id": "75e63f10-91ba-40b8-88f1-78f077a10310", "prefix_titles": [["title", "Attention, please! A survey of Neural Attention Models in Deep Learning"], ["section", "Trends and Opportunities"], ["subsection", "Unsupervised Learning"]], "content": "In the last decade, unsupervised learning has also been recognized as one of the most critical challenges of machine learning since, in fact, human learning is mainly unsupervised~. Some works have recently successfully explored attention within purely unsupervised models. In GANs, attention has been used to improve the global perception of a model (i.e., the model learns which part of the image gives more attention to the others). SAGAN~ was one of the pioneering efforts to incorporate self-attention in Convolutional Gans to improve the quality of the images generated. Image Transformer is an end-to-end attention network created to generate high-resolution images that significantly surpassed state-of-the-art in ImageNet in 2018. AttGan~ uses attention to easily take advantage of multimodality to improve the generation of images. Combining a region of the image with a corresponding part of the word-context vector helps to generate new features with more details in each stage.\nAttention has still been little explored to make generative models simpler, scalable, and more stable. Perhaps the only approach in the literature to explore such aspects more deeply is DRAW~, which presents a sequential and straightforward way to generate images, being possible to refine image patches while more information is captured sequentially. However, the architecture was tested only in simple datasets, leaving open spaces for new developments. There is not much exploration of attention using autoencoders. Using VAEs, Bornschein et al.~ increased the generative models with external memory and used an attentional system to address and retrieve the corresponding memory content.\nIn Natural Language Processing, attention is explored in unsupervised models mainly to extract aspects of sentiment analysis. It is also used within autoencoders to generate semantic representations of phrases~. However, most studies still use supervised learning attention, and few approaches still focus on computer vision and NLP. Therefore, we believe that there is still a great path for research and exploration of attention in the unsupervised context, particularly we note that the construction of purely bottom-up attentional systems is not explored in the literature and especially in the context of unsupervised learning, these systems can great value, accompanied by inhibition and return mechanisms.", "cites": [166, 1255, 2669, 2634, 7194], "cite_extract_rate": 0.7142857142857143, "origin_cites_number": 7, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.5, "critical": 3.0, "abstraction": 3.5}, "insight_level": "medium", "analysis": "The section synthesizes several key attention-based unsupervised learning works, connecting them within the broader context of generative models. It includes some critical analysis, particularly pointing out limited exploration of attention in autoencoders and simpler generative models. The section also abstracts to highlight broader research opportunities, such as the need for bottom-up attention systems in unsupervised learning, but it does not present a novel framework or deep meta-level insights."}}
{"id": "f3276cba-fff9-4a36-ade2-0bfd808d3c80", "title": "New Tasks and Robotics", "level": "subsection", "subsections": [], "parent_id": "75e63f10-91ba-40b8-88f1-78f077a10310", "prefix_titles": [["title", "Attention, please! A survey of Neural Attention Models in Deep Learning"], ["section", "Trends and Opportunities"], ["subsection", "New Tasks and Robotics"]], "content": "Although attention has been used in several domains, there are still potential applications that can benefit from it. The prediction of time series, medical applications, and robotics applications are little-explored areas of the literature. Predicting time series becomes challenging as the size of the series increases. Attentional neural networks can contribute significantly to improving results. Specifically, we believe that exploring RAM~ with multiple glimpses looking at different parts of the series or different frequency ranges can introduce a new way of computing time series. In medical applications, there are still few works that explore biomedical signals in attentional architectures. There are opportunities to apply attention to all applications, ranging from segmentation and image classification, support for disease diagnosis to support treatments such as Parkinson's, Alzheimer's, and other chronic diseases.\nFor robotics, there are countless opportunities. For years the robotics community has been striving for robots to perform tasks in a safe manner and with behaviors closer to humans. However, DL techniques need to cope well with multimodality, active learning, incremental learning, identify unknowns, uncertainty estimation, object and scene semantics, reasoning, awareness, and planning for this task. Architectures like RAM~, DRAW~ and Transformer~ can contribute a lot by being applied to visual odometry, SLAM and mapping tasks.", "cites": [180, 2634, 746], "cite_extract_rate": 1.0, "origin_cites_number": 3, "insight_result": {"type": "analytical", "scores": {"synthesis": 2.5, "critical": 2.5, "abstraction": 2.8}, "insight_level": "medium", "analysis": "The section highlights potential future applications of attention in robotics and other domains, drawing general inspiration from the cited works, but lacks deep synthesis or novel frameworks. It identifies gaps and suggests directions for future research, indicating some critical and abstract thinking, though the connections between the cited papers are minimal and the analysis remains at a surface level."}}
