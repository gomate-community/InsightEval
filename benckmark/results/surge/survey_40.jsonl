{"id": "e0f30243-71d9-4556-a468-79c7382f6912", "title": "Introduction", "level": "section", "subsections": [], "parent_id": "ff884408-d736-4f1c-976f-8cc088371f67", "prefix_titles": [["title", "A Survey on Dialogue Summarization: Recent Advances and New Frontiers"], ["section", "Introduction"]], "content": "Dialogue summarization aims to distill the most important information from a dialogue into a shorter passage, which can help people quickly capture the highlights of a semi-structured and multi-participant dialogue without reviewing the complex dialogue context . With the development of communication technology and the ravage of COVID-19, different types of dialogues have emerged as an important way for information exchange. Therefore, there is an urgent need for summarization techniques to save people from large amounts of dialogue data.  \nConventional works mainly focus on single-participant document summarization, such as news and scientific papers .\nThanks to the neural models, especially the sophisticated pre-trained language models, which have advanced these tasks significantly .\nDespite the success of single-participant document summarization, these methods can not be easily transferred to the multi-participant dialogue summarization.\nFirstly, the dialogue contains multiple participants, inherent topic drifts, frequent coreferences, diverse interactive signals and domain terminologies . All of these characteristics make dialogue a hard-to-model data type.\nSecondly, in terms of different domains, the above characteristics further pose domain-specific challenges to summarization models, e.g., \\textit{How to model long meeting transcripts} .\nThirdly, compared with widely used document summarization benchmarks, collecting labeled dialogue-summary paired data is highly-costing or even intractable . \nTo mitigate these challenges, researchers draw on successful experiences from the study of dialogue systems and natural language generation techniques and put their efforts on solving this challenging task, which result in nearly 100 papers covering various domains being published over the past 5 years.\nTo review the current progress and help new researchers get into the field quickly, we present this first survey for dialogue summarization.\nAs the preliminary, we quickly overview the recent progress in general summarization and capture several key time points and key techniques, this serves as a strong background before we dive into the dialogue summarization (see \\S\\ref{sec:bg}).\nAs the core content, we summarize existing works according to the domain of dialogue, mainly covering the meeting, chat, email thread, customer service and medical dialogue. \nFor each type of dialogue, we thoroughly go through related research works, organize them according to their unique challenges and provide suggestions for future works (see \\S\\ref{sec:tax}). \nFor example, we focus on two main streams of works for chat summarization including interaction and participant modeling .\nIn terms of customer service, we organize related works from two perspectives, one is inherent topic modeling , the other is task-oriented-specific information integration .\nBesides, we provide an overview of publicly available research datasets (see Table \\ref{tab:datasets}). Especially for meeting and chat summarization, we also carefully organize leaderboards under the unified evaluation metric by collecting reported results from published literatures and re-evaluating official outputs (see Table \\ref{tab:ami_bench} and Table \\ref{tab:samsum_bench}).\nBased on the analyses of existing works, we present several research directions, including faithfulness in dialogue summarization, multi-modal, multi-domain and multi-lingual dialogue summarization (see \\S\\ref{sec:new}). All of these frontiers not only pose new research challenges but also meet actual application needs and fit in with real-world scenarios.\nTo sum up, our contributions are as follows: \n\\begin{itemize}\n    \\item We are the first to present a comprehensive survey for the dialogue summarization task.\n    \\item We thoroughly summarize existing works according to different types of dialogues and carefully organize leaderboards under the unified evaluation metric.\n    \\item We discuss some new frontiers and highlight their challenges to motivate future researches.\n\\end{itemize}", "cites": [46, 42, 44, 45, 43, 7186], "cite_extract_rate": 0.6666666666666666, "origin_cites_number": 9, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.5, "critical": 3.0, "abstraction": 3.5}, "insight_level": "medium", "analysis": "The section synthesizes information from cited papers by highlighting domain-specific challenges and common issues in dialogue summarization, such as coreference and data collection. It provides some abstraction by grouping works based on dialogue types and identifying key research directions like faithfulness and multi-modal approaches. However, critical analysis is limited to surface-level observations of challenges without deep evaluation or comparison of methods."}}
{"id": "622e88e1-e43d-4b6b-b84e-48b94934d2eb", "title": "Overview of Summarization", "level": "subsection", "subsections": [], "parent_id": "f379cf0b-02f4-453c-83d0-ca363e690036", "prefix_titles": [["title", "A Survey on Dialogue Summarization: Recent Advances and New Frontiers"], ["section", "Background"], ["subsection", "Overview of Summarization"]], "content": "Automatic summarization is a fundamental task in natural language processing and has been continuously\nstudied for decades .\nIt aims to condense the original input into a shorter version covering salient information, which can help people quickly grasp the core content without diving into the details. \nIt is mainly divided into two paradigms: \\textit{extractive} and \\textit{abstractive}. \nExtractive methods select vital sentences as the summary, which is more accurate and faithful, while abstractive methods generate the summary using novel words, which improves the conciseness and fluency of the summary. \nPrevious works adopt machine learning algorithms to perform extractive summarization . \nWith sophisticated neural architectures, data-driven approaches have made much progress in both two paradigms. \nEspecially for abstractive methods, sequence-to-sequence learning combined with attention mechanism is adopted as the backbone architecture for solving this task .\nRecently, with the great success of pre-trained models in a wide range of natural language processing tasks, these models also become the {\\it de facto} way for summary generation and have achieved many state-of-the-art results .", "cites": [7186], "cite_extract_rate": 0.25, "origin_cites_number": 4, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 2.0, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section provides a general overview of summarization, distinguishing between extractive and abstractive methods, and briefly mentions recent trends like pre-trained models. However, it lacks in-depth synthesis of the cited papers, does not critically evaluate their contributions or limitations, and offers minimal abstraction beyond basic definitions and surface-level observations."}}
{"id": "b3ad2774-fdfd-4e1b-8896-c157d3b2199c", "title": "Evaluation Metrics", "level": "subsection", "subsections": [], "parent_id": "f379cf0b-02f4-453c-83d0-ca363e690036", "prefix_titles": [["title", "A Survey on Dialogue Summarization: Recent Advances and New Frontiers"], ["section", "Background"], ["subsection", "Evaluation Metrics"]], "content": "ROUGE  is conventionally adopted as the standard metric for evaluating summarization tasks, which mainly involves the F1 scores for ROUGE-1, ROUGE-2, and ROUGE-L that measure the word overlap, bi-gram overlap and longest common sequence between the ground truth and the generated summary respectively. \n\\begin{table}[t]\n\\small\n\\centering\n        \\scalebox{0.90}{\\begin{tabular}{l|c|c}\n            \\hline\n            \\textbf{Name} & \\textbf{Domain} & \\textbf{Language} \\\\\n            \\hline\n            \\hline\n            ICSI   & \\multirow{3}{*}{Meeting}  & English \\\\\n            AMI   &  & English \\\\\n            QMSum  &  & English \\\\\n            \\hdashline[1pt/3pt]\n            SAMSum   & \\multirow{2}{*}{Chat} & English \\\\\n            GupShup     &  & Code-Mix \\\\\n            \\hdashline[1pt/3pt]\n            CSDS  & \\multirow{3}{*}{\\makecell{Customer \\\\ Service} }  & Chinese \\\\\n            TODSum  &   & English  \\\\\n            TWEETSUMM   &  & English \\\\\n            \\hdashline[1pt/3pt]\n            CRD3    & TV Show & English \\\\\n               & Medical & Chinese \\\\\n            SumTitles    & Movie & English \\\\\n            \\textsc{MediaSum}  & Interview & English \\\\\n            \\textsc{DialogSum}  & Spoken & English \\\\\n            $\\textsc{EmailSum}$  & Email & English \\\\\n            ForumSum  & Forum & English \\\\\n            \\hdashline[1pt/3pt]\n            ConvoSumm    & Mix & English \\\\\n            \\hline\n        \\end{tabular}}\n\\caption{Major datasets for dialogue summarization.} \\label{tab:datasets}\n\\end{table}", "cites": [46, 7188, 7187, 7189], "cite_extract_rate": 0.2857142857142857, "origin_cites_number": 14, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 1.5, "abstraction": 1.5}, "insight_level": "low", "analysis": "The section briefly introduces ROUGE as a standard metric and presents a table of datasets, but it lacks integration of the cited papers into a broader discussion on evaluation. It does not synthesize insights about how different domains or languages influence the choice or performance of metrics. There is minimal critical analysis or abstraction of underlying principles in the evaluation process."}}
{"id": "bc46489a-7f49-4127-84a5-50496c13a1c9", "title": "Taxonomy", "level": "section", "subsections": ["4d11904b-9d4a-4186-add0-68097129b675", "f0d2d771-aa30-4722-a496-4a96e593c2ab", "755d60af-9ef3-4bcd-86c3-9ae8e03393a4", "c7916eee-f82e-42d0-8932-f94add4cd283", "5e5d3e8f-eca8-4635-b332-2ed0819f3a80"], "parent_id": "ff884408-d736-4f1c-976f-8cc088371f67", "prefix_titles": [["title", "A Survey on Dialogue Summarization: Recent Advances and New Frontiers"], ["section", "Taxonomy"]], "content": "\\label{sec:tax}\nIn this section, we describe the taxonomy of dialogue summarization according to the domain of input dialogue, including meeting, chat, email thread, customer service and medical dialogue. Table \\ref{tab:datasets} lists currently available datasets for these dialogue summarization researches. \n\\begin{table*}[t]\n\\small\n\\centering\n        \\begin{tabular}{l||ccc||ccc}\n            \\hline\n            &  \\multicolumn{3}{c||}{\\textbf{AMI}} & \\multicolumn{3}{c}{\\textbf{ICSI}} \\\\\n            \\textbf{Model} & \\textbf{ROUGE-1} & \\textbf{ROUGE-2} & \\textbf{ROUGE-L} & \\textbf{ROUGE-1} & \\textbf{ROUGE-2} & \\textbf{ROUGE-L}  \\\\\n            \\hline\n            \\hline\n            \\multicolumn{7}{c}{\\it Extractive Methods} \\\\\n            \\hline\n            TextRank  &35.19 &6.13 &15.70 &30.72 &4.69 &12.97  \\\\\n            SummaRunner  & 30.98 &5.54 &13.91 &27.60 &3.70 &12.52 \\\\\n            \\hline\n            \\hline\n            \\multicolumn{7}{c}{\\it Abstractive Methods} \\\\\n            \\hline\n            UNS  &37.86 &7.84 &13.72 & 31.73 & 5.14 & 14.50 \\\\\n            PGN  &42.60 &14.01 &22.62 & 35.89 & 6.92 & 15.67 \\\\\n            Sentence-Gated  & 49.29 & 19.31 & 24.82 & 39.37 & 9.57 & 17.17 \\\\\n            TopicSeg  & 51.53 &12.23 &25.47  & - & - & - \\\\\n            TopicSeg+VFOA  & 53.29 &13.51 &26.90  & - & - & - \\\\\n            HMNet  & 52.36 & 18.63 &24.00 & 45.97 & 10.14 & 18.54 \\\\\n            PGN($\\CalD_{\\sys}$)  &50.91 &17.75  &24.59 & - & - & - \\\\\n            \\textsc{DdaMS}  &51.42 &20.99 &24.89 &39.66 &10.09 &17.53 \\\\\n            \\textsc{DdaMS}+\\textsc{DdaDA}  &53.15 &22.32 &25.67 &40.41 &11.02 &19.18 \\\\\n            \\hline\n            \\hline\n            \\multicolumn{7}{c}{\\it Pre-trained Language Model-based Methods} \\\\\n            \\hline\n            Longformer-BART  &54.81  &20.83  &25.98  & 43.40 & 12.19 & 19.29 \\\\\n            Longformer-BART-arg  & 55.27 & 20.89 & 24.94 & 44.51 & 11.80 & 19.19 \\\\\n            \\textsc{Dialog}LM  & 53.72  & 19.61  & 51.83* & 49.56  & 12.53  & 47.08* \\\\\n            \\hline\n        \\end{tabular}\n\\caption{Leaderboard of meeting summarization on AMI \\protect and ICSI \\protect datasets. We adopt reported results from published literatures \\protect and corresponding publications. The results of Longformer \\protect are obtained by evaluating the output files provided by the author. Results with *\nindicate that ROUGE-L is calculated with sentence splitting.} \\label{tab:ami_bench}\n\\end{table*}", "cites": [47, 7189, 43, 45, 7186, 8314], "cite_extract_rate": 0.46153846153846156, "origin_cites_number": 13, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 2.0, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section presents a taxonomy of dialogue summarization by domain and includes a leaderboard of methods, but it lacks in-depth synthesis or critical evaluation of the cited works. It primarily describes results and models without connecting ideas across papers or identifying broader trends or limitations."}}
{"id": "4d11904b-9d4a-4186-add0-68097129b675", "title": "Meeting Summarization", "level": "subsection", "subsections": ["660dc32d-2be2-414b-97e6-6c1272a11f55"], "parent_id": "bc46489a-7f49-4127-84a5-50496c13a1c9", "prefix_titles": [["title", "A Survey on Dialogue Summarization: Recent Advances and New Frontiers"], ["section", "Taxonomy"], ["subsection", "Meeting Summarization"]], "content": "\\label{sec:meeting}\nMeeting plays an essential part in our daily life. \nEspecially due to the spread of COVID-19 worldwide, people are more dependent on online meetings to share information and collaborate with others.\nAccordingly, meeting summaries, aka meeting minutes could be of great value for both participants and non-participants to quickly grasp the main meeting ideas. \nThanks to the earlier publicly available datasets AMI  and ICSI , meeting summarization has attracted extensive research attentions. \nPrecedent works focus on extractive meeting summarization. They adopt various features to detect important utterances, such key phrases, topics and speaker characteristics.\nHowever, due to the multi-participants nature, information is scattered and incoherent in the meeting, which makes the extractive methods unsuitable for meeting summarization. \nTherefore, recent years witness a growing trend of abstractive meeting summarization methods .\nWith the development of neural networks, many works have explored the application of deep learning in meeting the summarization task and have achieved remarkable success .\nAlthough deep learning-based methods have strong modeling abilities, taking only literal information into consideration is not sufficient. \nThis is because there are diverse interactive signals among meeting utterances and the long meeting transcripts further pose challenges to traditional sequence-to-sequence models.\nTo this end, some works devote efforts to incorporate auxiliary information for better modeling meetings, such as dialogue discourse , dialogue acts  and domain terminologies .\nBesides, several strategies are carefully devised to handle long meeting transcripts, including hierarchical modeling strategy , sliding window strategy , retrieve-then-summarize strategy  and pre-training strategy .\nInstead of summarizing the whole meeting, generating meeting summaries of a particular aspect, such as decisions, actions, ideas and hypotheses, could also address specific needs.\nRecently, \\newcite{qmsum} propose the query-based meeting summarization task, which aims to summarize the specific part of the meeting according to the given query.\nIn addition to multi-party characteristics, meeting summarization has also been explored under the multi-modal setting. Meetings can include various types of non-verbal information that is displayed by the participants, such as audio, visual and motion features.\nThese features may be useful for detecting important utterances in a meeting.\nTherefore, a majority of works study both the extractive and abstractive multi-modal meeting summarization problem by fusing verbal and non-verbal features to enrich the representation of the utterance .", "cites": [47, 48, 42, 43, 45, 8314], "cite_extract_rate": 0.5454545454545454, "origin_cites_number": 11, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.5, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section demonstrates strong synthesis by organizing key trends in meeting summarization, including shifts from extractive to abstractive methods, the role of auxiliary information, and strategies for handling long transcripts. It critically highlights limitations of traditional models and deep learning approaches, such as insensitivity to interactive signals and data scarcity. The abstraction is evident in its discussion of broader challenges like multi-party dynamics, domain-specific needs, and multi-modal integration."}}
{"id": "ffcdcdb3-3417-48a7-89eb-73e66685373c", "title": "Highlight:", "level": "paragraph", "subsections": [], "parent_id": "5e9fb0e6-7427-4c9c-a0b4-e8cdc08f10ba", "prefix_titles": [["title", "A Survey on Dialogue Summarization: Recent Advances and New Frontiers"], ["section", "Taxonomy"], ["subsection", "Chat Summarization"], ["paragraph", "Leaderboard:"], ["paragraph", "Highlight:"]], "content": "Thanks to the pre-trained language models, current methods are skilled at transforming the original chat into a simple summary realization. However, they still have difficulty selecting the important parts and tend to generate hallucinations. In the future, powerful chat modeling strategies and reasoning abilities should be explored for this task, and more low-resource settings should be considered.\n\\begin{table}[t]\n\\small\n\\centering\n        \\begin{tabular}{l|ccc}\n            \\hline\n            \\textbf{Model} & \\textbf{R-1} & \\textbf{R-2} & \\textbf{R-L}  \\\\\n            \\hline\n            \\hline\n            \\multicolumn{4}{c}{\\it Extractive Methods} \\\\\n            \\hline\n            LONGEST-3 &32.46 &10.27 &29.92 \\\\\n            TextRank  &29.27 &8.02 &28.78 \\\\\n            \\hline\n            \\hline\n            \\multicolumn{4}{c}{\\it Abstractive Methods} \\\\\n            \\hline\n            Transformer  &36.62 &11.18 &33.06 \\\\\n            PGN  & 40.08 & 15.28 & 36.63 \\\\\n            D-HGN  &42.03  &18.07  &39.56   \\\\\n            TGDGA  &43.11 &19.15 &40.49 \\\\\n            \\hline\n            \\hline\n            \\multicolumn{4}{c}{\\it Pre-trained Language Model-based Methods} \\\\\n            \\hline\n            DialoGPT  &39.77 &16.58 &38.42 \\\\\n            \\hdashline[1pt/3pt]\n            UniLM  & 47.85 & 24.23 & 46.67 \\\\\n            BART  &52.98 &27.67 &49.06 \\\\\n            \\hdashline[1pt/3pt] \n            S-BART  & 50.70 & 25.50 & 48.08 \\\\\n            \\textsc{Frost}  & 51.86 & 27.67 & 47.52 \\\\\n            CODS  & 52.65 & 27.84 & 50.79 \\\\\n            MV-BART  &54.05 &28.56  &50.57 \\\\\n            BART($\\CalD_{\\sys}$)  &53.70 &28.79 &50.81 \\\\\n            Coref-ATTN  & 53.93 & 28.58 & 50.39 \\\\\n            \\hdashline[1pt/3pt] \n            Entity-Plan $^{\\dagger}$ & $\\text{56.53}$ & $\\text{32.40}$ & $\\text{54.92}$ \\\\\n            \\hline\n        \\end{tabular}\n\\caption{Leaderboard of chat summarization on the SAMSum dataset \\protect, where ``R'' is short for ``ROUGE''. We mainly adopt results from corresponding publications. Besides, the results of S-BART, MV-BART, Coref-ATTN and Entity-Plan are obtained by evaluating output files provided by the author. $\\dagger$ indicates the model obtains these results with the help of golden summaries.}\n\\label{tab:samsum_bench}\n\\end{table}", "cites": [38, 50, 49, 8315, 44, 7186, 42, 7189], "cite_extract_rate": 0.5, "origin_cites_number": 16, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.5, "abstraction": 3.5}, "insight_level": "high", "analysis": "The section provides a structured analysis of chat summarization methods, integrating results from various models and studies. It synthesizes the findings effectively by grouping methods (extractive, abstractive, pre-trained) and highlighting their performance. It also identifies limitations, such as hallucinations and the need for better modeling strategies and low-resource settings, showing both critical evaluation and abstraction of key issues."}}
{"id": "c7916eee-f82e-42d0-8932-f94add4cd283", "title": "Customer Service Summarization", "level": "subsection", "subsections": ["8a4d3441-a53c-40fb-81c7-43737005a422"], "parent_id": "bc46489a-7f49-4127-84a5-50496c13a1c9", "prefix_titles": [["title", "A Survey on Dialogue Summarization: Recent Advances and New Frontiers"], ["section", "Taxonomy"], ["subsection", "Customer Service Summarization"]], "content": "\\label{sec:cs}\nCustomer service is the direct one-on-one interaction between a customer and an agent, which frequently happens before and after the consumer behavior.\nThus, it is important for growing business. \nTo make the customer service more effective, automatic summarization is one way, which can provide the agent with quick solutions according to the previous condensed summary.\nTherefore, customer service summarization gains a lot of research interest in recent years.\nOn the one hand, participants in customer service have strong intent and clear motivations to address issues, which makes the customer service inherently logical and surrounds specific topics. To this end, some works explore topic modeling for this task.\n\\newcite{cs-kdd} employ a coarse-to-fine generation framework, which first generates a sequence of key points (topics) to indicate the logic of the dialogue and then realize the detailed summary. For example, a key point sequence can be {\\it question$\\rightarrow$solution$\\rightarrow$user approval$\\rightarrow$end}, which clearly shows the evolution of the dialogue. \nInstead of using explicitly pre-defined topics, \\newcite{cs-supervised-zou} draw support from neural topic modeling and propose a multi-role topic modeling mechanism to explore implicitly topics. \nTo alleviate data-insufficient problems, \\newcite{cs-unsupervised-zou} propose an unsupervised framework called RankAE, in which  topic utterances are first selected  according to centrality and diversity simultaneously, and the denoising auto-encoder is further employed to produce final summaries.\nOn the other hand, customer service is a kind of task-oriented dialogue, which contains informative entities, covers various domains and involves two distinct types of participants.\nTo integrate dialogue-specific information, \\newcite{todsum} craft a new dataset annotated with dialogue state knowledge, which is helpful for tracking the fine-grained dialogue information flow and generating faithful summaries.\nSince participants in customer service play distinct roles, in addition to the overall summary\nfor the whole dialogue, \\newcite{cs-tat} propose an unsupervised framework based on variational auto-encoder to generate summaries for the customer and the agent respectively. \n directly propose CSDS  datasets annotated with role-oriented summaries to acquire different speakersâ€™ viewpoints.", "cites": [46], "cite_extract_rate": 1.0, "origin_cites_number": 1, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.0, "abstraction": 3.5}, "insight_level": "medium", "analysis": "The section effectively synthesizes multiple papers by highlighting common themes such as topic modeling and role-oriented summarization, and it connects these methods to the specific characteristics of customer service dialogues. It offers some critical perspective by pointing out data limitations and the importance of task-specific features, but lacks deeper evaluative comparisons or limitations analysis. The section identifies patterns like the use of structured information and participant roles, offering a moderate level of abstraction."}}
{"id": "5d528f89-a844-4760-bdb5-2b840340054b", "title": "Faithfulness in Dialogue Summarization", "level": "subsection", "subsections": [], "parent_id": "91aeb887-b98b-43ab-a971-9b9c1c2ec04e", "prefix_titles": [["title", "A Survey on Dialogue Summarization: Recent Advances and New Frontiers"], ["section", "New Frontiers"], ["subsection", "Faithfulness in Dialogue Summarization"]], "content": "Even though current state-of-the-art summarization systems have already made great progress, they still suffer from the factual inconsistency problem, which distorts or fabricates the factual information in the article and is also known as hallucinations . \\newcite{Tang2021CONFITTF} systematically study the taxonomy of factuality errors for dialogue summarization,  which includes the following 8 error types: \\textit{Missing Information, Redundant Information, Circumstantial Error, Wrong Reference Error, Negation Error, Object Error, Tense Error} and \\textit{Modality Error}. \nSpecifically, the last five types of errors notoriously tend to appear in dialogue summaries, which largely hinder the application of dialogue summarization systems. \nTo remedy these issues, future works need specific designs target for the above errors. Importantly, fine-grained dialogue-specific features need to be incorporated into the summarization model, such as personal pronoun information, coreference information and tense information. On the one hand, these features can implicitly alleviate the difficulty of dialogue understanding. On the other hand, some features can directly serve as the explicitly extracted information to help final summary generation.", "cites": [51], "cite_extract_rate": 1.0, "origin_cites_number": 1, "insight_result": {"type": "analytical", "scores": {"synthesis": 2.5, "critical": 2.0, "abstraction": 2.5}, "insight_level": "medium", "analysis": "The section provides an analytical overview of factuality errors in dialogue summarization, referencing a taxonomy from a single cited paper. While it organizes the error types and suggests potential solutions, it lacks deeper synthesis with other works and critical evaluation of the cited paper's methodology or limitations. The abstraction is limited to general suggestions for model improvement rather than broader theoretical or conceptual insights."}}
{"id": "ee541925-2428-4609-82cb-31152ab0bf60", "title": "Multi-domain Dialogue Summarization", "level": "subsection", "subsections": [], "parent_id": "91aeb887-b98b-43ab-a971-9b9c1c2ec04e", "prefix_titles": [["title", "A Survey on Dialogue Summarization: Recent Advances and New Frontiers"], ["section", "New Frontiers"], ["subsection", "Multi-domain Dialogue Summarization"]], "content": "Multi-domain learning can mine shared information between different domains and further help the task of a specific domain, which is an effective learning method suitable for low-resource scenarios.\nThanks to diverse summarization datasets, there are already some works exploring the multi-domain learning or domain adaption for dialogue summarization . \nWe divide this direction into two categories: macro multi-domain learning and micro multi-domain learning. \nMacro multi-domain learning aims to use general domain summarization datasets, like news and scientific papers, to help the dialogue summarization task. \nThe basis for this learning method to work is that no matter what data type they belong to, they aim to pick the core content of the original text.\nHowever, dialogues have some unique characteristics like more coreferences and participant-related features. \nTherefore, directly using these general datasets may reduce their effectiveness.\nFuture works can first inject some dialogue-specific features, like replacing names with personal pronouns or transform the original general domain documents into turn-level documents at surface level, to further utilize these datasets.\nMicro multi-domain learning aims to use dialogue summarization datasets to help one specific dialogue summarization task.\nFor example, using meeting datasets to help with email tasks. As shown in Table \\ref{tab:datasets}, diverse dialogue summarization datasets covering various domains have been proposed in recent years. \nFuture works can adopt meta-learning methods or rely on pre-trained language models to unify different datasets and mine common features.", "cites": [7189], "cite_extract_rate": 1.0, "origin_cites_number": 1, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.0, "critical": 3.0, "abstraction": 3.5}, "insight_level": "medium", "analysis": "The section provides a basic synthesis of multi-domain dialogue summarization by categorizing it into macro and micro levels and relating it to general and domain-specific datasets. It critically notes the limitations of using general domain datasets for dialogue due to unique features like coreference and turn-level structure. The abstraction is moderate, identifying patterns such as the need for dialogue-specific adaptations and the potential of pre-trained models and meta-learning."}}
{"id": "d40cd418-3bf5-411d-819e-afa44e5a86d8", "title": "Multi-lingual Dialogue Summarization", "level": "subsection", "subsections": [], "parent_id": "91aeb887-b98b-43ab-a971-9b9c1c2ec04e", "prefix_titles": [["title", "A Survey on Dialogue Summarization: Recent Advances and New Frontiers"], ["section", "New Frontiers"], ["subsection", "Multi-lingual Dialogue Summarization"]], "content": "With the acceleration of globalization, a dialogue involving multinational participants becomes increasingly common thanks to the sophisticated instantaneous translation system. Therefore, there is an urgent need for providing people with dialogue summaries in a preferred language. However, current works overwhelmingly focused on English, while leaving other languages under exploration. We argue that the current dilemma is mainly caused by the intractable access to available multi-lingual data resources.\nFirstly, future works should devote efforts to creating a suitable testbed for multi-lingual dialogue summarization. As an initial step, \\newcite{gupshup} transform English utterances in the SAMSum dataset into Hindi-English utterances and study the chat summarization under the code-switched setting. \nFrom a higher point of view, large-scale high-quality datasets covering diverse languages should be carefully crafted.\nPractically speaking, on the one hand, researchers can translate one specific dataset into different languages followed by automatic and human quality checking to get aligned datasets. On the other hand, researchers can also borrow ideas from unsupervised multi-lingual learning to utilize currently available datasets in different languages. Secondly, future works should set up systematic settings for this multi-lingual research, including \\textit{one-to-one}, \\textit{one-to-many}, \\textit{many-to-one} and \\textit{many-to-many}, in which \\textit{one-to-one} setting can be further divided into \\textit{mono-lingual} setting and \\textit{cross-lingual} setting . Thirdly, plenty of multi-lingual pre-trained language models can be explored for this task. Especially, models that have already been fine-tuned on the translation datasets may bring significant benefits", "cites": [52], "cite_extract_rate": 1.0, "origin_cites_number": 1, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.5, "critical": 3.0, "abstraction": 3.5}, "insight_level": "medium", "analysis": "The section synthesizes the cited paper (Gupshup et al.) and extends its ideas to the context of dialogue summarization, establishing relevance to multi-lingual settings. It provides some critical analysis by highlighting the lack of exploration in non-English languages and suggesting practical solutions. The section also abstracts the problem to a broader level by discussing different multi-lingual settings and model opportunities, though the critique and synthesis remain somewhat focused on a limited number of approaches."}}
