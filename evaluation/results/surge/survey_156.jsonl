{"id": "a8226dc3-d362-4903-95b7-99729473d23c", "title": "Introduction", "level": "section", "subsections": [], "parent_id": "bd162e79-adf5-413e-a1f4-ec18c4226195", "prefix_titles": [["title", " A Comprehensive Survey on Graph Neural Networks"], ["section", "Introduction"]], "content": "\\label{sec:introduction}\n\\IEEEPARstart{T}{he} recent success of neural networks has boosted research on pattern recognition and data mining.  Many machine learning tasks such as object detection , machine translation , and speech recognition , which once heavily relied on handcrafted feature engineering to extract informative feature sets, has recently been revolutionized by various end-to-end deep learning paradigms, e.g.,  convolutional neural networks (CNNs) , recurrent neural networks (RNNs) , and autoencoders . The success of deep learning in many domains is partially attributed to the rapidly developing computational resources (e.g., GPU), the availability of big training data, and the effectiveness of deep learning to extract latent representations from Euclidean data (e.g., images, text, and videos). Taking image data as an example,  we can represent an image as a regular grid in the Euclidean space.  A convolutional neural network (CNN) is able to exploit the shift-invariance, local connectivity, and compositionality of image data . As a result, CNNs can extract local meaningful features that are shared with the entire data sets for various image analysis.  \nWhile deep learning effectively captures hidden patterns of Euclidean data, there is an increasing number of applications where data are \nrepresented in the form of graphs. \nFor examples, in e-commence, a graph-based learning system can exploit the interactions between users and products to make highly accurate recommendations. In chemistry, molecules are modeled as graphs, and their bioactivity needs to be identified for drug discovery. In a citation network, papers are linked to each other via citationships and they need to be categorized into different groups. The complexity of graph data has imposed significant challenges on existing machine learning algorithms. \nAs graphs can be irregular, a  graph  may  have  a  variable size of unordered nodes, and nodes from a graph may have a different number of neighbors, resulting in some important operations (e.g., convolutions) being  easy to  compute in the image domain, but difficult to apply to the graph domain.  Furthermore, a core assumption of existing machine learning algorithms is that instances are independent of each other. This assumption no longer holds for graph data because each instance (node) is related to others by links of various types, such as  citations, friendships, and interactions.\nRecently, there is increasing interest in extending deep learning approaches for graph data. Motivated by CNNs, RNNs, and autoencoders from deep learning, new general- izations and definitions of important operations have been rapidly developed over the past few years to handle the com- plexity of graph data. For example, a graph convolution can be generalized from a 2D convolution. As illustrated in Figure \\ref{gcn_cnn}, an image can be considered as a special case of graphs where pixels are connected by adjacent pixels. Similar to 2D convolution, one may perform graph convolutions by  taking  the  weighted  average  of  a  node's  neighborhood\ninformation.\nThere are a limited number of existing reviews on the topic of graph neural networks (GNNs). Using the term \\textit{geometric deep learning}, Bronstein et al.  give an overview of deep learning methods in the non-Euclidean domain, including graphs and manifolds. Although it is the first review on GNNs, this survey mainly  reviews  convolutional  GNNs.  Hamilton et al.  cover a limited number of GNNs with a focus on addressing the problem of network embedding.\nBattaglia et al.  position \\textit{graph networks} as the building blocks for learning from relational data, reviewing part of GNNs under a unified framework. \nLee et al.  conduct a partial survey of GNNs which apply different attention mechanisms.\nIn summary, existing surveys only include some of the GNNs and examine a limited number of works, thereby missing the most recent development of GNNs. Our survey provides a comprehensive overview of GNNs, for both interested researchers who want to enter this rapidly developing field and experts who would like to compare GNN models.\nTo cover a broader range of methods, this survey considers GNNs as all deep learning approaches for graph data.    \n\\begin{figure}[]\n\\centering\n\\subfloat[2D Convolution. Analogous to a graph, each pixel in an image is taken as a node where neighbors are determined by the filter size. The 2D convolution takes the weighted average of pixel values of the red node along with its neighbors. The neighbors of a node are ordered and have a fixed size. ]{\\includegraphics[width=1.5in]{fig/dat1.pdf}\n\\label{fig_first_case}}\n\\hfill\n\\subfloat[Graph Convolution. To get a hidden representation of the red node, one simple solution  of the graph convolutional operation is to take the average value of the node features of the red node along with its neighbors. Different from image data, the neighbors of a node are unordered and variable in size.]{\\includegraphics[width=1.5in]{fig/dat2.pdf}\n\\label{fig_second_case}}\n\\caption{2D Convolution vs. Graph Convolution.}\n\\label{gcn_cnn}\n\\end{figure}\n\\vspace{.2cm}\n\\textbf{Our contributions}\nOur paper makes notable contributions summarized as follows:\n\\begin{itemize}\n\\item \\textbf{New taxonomy} We propose a new taxonomy of graph neural networks.  Graph neural networks are categorized into four groups: recurrent graph neural networks, convolutional graph neural networks, graph autoencoders, and spatial-temporal graph neural networks. \n\\item \\textbf{Comprehensive review} We provide the most comprehensive overview of modern deep learning techniques for graph data. For each type of graph neural network, we provide detailed descriptions on representative models, make the necessary comparison, and summarise the corresponding algorithms.\n\\item \\textbf{Abundant resources} We collect abundant resources on graph neural networks,  including state-of-the-art models, benchmark data sets, open-source codes, and practical applications. This survey can be used as a hands-on guide for understanding, using, and developing different deep learning approaches for various real-life applications. \n\\item \\textbf{Future directions} We discuss theoretical aspects of graph neural networks, analyze the limitations of existing methods, and suggest four possible future research directions in terms of model depth, scalability trade-off, heterogeneity, and dynamicity.\n\\end{itemize}\n\\vspace{.2cm}\n\\textbf{Organization of our survey}\nThe rest of this survey is organized as follows. Section \\ref{sec:definition} outlines the background of graph neural networks, lists commonly used notations, and defines graph-related concepts. Section \\ref{sec:categorization} clarifies the categorization of graph neural networks. Section \\ref{sec:grn}-\\ref{sec:stgcn} provides an overview of graph neural network models. Section \\ref{sec:applications} presents a collection of applications across various domains.  Section \\ref{sec:fucture} discusses the current challenges and suggests future directions. Section \\ref{sec:conclusion} summarizes the paper.", "cites": [207, 206, 209, 208, 7007, 7006, 7008, 210], "cite_extract_rate": 0.6666666666666666, "origin_cites_number": 12, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.0, "abstraction": 4.0}, "insight_level": "high", "analysis": "The introduction synthesizes key concepts from multiple cited papers, such as the limitations of traditional machine learning on graph data and the evolution of GNNs from CNNs and RNNs. It also critically points out the shortcomings of existing surveys, such as limited scope or outdated coverage. The section abstracts the problem of non-Euclidean data and highlights the need for a unified and comprehensive approach, indicating a strong analytical perspective."}}
{"id": "0744df39-2d74-462f-9249-741d4e7d5e8f", "title": "Background", "level": "subsection", "subsections": [], "parent_id": "a05dd68c-b3d5-4369-9d68-2087acdb0348", "prefix_titles": [["title", " A Comprehensive Survey on Graph Neural Networks"], ["section", "Background \\& Definition"], ["subsection", "Background"]], "content": "\\vspace{2mm}\n\\textbf{A brief history of graph neural networks (GNNs)} Sperduti et al. (1997)  first applied neural networks to directed acyclic graphs, which motivated early studies on GNNs. The notion of graph neural networks was initially outlined in Gori et al. (2005)  and further elaborated in Scarselli et al. (2009) , and Gallicchio et al. (2010) . \nThese early studies fall into the category of recurrent graph neural networks (RecGNNs). They learn a target node's representation by propagating neighbor information in an iterative manner until a stable fixed point is reached. \nThis process is computationally expensive, and recently there have been increasing efforts to overcome these challenges . \nEncouraged by the success of CNNs in the computer vision domain, a large number of methods that re-define the notion of \\textit{convolution} for graph data are developed in parallel. These approaches are under the umbrella of convolutional graph neural networks (ConvGNNs). ConvGNNs are divided into two main streams, the spectral-based approaches and the spatial-based approaches.  The first prominent research on spectral-based ConvGNNs was presented by Bruna et al. (2013) , which developed a graph convolution based on the spectral graph theory.  Since this time, there have been increasing improvements, extensions, and approximations on spectral-based ConvGNNs .  The research of spatial-based ConvGNNs started much earlier than spectral-based ConvGNNs. In 2009, Micheli et al.  first addressed graph mutual dependency by architecturally composite non-recursive layers while inheriting ideas of message passing from RecGNNs.  However,  the importance of this work was overlooked. Until recently, many spatial-based ConvGNNs (e.g., ) emerged. \nThe timeline of representative RecGNNs and ConvGNNs is shown in the first column of Table \\ref{tab:pub}.\nApart from RecGNNs and ConvGNNs, many alternative GNNs have been developed in the past few years, including graph autoencoders (GAEs) and  spatial-temporal graph neural networks (STGNNs). These learning frameworks can be built on RecGNNs, ConvGNNs, or other neural architectures for graph modeling. \nDetails on the categorization of these methods are given in Section \\ref{sec:categorization}. \n\\vspace{.1cm}\n\\textbf{Graph neural networks vs. network embedding } \nThe research on GNNs is closely related to graph embedding or network embedding, another topic which attracts increasing attention from both the data mining and machine learning communities .  Network embedding aims at representing network nodes as low-dimensional vector representations, preserving both network topology structure and node content information, so that any subsequent graph analytics task such as classification, clustering, and recommendation  can be easily performed using simple off-the-shelf machine learning algorithms (e.g., support vector machines for classification). \nMeanwhile, GNNs are deep learning models aiming at addressing graph-related tasks in an end-to-end manner. Many GNNs explicitly extract high-level representations. \nThe main distinction between GNNs and network embedding is that GNNs are a group of neural network models which are designed for various tasks while network embedding covers various kinds of methods targeting the same task. Therefore, GNNs can address the network embedding problem through a graph autoencoder framework. On the other hand, network embedding contains other non-deep learning methods such as  matrix factorization  and random walks .\n\\vspace{.1cm}\n\\textbf{Graph neural networks vs. graph kernel methods}\nGraph kernels are historically dominant techniques to solve the problem of graph classification . These methods employ a kernel function to measure the similarity between pairs of graphs so that kernel-based algorithms like support vector machines can be used for supervised learning on graphs.  Similar to GNNs, graph kernels can embed graphs or nodes into vector spaces by a mapping function. The difference is that this mapping function is deterministic rather than learnable. Due to a pair-wise similarity calculation, graph kernel methods suffer significantly from computational bottlenecks. GNNs, on one hand, directly perform graph classification based on the extracted graph representations and therefore are much more efficient than graph kernel methods. For a further review of graph kernel methods, we refer the readers to .\n\t\\begin{table}[t]\n\t\t\\caption{Commonly used notations.}\n\t\t\\label{tab:notations}\n\t\t\\centering\n\t\t\\begin{tabular} {  l l p{7cm} } \\toprule\n\t\t\t\t\\textbf{Notations}& \\textbf{Descriptions} \\\\ \\midrule\n\t\t\t    $|\\cdot|$ & The length of a set. \\\\ \\hline\n\t\t\t\t$\\odot$ & Element-wise product. \\\\ \\hline\n\t\t\t\t$G$& A graph. \\\\ \\hline\n\t\t\t\t$V$& The set of nodes in a graph.\\\\ \\hline\n\t\t\t\t$v$ & A node $v\\in V$. \\\\ \\hline\n\t\t\t    $E$& The set of edges in a graph.\\\\ \\hline\n\t\t\t\t$e_{ij}$ & An edge $e_{ij}\\in E$.\\\\ \\hline\n\t\t\t\t$N(v)$ & The neighbors of a node $v$. \\\\ \\hline\n\t\t\t\t$\\mathbf{A}$ & The graph adjacency matrix.  \\\\ \\hline\n\t\t\t\t$\\mathbf{A}^T$ & The transpose of the matrix\n\t\t\t\t$\\mathbf{A}$. \\\\ \\hline\n\t\t\t\t$\\mathbf{A}^n, n\\in Z$ & The $n^{th}$ power of\n\t\t\t\t$\\mathbf{A}$. \\\\ \\hline\n\t\t\t\t$[\\mathbf{A},\\mathbf{B}]$ & The concatenation of $\\mathbf{A}$ and $\\mathbf{B}$. \\\\ \\hline\n                $\\mathbf{D}$ & The degree matrix of $\\mathbf{A}$. $\\mathbf{D}_{ii} = \\sum_{j=1}^n \\mathbf{A}_{ij}$. \\\\ \\hline\n\t\t\t\t$n$ & The number of nodes, $n = |V|$. \\\\ \\hline\n\t\t\t\t$m$ & The number of edges, $m = |E|$. \\\\ \\hline\n\t\t\t\t$d$  & The dimension of a node feature vector.\\\\ \\hline\n\t\t\t\t$b$ & The dimension of a hidden node feature vector. \\\\ \\hline\n\t\t\t    $c$  & The dimension of an edge feature vector.\\\\ \\hline\n\t\t\t\t$\\mathbf{X} \\in \\mathbf{R}^{n\\times d}$ & The feature matrix of a graph. \\\\ \\hline\n\t\t\t\t$\\mathbf{x} \\in \\mathbf{R}^n$ & The feature vector of a graph in the case of $d=1$. \\\\ \\hline\n\t\t\t\t$\\mathbf{x}_v \\in \\mathbf{R}^d$ & The feature vector of the node $v$. \\\\ \\hline\n\t\t\t\t$\\mathbf{X}^e \\in \\mathbf{R}^{m\\times c}$ & The edge feature matrix of a graph. \\\\ \\hline\n\t\t\t\t$\\mathbf{x}^e_{(v,u)} \\in \\mathbf{R}^{c}$ & The edge feature vector of the edge $(v,u)$. \\\\ \\hline\n\t\t\t\t$\\mathbf{X}^{(t)} \\in \\mathbf{R}^{n\\times d}$ & The node feature matrix of a graph at the time step $t$. \\\\ \\hline\n\t\t\t\t$\\mathbf{H} \\in \\mathbf{R}^{n \\times b}$ & The node hidden feature matrix. \\\\ \\hline\n\t\t\t\t$\\mathbf{h}_v \\in \\mathbf{R}^{b}$ & The hidden feature vector of node $v$. \\\\ \\hline\n\t\t\t\t$k$ & The layer index \\\\ \\hline\n\t\t\t\t$t$ & The time step/iteration index  \\\\ \\hline\n\t\t\t\t$\\sigma(\\cdot)$ & The sigmoid activation function. \\\\ \\hline\n\t\t\t\t$\\sigma_h(\\cdot)$ & The tangent hyperbolic activation function. \\\\ \\hline\t$\\mathbf{W},\\mathbf{\\Theta},w,\\theta$ & Learnable model parameters. \\\\  \n\t\t\t\t\\bottomrule\n\t\t\\end{tabular}\n\t\\end{table}", "cites": [214, 211, 8313, 219, 218, 8330, 220, 7213, 7007, 212, 7212, 216, 213, 217, 215], "cite_extract_rate": 0.5357142857142857, "origin_cites_number": 28, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.5, "critical": 3.0, "abstraction": 3.5}, "insight_level": "medium", "analysis": "The section synthesizes historical developments of GNNs, connecting key works across RecGNNs, ConvGNNs, and related methods like network embedding and graph kernels. It provides a critical comparison by highlighting limitations (e.g., computational expense of RecGNNs, pair-wise similarity bottlenecks in graph kernels) and distinguishing GNNs from alternative approaches. It also abstracts by framing broader design principles and categorization strategies, though it could offer deeper conceptual unification or novel insights for a higher rating."}}
{"id": "ee1a1414-0cdc-4dc2-877d-7e1b8a4a76a5", "title": "Categorization and  Frameworks", "level": "section", "subsections": ["451c6a2b-2b4e-4f5c-b5bc-1327b4039d75", "437f9624-bfd3-4a50-9659-1e7241453981"], "parent_id": "bd162e79-adf5-413e-a1f4-ec18c4226195", "prefix_titles": [["title", " A Comprehensive Survey on Graph Neural Networks"], ["section", "Categorization and  Frameworks"]], "content": "\\label{sec:categorization}\n\tIn this section, we present our taxonomy of graph neural networks (GNNs), as shown in Table \\ref{tab:pub}. We categorize graph neural networks (GNNs) into recurrent graph neural  networks (RecGNNs), convolutional graph neural networks (ConvGNNs), graph autoencoders (GAEs), and  spatial-temporal graph neural networks (STGNNs). Figure \\ref{manygcn} gives examples of various model architectures. \n\tIn the following, we give a brief introduction of each category.\n\t\\begin{table*}[htb]\n\t\t\\caption{Taxonomy and representative publications of Graph Neural Networks (GNNs)}\n\t\t\\label{tab:pub}\n\t\t\\centering\n\t\t\\begin{tabular}{l l l}\n\t\t\t\\toprule\n\t\t\t\\multicolumn{2}{l}{Category}                               & Publications \\\\ \\midrule\n\t\t\t\\multicolumn{2}{l}{Recurrent Graph Neural Networks (RecGNNs)} &  \\\\ \\midrule\n\t\t\t\\multirow{2}{*}{} & Spectral methods &              \\\\ \\cline{2-3} \n\t\t\tConvolutional Graph Neural Networks (ConvGNNs) & Spatial methods  & \\begin{tabular}[c]{@{}l@{}} \\\\\n\t\t\t   \\\\\n\t\t\t\\\\\n\t\t\t\\end{tabular}\\\\ \\midrule\n\t\t\t\\multirow{2}{*}{Graph Autoencoders (GAEs)} & Network Embedding &  \n                       \\\\ \\cline{2-3} \n             & Graph Generation &  \\\\ \\midrule\n\t\t\t\\multicolumn{2}{l}{Spatial-temporal Graph Neural Networks (STGNNs)}        &              \\\\ \\bottomrule\n\t\t\\end{tabular}\n\t\\end{table*}\n\t\\begin{figure}[htp]\n\t\t\\centering\n        \\subfloat[A ConvGNN with multiple graph convolutional layers.  A graph convolutional layer encapsulates each node's hidden representation by aggregating feature information from its neighbors. After feature aggregation, a non-linear transformation is applied to the resulted outputs. By stacking multiple layers, the final hidden representation of each node receives messages from a further neighborhood.]{\\includegraphics[width=3.5in]{fig/gcn1.pdf}\n\t\t\t    \\label{fig:gcn}\n        }\n        \\hfill\n\t\t\\subfloat[A ConvGNN with pooling and readout layers for graph classification . A graph convolutional layer is followed by a pooling layer to coarsen a graph into sub-graphs so that node representations on coarsened graphs represent higher graph-level representations. A readout layer summarizes the final graph representation by taking the sum/mean of hidden representations of sub-graphs. ]{\\includegraphics[width=3.5in]{fig/gcnpool1.pdf}\n\t\t\t\\label{fig:gcnpool}}\n\t\t\\hfill\n\t\t\\subfloat[A GAE for network embedding . The encoder uses graph convolutional layers to get a network embedding for each node. The decoder computes the pair-wise distance given network embeddings. After applying a non-linear activation function, the decoder reconstructs the graph adjacency matrix. The network is trained by minimizing the discrepancy between the real adjacency matrix and the reconstructed adjacency matrix.   ]{\\includegraphics[width=3.5in]{fig/gae1.pdf}\n\t\t\t\\label{fig:gae}}\n\t\t\\hfill\n\t\t\\subfloat[A STGNN for spatial-temporal graph forecasting . A graph convolutional layer is followed by a 1D-CNN layer. The graph convolutional layer operates on $A$ and $X^{(t)}$ to capture the spatial dependency, while the 1D-CNN layer slides over $X$ along the time axis to capture the temporal dependency. The output layer is a linear transformation, generating a prediction for each node, such as its future value at the next time step. ]{\\includegraphics[width=3.5in]{fig/stgcn1.pdf}\n\t\t\t\\label{fig:gst}}\n\t\t\\caption{Different graph neural network models built with graph convolutional layers. The term Gconv denotes a graph convolutional layer. The term MLP denotes a multi-layer perceptron. The term CNN denotes a standard convolutional layer. }\n\t\t\\label{manygcn}\n\t\\end{figure}", "cites": [7009, 231, 242, 225, 211, 8313, 27, 227, 240, 221, 238, 220, 237, 224, 222, 25, 226, 233, 228, 7213, 232, 8312, 7212, 241, 180, 216, 213, 239, 223, 230, 235, 7214, 23, 236, 229, 234], "cite_extract_rate": 0.7058823529411765, "origin_cites_number": 51, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 1.5, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section provides a taxonomy of GNNs and references various papers, but it does not synthesize or connect ideas across them effectively. It lacks critical evaluation or comparison of the cited works and offers minimal abstraction, primarily describing the categories and model components without deeper insights or analysis."}}
{"id": "451c6a2b-2b4e-4f5c-b5bc-1327b4039d75", "title": "Taxonomy of Graph Neural Networks (GNNs)", "level": "subsection", "subsections": [], "parent_id": "ee1a1414-0cdc-4dc2-877d-7e1b8a4a76a5", "prefix_titles": [["title", " A Comprehensive Survey on Graph Neural Networks"], ["section", "Categorization and  Frameworks"], ["subsection", "Taxonomy of Graph Neural Networks (GNNs)"]], "content": "\\noindent\\textbf{Recurrent graph neural networks (RecGNNs)} \n    mostly are pioneer works of graph neural networks. RecGNNs aim to learn node representations with recurrent neural architectures. They assume a node in a graph constantly exchanges information/message with its neighbors until a stable equilibrium is reached. \n    RecGNNs are conceptually important and inspired later research on convolutional graph neural networks.\n    In particular, the idea of message passing is inherited by spatial-based convolutional graph neural networks. \n    \\vspace{1mm}\n    \\noindent\\textbf{Convolutional graph neural networks (ConvGNNs)} generalize the operation of \\textit{convolution} from grid data to graph data. The main idea is to generate a node $v$'s representation by aggregating its own features  $\\mathbf{x}_v$ and neighbors' features $\\mathbf{x}_u$, where $u \\in N(v)$.\n    Different from RecGNNs, ConvGNNs stack multiple graph convolutional layers to extract  high-level node representations. \n    ConvGNNs play a central role in building up many other complex GNN models. Figure \\ref{fig:gcn} shows a ConvGNN for node classification. Figure \\ref{fig:gcnpool} demonstrates a ConvGNN for graph classification.\n    \\vspace{1mm}\\noindent\\textbf{Graph autoencoders (GAEs)} are unsupervised learning frameworks which encode nodes/graphs into a latent vector space and reconstruct graph data from the encoded information. GAEs are used to learn network embeddings and graph generative distributions. For network embedding, GAEs learn latent node representations through reconstructing graph structural information such as the graph adjacency matrix. For graph generation, some methods generate nodes and edges of a graph step by step while other methods output a graph all at once. Figure \\ref{fig:gae} presents a GAE for network embedding.\n    \\vspace{1mm}\\noindent\\textbf{Spatial-temporal graph neural networks (STGNNs)} aim to learn hidden patterns from spatial-temporal graphs, which become increasingly important in a variety of applications such as traffic speed forecasting , driver maneuver anticipation , and  human action recognition . \n    The key idea of STGNNs is to consider spatial dependency and temporal dependency at the same time. Many current approaches integrate graph convolutions to capture spatial dependency with RNNs or CNNs to model the temporal dependency. Figure \\ref{fig:gst} illustrates a STGNN for spatial-temporal graph forecasting.", "cites": [225, 23], "cite_extract_rate": 0.6666666666666666, "origin_cites_number": 3, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.5, "critical": 2.0, "abstraction": 2.5}, "insight_level": "medium", "analysis": "The section provides a clear overview of different GNN categories, including RecGNNs, ConvGNNs, GAEs, and STGNNs, and makes minimal connections to the cited papers, such as mentioning their application areas. However, it lacks deeper synthesis across multiple works and does not offer a comparative or critical evaluation of the cited methods. The abstraction is limited to general definitions and typical use cases of each category."}}
{"id": "437f9624-bfd3-4a50-9659-1e7241453981", "title": "Frameworks", "level": "subsection", "subsections": [], "parent_id": "ee1a1414-0cdc-4dc2-877d-7e1b8a4a76a5", "prefix_titles": [["title", " A Comprehensive Survey on Graph Neural Networks"], ["section", "Categorization and  Frameworks"], ["subsection", "Frameworks"]], "content": "With the graph structure and node content information as inputs,  the outputs of  GNNs can focus on different graph analytics tasks with one of the following mechanisms:\n\t\\begin{itemize}\n\t\t\\item \\textbf{Node-level} outputs relate to node regression and node classification tasks. RecGNNs and ConvGNNs can extract high-level node representations by information propagation/graph convolution. With a multi-perceptron or a softmax layer as the output layer, GNNs are able to perform node-level tasks in an end-to-end manner.\n\t\t\\item \\textbf{Edge-level} outputs relate to the edge classification and link prediction tasks.  With two nodes' hidden representations from GNNs as inputs, a similarity function or a neural network can be utilized to predict the label/connection strength of an edge.\n\t\t\\item \\textbf{Graph-level} outputs relate to the graph classification task. To obtain a compact representation on the graph level, GNNs are often combined with pooling and readout operations. Detailed information about pooling and readouts will be reviewed in Section \\ref{sec:pooling}.\n\t\\end{itemize}\n    \\vspace{2mm}\n    \\textit{Training Frameworks.} Many GNNs (e.g., ConvGNNs) can be trained in a (semi-) supervised or purely unsupervised way within an end-to-end learning framework, depending on the learning tasks and label information available at hand.\n    \\begin{itemize}\n        \\item \\textbf{Semi-supervised learning for node-level classification.} Given a single network with partial nodes being labeled and others remaining unlabeled, ConvGNNs can learn a robust model that effectively identifies the class labels for the unlabeled nodes . To this end, an end-to-end framework can be built by stacking a couple of graph convolutional layers followed by a softmax layer for multi-class classification. \n        \\item \\textbf{Supervised learning for graph-level classification.} Graph-level classification aims to predict the class label(s) for an entire graph . The end-to-end learning for this task can be realized with a combination of graph convolutional layers, graph pooling layers, and/or readout layers. While graph convolutional layers are responsible for exacting high-level node representations, graph pooling layers play the role of down-sampling, which coarsens each graph into a sub-structure each time. A readout layer collapses node representations of each graph into a graph representation. \n        By applying a multi-layer perceptron and a softmax layer to graph representations, we can build an end-to-end framework for graph classification. An example is given in Fig \\ref{fig:gcnpool}.\n        \\item \\textbf{Unsupervised learning for graph embedding.} When no class labels are available in graphs, we can learn the graph embedding in a purely unsupervised way in an end-to-end framework. These algorithms exploit edge-level information in two ways. One simple way is to adopt an autoencoder framework where the encoder employs graph convolutional layers to embed the graph into the latent representation upon which a decoder is used to reconstruct the graph structure .  Another popular way is to utilize the negative sampling approach which samples a portion of node pairs as negative pairs while existing node pairs with links in the graphs are positive pairs. Then a logistic regression layer is applied to distinguish between positive and negative pairs . \n    \\end{itemize}\n    In Table \\ref{tab:summary_gcn}, we summarize the main characteristics of representative RecGNNs and ConvGNNs. Input sources, pooling layers, readout layers, and time complexity are compared among various models. In more detail, we only compare the time complexity of the message passing/graph convolution operation in each model. As methods in  and  require eigenvalue decomposition, the time complexity is $O(n^3)$. The time complexity of  is also $O(n^3)$ due to the node pair-wise shortest path computation.  Other methods incur equivalent time complexity, which is $O(m)$ if the graph adjacency matrix is sparse and is $O(n^2)$ otherwise. This is because in these methods the computation of each node $v_i$'s representation involves its $d_i$ neighbors, and the sum of $d_i$ over all nodes exactly equals the number of edges. The time complexity of several methods are missing in Table \\ref{tab:summary_gcn}. These methods either lack a time complexity analysis in their papers or report the time complexity of their overall models or algorithms. \n    \\begin{table*}[]\n    \t\\caption{Summary of RecGNNs and ConvGNNs. \n    \tMissing values (``-\") in pooling and readout layers indicate that the method only experiments on node-level/edge-level tasks. \n    \t}\n\t\t\\label{tab:summary_gcn}\n\t\t\\centering\n        \\begin{tabular}{l l l l l l }\n        \\toprule\n        \\multirow{2}{*}{Approach} & \\multirow{2}{*}{Category} & \\multirow{2}{*}{Inputs}  & \\multirow{2}{*}{Pooling}  & \\multirow{2}{*}{Readout} & \\multirow{2}{*}{Time Complexity} \\\\ \n        &&&&& \\\\ \\midrule\n        GNN* (2009) & RecGNN & $A,X,X^e$ & - &  a dummy super node          & $O(m)$ \\\\ \\midrule\n        GraphESN (2010)  & RecGNN & $A,X$ & - & mean & $O(m)$\\\\ \\midrule\n        GGNN (2015)  & RecGNN & $A,X$ & - & attention sum & $O(m)$ \\\\ \\midrule\n        SSE (2018)  & RecGNN & $A,X$ & - & - & - \\\\ \\midrule\n        Spectral CNN (2014) &  Spectral-based ConvGNN &  $A,X$   & spectral clustering+max pooling & max & $O(n^3)$ \\\\ \\midrule\n        Henaff et al. (2015)  & Spectral-based ConvGNN&  $A,X$   & spectral clustering+max pooling &  & $O(n^3)$ \\\\ \\midrule\n        ChebNet (2016)  & Spectral-based ConvGNN & $A,X$ &  efficient pooling & sum & $O(m)$ \\\\ \\midrule\n        GCN (2017)  & Spectral-based ConvGNN & $A,X$ & - & - & $O(m)$ \\\\ \\midrule\n        CayleyNet (2017) & Spectral-based ConvGNN & $A,X$ & mean/graclus pooling & - & $O(m)$\\\\ \\midrule\n        AGCN (2018)  & Spectral-based ConvGNN &$A,X$ & max pooling & sum & $O(n^2)$ \\\\ \\midrule\n        DualGCN (2018)  & Spectral-based ConvGNN & $A,X$ & - & - & $O(m)$\\\\ \\midrule\n        NN4G (2009)  & Spatial-based ConvGNN & $A,X$ & - & sum/mean &$O(m)$ \\\\ \\midrule\n        DCNN (2016)  & Spatial-based ConvGNN & $A,X$ & - & mean & $O(n^2)$ \\\\ \\midrule\n        PATCHY-SAN (2016)  & Spatial-based ConvGNN & $A,X,X^e$  &  - & sum & -\\\\ \\midrule\n        MPNN (2017)  & Spatial-based ConvGNN & $A,X,X^e$ & - & attention sum/set2set & $O(m)$ \\\\ \\midrule\n        GraphSage (2017)  & Spatial-based ConvGNN & $A,X$ & - & - & - \\\\ \\midrule\n        GAT (2017)  & Spatial-based ConvGNN & $A,X$ & - & - & $O(m)$\\\\ \\midrule\n        MoNet (2017)  & Spatial-based ConvGNN & $A,X$ & - & - & $O(m)$  \\\\ \\midrule\n        LGCN (2018)  & Spatial-based ConvGNN & $A,X$ & - & - & -\\\\ \\midrule\n        PGC-DGCNN (2018)  & Spatial-based ConvGNN & $A,X$ & sort pooling & attention sum & $O(n^3)$ \\\\ \\midrule\n        CGMM (2018)  &Spatial-based ConvGNN & $A,X,X^e$ & - & sum & - \\\\ \\midrule\n        GAAN (2018)  & Spatial-based ConvGNN &$A,X$ & - & - & $O(m)$ \\\\ \\midrule\n        FastGCN (2018)  & Spatial-based ConvGNN & $A,X$ & - & - & - \\\\ \\midrule\n        StoGCN (2018)  & Spatial-based ConvGNN & $A,X$ & - & - & - \\\\ \\midrule\n        Huang et al. (2018)  & Spatial-based ConvGNN & $A,X$ & - & - & - \\\\ \\midrule\n        DGCNN (2018)  & Spatial-based ConvGNN & $A,X$ & sort pooling &  - & $O(m)$ \\\\ \\midrule\n        DiffPool (2018) & Spatial-based ConvGNN & $A,X$ & differential pooling & mean & $O(n^2)$ \\\\ \\midrule\n        GeniePath (2019)  & Spatial-based ConvGNN & $A,X$ & - & - & $O(m)$  \\\\ \\midrule\n        DGI (2019)  & Spatial-based ConvGNN & $A,X$ & - & - & $O(m)$ \\\\ \\midrule\n        GIN (2019)  & Spatial-based ConvGNN &$A,X$ & - & sum &  $O(m)$ \\\\ \\midrule\n        ClusterGCN (2019)  & Spatial-based ConvGNN & $A,X$ & - & - & - \\\\ \\midrule\n        \\end{tabular}\n        \\end{table*}", "cites": [231, 242, 211, 8313, 27, 240, 220, 237, 224, 226, 233, 228, 7213, 232, 239, 241, 213, 7212, 216, 180, 223, 230, 235, 229, 234], "cite_extract_rate": 0.7142857142857143, "origin_cites_number": 35, "insight_result": {"type": "comparative", "scores": {"synthesis": 3.5, "critical": 2.5, "abstraction": 3.0}, "insight_level": "medium", "analysis": "The section synthesizes information from multiple papers to categorize GNNs by task level (node, edge, graph) and training approach, showing a basic level of integration. It includes a comparative table that organizes models by input, pooling, readout, and time complexity, which provides some structure. However, it lacks deeper critical evaluation of the methods' strengths and weaknesses and offers limited abstraction beyond the listed features."}}
{"id": "8fcdb31f-f590-41e8-bb05-0d217c2c9b41", "title": "Recurrent Graph Neural Networks", "level": "section", "subsections": [], "parent_id": "bd162e79-adf5-413e-a1f4-ec18c4226195", "prefix_titles": [["title", " A Comprehensive Survey on Graph Neural Networks"], ["section", "Recurrent Graph Neural Networks"]], "content": "\\label{sec:grn}\n    Recurrent graph neural networks (RecGNNs) are mostly pioneer works of GNNs.  They apply the same set of parameters recurrently over nodes in a graph to extract high-level node representations. Constrained by computational power, earlier research mainly focused on directed acyclic graphs .\n    Graph Neural Network (GNN*\\footnote{As GNN is used to represent broad graph neural networks in the survey, we name this particular method GNN* to avoid ambiguity.}) proposed by Scarselli et al. extends prior recurrent models to handle general types of graphs, e.g., acyclic, cyclic, directed, and undirected graphs .  Based on an information diffusion mechanism, GNN* updates nodes' states by exchanging neighborhood information recurrently until a stable equilibrium is reached.  A node's hidden state is recurrently updated by\n    \\begin{equation}\n    \\label{eq:gnn}\n    \\mathbf{h}_v^{(t)} = \\sum_{u\\in N(v)}f(\\mathbf{x}_v,\\mathbf{x^e}_{(v,u)}, \\mathbf{x}_{u}, \\mathbf{h}^{(t-1)}_{u}),\n    \\end{equation}\n    where $f(\\cdot)$ is a parametric function, and $\\mathbf{h}^{(0)}_v$ is initialized randomly. The sum operation enables GNN* to be applicable to all nodes, even if the number of neighbors differs and no neighborhood ordering is known. \n    To ensure convergence, the recurrent function $f(\\cdot)$ must be a contraction mapping, which shrinks the distance between two points after projecting them into a latent space. \n    In the case of $f(\\cdot)$ being a neural network, a penalty term has to be imposed on the Jacobian matrix of parameters.  \n    When a convergence criterion is satisfied,  the last step node hidden states are forwarded to a readout layer. GNN* alternates the stage of node state propagation and the stage of parameter gradient computation to minimize a training objective.  This strategy enables GNN* to handle cyclic graphs.  In follow-up works,  Graph Echo State Network (GraphESN)  extends echo state networks to improve the training efficiency of GNN*. GraphESN consists of an encoder and an output layer. The encoder is randomly initialized and requires no training. It implements a contractive state transition function to recurrently update node states until the global graph state reaches convergence. Afterward, the output layer is trained by taking the fixed node states as inputs.\n    Gated Graph Neural Network (GGNN)  employs a gated recurrent unit (GRU)  as a recurrent function, reducing the recurrence to a fixed number of steps. The advantage is that it no longer needs to constrain parameters to ensure convergence. A node hidden state is updated by its previous hidden states and its neighboring hidden states, defined as\n    \\begin{equation}\n    \\mathbf{h}_v^{(t)} = GRU(\\mathbf{h}_v^{(t-1)},\\sum_{u\\in N(v)}\\mathbf{W}\\mathbf{h}_u^{(t-1)}),\n    \\end{equation}\n    where $\\mathbf{h}_v^{(0)}=\\mathbf{x}_v$.\n     Different from GNN* and GraphESN, GGNN uses the back-propagation through time (BPTT) algorithm to learn the model parameters.  This can be problematic for large graphs, as GGNN needs to run the recurrent function multiple times over all nodes, requiring the intermediate states of all nodes to be stored in memory.\n    Stochastic Steady-state Embedding (SSE) proposes a learning algorithm that is more scalable to large graphs . SSE updates node hidden states recurrently in a stochastic and asynchronous fashion.  It alternatively samples a batch of nodes for state update and a batch of nodes for gradient computation. To maintain stability, the recurrent function of SSE is defined as a weighted average of the historical states and new states, which takes the form\n    \\begin{equation}\n    \\label{eq:sse1}\n    \\mathbf{h}_v^{(t)} = (1-\\alpha)\\mathbf{h}_v^{(t-1)}+\\alpha \\mathbf{W_1}\\sigma(\\mathbf{W_2}[\\mathbf{x}_v,\\sum_{u\\in N(v)}[\\mathbf{h}_u^{(t-1)},\\mathbf{x}_u]]),\n    \\end{equation}\n    where $\\alpha$ is a hyper-parameter, and $\\mathbf{h}_v^{(0)}$ is initialized randomly.  While conceptually important, SSE does not theoretically prove that the node states will gradually converge to fixed points by applying Equation \\ref{eq:sse1} repeatedly.", "cites": [243, 211], "cite_extract_rate": 0.2857142857142857, "origin_cites_number": 7, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.5, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section synthesizes information from multiple works, including GNN*, GraphESN, GGNN, and SSE, and integrates them into a coherent narrative about the evolution and characteristics of Recurrent GNNs. It provides critical analysis by pointing out limitations such as the lack of theoretical convergence proof in SSE and memory issues in GGNN. The section also abstracts the underlying principles of recurrence in GNNs, such as convergence strategies and state update mechanisms, offering a meta-level understanding of the category."}}
{"id": "295e8f13-8848-4c03-a217-b5b07c87ff6c", "title": "Spectral-based ConvGNNs", "level": "subsection", "subsections": [], "parent_id": "a40bc631-56aa-4de4-9059-a986cd955767", "prefix_titles": [["title", " A Comprehensive Survey on Graph Neural Networks"], ["section", "Convolutional Graph Neural  Networks"], ["subsection", "Spectral-based ConvGNNs"]], "content": "\\label{sec:spectral_gcn}\n\t\\vspace{2mm}\n\t\\textbf{Background} Spectral-based methods have a solid mathematical foundation in graph signal processing . They assume graphs to be undirected. The normalized graph Laplacian matrix is a mathematical representation of an undirected graph, defined as $\\mathbf{L}=\\mathbf{I_n}- \\mathbf{D}^{-\\frac{1}{2}}\\mathbf{A}\\mathbf{D}^{-\\frac{1}{2}}$, where $\\mathbf{D}$ is a diagonal matrix of node degrees, $\\mathbf{D}_{ii}=\\sum_j(\\mathbf{A}_{i,j})$. The normalized graph Laplacian matrix possesses the property of being real symmetric positive semidefinite.  With this property, the normalized Laplacian matrix can be factored as $\\mathbf{L}=\\mathbf{U}\\mathbf{\\Lambda}\\mathbf{U}^T$, where $\\mathbf{U}=[\\mathbf{u_0},\\mathbf{u_1},\\cdots,\\mathbf{u_{n-1}}] \\in \\mathbf{R}^{n\\times n}$ is the matrix of eigenvectors ordered by eigenvalues and $\\mathbf{\\Lambda}$ is the diagonal matrix of eigenvalues (spectrum), $\\mathbf{\\Lambda}_{ii}=\\lambda_i$. The eigenvectors of the normalized Laplacian matrix form an orthonormal space, in mathematical words $\\mathbf{U}^T\\mathbf{U}=\\mathbf{I}$.  In graph signal processing, a graph signal $\\mathbf{x} \\in  \\mathbf{R}^n$ is a feature vector of all nodes of a graph where $x_i$ is the value of the $i^{th}$ node. The \\textit{graph Fourier transform} to a signal $\\mathbf{x}$ is defined as $\\mathscr{F}(\\mathbf{x}) = \\mathbf{U}^T\\mathbf{x}$, and the inverse graph Fourier transform  is defined as $\\mathscr{F}^{-1}(\\mathbf{\\hat{x}}) = \\mathbf{U}\\hat{\\mathbf{x}}$, where $\\mathbf{\\hat{x}}$ represents the resulted signal from the graph Fourier transform. The graph Fourier transform projects the input graph signal to the orthonormal space where the basis is formed by eigenvectors of the normalized graph Laplacian. Elements of the transformed signal $\\mathbf{\\hat{x}}$  are the coordinates of the graph signal in the new space so that the input signal can be represented as $\\mathbf{x}=\\sum_i \\hat{x}_i\\mathbf{u}_i$, which is exactly the inverse graph Fourier transform. Now the graph convolution of the input signal $\\mathbf{x}$ with a filter $\\mathbf{g}\\in \\mathbf{R}^n$ is defined as \n\t\\begin{equation}\n\t\\label{eq:graphconv}\n\t\\begin{aligned}\n\t\\mathbf{x} \\ast_G \\mathbf{g}&= \\mathscr{F}^{-1}(\\mathscr{F}(\\mathbf{x})\\odot\\mathscr{F}(\\mathbf{g})) \\\\\n\t&  = \\mathbf{U}(\\mathbf{U}^T\\mathbf{x}\\odot \\mathbf{U}^T \\mathbf{g}),\n\t\\end{aligned}\n\t\\end{equation}\n\twhere $\\odot$ denotes the element-wise product.  If we denote a filter as $\\mathbf{g_\\theta} = diag(\\mathbf{U}^T\\mathbf{g})$, then the spectral graph convolution is simplified as \n\t\\begin{equation}\n\t\\label{eq:2}\n\t\\mathbf{x} \\ast_G \\mathbf{g_\\theta} = \\mathbf{U}\\mathbf{g_\\theta} \\mathbf{U}^T\\mathbf{x}.\n\t\\end{equation}\n\tSpectral-based ConvGNNs all follow this definition. The key difference lies in the choice of the filter $\\mathbf{g_\\theta}$.\n\tSpectral Convolutional Neural Network (Spectral CNN)  assumes the filter $\\mathbf{g_\\theta}=\\mathbf{\\Theta}_{i,j}^{(k)}$ is a set of learnable parameters and considers graph signals with multiple channels. The graph convolutional layer of Spectral CNN is defined as \n\t\\begin{equation}\n\t\\label{eq:3}\n\t\\mathbf{H}_{:,j}^{(k)} = \\sigma(\\sum_{i=1}^{f_{k-1}}\\mathbf{U}\\mathbf{\\Theta}_{i,j}^{(k)}\\mathbf{U}^T\\mathbf{H}_{:,i}^{(k-1)}) \\quad(j=1,2,\\cdots, f_k),\n\t\\end{equation}\n\twhere $k$ is the layer index, $\\mathbf{H}^{(k-1)} \\in \\mathbf{R}^{n\\times f_{k-1}}$ is the input graph signal, $\\mathbf{H}^{(0)}=\\mathbf{X}$, $f_{k-1}$ is the number of input channels and $f_k$ is the number of  output channels, $\\mathbf{\\Theta}_{i,j}^{(k)}$ is a diagonal matrix filled with learnable parameters.  Due to the eigen-decomposition of the Laplacian matrix, Spectral CNN faces three limitations. First, any perturbation to a graph results in a change of eigenbasis. Second, the learned filters are domain dependent, meaning they cannot be applied to a graph with a different structure. Third, eigen-decomposition requires $O(n^3)$ computational complexity.  In follow-up works, ChebNet  and GCN  reduce the computational complexity to $O(m)$ by making several approximations and simplifications. \n\tChebyshev Spectral CNN (ChebNet)  approximates the filter $\\mathbf{g}_\\theta$ by Chebyshev polynomials of the diagonal matrix of eigenvalues, i.e, $\\mathbf{g_\\theta}= \\sum_{i=0}^{K} \\theta_i T_i(\\mathbf{\\tilde{\\Lambda}})$, where $\\mathbf{\\tilde{\\Lambda}} = 2\\mathbf{\\Lambda}/\\lambda_{max}-\\mathbf{I_n}$, and the values of $\\mathbf{\\tilde{\\Lambda}}$ lie in $[-1,1]$. The Chebyshev polynomials are defined recursively by $T_i(\\mathbf{x}) = 2\\mathbf{x}T_{i-1}(\\mathbf{x})-T_{i-2}(\\mathbf{x})$ with $T_0(\\mathbf{x}) = 1$ and $T_1(\\mathbf{x})=\\mathbf{x}$. As a result, the convolution of a graph signal $\\mathbf{x}$ with the defined filter $\\mathbf{g_\\theta}$ is \n\t\\begin{equation}\n\t\\label{eq:chebpoly}\n\t\\mathbf{x} \\ast_G \\mathbf{g_\\theta} = \\mathbf{U}(\\sum_{i=0}^{K} \\theta_i T_i(\\mathbf{\\tilde{\\Lambda}}))\\mathbf{U}^T\\mathbf{x}, \\\\\n\t\\end{equation}\n\twhere $\\mathbf{\\tilde{L}} = 2\\mathbf{L}/\\lambda_{max}-\\mathbf{I_n}$. \n\tAs $T_i(\\mathbf{\\tilde{L}})=\\mathbf{U}T_i(\\mathbf{\\tilde{\\Lambda}})\\mathbf{U}^T$, which can be proven by induction on $i$, ChebNet takes the form, \n\t\\begin{equation}\n\t\\label{eq:chebnet}\n\t\\mathbf{x} \\ast_G \\mathbf{g_\\theta} = \\sum_{i=0}^{K} \\theta_iT_i(\\mathbf{\\tilde{L}})\\mathbf{x}, \n\t\\end{equation}\n\tAs an improvement over Spectral CNN, the filters defined by ChebNet are localized in space, which means filters can extract local features independently of the graph size. The spectrum of ChebNet is mapped to $[-1,1]$ linearly. CayleyNet  further applies Cayley polynomials which are parametric rational complex functions to capture narrow frequency bands. The spectral graph convolution of CayleyNet is defined as \n\t\\begin{equation}\n\t    \\mathbf{x} \\ast_G \\mathbf{g_\\theta} = c_0\\mathbf{x}+2Re\\{\\sum_{j=1}^rc_j(h\\mathbf{L}- i\\mathbf{I})^j(h\\mathbf{L}+ i\\mathbf{I})^{-j}\\mathbf{x}\\},\n\t\\end{equation}\n    where $Re(\\cdot)$ returns the real part of a complex number, $c_0$ is a real coefficent, $c_j$ is a complex coefficent, $i$ is the imaginary number, and $h$ is a parameter which controls the spectrum of a Cayley filter. While preserving spatial locality, CayleyNet shows that ChebNet can be considered as a special case of CayleyNet.\n    Graph Convolutional Network (GCN)  introduces a first-order approximation of ChebNet.  Assuming $K=1$ and $\\lambda_{max} = 2$\n\t, Equation \\ref{eq:chebnet} is simplified as \n\t\\begin{equation}\n\t\\label{eq:1stchebnet}\n\t\\mathbf{x} \\ast_G \\mathbf{g_\\theta}= \\theta_0\\mathbf{x}-\\theta_1\\mathbf{D}^{-\\frac{1}{2}}\\mathbf{A}\\mathbf{D}^{-\\frac{1}{2}}\\mathbf{x}.\n\t\\end{equation}\n\tTo restrain the number of parameters and avoid over-fitting, GCN further assume $\\theta=\\theta_0=-\\theta_1$,  leading to the following definition of a graph convolution,\n\t\\begin{equation}\n\t\\label{eq:1stchebnetb}\n\t\\mathbf{x} \\ast_G \\mathbf{g_\\theta} = \\theta(\\mathbf{I_n}+\\mathbf{D}^{-\\frac{1}{2}}\\mathbf{A}\\mathbf{D}^{-\\frac{1}{2}})\\mathbf{x}.\n\t\\end{equation}\n\tTo allow multi-channels of inputs and outputs, GCN modifies Equation \\ref{eq:1stchebnetb} into a compositional layer, defined as \n\t\\begin{equation}\n\t\\label{eq:1stchebnetc}\n\t\\mathbf{H}= \\mathbf{X}\\ast_G \\mathbf{g_\\Theta} = f(\\mathbf{\\bar{A}}\\mathbf{X} \\mathbf{\\Theta}),\n\t\\end{equation} \n\twhere $\\mathbf{\\bar{A}} =\\mathbf{I_n}+\\mathbf{D}^{-\\frac{1}{2}}\\mathbf{A}\\mathbf{D}^{-\\frac{1}{2}}$ and $f(\\cdot)$ is an activation function.  Using $\\mathbf{I_n}+\\mathbf{D}^{-\\frac{1}{2}}\\mathbf{A}\\mathbf{D}^{-\\frac{1}{2}}$ empirically causes numerical instability to GCN. To address this problem, GCN applies a normalization trick to replace $\\mathbf{\\bar{A}}=\\mathbf{I_n}+\\mathbf{D}^{-\\frac{1}{2}}\\mathbf{A}\\mathbf{D}^{-\\frac{1}{2}}$ by $\\mathbf{\\bar{A}}=\\tilde{\\mathbf{D}}^{-\\frac{1}{2}}\\tilde{\\mathbf{A}}\\tilde{\\mathbf{D}}^{-\\frac{1}{2}}$ with $\\tilde{\\mathbf{A}}=\\mathbf{A}+\\mathbf{I_n}$ and $\\tilde{\\mathbf{D}}_{ii}=\\sum_j \\tilde{\\mathbf{A}}_{ij}$. \n\tBeing a spectral-based method, GCN can be also interpreted as a spatial-based method. \n\tFrom a spatial-based perspective, GCN can be considered as aggregating feature information from a node's neighborhood. \n\tEquation \\ref{eq:1stchebnetc} can be expressed as\n\t\\begin{equation}\n\t    \\mathbf{h}_v = f(\\mathbf{\\Theta}^T(\\sum_{u\\in\\{N(v)\\cup v\\}} \\bar{A}_{v,u}\\mathbf{x}_u))\\quad \\forall v\\in V.\n\t    \\label{eq:sgcn}\n\t\\end{equation}\n    Several recent works made incremental improvements over GCN  by exploring alternative symmetric matrices.\n    Adaptive Graph Convolutional Network (AGCN)  learns hidden structural relations unspecified by the graph adjacency matrix. It constructs a so-called residual graph adjacency matrix through a learnable distance function which takes two nodes' features as inputs. Dual Graph Convolutional Network (DGCN)  introduces a dual graph convolutional architecture with two graph convolutional layers in parallel. While these two layers share parameters, they use the normalized adjacency matrix $\\mathbf{\\bar{A}}$ and the positive pointwise mutual information (PPMI) matrix which captures nodes co-occurrence information through random walks sampled from a graph. \n    The PPMI matrix is defined as \n\t\\begin{equation}\n\t\\mathbf{PPMI}_{v_1,v_2} = max(\\log (\\frac{count(v_1,v_2)\\cdot |D|}{count(v_1)count(v_2)}),0),\n\t\\end{equation}\n\twhere $v_1,v_2\\in V$, $|D|=\\sum_{v_1,v_2}count(v_1,v_2)$ and the $count(\\cdot)$ function returns the frequency that node $v$ and/or node $u$ co-occur/occur in sampled random walks. By ensembling outputs from dual graph convolutional layers, DGCN encodes both local and global structural information without the need to stack multiple graph convolutional layers.", "cites": [241, 8313, 245, 213, 244, 220], "cite_extract_rate": 0.6666666666666666, "origin_cites_number": 9, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.2, "critical": 3.8, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section provides a strong synthesis of spectral-based ConvGNNs, integrating foundational mathematical concepts from multiple papers to present a coherent narrative of the evolution from Spectral CNN to ChebNet and GCN. It includes critical analysis by highlighting limitations such as computational complexity and domain dependence. The abstraction is evident in how it generalizes the role of filters and normalization in spectral graph convolution, offering broader theoretical insights."}}
{"id": "b3e043da-846a-4ac3-ae85-634ad5757d80", "title": "Spatial-based ConvGNNs", "level": "subsection", "subsections": [], "parent_id": "a40bc631-56aa-4de4-9059-a986cd955767", "prefix_titles": [["title", " A Comprehensive Survey on Graph Neural Networks"], ["section", "Convolutional Graph Neural  Networks"], ["subsection", "Spatial-based ConvGNNs"]], "content": "\\label{sec:spatial_gcn}\n    Analogous to the convolutional operation of a conventional CNN on an image, spatial-based methods define graph convolutions based on a node's spatial relations. Images can be considered as a special form of graph with each pixel representing a node. \n    Each pixel is directly connected to its nearby pixels, as illustrated in Figure \\ref{fig_first_case}.  A filter is applied to a $3\\times 3$ patch by taking the weighted average of pixel values of the central node and its neighbors across each channel. Similarly, the spatial-based graph convolutions convolve the central node's representation with its neighbors' representations to derive the updated representation for the central node, as illustrated in Figure \\ref{fig_second_case}. From another perspective, spatial-based ConvGNNs share the same idea of information propagation/message passing with RecGNNs. The spatial graph convolutional operation essentially propagates node information along edges. \n    Neural Network for Graphs (NN4G) , proposed in parallel with GNN*, is the first work towards spatial-based ConvGNNs. Distinctively different from RecGNNs, NN4G learns graph mutual dependency through a compositional neural architecture with independent parameters at each layer. The neighborhood of a node can be extended through incremental construction of the architecture.\n    NN4G performs graph convolutions by summing up a node's neighborhood information directly. It also applies residual connections and skip connections to memorize information over each layer. As a result, NN4G derives its next layer node states by\n    \\begin{equation}\n        \\mathbf{h}_v^{(k)} = f(\\mathbf{W}^{(k)^T}\\mathbf{x}_v+\\sum_{i=1}^{k-1}\\sum_{u\\in N(v)}\\mathbf{\\Theta}^{(k)^T}\\mathbf{h}_u^{(k-1)}),\n        \\label{eq:nn4g}\n    \\end{equation}\n    where $f(\\cdot)$ is an activation function and $\\mathbf{h}_v^{(0)}=\\mathbf{0}$.  Equation \\ref{eq:nn4g} can also be written in a matrix form:\n    \\begin{equation}\n        \\mathbf{H}^{(k)} = f(\\mathbf{X}\\mathbf{W}^{(k)}+\\sum_{i=1}^{k-1}\\mathbf{A}\\mathbf{H}^{(k-1)}\\mathbf{\\Theta}^{(k)}),\n    \\end{equation}\n    which resembles the form of GCN . One difference is that NN4G uses the unnormalized adjacency matrix which may potentially cause hidden node states to have extremely different scales.\n    Contextual Graph Markov Model (CGMM)  proposes a probabilistic model inspired by NN4G. While maintaining spatial locality, CGMM has the benefit of probabilistic interpretability.\n    Diffusion Convolutional Neural Network (DCNN)  regards graph convolutions as a diffusion process. It assumes information is transferred from one node to one of its neighboring nodes with a certain transition probability so that information distribution can reach equilibrium after several rounds. DCNN defines the diffusion graph convolution as\n    \\begin{equation}\n\t\\label{eq:dcnn}\n\t\\mathbf{H}^{(k)} = f(\\mathbf{W}^{(k)}\\odot \\mathbf{P}^{k} \\mathbf{X}),\n\t\\end{equation}\n    where $f(\\cdot)$ is an activation function and the probability transition matrix $\\mathbf{P}\\in\\mathbf{R}^{n\\times n}$ is computed by $\\mathbf{P}= \\mathbf{D}^{-1}\\mathbf{A}$.  Note that in DCNN, the hidden representation matrix $\\mathbf{H}^{(k)}$ remains the same dimension as the input feature matrix $\\mathbf{X}$ and is not a function of its previous hidden representation matrix $\\mathbf{H}^{(k-1)}$. DCNN concatenates $\\mathbf{H}^{(1)},\\mathbf{H}^{(2)},\\cdots,\\mathbf{H}^{( K)} $ together as the final model outputs. As the stationary distribution of a diffusion process is a summation of power series of probability transition matrices, Diffusion Graph Convolution (DGC)  sums up outputs at each diffusion step instead of concatenation. It defines the diffusion graph convolution by\n    \\begin{equation}\n    \\label{eq:dcn}\n    \\mathbf{H} = \\sum_{k=0}^{K} f(\\mathbf{P}^k\\mathbf{X}\\mathbf{W}^{(k)}),\n\\end{equation}\n    where $\\mathbf{W}^{(k)}\\in \\mathbf{R}^{D\\times F}$ and $f(\\cdot)$ is an activation function. \n    Using the power of a transition probability matrix implies that distant neighbors contribute very little information to a central node. PGC-DGCNN  increases the contributions of distant neighbors based on shortest paths.  It defines a shortest path adjacency matrix $\\mathbf{S}^{(j)}$. If the shortest path from a node $v$ to a node $u$ is of length $j$, then $\\mathbf{S}^{(j)}_{v,u}=1$ otherwise 0. With a hyperparameter $r$ to control the receptive field size, PGC-DGCNN introduces a graph convolutional operation as follows \n    \\begin{equation}\n        \\mathbf{H}^{(k)} = \\parallel_{j=0}^r f((\\tilde{\\mathbf{D}}^{(j)})^{-1}\\mathbf{S}^{(j)}\\mathbf{H}^{(k-1)}\\mathbf{W}^{(j,k)}),\n    \\end{equation}\n    where $\\tilde{D}^{(j)}_{ii}=\\sum_l S_{i,l}^{(j)}$, $\\mathbf{H}^{(0)}=\\mathbf{X}$, and $\\parallel$ represents the concatenation of vectors. The calculation of the shortest path adjacency matrix can be expensive with $O(n^3)$ at maximum.  Partition Graph Convolution (PGC)  partitions a node's neighbors into $Q$ groups based on certain criteria not limited to shortest paths.  PGC constructs $Q$ adjacency matrices according to the defined neighborhood by each group. Then, PGC applies GCN  with a different parameter matrix to each neighbor group and sums the results:\n\t\\begin{equation}\n\t\\label{eq:pgcn}\n\t\\mathbf{H}^{(k)} = \\sum_{j=1}^{Q} \\mathbf{\\bar{A}}^{(j)}\\mathbf{H}^{(k-1)}\\mathbf{W}^{(j,k)},\n\t\\end{equation}\n\twhere $\\mathbf{H}^{(0)}=\\mathbf{X}$, $\\mathbf{\\bar{A}}^{(j)}=\\tilde{(\\mathbf{D}}^{(j)})^{-\\frac{1}{2}}\\tilde{\\mathbf{A}}^{(j)}\\tilde{(\\mathbf{D}}^{(j)})^{-\\frac{1}{2}}$ and $\\tilde{\\mathbf{A}}^{(j)}=\\mathbf{A}^{(j)}+\\mathbf{I}$.\n    Message Passing Neural Network (MPNN)  outlines a general framework of spatial-based ConvGNNs. It treats graph convolutions as a message passing process in which information can be passed from one node to another along edges directly. MPNN runs K-step message passing iterations to let information propagate further. The message passing function (namely the spatial graph convolution) is defined as\n\t\\begin{equation}\n\t\\mathbf{h}_v^{(k)} = U_k(\\mathbf{h}_v^{(k-1)},\\sum_{u\\in N(v)} M_k(\\mathbf{h}_v^{(k-1)},\\mathbf{h}_u^{(k-1)},\\mathbf{x}^e_{vu})),\n\t\\end{equation}\n\twhere $\\mathbf{h}_v^{(0)}=\\mathbf{x}_v$, $U_k(\\cdot)$ and $M_k(\\cdot)$ are functions with learnable parameters.  After deriving the hidden representations of each node, $\\mathbf{h}_v^{(K)}$ can be passed to an output layer to perform node-level prediction tasks or to a readout function to perform graph-level prediction tasks.  The readout function generates a representation of the entire graph based on node hidden representations. It is generally defined as\n\t\\begin{equation}\n\t\\mathbf{h}_G = R({\\mathbf{h}_v^{(K)}|v\\in G}),\n\t\\end{equation}\n\twhere $R(\\cdot)$ represents the readout function with learnable parameters. MPNN can cover many existing GNNs by assuming different forms of $U_k(\\cdot),M_k(\\cdot)$, and $R(\\cdot)$, such as . However, Graph Isomorphism Network (GIN)  finds that previous MPNN-based methods are incapable of distinguishing different graph structures based on the graph embedding they produced. To amend this drawback,  GIN adjusts the weight of the central node by a learnable parameter $\\epsilon^{(k)}$. It performs graph convolutions by\n\t\\begin{equation}\n\t    \\mathbf{h}_v^{(k)} = MLP((1+\\epsilon^{(k)})\\mathbf{h}_v^{(k-1)}+\\sum_{u\\in N(v)}\\mathbf{h}_u^{(k-1)}),\n\t\\end{equation}\n    where $MLP(\\cdot)$ represents a multi-layer perceptron.\n    As the number of neighbors of a node can vary from one to a thousand or even more, it is inefficient to take the full size of a node's neighborhood. GraphSage  adopts sampling to obtain a fixed number of neighbors for each node. It performs graph convolutions by \n\t\\begin{equation}\n\t\\mathbf{h}^{(k)}_v=\\sigma(\\mathbf{W}^{(k)}\\cdot f_k(\\mathbf{h}_v^{(k-1)},\\{\\mathbf{h}_u^{(k-1)},\\forall u \\in S_{\\mathcal{N}(v)}\\})),\n\t\\end{equation}\n\twhere $\\mathbf{h}^{(0)}_v=\\mathbf{x}_v$, $f_k(\\cdot)$ is an aggregation function, $S_{\\mathcal{N}(v)}$ is a random sample of the node $v$'s neighbors. The aggregation function should be invariant to the permutations of node orderings such as a mean, sum or max function. \n\t\\begin{figure}[]\n\t\t\\centering\n\t\t\\subfloat[GCN  explicitly assigns a non-parametric weight $a_{ij}=\\frac{1}{\\sqrt{deg(v_i)deg(v_j)}}$ to the neighbor $v_j$ of $v_i$ during the aggregation process. ]{\\includegraphics[width=1.5in]{fig/agg1.pdf}\n\t\t\t\\label{fig:demo_gcn}}\n\t\t\\hfill\n\t\t\\subfloat[GAT  implicitly captures the weight $a_{ij}$ via an end-to-end neural network architecture, so that more important nodes receive larger weights. ]{\\includegraphics[width=1.5in]{fig/agg2.pdf}\n\t\t\t\\label{fig:demo_gat}}\n\t\t\\caption{Differences between GCN  and GAT }\n\t\t\\label{gcn_gat}\n\t\\end{figure}\n\tGraph Attention Network (GAT) \n\tassumes contributions of neighboring nodes to the central node are neither identical like GraphSage , nor pre-determined like GCN  (this difference is illustrated in Figure \\ref{gcn_gat}). GAT adopts attention mechanisms to learn the relative weights between two connected nodes.  The graph convolutional operation according to GAT is defined as,\n\t\\begin{equation}\n\t\\label{eq:13}\n\t\\mathbf{h}_v^{(k)} = \\sigma(\\sum_{u\\in\\mathcal{N}(v)\\cup v}\\alpha_{vu}^{(k)}\\mathbf{W}^{(k)}\\mathbf{h}_u^{(k-1)}),\n\t\\end{equation}\n\twhere $\\mathbf{h}^{(0)}_v=\\mathbf{x}_v$. The attention weight $\\alpha_{vu}^{(k)}$ measures the connective strength between the node $v$ and its neighbor $u$:\n\t\\begin{equation}\n\t    \\alpha_{vu}^{(k)} = softmax(g(\\mathbf{a}^T[\\mathbf{W}^{(k)}\\mathbf{h}_v^{(k-1)}||\\mathbf{W}^{(k)}\\mathbf{h}_u^{(k-1)})),\n\t\\end{equation}\n\twhere $g(\\cdot)$ is a LeakyReLU activation function and $\\mathbf{a}$ is a vector of learnable parameters. The softmax function ensures that the attention weights sum up to one over all neighbors of the node $v$.\n\tGAT further performs the multi-head attention to increase the model's expressive capability. This shows an impressive improvement over GraphSage on node classification tasks. While GAT assumes the contributions of attention heads are equal, Gated  Attention  Network (GAAN)  introduces a self-attention  mechanism  which computes an additional attention score for each attention head. Apart from applying graph attention spatially, GeniePath  further proposes an LSTM-like gating mechanism to control information flow across graph convolutional layers. There are other graph attention models which might be of interest . However, they do not belong to the ConvGNN framework. \n\tMixture Model Network (MoNet) \n    adopts a different approach to assign different weights to a node's neighbors. It introduces node pseudo-coordinates to determine the relative position between a node and its neighbor. Once the relative position between two nodes is known, a weight function maps the relative position to the relative weight between these two nodes. In such a way, the parameters of a graph filter can be shared across different locations.  Under the MoNet framework, several existing approaches for manifolds such as Geodesic CNN (GCNN) , Anisotropic CNN (ACNN) , Spline CNN , and for graphs such as GCN , DCNN  can be generalized as special instances of MoNet by constructing nonparametric weight functions.  MoNet additionally proposes a Gaussian kernel with learnable parameters to learn the weight function adaptively.\n    Another distinct line of works achieve weight sharing across different locations by ranking a node's neighbors based on certain criteria and associating each ranking with a learnable weight. PATCHY-SAN  orders neighbors of each node according to their graph labelings and selects the top $q$ neighbors.  Graph labelings are essentially node scores which can be derived by node degree, centrality, and Weisfeiler-Lehman color .  As each node now has a fixed number of ordered neighbors, graph-structured data can be converted into grid-structured data. PATCHY-SAN applies a standard 1D convolutional filter to aggregate neighborhood feature information where the order of the filter's weights corresponds to the order of a node's neighbors.\n    The ranking criterion of PATCHY-SAN only considers graph structures, which requires heavy computation for data processing.  Large-scale Graph Convolutional Network (LGCN)  ranks a node's neighbors based on node feature information. For each node, LGCN assembles a feature matrix which consists of its neighborhood and sorts this feature matrix along each column. The first $q$ rows of the sorted feature matrix are taken as the input data for the central node. \n\\begin{table*}[]\n\\centering\n\\caption{Time and memory complexity comparison for ConvGNN training algorithms (summarized by ). $n$ is the total number of nodes. $m$ is the total number of edges. $K$ is the number of layers. $s$ is the batch size. $r$ is the number of neighbors being sampled for each node. For simplicity, the dimensions of the node hidden features remain constant, denoted by $d$.}\n\\label{tab:complex}\n\\begin{tabular}{llllll}\n\\toprule\n     Complexity             & GCN  & GraphSage  & FastGCN  & StoGCN   & Cluster-GCN  \\\\ \\midrule\nTime    &  $O(Kmd+Knd^2)$    &   $O(r^Knd^2)$       &  $O(Krnd^2)$       &   $O(Kmd+Knd^2+r^Knd^2)$              &       $O(Kmd+Knd^2)$      \\\\ \\hline\nMemory &  $O(Knd+Kd^2)$   &    $O(sr^Kd+Kd^2)$       &   $O(Ksrd+Kd^2)$      & $O(Knd+Kd^2)$                 &  $O(Ksd+Kd^2)$    \n\\\\ \\bottomrule\n\\end{tabular}\n\\end{table*}\n\t\\vspace{2mm}\n\t\\noindent\\textbf{Improvement in terms of training efficiency}\n\tTraining ConvGNNs such as GCN  usually is required to save the whole graph data and intermediate states of all nodes into memory. The full-batch training algorithm for ConvGNNs suffers significantly from the memory overflow problem, especially when a graph contains millions of nodes.  To save memory,  GraphSage  proposes a batch-training algorithm for ConvGNNs. It samples a tree rooted at each node by recursively expanding the root node's neighborhood by $K$ steps with a fixed sample size. For each sampled tree, GraphSage computes the root node's hidden representation by hierarchically aggregating hidden node representations from bottom to top. \n\tFast Learning with Graph Convolutional Network (FastGCN)  samples a fixed number of nodes for each graph convolutional layer instead of sampling a fixed number of neighbors for each node like GraphSage . It\n    interprets graph convolutions as integral transforms of embedding functions of nodes under probability measures.  Monte Carlo approximation and variance reduction techniques are employed to facilitate the training process.  As FastGCN samples nodes independently for each layer,  between-layers connections are potentially sparse. Huang et al.  propose an adaptive layer-wise sampling approach where node sampling for the lower layer is conditioned on the top one. This method achieves higher accuracy compared to FastGCN at the cost of employing a much more complicated sampling scheme. \n    In another work, Stochastic Training of Graph Convolutional Networks\n    (StoGCN)  reduces the receptive field size of a graph convolution to an arbitrarily small scale using historical node representations as a control variate. StoGCN achieves comparable performance even with two neighbors per node. However, StoGCN still has to save intermediate states of all nodes, which is memory-consuming for large graphs.\n    Cluster-GCN  samples a subgraph using a graph clustering algorithm and performs graph convolutions to nodes within the sampled subgraph. As the neighborhood search is also restricted within the sampled subgraph, Cluster-GCN is capable of handling larger graphs and using deeper architectures at the same time, in less time and with less memory.\n    Cluster-GCN notably provides a straightforward comparison of time complexity and memory complexity for existing ConvGNN training algorithms. We analyze its results based on Table \\ref{tab:complex}. \n    In Table \\ref{tab:complex}, GCN  is the baseline method which conducts the full-batch training. GraphSage saves memory at the cost of sacrificing time efficiency. Meanwhile, the time and memory complexity of GraphSage grows exponentially with an increase of $K$ and $r$. The time complexity of Sto-GCN is the highest, and the bottleneck of the memory remains unsolved. However, Sto-GCN can achieve satisfactory performance with very small $r$. The time complexity of Cluster-GCN remains the same as the baseline method since it does not introduce redundant computations. Of all the methods, Cluster-GCN realizes the lowest memory complexity.\n    \\vspace{2mm}\n\t\\noindent\\textbf{Comparison between spectral and spatial models}\n    Spectral models have a theoretical foundation in graph signal processing. By designing new graph signal filters (e.g., Cayleynets ), one can build new ConvGNNs. However, spatial models are preferred over spectral models due to efficiency, generality, and flexibility issues.\n\tFirst, spectral models are less efficient than spatial models. Spectral models either need to perform eigenvector computation or handle the whole graph at the same time.\n\tSpatial models are more scalable to large graphs as they directly perform convolutions in the graph domain via information propagation. The computation can be performed in a batch of nodes instead of the whole graph. \n    Second, spectral models which rely on a graph Fourier basis generalize poorly to new graphs. They assume a fixed graph. Any perturbations to a graph would result in a change of eigenbasis.\n    Spatial-based models, on the other hand, perform graph convolutions locally on each node where weights can be easily shared across different locations and structures.  \n\tThird, spectral-based models are limited to operate on undirected graphs. \n\tSpatial-based models are more flexible to handle multi-source graph inputs such as edge inputs , directed graphs , signed graphs , and heterogeneous graphs , because these graph inputs can be incorporated into the aggregation function easily.", "cites": [251, 231, 8334, 242, 225, 8333, 27, 7215, 237, 220, 226, 233, 253, 250, 228, 246, 247, 234, 8331, 239, 216, 180, 7212, 223, 230, 252, 235, 23, 8332, 248, 249], "cite_extract_rate": 0.8378378378378378, "origin_cites_number": 37, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.5, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section effectively synthesizes spatial-based ConvGNN methods by connecting core ideas such as message passing, diffusion processes, and sampling techniques across multiple papers. It demonstrates abstraction by framing these methods under a unified concept of spatial graph convolutions and highlights limitations, such as scalability issues. The critical evaluation is evident in the discussion of shortcomings like unnormalized adjacency matrices in NN4G and the inability of some MPNN variants to distinguish graph structures."}}
{"id": "a509c733-8164-47fc-893b-b30a249dafac", "title": "Graph Pooling Modules", "level": "subsection", "subsections": [], "parent_id": "a40bc631-56aa-4de4-9059-a986cd955767", "prefix_titles": [["title", " A Comprehensive Survey on Graph Neural Networks"], ["section", "Convolutional Graph Neural  Networks"], ["subsection", "Graph Pooling Modules"]], "content": "\\label{sec:pooling}\n    After a GNN generates node features, we can use them for the final task. But using all these features directly can be computationally challenging, thus, a down-sampling strategy is needed. Depending on the objective and the role it plays in the network, different names are given to this strategy: (1) the pooling operation aims to reduce the size of parameters by down-sampling the nodes to generate smaller representations and thus avoid overfitting, permutation invariance, and computational complexity issues; (2) the readout operation is mainly used to generate graph-level representation based on node representations. Their mechanism is very similar. In this chapter, we use pooling to refer to all kinds of down-sampling strategies applied to GNNs.\n    In some earlier works, the graph coarsening algorithms use eigen-decomposition to coarsen graphs based on their topological structure. However, these methods suffer from the time complexity issue. The Graclus algorithm  is an alternative of eigen-decomposition to calculate a clustering version of the original graph. Some recent works  employed it as a pooling operation to coarsen graphs. \n    Nowadays, mean/max/sum pooling is the most primitive and effective way to implement down-sampling since calculating the mean/max/sum value in the pooling window is fast:\n    \\begin{equation}\n    \\label{eq:basicpool}\n    \\mathbf{h}_G = mean/max/sum(\\mathbf{h}_1^{(K)}, \\mathbf{h}_2^{(K)}, ..., \\mathbf{h}_n^{(K)}),\n    \\end{equation}\n    where $K$ is the index of the last graph convolutional layer.\n    Henaff et al.  show that performing a simple max/mean pooling at the beginning of the network is especially important to reduce the dimensionality in the graph domain and mitigate the cost of the expensive graph Fourier transform operation. Furthermore, some works  also use attention mechanisms to enhance the mean/sum pooling.\n    Even with attention mechanisms, the reduction operation (such as sum pooling) is not satisfactory since it makes the embedding inefficient: a fixed-size embedding is generated regardless of the graph size. Vinyals et al.  propose the Set2Set method to generate a memory that increases with the size of the input. It then implements an LSTM that intends to integrate order-dependent information into the memory embedding before a reduction is applied that would otherwise destroy that information.\n    Defferrard et al.  address this issue in another way by rearranging nodes of a graph in a meaningful way. They devise an efficient pooling strategy in their approach ChebNet. Input graphs are first coarsened into multiple levels by the Graclus algorithm . After coarsening, the nodes of the input graph and its coarsened version are rearranged into a balanced binary tree. Arbitrarily aggregating the balanced binary tree from bottom to top will arrange similar nodes together. Pooling such a rearranged signal is much more efficient than pooling the original.\n    Zhang et al.  propose the DGCNN with a similar pooling strategy named SortPooling which performs pooling by rearranging nodes to a meaningful order. Different from ChebNet , DGCNN sorts nodes according to their structural roles within the graph. The graph's unordered node features from spatial graph convolutions are treated as continuous WL colors , and they are then used to sort nodes. In addition to sorting the node features, it unifies the graph size to $q$ by truncating/extending the node feature matrix. The last $n-q$ rows are deleted if $n>q$, otherwise $q-n$ zero rows are added. \n    The aforementioned pooling methods mainly consider graph features and ignore the structural information of graphs. Recently, a differentiable pooling (DiffPool)  is proposed, which can generate hierarchical representations of graphs. \n    Compared to all previous coarsening methods, DiffPool does not simply cluster the nodes in a graph but learns a cluster assignment matrix $\\mathbf{S}$ at layer $k$ referred to as $\\mathbf{S}^{(k)} \\in \\mathbf{R}^{n_k \\times n_{k+1}}$, where $n_k$ is the number of nodes at the $k^{th}$ layer. The probability values in matrix $\\mathbf{S}^{(k)}$ are being generated based on node features and topological structure using\n\t\\begin{equation}\n\t\\label{eq:difpool3}\n\t\\mathbf{S}^{(k)} = softmax(ConvGNN_k(\\mathbf{A}^{(k)}, \\mathbf{H}^{(k)})).\n\t\\end{equation}\n    The core idea of this is to learn comprehensive node assignments which consider both topological and feature information of a graph, so Equation \\ref{eq:difpool3} can be implemented with any standard ConvGNNs. \n    However, the drawback of DiffPool is that it generates dense graphs after pooling and thereafter the computational complexity becomes $O(n^2)$. \n    Most recently, the SAGPool  approach is proposed, which considers both node features and graph topology and learns the pooling in a self-attention manner. \n    Overall, pooling is an essential operation to reduce graph size. How to improve the effectiveness and computational complexity of pooling is an open question for investigation.", "cites": [239, 7213, 211, 255, 8313, 220, 216, 224, 254], "cite_extract_rate": 0.75, "origin_cites_number": 12, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.5, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section synthesizes a range of pooling methods for GNNs, effectively connecting different papers to highlight evolution and trends in the field. It provides critical analysis by pointing out limitations such as inefficiency, lack of structural information, and computational complexity. The abstraction is strong as it identifies broader patterns, such as the shift from feature-based to differentiable and attention-based pooling strategies."}}
{"id": "f76fd111-b070-4970-92d4-58907c347096", "title": "Discussion of Theoretical Aspects", "level": "subsection", "subsections": [], "parent_id": "a40bc631-56aa-4de4-9059-a986cd955767", "prefix_titles": [["title", " A Comprehensive Survey on Graph Neural Networks"], ["section", "Convolutional Graph Neural  Networks"], ["subsection", "Discussion of Theoretical Aspects"]], "content": "We discuss the theoretical foundation of graph neural networks from different perspectives.\n\t\\vspace{2mm}\n\t\\noindent\\textbf{Shape of receptive field}\n    The receptive field of a node is the set of nodes that contribute to the determination of its final node representation. When compositing multiple spatial graph convolutional layers, the receptive field of a node grows one step ahead towards its distant neighbors each time. Micheli   prove that a finite number of spatial graph convolutional layers exists such that for each node $v \\in V$ the receptive field of node $v$ covers all nodes in the graph. As a result, a ConvGNN is able to extract global information by stacking local graph convolutional layers.  \n\t\\vspace{2mm}\n\t\\noindent\\textbf{VC dimension}\n\tThe VC dimension is a measure of model complexity defined as the largest number of points that can be shattered by a model. There are few works on analyzing the VC dimension of GNNs. Given the number of model parameter $p$ and the number of nodes $n$, Scarselli et al.   derive that the VC dimension of a GNN*  is $O(p^4n^2)$ if it uses the sigmoid or tangent hyperbolic activation and is $O(p^2n)$ if it uses the piecewise polynomial activation function. This result\n\tsuggests that the model complexity of a GNN*  increases rapidly with $p$ and $n$ if the sigmoid or tangent hyperbolic activation is used.  \n\t\\vspace{2mm}\n\t\\noindent\\textbf{Graph isomorphism} Two graphs are isomorphic if they are topologically identical. Given two non-isomorphic graphs $G_1$ and $G_2$, Xu et al.  prove that if a GNN maps $G_1$ and $G_2$ to different embeddings, these two graphs can be identified as non-isomorphic by the Weisfeiler-Lehman (WL) test of isomorphism . They show that common GNNs such as GCN  and GraphSage  are incapable of distinguishing different graph structures. Xu et al.  further prove if the aggregation functions and the readout functions of a GNN are injective, the GNN is at most as powerful as the WL test in distinguishing different graphs.\n\t\\vspace{2mm}\n\t\\noindent\\textbf{Equivariance and invariance}\n\tA GNN must be an equivariant function when performing node-level tasks and must be an invariant function when performing graph-level tasks. For node-level tasks, let $f(\\mathbf{A},\\mathbf{X}) \\in R^{n\\times d}$ be a GNN and $\\mathbf{Q}$ be any permutation matrix that changes the order of nodes. A GNN is equivariant if it satisfies $f(\\mathbf{Q}\\mathbf{A}\\mathbf{Q}^T,\\mathbf{Q}\\mathbf{X})=\\mathbf{Q}f(\\mathbf{A},\\mathbf{X})$. For graph-level tasks, let $f(\\mathbf{A},\\mathbf{X}) \\in R^{d}$. A GNN is invariant if it satisfies $f(\\mathbf{Q}\\mathbf{A}\\mathbf{Q}^T,\\mathbf{Q}\\mathbf{X})=f(\\mathbf{A},\\mathbf{X})$. In order to achieve equivariance or invariance, components of a GNN must be invariant to node orderings. Maron et al.  theoretically study the characteristics of permutation invariant and equivariant linear layers for graph data.\n\t\\vspace{2mm}\n\t\\noindent\\textbf{Universal approximation} It is well known that multi-perceptron feedforward neural networks with one hidden layer can approximate any Borel measurable functions . The universal approximation capability of GNNs has seldom been studied. Hammer et al.  prove that cascade correlation can approximate functions with structured outputs. Scarselli et al.  prove that a RecGNN  can approximate any function that preserves unfolding equivalence up to any degree of precision. \tTwo nodes are unfolding equivalent if their unfolding trees are identical where the unfolding tree of a node is constructed by iteratively extending a node's neighborhood at a certain depth. Xu et al.  show that ConvGNNs under the framework of message passing  are not universal approximators of continuous functions defined on multisets. Maron et al.  prove that an invariant graph network can approximate an arbitrary invariant function defined on graphs.\n\\begin{table*}[]\n\t\t\\caption{Main characteristics of selected  GAEs}\n\t\t\\label{tab:summary_gae}\n\t\t\\centering\n\\begin{tabular}{lllll}\n\\toprule\nApproaches & Inputs & Encoder & Decoder & Objective  \\\\ \\toprule\n  DNGR (2016)          &  $A$      &    a multi-layer perceptron     &  a multi-layer perceptron       &  reconstruct the PPMI matrix           \\\\ \\midrule\n  SDNE (2016)          &  $A$      &   a multi-layer perceptron     &  a multi-layer perceptron      &        preserve node 1st-order and 2nd-order proximity       \\\\ \\midrule\n  GAE* (2016)           &  $A,X$      & a ConvGNN        & a similarity measure         &  reconstruct the adjacency matrix              \\\\ \\midrule\n  VGAE (2016)           &  $A,X$      &      a ConvGNN       & a similarity measure        &         learn the generative distribution of data       \\\\ \\midrule\n  ARVGA (2018)  &   $A,X$     &   a ConvGNN        & a similarity measure         &    learn the generative distribution of data adversarially            \\\\ \\midrule\n  DNRE (2018)  &   $A$     &  an LSTM network       &  an identity function       &  recover network embedding               \\\\ \\midrule\n  NetRA (2018) &   $A$     &   an LSTM network       &    an LSTM network     &      recover network embedding with adversarial training          \\\\ \\midrule\n  DeepGMG (2018) &   $A,X,X^e$     &   a RecGNN      &  a decision process       &      maximize the expected joint log-likelihood           \\\\ \\midrule\n  GraphRNN (2018) &    $A$    &  a RNN      &  a decision process       &        maximize the likelihood of permutations         \\\\ \\midrule\n  GraphVAE (2018) &  $A,X,X^e$     &  a ConvGNN       & a multi-layer perceptron       &    optimize the reconstruction loss            \\\\ \\midrule\n  RGVAE (2018) &   $A,X,X^e$      &   a CNN     & a deconvolutional net       &  optimize the reconstruction loss  with validity constraints              \\\\ \\midrule\n  MolGAN (2018) &   $A,X,X^e$     &  a ConvGNN       &  a multi-layer perceptron      &     optimize the generative adversarial loss and the RL loss           \\\\ \\midrule\n  NetGAN (2018) &   $A$     &    an LSTM network     &  an LSTM network       &          optimize the generative adversarial loss      \\\\ \\midrule\n\\end{tabular}\n\\end{table*}", "cites": [7009, 231, 242, 227, 256, 222, 232, 216, 7214, 236, 229], "cite_extract_rate": 0.4583333333333333, "origin_cites_number": 24, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.0, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section analytically synthesizes multiple theoretical aspects of ConvGNNs, drawing insights from various papers to explain concepts like receptive fields, VC dimension, graph isomorphism, and universal approximation. It abstracts these ideas to discuss broader principles such as model complexity, expressiveness, and invariance. While it provides useful theoretical comparisons and highlights limitations (e.g., non-universality of message passing GNNs), it could offer deeper critique by evaluating the implications or suggesting future research directions."}}
{"id": "2694dc31-da30-4325-9670-05a62cf42db2", "title": "Network Embedding", "level": "subsection", "subsections": [], "parent_id": "ab230956-4fa9-4164-b53c-23dede1161c3", "prefix_titles": [["title", " A Comprehensive Survey on Graph Neural Networks"], ["section", "Graph autoencoders"], ["subsection", "Network Embedding"]], "content": "A network embedding is a low-dimensional vector representation of a node which preserves a node's topological information.  GAEs learn network embeddings using an encoder to extract network embeddings and using a decoder to enforce network embeddings to preserve the graph topological information such as the PPMI matrix and the adjacency matrix.\n    Earlier approaches mainly employ multi-layer perceptrons to build GAEs for network embedding learning. Deep Neural Network for Graph Representations (DNGR)  uses a stacked denoising autoencoder  to encode and decode the PPMI matrix via multi-layer perceptrons. \n\tConcurrently, Structural Deep Network Embedding (SDNE)  uses a stacked autoencoder to preserve the node first-order proximity and second-order proximity jointly. SDNE proposes two loss functions on the outputs of the encoder and the outputs of the decoder separately. The first loss function enables the learned network embeddings to preserve the node first-order proximity by minimizing the distance between a node's network embedding and its neighbors' network embeddings. The  first loss function $L_{1st}$ is defined as \n\t\\begin{equation}\n\tL_{1st} = \\sum_{(v,u)\\in E} A_{v,u}||enc(\\mathbf{x}_v)-enc(\\mathbf{x}_u)||^2,\n\t\\end{equation}\n\twhere $\\mathbf{x}_v=\\mathbf{A}_{v,:}$ and $enc(\\cdot)$ is an encoder which consists of a multi-layer perceptron. The second loss function enables the learned network embeddings to preserve the node second-order proximity by minimizing the distance between a node's inputs and its reconstructed inputs. Concretely, the second loss function $L_{2nd}$ is defined as \n\t\\begin{equation}\n\tL_{2nd} = \\sum_{v \\in V} ||(dec(enc(\\mathbf{x}_v))-\\mathbf{x}_v)\\odot \\mathbf{b}_v||^2,\n\t\\end{equation}\n\twhere  $b_{v,u}=1$ if $A_{v,u}=0$, $b_{v,u}=\\beta>1$ if $A_{v,u}=1$, and $dec(\\cdot)$ is a decoder which consists of a multi-layer perceptron. \n    DNGR  and SDNE  only consider node structural information which is about the connectivity between pairs of nodes. They ignore nodes may contain feature information that depicts the attributes of nodes themselves.  Graph Autoencoder (GAE*\\footnote{We name it GAE* to avoid ambiguity in the survey.})  leverages GCN  to encode node structural information and node feature information at the same time.  The encoder of GAE* consists of two graph convolutional layers, which takes the form\n    \\begin{equation}\n        \\label{eq:gae}\n        \\mathbf{Z} = enc(\\mathbf{X},\\mathbf{A}) = Gconv(f(Gconv(\\mathbf{A},\\mathbf{X};\\mathbf{\\Theta_1}));\\mathbf{\\Theta_2)},\n    \\end{equation}\n\twhere $\\mathbf{Z}$ denotes the network embedding matrix of a graph, $f(\\cdot)$ is a ReLU activation function and the $Gconv(\\cdot)$ function is a graph convolutional layer defined by Equation \\ref{eq:1stchebnetc}. The decoder of GAE* aims to decode node relational information from their embeddings by reconstructing the graph adjacency matrix, which is defined as \n\t\\begin{equation}\n\t\\hat{\\mathbf{A}}_{v,u} = dec(\\mathbf{z}_v,\\mathbf{z}_u) = \\sigma(\\mathbf{z}_v^T\\mathbf{z}_u),\n\t\\end{equation}\n\twhere $\\mathbf{z}_v$ is the embedding of node $v$.\n\tGAE* is trained by minimizing the negative cross entropy given the real adjacency matrix $\\mathbf{A}$ and the reconstructed adjacency matrix $\\hat{\\mathbf{A}}$.\n    Simply reconstructing the graph adjacency matrix may lead to overfitting due to the capacity of the autoencoders.  Variational Graph Autoencoder (VGAE)  is a variational version of GAE to learn the distribution of data. VGAE optimizes the variational lower bound $L$:\n\t\\begin{equation}\n\t    \\label{eq:vgae}\n\t    L = E_{q(\\mathbf{Z}|\\mathbf{X},\\mathbf{A})}[\\log p(\\mathbf{A}|\\mathbf{Z})]-KL[q(\\mathbf{Z}|\\mathbf{X},\\mathbf{A})||p(\\mathbf{Z})],\n\t\\end{equation}\n\twhere $KL(\\cdot)$ is the Kullback-Leibler divergence function which measures the distance between two distributions, $p(\\mathbf{Z})$ is a Gaussian prior $p(\\mathbf{Z})=\\prod_{i=1}^np(\\mathbf{z}_i)=\\prod_{i=1}^nN(\\mathbf{z}_i|0,\\mathbf{I})$,  $p(A_{ij}=1|\\mathbf{z}_i,\\mathbf{z}_j)=dec(\\mathbf{z}_i,\\mathbf{z}_j)=\\sigma(\\mathbf{z}_i^T\\mathbf{z}_j)$, $q(\\mathbf{Z}|\\mathbf{X},\\mathbf{A})=\\prod_{i=1}^nq(\\mathbf{z}_i|\\mathbf{X},\\mathbf{A})$  with $q(\\mathbf{z}_i|\\mathbf{X},\\mathbf{A})=N(\\mathbf{z}_i|\\mathbf{\\mu}_i,diag(\\mathbf{\\sigma}_i^2))$. The mean vector $\\mathbf{\\mu}_i$ is the $i^{th}$ row of an encoder's outputs defined by Equation \\ref{eq:gae} and $\\log \\mathbf{\\sigma}_i$ is derived similarly as $\\mathbf{\\mu}_i$ with another encoder. According to Equation \\ref{eq:vgae}, VGAE assumes the empirical distribution $q(\\mathbf{Z}|\\mathbf{X},\\mathbf{A})$ should be as close as possible to the prior distribution $p(\\mathbf{Z})$.\n    To further enforce the empirical distribution $q(\\mathbf{Z}|\\mathbf{X},\\mathbf{A})$ approximate the prior distribution $p(\\mathbf{Z})$, Adversarially Regularized Variational Graph Autoencoder (ARVGA)\n\t employs the training scheme of a generative adversarial networks (GAN) . A GAN plays a competition game between a generator and a discriminator in training generative models. A generator tries to generate `fake samples' to be as real as possible while a discriminator attempts to distinguish the `fake samples' from real ones. Inspired by GANs, ARVGA endeavors to learn an encoder that produces an empirical distribution $q(\\mathbf{Z}|\\mathbf{X},\\mathbf{A})$ which is indistinguishable from the prior distribution $p(\\mathbf{Z})$.\n\tSimilar as GAE*, GraphSage  encodes node features with two graph convolutional layers. \n\tInstead of optimizing the reconstruction error, GraphSage shows that the relational information between two nodes can be preserved by negative sampling with the loss:\n\t\\begin{equation}\n\t    L(\\mathbf{z}_v) = -log(dec(\\mathbf{z}_v,\\mathbf{z}_u))-QE_{v_n\\sim P_n(v)}\\log (-dec(\\mathbf{z}_v,\\mathbf{z}_{v_n})),\n\t\\end{equation}\n\twhere node $u$ is a neighbor of node $v$, node $v_n$ is a distant node to node $v$ and is sampled from a negative sampling distribution $P_n(v)$, and Q is the number of negative samples. This loss function essentially enforces close nodes to have similar representations and distant nodes to have dissimilar representations. DGI  alternatively drives local network embeddings to capture global structural information by maximizing local mutual information. It shows a distinct improvement over GraphSage  experimentally. \n    For the aforementioned methods, they essentially learn network embeddings by solving a link prediction problem. However, the sparsity of a graph causes the number of positive node pairs to be far less than the number of negative node pairs. To alleviate the data sparsity problem in learning network embedding, another line of works convert a graph into sequences by random permutations or random walks. In such a way, those deep learning approaches which are applicable to sequences can be directly used to process graphs.\n\tDeep Recursive Network Embedding (DRNE)  assumes a node's network embedding should approximate the aggregation of its neighborhood network embeddings. It adopts a Long Short-Term Memory (LSTM) network  to aggregate a node's neighbors. The reconstruction error of DRNE is defined as \n\t\\begin{equation}\n\t\\label{eq:drne}\n\t    L = \\sum_{v\\in V} ||\\mathbf{z}_v-LSTM(\\{\\mathbf{z}_u|u\\in N(v)\\})||^2,\n\t\\end{equation}\n\twhere $\\mathbf{z}_v$ is the network embedding of node $v$ obtained by a dictionary look-up, and the LSTM network takes a random sequence of node $v$'s neighbors ordered by their node degree as inputs. As suggested by Equation \\ref{eq:drne}, DRNE implicitly learns network embeddings via an LSTM network rather than using the LSTM network to generate network embeddings. It avoids the problem that the LSTM network is not invariant to the permutation of node sequences. \n\tNetwork Representations with Adversarially Regularized Autoencoders (NetRA)  proposes a graph encoder-decoder framework with a general loss function, defined as\n    \\begin{equation}\n        L= -E_{\\mathbf{z}\\sim P_{data}(\\mathbf{z})}(dist(\\mathbf{z},dec(enc(\\mathbf{z})))),\n    \\end{equation}\n    where $dist(\\cdot)$ is the distance measure between the node embedding $\\mathbf{z}$ and the reconstructed $\\mathbf{z}$. The encoder and decoder of NetRA are LSTM networks with random walks rooted on each node $v\\in V$ as inputs.\n    Similar to ARVGA , NetRA regularizes the learned network embeddings within a prior distribution via adversarial training. Although NetRA ignores the node permutation variant problem of LSTM networks, the experimental results validate the effectiveness of NetRA.", "cites": [242, 229, 232, 240, 257], "cite_extract_rate": 0.38461538461538464, "origin_cites_number": 13, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.5, "abstraction": 3.5}, "insight_level": "high", "analysis": "The section effectively synthesizes key ideas from multiple papers on graph autoencoders, linking their approaches to the broader context of network embedding. It provides critical analysis by pointing out limitations such as overfitting and data sparsity, and discusses how different methods address these issues. The section abstracts from specific implementations to highlight overarching strategies like proximity preservation, reconstruction, and adversarial regularization."}}
{"id": "d1cd6f08-a27a-4124-b38a-402443ad6ba9", "title": "Graph Generation", "level": "subsection", "subsections": [], "parent_id": "ab230956-4fa9-4164-b53c-23dede1161c3", "prefix_titles": [["title", " A Comprehensive Survey on Graph Neural Networks"], ["section", "Graph autoencoders"], ["subsection", "Graph Generation"]], "content": "With multiple graphs, GAEs are able to learn the generative distribution of graphs by encoding graphs into hidden representations and decoding a graph structure given hidden representations. The majority of GAEs for graph generation are designed to solve the molecular graph generation problem, which has a high practical value in drug discovery. These methods either propose a new graph in a sequential manner or in a global manner.  \n\tSequential approaches generate a graph by proposing nodes and edges step by step. Gomez et al. , Kusner et al. , and Dai et al.  model the generation process of a string representation of molecular graphs named SMILES with deep CNNs and RNNs as the encoder and the decoder respectively. While these methods are domain-specific, alternative solutions are applicable to general graphs by means of iteratively adding nodes and edges to a growing graph until a certain criterion is satisfied.  \n\tDeep Generative Model of Graphs (DeepGMG) \n\tassumes the probability of a graph is the sum over all possible node permutations:\n\t\\begin{equation}\n\t    p(G)=\\sum_\\pi p(G,\\pi),\n\t\\end{equation}\n\twhere $\\pi$ denotes a node ordering. It captures the complex joint probability of all nodes and edges in the graph.\n\tDeepGMG generates graphs by making a sequence of decisions, namely whether to add a node, which node to add, whether to add an edge, and which node to connect to the new node. The decision process of generating nodes and edges is conditioned on the node states and the graph state of a growing graph updated by a RecGNN.  In another work, GraphRNN  proposes a graph-level RNN and an edge-level RNN to model the generation process of nodes and edges.\n    The graph-level RNN adds a new node to a node sequence each time while the edge-level RNN produces a binary sequence indicating connections between the new node and the nodes previously generated in the sequence. \n    Global approaches output a graph all at once.  Graph Variational Autoencoder (GraphVAE)  models the existence of nodes and edges as independent random variables. By assuming the posterior distribution $q_\\mathbf{\\phi}(\\mathbf{z}|G)$ defined by an encoder and the generative distribution $p_\\theta(G|\\mathbf{z})$ defined by a decoder, GraphVAE optimizes the variational lower bound:\n    \\begin{equation}\nL(\\mathbf{\\phi},\\mathbf{\\theta};G)= E_{q_\\mathbf{\\phi}(z|G)}[-\\log p_\\theta(G|\\mathbf{z})]+KL[q_\\mathbf{\\phi}(\\mathbf{z}|G)||p(\\mathbf{z})],\n    \\end{equation}\n    where $p(\\mathbf{z})$ follows a Gaussian prior, $\\mathbf{\\phi}$ and $\\mathbf{\\theta}$ are learnable parameters. With a ConvGNN as the encoder and a simple multi-layer perception as the decoder, GraphVAE outputs a generated graph with its adjacency matrix, node attributes and edge attributes. It is challenging to control the global properties of generated graphs, such as graph connectivity, validity, and node compatibility.  Regularized Graph Variational Autoencoder (RGVAE)  further imposes validity constraints on a graph variational autoencoder to regularize the output distribution of the decoder. \n    Molecular Generative Adversarial Network (MolGAN)  integrates convGNNs , GANs  and reinforcement learning objectives to generate graphs with the desired properties. MolGAN consists of a generator and a discriminator, competing with each other to improve the authenticity of the generator. In MolGAN, the generator tries to propose a fake graph along with its feature matrix while the discriminator aims to distinguish the fake sample from the empirical data. Additionally, a reward network is introduced in parallel with the discriminator to encourage the generated graphs to possess certain properties according to an external evaluator. \n    NetGAN  combines LSTMs  with Wasserstein GANs  to generate graphs from a random-walk-based approach. NetGAN trains a generator to produce plausible random walks through an LSTM network and enforces a discriminator to identify fake random walks from the real ones. After training, a new graph is derived by normalizing a co-occurrence matrix of nodes computed based on random walks produced by the generator. \n    In brief, sequential approaches linearize graphs into sequences. They can lose structural information due to the presence of cycles.  Global approaches produce a graph all at once. They are not scalable to large graphs as the output space of a GAE is up to $O(n^2)$.", "cites": [7214, 259, 8335, 227, 7009, 236, 258, 64, 222, 8317], "cite_extract_rate": 0.7692307692307693, "origin_cites_number": 13, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.5, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section effectively synthesizes information from multiple papers to present two distinct paradigms for graph generation: sequential and global approaches. It analytically explains the methods used in these approaches and identifies their limitations (e.g., loss of structural information, scalability issues). The abstraction is strong, as it frames the discussed models under a general GAE umbrella and highlights key design choices and challenges in graph generation."}}
{"id": "941a7454-1949-40f9-adf7-149d38c88dd5", "title": "Spatial-temporal Graph Neural Networks", "level": "section", "subsections": [], "parent_id": "bd162e79-adf5-413e-a1f4-ec18c4226195", "prefix_titles": [["title", " A Comprehensive Survey on Graph Neural Networks"], ["section", "Spatial-temporal Graph Neural Networks"]], "content": "\\label{sec:stgcn}\nGraphs in many real-world applications are dynamic both in terms of graph structures and graph inputs. Spatial-temporal graph neural networks (STGNNs) occupy important positions in capturing the dynamicity of graphs. Methods under this category aim to model the dynamic node inputs while assuming interdependency between connected nodes. For example, a traffic network consists of speed sensors placed on roads where edge weights are determined by the distance between pairs of sensors. As the traffic condition of one road may depend on its adjacent roads' conditions, it is necessary to consider spatial dependency when performing traffic speed forecasting.\nAs a solution,  STGNNs capture spatial and temporal dependencies of a graph simultaneously. The task of STGNNs can be forecasting future node values or labels, or predicting spatial-temporal graph labels.  STGNNs follow two directions, RNN-based methods and CNN-based methods.\nMost RNN-based approaches capture spatial-temporal dependencies by filtering inputs and hidden states passed to a recurrent unit using graph convolutions . To illustrate this, suppose a simple RNN takes the form\n\\begin{equation}\n    \\label{eq:rnn}\n    \\mathbf{H}^{(t)} = \\sigma(\\mathbf{W}\\mathbf{X}^{(t)}+\\mathbf{U}\\mathbf{H}^{(t-1)}+\\mathbf{b}), \n\\end{equation}\nwhere $\\mathbf{X}^{(t)}\\in \\mathbf{R}^{n\\times d}$ is the node feature matrix at time step $t$. After inserting graph convolution, Equation \\ref{eq:rnn} becomes\n\\begin{equation}\n    \\label{eq:rnn1}\n    \\mathbf{H}^{(t)} = \\sigma(Gconv(\\mathbf{X}^{(t)},\\mathbf{A};\\mathbf{W})+Gconv(\\mathbf{H}^{(t-1)},\\mathbf{A};\\mathbf{U})+\\mathbf{b}),\n\\end{equation}\nwhere $Gconv(\\cdot)$ is a graph convolutional layer. \nGraph Convolutional Recurrent Network (GCRN)  combines a LSTM network with ChebNet . Diffusion Convolutional Recurrent Neural Network (DCRNN)  incorporates a proposed diffusion graph convolutional layer (Equation \\ref{eq:dcn}) into a GRU network. In addition, DCRNN adopts an encoder-decoder framework to predict the future $K$ steps of node values. \nAnother parallel work uses node-level RNNs and edge-level RNNs to handle different aspects of temporal information. Structural-RNN  proposes a recurrent framework to predict node labels at each time step. It comprises two kinds of RNNs, namely a node-RNN and an edge-RNN. The temporal information of each node and each edge is passed through a node-RNN and an edge-RNN respectively. To incorporate the spatial information, a node-RNN takes the outputs of edge-RNNs as inputs. Since assuming different RNNs for different nodes and edges significantly increases model complexity, it instead splits nodes and edges into semantic groups. \nNodes or edges in the same semantic group share the same RNN model, which saves the computational cost. \nRNN-based approaches suffer from time-consuming iterative propagation and gradient explosion/vanishing issues. As alternative solutions, CNN-based approaches tackle spatial-temporal graphs in a non-recursive manner with the advantages of parallel computing, stable gradients, and low memory requirements. As illustrated in Fig \\ref{fig:gst}, CNN-based approaches interleave 1D-CNN layers with graph convolutional layers to learn temporal and spatial dependencies respectively. Assume the inputs to a spatial-temporal graph neural network is a tensor $\\mathbf{\\mathcal{X}}\\in R^{T\\times n\\times d}$, the 1D-CNN layer slides over $\\mathbf{\\mathcal{X}}_{[:,i,:]}$ along the time axis to aggregate temporal information for each node while the graph convolutional layer operates on $\\mathbf{\\mathcal{X}}_{[i,:,:]}$ to aggregate spatial information at each time step.  CGCN  integrates 1D convolutional layers with ChebNet  or GCN  layers. It constructs a spatial-temporal block by stacking a gated 1D convolutional layer, a graph convolutional layer and another gated 1D convolutional layer in a sequential order. ST-GCN  composes a spatial-temporal block using a 1D convolutional layer and a PGC layer (Equation \\ref{eq:pgcn}). \nPrevious methods all use a pre-defined graph structure. They assume the pre-defined graph structure reflects the genuine dependency relationships among nodes. However,  with many snapshots of graph data in a spatial-temporal setting, it is possible to learn latent static graph structures automatically from data. To realize this, Graph WaveNet  proposes a self-adaptive adjacency matrix to perform graph convolutions. The self-adaptive adjacency matrix is defined as \n\\begin{equation}\n    \\mathbf{A}_{adp}=SoftMax(ReLU(\\mathbf{E}_1\\mathbf{E}_2^T)),\n\\end{equation}\nwhere the SoftMax function is computed along the row dimension, $\\mathbf{E1}$ denotes the source node embedding and $\\mathbf{E2}$ denotes the target node embedding with learnable parameters. By multiplying $\\mathbf{E1}$ with $\\mathbf{E2}$, one can get the dependency weight between a source node and a target node.\nWith a complex CNN-based spatial-temporal neural network,  Graph WaveNet performs well without being given an adjacency matrix.\nLearning latent static spatial dependencies can help researchers discover interpretable and stable correlations among different entities in a network. However, in some circumstances, learning latent dynamic spatial dependencies may further improve model precision. For example, in a traffic network, the travel time between two roads may depend on their current traffic conditions. GaAN  employs attention mechanisms to learn dynamic spatial dependencies through an RNN-based approach. An attention function is used to update the edge weight between two connected nodes given their current node inputs.  \nASTGCN  further includes a spatial attention function and a temporal attention function to learn latent dynamic spatial dependencies and temporal dependencies through a CNN-based approach. \nThe common drawback of learning latent spatial dependencies is that it needs to calculate the spatial dependency weight between each pair of nodes, which costs $O(n^2)$.", "cites": [23, 225, 8312, 8313, 238, 25, 27], "cite_extract_rate": 0.7, "origin_cites_number": 10, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.3, "critical": 3.8, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section effectively synthesizes multiple cited works, integrating them into a structured overview of RNN- and CNN-based STGNN approaches, and explains how they handle spatial and temporal dependencies. It also provides some critical analysis, such as pointing out the drawbacks of RNNs and the computational cost of adjacency matrix learning. The discussion abstracts beyond individual papers to highlight overarching trends and design choices in spatial-temporal graph modeling."}}
{"id": "6a431d99-8917-4911-8b07-e29e7a007f46", "title": "Data Sets", "level": "subsection", "subsections": [], "parent_id": "914a6f49-f2ab-46dc-bd3b-4027cdae5064", "prefix_titles": [["title", " A Comprehensive Survey on Graph Neural Networks"], ["section", "Applications"], ["subsection", "Data Sets"]], "content": "We mainly sort data sets into four groups, namely citation networks, biochemical graphs, social networks, and others.  In Table \\ref{tab:datafreq}, we summarize selected benchmark data sets. More details is given in the Supplementary Material A.\n\t\\begin{table*}[htbp]\n\t\t\\caption{Summary of selected benchmark data sets.}\n\t\t\\label{tab:datafreq}\n\t\t\\centering\n\t\t\\begin{tabular}{l l l l l l l l l }\n\t\t\t\\toprule\n\t\t\t\\multicolumn{1}{l}{Category} & Data set & Source &\\# Graphs & \\# Nodes(Avg.) & \\#     Edges (Avg.) & \\#Features & \\# Classes & Citation \\\\ \n\t\t\t\\midrule\n\t\t\t\\hline\n\t\t\t\\multicolumn{1}{l|}{\\multirow{4}{*}{\\begin{tabular}[c]{@{}l@{}}Citation\\\\Networks \\end{tabular}}} & Cora & &1 & 2708 & 5429 & 1433 & 7 &  \\begin{tabular}[c]{@{}l@{}}\n\t\t\t   \\\\ \n\t\t\t   \\\\ \n\t\t\t\\end{tabular}\\\\ \\cline{2-9} \n\t\t\t\\multicolumn{1}{l|}{} & Citeseer &  &1 & 3327 & 4732 & 3703 & 6 &        \\begin{tabular}[c]{@{}l@{}}\\\\\n\t\t\t\\\\\n\t\t\t\\end{tabular}                                                  \\\\ \\cline{2-9} \n\t\t\t\\multicolumn{1}{l|}{}                                   & Pubmed                          &                                                                            &1       & 19717           & 44338    & 500        & 3         &            \\begin{tabular}[c]{@{}l@{}} \\\\\n\t\t\t\\\\ \\\\\n\t\t\t\\end{tabular}\n\t\t\t\\\\ \\cline{2-9} \n\t\t\t\\multicolumn{1}{l|}{}                                   & DBLP (v11)                            &          \\begin{tabular}[c]{@{}l@{}}\\\\\\end{tabular}         &1                                                                & 4107340           & 36624464    &        -    & -         &                                                         \\\\ \\hline\n\t\t\t\\multicolumn{1}{l|}{\\multirow{8}{*}{\\begin{tabular}[c]{@{}l@{}}Bio-\\\\chemical \\\\Graphs\\end{tabular}}}   & PPI                             &       & 24                                                                            & 56944 & 818716        & 50         & 121       &              \\begin{tabular}[c]{@{}l@{}}\\\\\\end{tabular}                                           \\\\ \\cline{2-9} \n\t\t\t\\multicolumn{1}{l|}{}                                   & NCI-1                           &                    &           4110                                                    &    29.87             &     32.30     &   37        &    2       &       \\begin{tabular}[c]{@{}l@{}} \\end{tabular}                                               \\\\ \\cline{2-9} \n\t\t\t\\multicolumn{1}{l|}{}                                   & MUTAG                         &                &          188                                                         &        17.93         &   19.79       &       7     &      2     &   \\begin{tabular}[c]{@{}l@{}}    \\\\ \\end{tabular}                                                \\\\ \\cline{2-9} \n\t\t\t\\multicolumn{1}{l|}{}                                   & D\\&D                             &                               &          1178                                          &        284.31         &   715.65      &       82     &    2       &                 \\begin{tabular}[c]{@{}l@{}}  \\end{tabular}                                     \\\\ \\cline{2-9}\n\t\t\t\\multicolumn{1}{l|}{}                                   & PROTEIN                             &                               &        1113                                            &        39.06         &   72.81       &       4     &    2       &                 \\begin{tabular}[c]{@{}l@{}} \\\\ \\end{tabular}                                     \\\\ \\cline{2-9}\n\t\t\t\\multicolumn{1}{l|}{}                                   & PTC                             &                               &          344                                          &        25.5         &   -       &       19     &    2       &                 \\begin{tabular}[c]{@{}l@{}} \\\\ \\end{tabular}   \n\t\t\t\\\\ \\cline{2-9}\n\t\t\t\\multicolumn{1}{l|}{}                                   & QM9       &                      &                133885                                                                   &          -       &      -    &       -     &     -      &                                                         \\\\\n\t\t\t\\cline{2-9}\n\t\t\t\\multicolumn{1}{l|}{}                                   & Alchemy                             &                               &                      119487                              &       -        &   -       &       -     &    -       &  -\n\t\t\t\\\\ \\hline\n\t\t\t\\multicolumn{1}{l|}{\\multirow{2}{*}{\\begin{tabular}[c]{@{}l@{}}Social \\\\Networks\\end{tabular}}}     & Reddit                          &                            &1                                                       &    232965             &     11606919     &   602         &    41       &     \\begin{tabular}[c]{@{}l@{}}  \\\\  \\end{tabular}                                                 \\\\ \\cline{2-9}\n            \\multicolumn{1}{l|}{}   & BlogCatalog                     &                                            & 1                                       & 10312           & 333983   &   -         & 39        &                                                         \\\\ \\hline\n\t\t\t\\multicolumn{1}{l|}{\\multirow{3}{*}{Others}} & MNIST                   &       &  70000                                                                    &       784          &     -     &       1     &     10      &                                                         \\\\ \\cline{2-9} \n\t\t\t\\multicolumn{1}{l|}{} & METR-LA                    &        &       1                                                                    &        207         &     1515     &     2       &   -        &                                                         \\\\ \\cline{2-9} \n\t\t\t\\multicolumn{1}{l|}{}                                   & Nell                            &        &        1                                                                   & 65755           & 266144   & 61278      & 210       &                                                       \\\\\n\t\t\t\\hline\n\t\t\t\\bottomrule\n\t\t\\end{tabular}\n\t\\end{table*}\n\\begin{comment}\n\\begin{table*}[]\n\\centering\n\\caption{Benchmark performance for graph classification on five frequently used data sets. The listed methods all adopt 10-fold cross-validation. \nMean accuracy with the standard deviation for each method is reported. }\n\\label{tab:bengraph}\n\\begin{tabular}{llllll}\n\\toprule\n           & NCI-1 & MUTAG & D\\&D & PROTEIN & PTC  \\\\ \\midrule\nPATCHY-SAN (2016)  &   78.59$\\pm$1.89    &  \\textbf{92.63$\\pm$4.21}      & 77.12$\\pm$2.41      &  75.89$\\pm$2.76    &      60.00$\\pm$4.82           \\\\ \\hline\nPGC-DGCNN (2018)        &  76.13$\\pm$0.73     &  87.22$\\pm$1.43     &    78.93$\\pm$0.91   &  \\textbf{76.45$\\pm$1.02}    &   61.06$\\pm$1.83              \\\\ \\hline\nDGCNN (2018)  &  74.44$\\pm$0.47     &     -   &  \\textbf{79.37$\\pm$0.94}     &  75.54$\\pm$0.94    &    -              \\\\ \\hline\nGIN (2019)        &  \\textbf{82.70$\\pm$1.60}     &   89.00$\\pm$6.00     &   -    &  75.90$\\pm$3.80    &        \\textbf{63.70$\\pm$8.20}           \\\\ \\hline\n\\end{tabular}\n\\end{table*}\n\\end{comment}\n\\begin{comment}\n\\begin{table}[]\n\t\\scriptsize\n\\begin{tabular}{lllll}\n\\hline\nData        & PATCHY-SAN & PGC-DGCNN & DGCNN & GIN \\\\ \\hline\nNCI-1   & 78.59$\\pm$1.89                                                & 76.13$\\pm$0.73                                          & 74.44$\\pm$0.47                                    & \\textbf{82.70$\\pm$1.60}     \\\\ \\hline\nMUTAG   & \\textbf{92.63$\\pm$4.21}                      & 87.22$\\pm$1.43                                          & -                                                 & 89.00$\\pm$6.00                               \\\\ \\hline\nD\\&D    & 77.12$\\pm$2.41                                                & 78.93$\\pm$0.91                                          & \\textbf{79.37$\\pm$0.94}          & -                                            \\\\ \\hline\nPROTEIN & 75.89$\\pm$2.76 & \\textbf{76.45$\\pm$1.02}&  75.54$\\pm$0.94                                    & 75.90$\\pm$3.80                               \\\\ \\hline\nPTC     & 60.00$\\pm$4.82                                                & 61.06$\\pm$1.83                                          & -                                                 & \\textbf{63.70$\\pm$8.20}     \\\\ \\cline{5-5}  \\hline\n\\end{tabular}\n\\end{table}\n\\end{comment}", "cites": [7009, 231, 261, 242, 8313, 27, 7215, 240, 221, 220, 237, 224, 226, 233, 228, 246, 232, 8312, 8331, 7212, 239, 180, 216, 213, 230, 235, 7214, 23, 229, 260, 248, 234], "cite_extract_rate": 0.6274509803921569, "origin_cites_number": 51, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 1.5, "abstraction": 1.5}, "insight_level": "low", "analysis": "The section provides a descriptive listing of graph datasets used in the field, with minimal synthesis or integration of the cited papers. It does not connect the datasets to broader themes in graph neural networks or explain their relevance to the discussed methods. There is little to no critical analysis or abstraction beyond the raw data presented."}}
{"id": "b8c7e834-05a0-4b80-818f-d7a6aa8521fb", "title": "Evaluation \\& Open-source Implementations", "level": "subsection", "subsections": [], "parent_id": "914a6f49-f2ab-46dc-bd3b-4027cdae5064", "prefix_titles": [["title", " A Comprehensive Survey on Graph Neural Networks"], ["section", "Applications"], ["subsection", "Evaluation \\& Open-source Implementations"]], "content": "Node classification and graph classification are common tasks to assess the performance of RecGNNs and ConvGNNs. \n    \\vspace{1mm}\n    \\textbf{Node Classification} In node classification, most methods follow a standard split of train/valid/test on benchmark data sets including Cora, Citeseer, Pubmed, PPI, and Reddit.  They reported the average accuracy or F1 score on the test data set over multiple runs. A summarization of experimental results of methods can be found in the Supplementary Material B.  It should be noted that these results do not necessarily represent a rigorous comparison. \n    Shchur et al. identified  two pitfalls in evaluating the performance GNNs on node classification. First, using the same train/valid/test split throughout all experiments underestimates the generalization error. Second, different methods employed different training techniques such as hyper-parameter tuning, parameter initialization, learning rate decay, and early stopping. For a relatively fair comparison, we refer the readers to  Shchur et al. . \n    \\vspace{1mm}\n    \\textbf{Graph Classification} In graph classification, researchers often adopt 10-fold cross validation (cv) for model evaluation. However, as pointed out by , the experimental settings are ambiguous and not unified across different works. In particular,  raises the concern of the correct usage of data splits for model selection versus model assessment. An often encountered problem is that the external test set of each fold is used both for model selection and risk assessment.  compare GNNs in a standardized and uniform evaluation framework. They apply an external 10 fold CV to get an estimate of the generalization performance of a model and  an inner holdout technique with a 90\\%/10\\% training/validation split for model selection. An alternative procedure would be a double cv method, which uses an external $k$ fold cv for model assessment and an inner $k$ fold cv for model selection. We refer the readers to  for a detailed and rigorous comparison of GNN methods for graph classification.\n    \\vspace{1mm}\n    \\textbf{Open-source implementations} facilitate the work of baseline experiments in deep learning research.  In the Supplementary Material C, we provide the hyperlinks of the open-source implementations of the GNN models reviewed in this paper. Noticeably, Fey et al.  published a geometric learning library in PyTorch named PyTorch Geometric \\footnote{\\url{https://github.com/rusty1s/pytorch_geometric}}, which implements many GNNs. Most recently, the Deep Graph Library (DGL) \\footnote{https://www.dgl.ai/}  is released which provides a fast implementation of many GNNs on top of popular deep learning platforms such as PyTorch and MXNet.", "cites": [7010, 251], "cite_extract_rate": 0.5, "origin_cites_number": 4, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.5, "critical": 4.0, "abstraction": 3.0}, "insight_level": "medium", "analysis": "The section integrates insights from Shchur et al. and other works to highlight critical issues in the evaluation of GNNs, such as data split reuse and inconsistent training protocols. It offers a nuanced critique of evaluation practices, pointing out their shortcomings and suggesting standardized alternatives. While it draws connections between these issues, the abstraction is limited to general evaluation strategies rather than broader theoretical or methodological principles."}}
{"id": "96a2828f-755b-4bd5-b711-f14f23ce44e9", "title": "Practical Applications", "level": "subsection", "subsections": [], "parent_id": "914a6f49-f2ab-46dc-bd3b-4027cdae5064", "prefix_titles": [["title", " A Comprehensive Survey on Graph Neural Networks"], ["section", "Applications"], ["subsection", "Practical Applications"]], "content": "GNNs have many applications across different tasks and domains. Despite general tasks which can be handled by each category of GNNs directly, including node classification, graph classification, network embedding, graph generation, and spatial-temporal graph forecasting, other general graph-related tasks such as node clustering , link prediction , and graph partitioning  can also be addressed by GNNs.  We detail some applications based on the following research domains.\n    \\vspace{2mm}\\noindent\\textbf{Computer vision}\n    Applications of GNNs in computer vision include scene graph generation, point clouds classification, and action recognition.\n    Recognizing semantic relationships between objects facilitates the understanding of the meaning behind a visual scene. Scene graph generation models aim to parse an image into a semantic graph which consists of objects and their semantic relationships .   Another application inverses the process by generating realistic images given scene graphs . As natural language can be parsed as semantic graphs where each word represents an object, it is a promising solution to synthesize images given textual descriptions. \n    Classifying and segmenting points clouds enables LiDAR devices to `see' the surrounding environment. A point cloud is a set of 3D points recorded by LiDAR scans.   convert point clouds into k-nearest neighbor graphs or superpoint graphs and use ConvGNNs to explore the topological structure.\n    Identifying human actions contained in videos facilitates a better understanding of video content from a machine aspect. Some solutions detect the locations of human joints in video clips. Human joints which are linked by skeletons naturally form a graph. Given the time series of human joint locations,  apply STGNNs to learn human action patterns.\n    Moreover, the number of applicable directions of GNNs in computer vision is still growing. It includes human-object interaction , few-shot image classification , semantic segmentation , visual reasoning , and question answering .\n    \\vspace{2mm}\\noindent\\textbf{Natural language processing} \n    A common application of GNNs in natural language processing is text classification. GNNs utilize the inter-relations of documents or words to infer document labels . \n    Despite the fact that natural language data exhibit a sequential order,  they may also contain an internal graph structure, such as a syntactic dependency tree. A syntactic dependency tree defines the syntactic relations among words in a sentence. Marcheggiani et al.  propose the Syntactic GCN which runs on top of a CNN/RNN sentence encoder. The Syntactic GCN aggregates hidden word representations based on the syntactic dependency tree of a sentence. Bastings et al.   apply the Syntactic GCN to the task of neural machine translation. Marcheggiani et al.  further adopt the same model as Bastings et al.   to handle the semantic dependency graph of a sentence. \n    Graph-to-sequence learning learns to generate sentences with the same meaning given a semantic graph of abstract words (known as Abstract Meaning Representation). Song et al.  propose a graph-LSTM to encode graph-level semantic information. Beck et al.   apply a GGNN  to graph-to-sequence learning and neural machine translation.\n    The inverse task is sequence-to-graph learning. Generating a semantic or knowledge graph given a sentence is very useful in knowledge discovery .\n    \\vspace{2mm}\\noindent\\textbf{Traffic} Accurately forecasting traffic speed, volume or the density of roads in traffic networks is fundamentally important in a smart transportation system.    address the traffic prediction problem using STGNNs. They consider the traffic network as a spatial-temporal graph where the nodes are sensors installed on roads, the edges are measured by the distance between pairs of nodes, and each node has the average traffic speed within a window as dynamic input features.  Another industrial-level application is taxi-demand prediction. \n    Given historical taxi demands, location information, weather data, and event features,  Yao et al.  incorporate LSTM, CNN and network embeddings trained by LINE  to form a joint representation for each location to predict the number of taxis demanded for a location within a time interval. \n    \\vspace{2mm}\\noindent\\textbf{Recommender systems}\n    Graph-based recommender systems take items and users as nodes. By leveraging the relations between items and items, users and users, users and items, as well as content information, graph-based recommender systems are able to produce high-quality recommendations. The key to a recommender system is to score the importance of an item to a user. As a result, it can be cast as a link prediction problem. To predict the missing links between users and items, Van et al.  and Ying et al.  propose a GAE which uses ConvGNNs as encoders. Monti et al.  combine RNNs with graph convolutions to learn the underlying process that generates the known ratings.\n    \\vspace{2mm}\\noindent\\textbf{Chemistry} In the field of chemistry, researchers apply GNNs to study the graph structure of molecules/compounds. In a molecule/compound graph, atoms are considered as nodes, and chemical bonds are treated as edges. Node classification, graph classification,  and graph generation are the three main tasks targeting molecular/compound graphs in order to  learn molecular fingerprints , to predict molecular properties , to infer protein interfaces , and to synthesize chemical compounds .\n\t\\vspace{2mm}\\noindent\\textbf{Others} The application of GNNs is not limited to the aforementioned domains and tasks.\n\tThere have been explorations of applying GNNs to a variety of problems such as program verification , program reasoning , social influence prediction , adversarial attacks prevention , electrical health records modeling , brain networks , event detection , and combinatorial optimization .", "cites": [279, 7011, 8337, 7012, 242, 225, 211, 271, 273, 27, 7013, 286, 280, 281, 285, 262, 270, 265, 278, 266, 268, 222, 276, 25, 267, 269, 22, 264, 8336, 272, 7014, 284, 274, 275, 180, 216, 263, 7214, 23, 282, 283, 7216, 277, 8332, 249], "cite_extract_rate": 0.8333333333333334, "origin_cites_number": 54, "insight_result": {"type": "descriptive", "scores": {"synthesis": 3.0, "critical": 2.0, "abstraction": 2.5}, "insight_level": "medium", "analysis": "The section provides a descriptive overview of GNN applications across various domains, with reasonable synthesis of ideas by grouping them into thematic areas. However, it lacks critical evaluation of the cited works and minimal abstraction beyond individual examples, focusing mainly on summarizing the scope of applications."}}
{"id": "b909c379-0640-4f2f-bac7-3aa59644748b", "title": "Future Directions", "level": "section", "subsections": [], "parent_id": "bd162e79-adf5-413e-a1f4-ec18c4226195", "prefix_titles": [["title", " A Comprehensive Survey on Graph Neural Networks"], ["section", "Future Directions"]], "content": "\\label{sec:fucture}\n\tThough GNNs have proven their power in learning graph data,  challenges still exist due to the complexity of graphs. In this section, we suggest four future directions of GNNs.\n\t\\vspace{2mm}\\noindent\\textbf{Model depth}\n\tThe success of deep learning lies in deep neural architectures .   However, Li et al. show that the performance of a ConvGNN drops dramatically with an increase in the number of graph convolutional layers . As graph convolutions push representations of adjacent nodes closer to each other, in theory, with an infinite number of graph convolutional layers, all nodes' representations will converge to a single point .\n\tThis raises the question of whether going deep is still a good strategy for learning graph data.\n\t\\vspace{2mm}\\noindent\\textbf{Scalability trade-off} The scalability of GNNs is gained at the price of corrupting graph completeness.  Whether using sampling or clustering, a model will lose part of the graph information.  By sampling, a node may miss its influential neighbors. By clustering,  a graph may be deprived of a distinct structural pattern. How to trade-off algorithm scalability and graph integrity could be a future research direction.\n\t\\vspace{2mm}\\noindent\\textbf{Heterogenity}\n\tThe majority of current GNNs assume homogeneous graphs.  It is difficult to directly apply current GNNs to heterogeneous graphs, which may contain different types of nodes and edges, or different forms of node and edge inputs,  such as images and text. Therefore, new methods should be developed to handle heterogeneous graphs.\n\t\\vspace{2mm}\\noindent\\textbf{Dynamicity}\n\tGraphs are in nature dynamic in a way that nodes or edges may appear or disappear, and that node/edge inputs may change time by time. New graph convolutions are needed to adapt to the dynamicity of graphs. Although the dynamicity of graphs can be partly addressed by STGNNs,  few of them consider how to perform graph convolutions in the case of dynamic spatial relations.", "cites": [97, 221], "cite_extract_rate": 1.0, "origin_cites_number": 2, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.0, "critical": 3.5, "abstraction": 3.5}, "insight_level": "medium", "analysis": "The section shows analytical tendencies by identifying key challenges and future research directions in GNNs. It synthesizes the main finding from Paper 2 regarding the performance degradation of deep ConvGNNs and links it to broader architectural considerations. While it points out limitations (e.g., scalability vs. graph integrity), it does not deeply critique the cited works or compare multiple approaches systematically, nor does it generalize to a meta-level framework."}}
{"id": "ad525a4f-0445-46a7-a635-89b51f37e1fa", "title": "Open-source Implementations", "level": "subsection", "subsections": [], "parent_id": "39eb9c0b-e91c-49ff-b9fd-c847d2c7f7f2", "prefix_titles": [["title", " A Comprehensive Survey on Graph Neural Networks"], ["section", "Conclusion"], ["subsection", "Open-source Implementations"]], "content": "Here we summarize the open-source implementations of graph neural networks reviewed in the survey. We provide the hyperlinks of the source codes of the GNN models in table \\ref{tab:codes}. \n\\begin{comment}\n\t    \t\\begin{table*}[htbp]\n\t\t\\caption{A Summary of Open-source Implementations}\n\t\t\\label{tab:codes}\n\t\t\\centering\n\t\t\\begin{tabular}{ l l l }\n\t\t\t\\toprule\n\t\t\t Model & Framework & Github Link \\\\ \\midrule\n\t\t\t GGNN (2015)       &    torch         &      \\url{https://github.com/yujiali/ggnn}       \\\\ \\hline\n\t\t\t SSE (2018)       &    c         &      \\url{https://github.com/Hanjun-Dai/steady_state_embedding}       \\\\ \\hline\n\t\t\t ChebNet (2016)     & tensorflow  &\\url{https://github.com/mdeff/cnn_graph}    \\\\ \\hline \n\t\t\t GCN (2017)  & tensorflow  &\\url{https://github.com/tkipf/gcn}          \\\\ \\hline\n\t\t\t CayleyNet (2017)  & tensorflow & \\url{https://github.com/amoliu/CayleyNet}.  \\\\ \\hline \n\t\t\t DualGCN (2018)  & theano & \\url{https://github.com/ZhuangCY/DGCN} \\\\ \\hline\n\t\t\t GraphSage (2017)      &  tensorflow           &        \\url{https://github.com/williamleif/GraphSAGE}     \\\\ \\hline\n\t\t\tGAT (2017)           &     tensorflow        &    \\url{https://github.com/PetarV-/GAT}         \\\\ \\hline \n\t\t\tLGCN (2018)           &    tensorflow         &      \\url{https://github.com/divelab/lgcn/}       \\\\ \\hline\n\t\t\tPGC-DGCNN (2018)  & pytorch & \\url{https://github.com/dinhinfotech/PGC-DGCNN} \\\\ \\hline\n\t\t\tFastGCN (2018)  & tensorflow & \\url{https://github.com/matenure/FastGCN} \\\\ \\hline\n\t\t\tStoGCN (2018)  & tensorflow & \\url{https://github.com/thu-ml/stochastic_gcn} \\\\ \\hline\n\t\t\tDGCNN (2018)  & torch & \\url{https://github.com/muhanzhang/DGCNN} \\\\ \\hline\n\t\t\tDiffPool (2018)  & pytorch & \\url{https://github.com/RexYing/diffpool} \\\\ \\hline\n\t\t\tDGI (2019)  & pytorch & \\url{https://github.com/PetarV-/DGI} \\\\ \\hline\n\t\t\tGIN (2019)  & pytorch & \\url{https://github.com/weihua916/powerful-gnns} \\\\ \\hline\n\t\t\tCluster-GCN (2019)  & pytorch & \\url{https://github.com/benedekrozemberczki/ClusterGCN} \\\\ \\hline\n\t\t\tDNGR (2016)           &      matlab       & \\url{https://github.com/ShelsonCao/DNGR}            \\\\ \\hline \n\t\t\tSDNE (2016)            & tensorflow            &    \\url{https://github.com/suanrong/SDNE}         \\\\ \\hline \n            GAE (2016)            &  tensorflow           &    \\url{https://github.com/limaosen0/Variational-Graph-Auto-Encoders}         \\\\ \\hline \n\t\t\tARVGA (2018)            &  tensorflow           &    \\url{https://github.com/Ruiqi-Hu/ARGA}         \\\\ \\hline \n\t\t\tDRNE (2016)           &      tensorflow       & \\url{https://github.com/tadpole/DRNE}            \\\\ \\hline\n\t\t\tGraphRNN (2018)       &    tensorflow         &    \\url{https://github.com/snap-stanford/GraphRNN}         \\\\ \\hline  \n\t\t\tMolGAN (2018)  & tensorflow & \\url{https://github.com/nicola-decao/MolGAN} \\\\ \\hline\n\t\t\tNetGAN (2018)  & tensorflow & \\url{https://github.com/danielzuegner/netgan}  \\\\ \\hline\n\t\t\tGCRN (2016)  & tensorflow & \\url{https://github.com/youngjoo-epfl/gconvRNN} \\\\ \\hline\n\t        DCRNN (2018)         &     tensorflow        &      \\url{https://github.com/liyaguang/DCRNN}        \\\\ \\hline \n\t        \t\t    Structural RNN (2016)  &     theano        & \\url{https://github.com/asheshjain399/RNNexp}            \\\\ \\hline\n\t\t\tCGCN (2017)        &   tensorflow          &    \\url{https://github.com/VeritasYin/STGCN_IJCAI-18}        \\\\ \\hline \n\t\t\tST-GCN (2018)         & pytorch           &   \\url{https://github.com/yysijie/st-gcn}          \\\\\n\t\t\t\\hline\n\t\t\tGraphWaveNet (2019)  & pytorch & \\url{https://github.com/nnzhan/Graph-WaveNet} \\\\ \\hline\n\t\t\tASTGCN (2019)  & mxnet & \\url{https://github.com/Davidham3/ASTGCN} \\\\ \\bottomrule\n\t\t\\end{tabular}\n\t\\end{table*}\n\\end{comment}\n\\balance\n\\end{document}", "cites": [7009, 231, 242, 225, 211, 8313, 240, 237, 220, 224, 25, 228, 232, 8312, 239, 180, 230, 7214, 23, 229, 234], "cite_extract_rate": 0.6774193548387096, "origin_cites_number": 31, "insight_result": {"type": "descriptive", "scores": {"synthesis": 1.5, "critical": 1.0, "abstraction": 1.3}, "insight_level": "low", "analysis": "The section is purely descriptive, listing open-source implementations of GNN models with minimal contextual or conceptual integration. It does not synthesize ideas across the cited papers, nor does it critically evaluate their approaches or identify broader patterns or trends in the field."}}
