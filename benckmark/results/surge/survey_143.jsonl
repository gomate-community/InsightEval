{"id": "2d4801fa-4383-44ef-862a-1e4c5777e976", "title": "Introduction", "level": "section", "subsections": [], "parent_id": "a9f9fefb-0309-4d28-92cc-37901b6afe54", "prefix_titles": [["title", "A Survey on Subgraph Counting: Concepts, Algorithms and Applications to Network Motifs and Graphlets"], ["section", "Introduction"]], "content": "Networks (or graphs) are a very flexible and powerful way of modeling many real-world systems. In its essence, they capture the interactions of a system, by representing entities as nodes and their relations as edges connecting them (e.g., people are nodes in social networks and edges connect those that have some relationship between them, such as friendships or citations). Networks have thus been used to analyze all kinds of social, biological and communication processes~. Extracting information from networks is therefore a vital interdisciplinary task that has been emerging as a research area by itself, commonly known as Network Science~.\nOne very common and important methodology is to look at the networks from a subgraph perspective, identifying the characteristic and recurrent connection patterns. For instance, network motif analysis~ has identified the feed-forward loop as a recurring and crucial functional pattern in many real biological networks, such as gene regulation and metabolic networks . Another example is the usage of graphlet-degree distributions to show that protein-protein interaction networks are more akin to geometric graphs than with traditional scale-free models~.\nAt the heart of these topologically rich approaches lies the subgraph counting problem, that is, the ability to compute subgraph frequencies. However, this is a very hard computational task. In fact, determining if one subgraph exists at all in another larger network (i.e., \\textit{subgraph isomorphism}~) is an \\mbox{NP-Complete} problem~. Determining the exact frequency is even harder, and millions or even billions of subgraph occurrences are typically found even in relatively small networks.\nGiven both its usefulness and hard tractability, subgraph counting has been raising a considerable amount of interest from the research community, with a large body of published literature. This survey aims precisely to organize and summarize these research results, providing a comprehensive overview of the field. Our main contributions are the following:\n\\begin{itemize}\n\t\\item \\textbf{A comprehensive review of algorithms for \\textit{exact} subgraph counting.} We give a structured historical perspective on algorithms for computing exact subgraph frequencies. We provide a complete overview table in which we employ a taxonomy that allows to classify all algorithms on a set of key characteristics, highlighting their main similarities and differences. We also identify and describe the main conceptual ideas, giving insight on their main advantages and possible limitations. We also provide links to existing implementations, exposing which approaches are readily available.\n\t\\item \\textbf{A comprehensive review of algorithms for \\textit{approximate} subgraph counting.} Given the hardness of the problem, many authors have resorted to approximation schemes, which allow trading some accuracy for faster execution times. As on the exact case, we provide historical context, links to implementations and we give a classification and description of key properties, explaining how the existing approaches deal with the balance between precision and running time.\n\t\\item \\textbf{A comprehensive review of \\textit{parallel} subgraph counting methodologies.} It is only natural that researchers have tried to harness the power of parallel architectures to provide scalable approaches that might decrease the needed computation time. As before, we provide an historical overview,  coupled with classification on a set of important aspects, such as the type of parallel platform or availability of an implementation. We also give particular attention to how the methodologies tackle the unbalanced nature of the search space.\n\\end{itemize} \nWe complement this journey trough the algorithmic strategies with a \\textit{clear formal definition of the subgraph counting problem} being discussed here, an \\textit{overview of its applications} and complete and a large number of \\textit{references to related work} that is not directly in the scope of this article. We believe that this survey provides the reader with an insightful and complete perspective on the field, both from a methodological and an application point of view.\nThe remainder of this paper is structured as follows. Section~\\ref{sec:preliminaries} presents necessary terminology, formally describes subgraph counting, and describes possible applications related subgraph counting. Section~\\ref{sec:exact} reviews exact algorithms, divided between full enumeration and analytical methods. Approximate algorithms are described in Section~\\ref{sec:sampling} and parallel strategies are presented in Section~\\ref{sec:parallel}. Finally, in Section~\\ref{sec:conclusions} we give our concluding remarks.\n\\newpage", "cites": [8852], "cite_extract_rate": 0.1111111111111111, "origin_cites_number": 9, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 2.0, "abstraction": 2.0}, "insight_level": "low", "analysis": "The introduction provides a factual overview of subgraph counting and its applications, referencing related work like network motifs and graphlets. However, it lacks synthesis of the cited papers and does not deeply integrate or compare ideas. It offers minimal critical analysis and primarily describes the field without generalizing to broader principles or frameworks."}}
{"id": "de74a3ce-bb73-4ad6-9cdb-5c0419ddcccb", "title": "Algorithms Not Considered", "level": "subsection", "subsections": [], "parent_id": "2222dac9-0087-4cc7-94e5-88b07162acb0", "prefix_titles": [["title", "A Survey on Subgraph Counting: Concepts, Algorithms and Applications to Network Motifs and Graphlets"], ["section", "Preliminaries"], ["subsection", "Algorithms Not Considered"]], "content": "In this work we focus on practical algorithms that are capable of counting all subgraphs of a given size. Therefore, algorithms that only target specific subgraphs are not considered (e.g., triads~, cliques~, stars~ or subtrees~). Furthermore, given our focus on generalizability, we do not consider algorithms that are only capable of counting sugraphs in specific graphs (e.g., bipartite networks~, trees~), or that only count local subgraphs~.\nGraphs used throughout this work are simple, have a single layer of connectivity and do not distinguish the node or edge types with qualitative or quantitative features. Therefore we do not discuss here algorithms that use colored nodes or edges~, and neither those that consider networks that are heterogeneous~, multilayer ~, labelled/attributed~, probabilistic~ or any kind of weighted graphs~.\nFinally, the networks we consider are static and do not change their topology. We should however note that there has been an increasing interest in temporal networks, that evolve over time~. Some algorithms beyond the scope of this survey try to tackle temporal subgraph counting, either by considering temporal networks as a series of static snapshots~, by timestamping edges~, or by considering a stream of small updates to the graph topology~.\n\\input{sections/Applications}\\", "cites": [8853, 8854, 8857, 4912, 9130, 8855, 4910, 4911, 8856], "cite_extract_rate": 0.3333333333333333, "origin_cites_number": 27, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 2.0, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section provides a clear list of algorithms and network types that fall outside the survey's scope, citing relevant papers as examples. However, it lacks deeper synthesis, critical evaluation, or abstraction. The discussion is primarily descriptive, mentioning excluded approaches without comparing them or analyzing their relevance or limitations in relation to the survey's focus."}}
{"id": "a6618461-2262-429f-8304-20aff1c4afc2", "title": "Exact Counting", "level": "section", "subsections": ["e2452b11-f065-4855-b11a-851d30f1cc0d", "cab7da01-9bb6-4e0a-9d3c-d180e0b3490d", "47eb54f8-e175-4a0d-b42b-644149bacf55"], "parent_id": "a9f9fefb-0309-4d28-92cc-37901b6afe54", "prefix_titles": [["title", "A Survey on Subgraph Counting: Concepts, Algorithms and Applications to Network Motifs and Graphlets"], ["section", "Exact Counting"]], "content": "\\label{sec:exact}\nAs subgraph counting evolved over the years,\na multitude of algorithms and methods were developed that address the\nproblem in different ways and for distinct purposes. As such, it is\nuseful, although not easy, to group strategies together in order\nto facilitate their understanding as well as learn why and how they\ncame about. With this in mind we divided this section into two major\ngroups of algorithms, namely enumeration and analytic approaches, which are further subdivided\nin their respective section. Table~\\ref{tab:over_exact} summarizes our proposed taxonomy composed \nof six aspects, ordered by their publication year: (i) \\textbf{approach} (enumeration or analytic), \n(ii) \\textbf{type} (a subgroup of the underlying approach), (iii) \\textbf{$k$-restriction} (does the method only work\nfor certain subgraph sizes?), (iv) \\textbf{orbit awareness} (does the method\nalso count orbits?), (v) \\textbf{directed} (is the method applicable to directed graphs?) and (vi) if code is \\textbf{publicly available}. At the end of this section,\nwe also present some related theoretical results that influenced some of the algorithms\nwe discuss.\n\\begin{table}[H]\n\t\\small\n\t\\centering\n\t\\def\\arraystretch{1.0}\n\t\\caption{Overview of all major exact algorithms.}\n\t\\label{tab:over_exact}\n\t\\vspace{-0.2cm}\n\t\\begin{tabular}{$l^c^c^c^c^c^c^c}\n\t\t\\rowstyle{\\bfseries}\n\t\t& Year & Approach & Type & $k$-restriction & Orbit & Directed & Code \\\\ \\hline\n\t\t\\textsc{Mfinder}  & 2002 & Enum. & Classical & None & \\xmark & \\cmark & \\\\\n\t\t\\textsc{ESU}  & 2005 & Enum. & Classical & None & \\xmark & \\cmark &  \\\\\n\t\t\\textsc{Itzhack}  & 2007 & Enum. & Classical & $\\leq 5$ & \\xmark & \\cmark & \\xmark \\\\\n\t\t\\textsc{Grochow}  & 2007 & Enum. & Single-subgraph & None & \\xmark & \\cmark & \\xmark \\\\\n\t\t\\textsc{Kavosh}  & 2009  & Enum. & Classical & None & \\xmark & \\cmark & \\\\\t\n\t\t\\textsc{Gtries}  & 2010 & Enum. & Encapsulation & None & \\cmark & \\cmark & \\\\\t\n\t\t\\textsc{Rage}  & 2010 & Analytic & Decomposition & $\\leq 5$ & \\xmark & \\cmark &  \\\\\n\t\t\\textsc{NeMo}  & 2011 & Enum. & Single-subgraph& None & \\xmark & \\cmark &  \\\\\n\t\t\\textsc{Netmode}  & 2012 & Enum. & Encapsulation & $\\leq 6$ & \\xmark & \\cmark & \\\\\n\t\t\\textsc{SCMD}  & 2012 & Enum. & Encapsulation & None & \\xmark & \\xmark & \\xmark\\\\\n\t\t\\textsc{acc-Motif}  & 2012 & Analytic & Decomposition & $\\leq 6$ & \\xmark & \\cmark & \\\\\n\t\t\\textsc{ISMAGS}  & 2013 & Enum. & Single-subgraph & None & \\xmark & \\cmark & \\\\\n\t\t\\textsc{Quatexelero}  & 2013 & Enum. & Encapsulation & None & \\xmark & \\cmark & \\\\\n\t\t\\textsc{FaSE}  & 2013 & Enum. & Encapsulation & None & \\xmark & \\cmark &  \\\\\n\t\t\\textsc{ENSA}  & 2014 & Enum. & Encapsulation & None & \\xmark & \\cmark & \\xmark \\\\\n\t\t\\textsc{Orca}  & 2014 & Analytic & Matrix-based & $\\leq 5$ & \\cmark & \\xmark & \\\\\n\t\t\\textsc{Hash-ESU}  & 2015 & Enum. & Encapsulation & None & \\xmark & \\cmark & \\xmark \\\\\n\t\t\\textsc{Song}  & 2015 & Enum. & Encapsulation & None & \\xmark & \\cmark & \\xmark \\\\\n\t\t\\textsc{Ortmann}  & 2016 & Analytic & Matrix-based & $\\leq 4$ & \\cmark & \\cmark & \\xmark\\\\\n\t\t\\textsc{PGD}  & 2016 & Analytic & Decomposition & $\\leq 4$ & \\cmark & \\xmark & \\\\\n\t\t\\textsc{Patcomp}  & 2017 & Enum. & Encapsulation & None &  \\xmark & \\cmark & \\xmark \\\\\n\t\t\\textsc{Escape}  & 2017 & Analytic & Decomposition & $\\leq 5$ & \\cmark & \\xmark &  \\\\\n\t\t\\textsc{Jesse}  & 2017 & Analytic & Matrix-based & None & \\cmark & \\xmark &  \\\\\n\t\t\\end{tabular}\n\t\t\\end{table}", "cites": [4913, 4914], "cite_extract_rate": 0.0425531914893617, "origin_cites_number": 47, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.5, "critical": 2.0, "abstraction": 2.0}, "insight_level": "medium", "analysis": "The section provides a descriptive overview of exact subgraph counting algorithms by categorizing them into 'enumeration' and 'analytic' approaches, with additional attributes like k-restriction, orbit awareness, and directed graph support. While it organizes information in a structured table and mentions a taxonomy, it lacks deep synthesis or cross-paper analysis. The critique of individual papers is minimal, and no overarching principles or meta-level insights are clearly articulated."}}
{"id": "34d6ff46-99db-4ab4-8410-8e57ae2fe9b5", "title": "Matrix based methods", "level": "subsubsection", "subsections": [], "parent_id": "cab7da01-9bb6-4e0a-9d3c-d180e0b3490d", "prefix_titles": [["title", "A Survey on Subgraph Counting: Concepts, Algorithms and Applications to Network Motifs and Graphlets"], ["section", "Exact Counting"], ["subsection", "Analytic approaches"], ["subsubsection", "Matrix based methods"]], "content": "The first known method to apply a practical analytic approach based on\nmatrix multiplication to subgraph counting was \\textsc{ORCA}, a work by\n\\citeAutRef{hovcevar2014combinatorial}, which is based on counting orbits\nand not directly subgraphs. Their original work was targeted at orbits\nin subgraphs up to 5 vertices and, because of that, they count\ninduced subgraphs specifically, while most analytic approaches count non-induced occurrences. \n\\textsc{ORCA} works by setting up a system of linear equations per vertex of the input graph that relate different orbit frequencies, which are the system's variables. This system of linear equations contains information about the input graph. By construction, the matrix has a\nrank equal to the number of orbits minus 1, thus to solve it one only\nneed to find the value of one the orbit frequencies and use any\nstandard linear algebra method to solve it. Usually, the orbit\npertaining to the clique is chosen, since there are efficient\nalgorithms to count this orbit and, for sparse enough networks, it is usually the one with the\nleast occurrences, making it less expensive to count.\nLater, the authors of \\textsc{ORCA} extended their work by suggesting a\nway of producing equations for arbitrary sized subgraphs~, although their available practical implementation is still limited to size 5~. Another possible extension for \\textsc{ORCA} was proposed by~ with the \\textsc{Jesse} algorithm, which was further complemented with a strategy for optimizing the computation by carefully selecting less expensive equations~. \nSimilar to \\textsc{ORCA}, but using a different strategy, \\citeAutRef{ortmann2016quad} proposed a new method, which\nthey further improved and better described in\n. They also target orbits, but for\nsubgraphs of size up to 4. Their approach is based on looking into\nnon-induced subgraphs using them to build linear equations that are\nless expensive to compute. Additionally, they also apply an improved\nclique counting algorithm. \\citeAutRef{ortmann2016quad} did not name their algorithm, so we will refer to it as the \\textsc{Ortmann}\nalgorithm from here on.", "cites": [4913], "cite_extract_rate": 0.2, "origin_cites_number": 5, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.5, "critical": 3.0, "abstraction": 3.0}, "insight_level": "medium", "analysis": "The section provides an analytical overview of matrix-based methods for subgraph counting, particularly focusing on ORCA and the Ortmann algorithm. It connects these methods by highlighting their shared use of linear equations and orbit counting, and contrasts their strategies, such as induced vs. non-induced subgraphs. While it includes some critical perspectives (e.g., limitations in implementation), it could offer deeper comparative analysis and broader abstraction to elevate the insight level further."}}
{"id": "69e10b13-9779-4075-8acc-789400f8c8cd", "title": "Decomposition methods", "level": "subsubsection", "subsections": [], "parent_id": "cab7da01-9bb6-4e0a-9d3c-d180e0b3490d", "prefix_titles": [["title", "A Survey on Subgraph Counting: Concepts, Algorithms and Applications to Network Motifs and Graphlets"], ["section", "Exact Counting"], ["subsection", "Analytic approaches"], ["subsubsection", "Decomposition methods"]], "content": "Before \\textsc{ORCA} was proposed, the first ever practical method that\nused an analytic approach to subgraph counting was \\textsc{Rage}, by {\\bf\n  Marcus and Shavitt}~. Their method is based on~\nwhich employs similar techniques but with a more theoretical\nfocus. \\textsc{Rage} targets non-induced subgraphs and orbits of size 3\nand 4. It does so by running a different algorithm for each of the 8\nexisting subgraphs. Each algorithm is based on merging the\nneighborhoods of pairs of vertices to ensure that a given quartet of\nvertices have the desired edges to form a certain subgraph.\n\\textsc{acc-Motif}, which was proposed by \\citeAutRef{meira2012accelerated}\nand then further improved in\n, was also one of the first methods to employ an\nanalytic strategy, but stands out as the only known analytic method\nthat also works for directed subgraphs. \\textsc{acc-Motif} also targets\nnon-induced subgraphs and their latest version supports up to size 6\nsubgraphs.\nAnother method that followed this trend of decomposition methods is\n\\textsc{PGD}, proposed by {\\bf Ahmed et al.}~. This method builds on\nthe classic triangle counting algorithm to count several primitives\nthat are then used to obtain the frequency of each subgraph and\norbit. It is currently one of the fastest methods, however it can only\ncount undirected subgraphs of size 3 and 4. Additionally, as most\nanalytic methods, it is highly parallelizible. Due to its versatile nature, \\textsc{PGD} has been expanded to other\nfrequency metrics and it stands out as one of the only available\nefficient methods that can count motifs incident to a vertex or edge\nof the graph~, in what is called a ``local\nsubgraph count''.\nMore recently, \\textsc{ESCAPE} was proposed by \\citeAutRef{pinar2017escape}. This method is based on a divide and conquer\napproach that identifies substructures of each counting subgraph to\npartition them into smaller patterns. It is a very general method, but\nwith the correct choices for decomposition, it is possible to describe\na set of formulas to compute the frequency of each subgraph. The\noriginal paper only describes the resulting formulas to subgraphs up\nto size 5, however larger sizes can be obtained with some effort. As\nof this writing, it is possibly the most efficient algorithm to count\nundirected subgraphs and orbits up to size 5.", "cites": [3958], "cite_extract_rate": 0.14285714285714285, "origin_cites_number": 7, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.5, "critical": 2.0, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section provides a factual description of various decomposition methods for exact subgraph counting, mentioning their targets (e.g., size, directionality) and distinguishing features. However, it lacks deeper synthesis across the cited works and does not connect them into a broader conceptual framework. Critical evaluation is minimal, with only superficial mentions of limitations (e.g., 'with some effort'), and no meta-level abstraction or novel insights are presented."}}
{"id": "47eb54f8-e175-4a0d-b42b-644149bacf55", "title": "Theoretical Results", "level": "subsection", "subsections": [], "parent_id": "a6618461-2262-429f-8304-20aff1c4afc2", "prefix_titles": [["title", "A Survey on Subgraph Counting: Concepts, Algorithms and Applications to Network Motifs and Graphlets"], ["section", "Exact Counting"], ["subsection", "Theoretical Results"]], "content": "Even though the focus of this work is to look at the proposed\npractical algorithms, it is\nimportant to note that some of the existing work drew\ninspiration from numerous more theoretical-oriented works. Thus, it is\nof relevance to briefly summarize some of the achievements in this\narea and we will do so with a special interest in those that directly\ninfluenced some of the algorithms discussed in this section.\nThe first interest in subgraph counting stemmed from the world of\nenumeration algorithms. The book ``Enumeration in\nGraphs''~ surveyed several methods to\nenumerate several different structures in a graph, such as cycles,\ntrees or cliques. Even though these are specific subpatterns, they\noften represent the fundamental computation that needs to be done\nin order to enumerate any subgraph. These ideas were translated into\nworks that count\nsubgraphs by efficiently enumerating simpler substructures like\nthese~. Approximation schemes can also be developed with this in mind, which approximates the frequency\nof several subgraph families like cycles or paths and then generalize\nthese for all size 4 subgraphs~.\nAnother example of an initially purely theoretical technique is the work by~\\citeAutRef{kowaluk2013counting}, which was one of the inspirations for the\nmultitude of matrix based analytic algorithms for counting\nsubgraphs. In fact, the most efficient algorithms are\nbased on several theoretical foundations that allow a tighter analysis of\nruntime. Due to this interplay, it is worth mentioned a few more recent papers\non subgraph counting and enumerating. There is an interest in\nfinding efficient algorithms that are parameterized or sensitive to certain properties of\nthe graph, such as independent sets~ or its maximum degree~. Another current interest is in counting\nand enumerating subgraphs in a dynamic or online environment~. Finally, another active theoretical\ntopic is to find optimal algorithms for\nenumeration, as in~, as\nwell as proving lower bounds on their time complexity, as~\\citeAutRef{bjorklund2014listing} does for triangle listing.", "cites": [8858, 4915], "cite_extract_rate": 0.25, "origin_cites_number": 8, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.5, "critical": 2.5, "abstraction": 3.0}, "insight_level": "medium", "analysis": "The section provides a general overview of theoretical results that underpin practical subgraph counting algorithms, making some effort to connect ideas from different works, particularly around enumeration algorithms and parameterized approaches. While it identifies broader themes (e.g., dynamic environments, optimal algorithms, lower bounds), it does so without deeply evaluating or contrasting the cited papers. The abstraction is moderate, but the critical analysis is limited to mentioning general advantages and limitations rather than offering in-depth critique."}}
{"id": "68736c7a-a268-4806-9986-477440316a7a", "title": "Approximate Counting", "level": "section", "subsections": ["74d93f5a-15fb-4d46-abc4-130446dd6e6e", "b39b007a-4228-4c3f-8c9f-2a8b1ce788bd", "07499d4a-cb11-4752-9715-1704ec5d13aa", "618d48d5-8ed5-40db-bcd0-ad743ac043a0", "4b1991b4-b42a-4ba2-ab3d-2526fdf694ca"], "parent_id": "a9f9fefb-0309-4d28-92cc-37901b6afe54", "prefix_titles": [["title", "A Survey on Subgraph Counting: Concepts, Algorithms and Applications to Network Motifs and Graphlets"], ["section", "Approximate Counting"]], "content": "\\label{sec:sampling}\nDespite the significant advances made towards faster subgraph counting algorithms, current state of the art\nalgorithms that determine exact frequencies still take hours, if not days, for very large networks.\nWith the ever increasing amount of data our society generates (e.g., in big social networks such as Twitter\nand Facebook new members/nodes join every second), it is unfeasible to count all possible subgraphs. To solve\nthis problem, subgraph counting research drifted towards approximating these frequencies, making a trade-off between\nlosing accuracy but gaining time. Additionally, in some applications, approximate subgraphs counts might be sufficient~.\nThroughout this section we make a distinction between algorithms that estimate (i) subgraph frequencies or (ii) subgraph concentrations. Estimating subgraph frequencies is harder since the algorithm needs\nto know the magnitude of the values, whereas to estimate concentrations the algorithm only needs to know the different\nproportions of each subgraph in the network. Obtaining subgraph concentrations from subgraph frequencies is trivial but the reverse requires extra computational tasks.\nWe further split the approximate counting algorithms in five broad categories: \\textbf{randomised enumeration}, \\textbf{enumerate-generalize}, \\textbf{path sampling},\n\\textbf{random walk}, and \\textbf{colour coding}. In each subsection, we provide an algorithmic overview of each strategy and delve into\nthe individual algorithms that implement it and how they differ between themselves.\nTables~\\ref{tab:approx_algs} and~\\ref{tab:restaccess_algs} summarize the algorithms we discuss in the section. We split the methods into\nalgorithms where the\nfull topology is assumed (Table~\\ref{tab:approx_algs}) and algorithms tailored to networks with restricted access (Table~\\ref{tab:restaccess_algs}). Although some algorithms from each category may work in the other setting,\nthey excel for the task they were designed for and the distinction should be made clear. The tables summarize our proposed taxonomy composed \nof five aspects, ordered by their publication year: (i) the type of {\\bf output} (frequencies or\nconcentrations), (ii) \\textbf{$k$-restrictions} (does the method only work\nfor certain subgraph sizes?), (iii) \\textbf{directed} (is the method applicable to directed graphs?), (iv) the {\\bf strategy} it employs, according to\nour taxonomy, and (v) if code is \\textbf{publicly available}. Note that some authors do not have \nexecutable versions publicly available, but will be happy to share them through email. We mark these algorithms with a \\cmark in the code\ncolumn of the table.\n\\begin{table}[!h]\n        \\small \n        \\centering\n        \\def\\arraystretch{1.0}\n        \\caption{Algorithms for approximate subgraph counting.}\n        \\label{tab:approx_algs}\n        \\begin{tabular}{$l^l^l^c^c^l^c }\n                \\rowstyle{\\bfseries}\n                & Year & Output & $k$-restriction & Directed & Strategy & Code\\\\\n                & & & & \\\\[-8pt] \n                         \\hline\n                         \\textsc{ESA}~  & 2004 & Conc. & None & \\cmark & Random Walk &   \\\\[2pt]\n                         \\textsc{RAND-ESU}~  & 2005 & Freq. & None & \\cmark & Rand. Enum. &   \\\\[2pt]\n                         \\textsc{TNP}~  & 2006 & Conc. & 5 & \\xmark & Enum. - Generalize & \\xmark  \\\\[2pt]\n                         \\textsc{RAND-GTrie}~  & 2010 & Freq. & None & \\cmark & Rand. Enum. & \\\\[2pt]\n                         \\textsc{GUISE}~  & 2012 & Conc. & 5 & \\xmark & Random Walk &   \\\\[2pt]\n                         \\textsc{RAND-SCMD}~  & 2012 & Freq. & None & \\cmark & Enum. - Generalize & \\xmark  \\\\[2pt]\n                         \\textsc{Wedge Sampling}~  & 2013 & Freq. & 3 & \\cmark & Path Sampling &   \\\\[2pt]\n                         \\textsc{GRAFT}~  & 2014 & Freq. & 5 & \\xmark & Enum. - Generalize &   \\\\[2pt]\n                         \\textsc{PSRW \\& MSS}~  & 2014 & Conc. & None & \\xmark & Random Walk & \\xmark  \\\\[2pt]\n                         \\textsc{MHRW}~  & 2015 & Conc. & None & \\xmark & Random Walk & \\cmark  \\\\[2pt]\n                         \\textsc{RAND-FaSE}~  & 2015 & Freq. & None & \\cmark & Rand. Enum. &   \\\\[2pt]\n                         \\textsc{Path Sampling}~  & 2015 & Freq. & 4 & \\xmark & Path Sampling & \\xmark  \\\\[2pt]\n                         \\textsc{$k$-profile sparsifier}~  & 2016 & Freq. & 4 & \\xmark & Enum. - Generalize &  \\\\[2pt]\n                         \\textsc{MOSS}~ & 2018 & Freq. & 5 & \\xmark & Path Sampling &   \\\\[2pt]\n                         \\textsc{SSRW}~ & 2018 & Freq. & 7 & \\xmark & Random Walk & \\xmark \\\\[2pt]\n                         \\textsc{CC}~ & 2018 & Freq. & None & \\xmark & Color Coding &  \\\\[2pt]\n        \\end{tabular}\n\\end{table}\n\\begin{table}[!h]\n        \\small \n        \\centering\n        \\def\\arraystretch{1.0}\n        \\caption{Algorithms for approximate subgraph counting with restricted access.}\n        \\label{tab:restaccess_algs}\n        \\begin{tabular}{$l^l^l^c^c^l^c }\n                \\rowstyle{\\bfseries}\n                & Year & Output & $k$-restriction & Directed & Strategy & Code\\\\\n                & & & &  \\\\[-8pt]\n                \\hline\n                         \\textsc{WRW}~  & 2016 & Conc. & None & \\xmark & Random Walk & \\xmark  \\\\[2pt]\n                         \\textsc{IMPR}~  & 2016 & Freq. & 5 & \\xmark & Random Walk &   \\\\[2pt]\n                         \\textsc{CSS} \\& \\textsc{NB-SRW}~  & 2016 & Conc. & None & \\xmark & Random Walk & \\cmark  \\\\[2pt]\n                         \\textsc{Minfer}~  & 2017 & Conc. & 5 & \\cmark & Enumerate - Generalize & \\xmark  \\\\[2pt]\n        \\end{tabular}\n\\end{table}", "cites": [8859, 4916, 4920, 4921, 4917, 4919, 4918], "cite_extract_rate": 0.22580645161290322, "origin_cites_number": 31, "insight_result": {"type": "comparative", "scores": {"synthesis": 3.5, "critical": 2.5, "abstraction": 3.0}, "insight_level": "medium", "analysis": "The section organizes approximate counting algorithms into a structured taxonomy and compares them based on key attributes like output type, k-restriction, and strategy. It integrates multiple papers into categories but does not deeply synthesize their underlying ideas or methodologies. The critical analysis is limited, as the section mainly reports features without evaluating trade-offs or limitations in detail. Some abstraction is achieved through the classification framework, but broader conceptual insights are not fully developed."}}
{"id": "b39b007a-4228-4c3f-8c9f-2a8b1ce788bd", "title": "Enumerate-Generalize", "level": "subsection", "subsections": [], "parent_id": "68736c7a-a268-4806-9986-477440316a7a", "prefix_titles": [["title", "A Survey on Subgraph Counting: Concepts, Algorithms and Applications to Network Motifs and Graphlets"], ["section", "Approximate Counting"], ["subsection", "Enumerate-Generalize"]], "content": "The general idea of these algorithms is to perform an exact count on a smaller network that was obtained from the original one (e.g., a sample, or a compressed network).\nFrom the frequencies of each subgraph in the smaller network, the frequencies in the original network are estimated. Algorithms vary on (i) how the smaller network is obtained and on (ii) which estimator they use.\nThe first example of an algorithm in this category is Targeted Node Processing (\\textsc{TNP}) by~\\citeAutRef{prvzulj2006efficient}.\nThis algorithm is specially tailored for protein-protein interaction\n,that, according to the authors,\nhave a periphery that is sparser than the more central parts of the network. Using this information, it performs an exact count\nof the subgraphs in the periphery of the network and uses their frequencies to estimate the frequencies in the rest\nof the network. The authors claim that, due to the uniformity of the aforementioned networks, the distribution of the subgraphs\nin the fringe is representative of the distribution in the rest of the network.\n\\textsc{SCMD} by \\citeAutRef{wang2012symmetry} (already covered in Section~\\ref{sec:exact_encap})\nallows the use of any approximate counting method in the compressed graph. There is no guarantee that subgraphs are\ncounted uniformly in the compressed graph, introducing a bias that needs to be corrected. The authors give the example of this bias\nwhen using their method in conjunction with \\textsc{RAND-ESU}. If each leaf (subgraph)\nof depth $k$ in the search tree is reached with probability $P$ and a specific subgraph in the compressed graph is sampled\nwith probability $\\rho$, then, to correct the sampling bias, the probability of decompressing the relevant $k$-subgraph is $P/\\rho$.\nIn \\textsc{GRAFT}, \\citeAutRef{rahman2014graft} provide a strategy for counting undirected graphlets of size up to 5, using edge sampling.\nThe algorithm starts by picking an edge $e_g$ from each of the 29 graphlets and a set of edges sampled\nfrom the graph $\\mathcal{S}$, without replacement. For each edge $e \\in \\mathcal{S}$ and for each graphlet $g$, the frequency of $g$ is \ncalculated such that $e$ has the same position in $g$ as $e_g$ ($e$ is said to be aligned with $e_g$). These frequencies are summed for all\nedges and divided by a normalising factor, based on the automorphisms of each graphlet, which becomes the estimation for the\nfrequency of that graphlet in the whole network. Note that if $\\mathcal{S}$ is equal to $E(G)$, the algorithm outputs an exact answer.\n\\citeAut{elenberg2015beyond} create estimators for the frequency of size 3~ and 4~\nsubgraphs. A major difference from this work to previous ones is that \\citeAut{elenberg2015beyond} estimate the frequencies of subgraphs\nthat are not connected, besides the usual connected ones. The authors start by removing each edge from the network with a certain probability \nand computing the exact counts in this ``sub-sampled'' network. Then, they craft a set of linear equations that relate the exact\ncounts on this smaller network to the ones of the original network. Using these equations, the estimation of the frequency\nof the subgraphs in the original network follows.\n\\citeAutRef{wang2017inferring} introduce an algorithm that aims to estimate the subgraph concentrations of a network\nwhen only a fraction of its edges are known. They call this a ``RESampled Graph'', obtained from the real network through\nrandom edge sampling, a common scenario on applications such as network traffic analysis. A key aspect of this algorithm is the number of non-\ninduced subgraphs of a size $k$ graphlet that are isomorphic to another size $k$ graphlet, an example of this calculation can be found in\nTable~\\ref{tab:noninduc_rel4}. Using this number and the proportion of edges\nsampled to form the smaller network,  the authors compute the probability that a subgraph in the ``RESampled Graph'' is isomorphic to\nanother subgraph in the original graph. Then, an exact counting algorithm is applied to the ``RESampled Graph'' and by composing the\nresults from this algorithm with the aforementioned probability, the subgraph concentrations in the original network are estimated.", "cites": [4918, 4921], "cite_extract_rate": 1.0, "origin_cites_number": 2, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.0, "abstraction": 3.5}, "insight_level": "medium", "analysis": "The section synthesizes multiple approximate counting algorithms by highlighting their shared 'enumerate-generalize' approach and varying aspects such as sampling strategy and estimator correction. It provides some critical analysis, particularly around the issue of sampling bias in SCMD and how it is corrected. The abstraction level is moderate, as it generalizes the idea of using a smaller network to estimate subgraph frequencies but does not fully articulate a meta-level framework or principle."}}
{"id": "cb91ac12-7c2c-4505-99a9-7274208a2c96", "title": "Parallel Strategies", "level": "section", "subsections": ["18c5decb-090f-448d-9684-7eb9bf36e215", "42c7320c-fdda-4e88-bc26-85d4eff62e8a", "d46b0766-44c7-4528-b032-3f000eb4b78f", "d479ff2c-0596-46ca-ac6d-294302b8e128", "7776fb24-158e-4cac-92d6-377837b1f310", "dd87f588-f9e1-44e5-8f6f-4d32580ba3be"], "parent_id": "a9f9fefb-0309-4d28-92cc-37901b6afe54", "prefix_titles": [["title", "A Survey on Subgraph Counting: Concepts, Algorithms and Applications to Network Motifs and Graphlets"], ["section", "Parallel Strategies"]], "content": "\\label{sec:parallel}\nBy this point it should be clear that subgraph counting is a computationally hard problem. As discussed in Section~\\ref{sec:exact}, analytic approaches are much more efficient than enumeration algorithms; however, they are specific to certain sets of small subgraphs. Sampling strategies can produce results in a fraction of the time; but there's a trade-off between time and accuracy. Therefore, speeding up subgraph counting remains a crucial task. The availability of parallel environments, such as multicores, hybrid clusters, and GPUs gave rise to strategies that leverage on these resources. Here we follow a different organizational approach than Sections~\\ref{sec:exact} and~\\ref{sec:sampling}: we first give an historic overview of the parallel algorithms put forward throughout the years and then we discuss the strategies on a higher level. This is done because most parallel algorithms have a sequential counterpart (already described in previous sections) and many common aspects can be found between the parallel strategies. Table~\\ref{tab:paralgs1} summarizes our proposed taxonomy composed \nof seven aspects, ordered by their publication year: (i) their computational \\textbf{platform}, (ii) the \\textbf{initial work-units} (what part of the graph is divided initially), (iii) the \\textbf{runtime work-units} (what part of the graph is divided during runtime), (iv) the \\textbf{search traversal} strategy (how the graph is explored), (v) the \\textbf{work division} strategy (how work-units are distributed), (vi) how \\textbf{work sharing} is performed (if applicable) between workers (e.g., CPU processors, or CPU/GPU threads), and (vii) if code is \\textbf{publicly available}.\n\\begin{table}[!h]\n\t\\footnotesize\n\t\\centering\n\t\\def\\arraystretch{1.0}\n\t\\caption{Parallel algorithms for subgraph counting.}\n\t\\label{tab:paralgs1}\n\t\\begin{tabular}{c^c^c^c^c^c^c^c^c^l }\n\t\t\\rowstyle{\\bfseries}\n\t\t& \\multirow{2}{*}{Year} & \\multirow{2}{*}{Platform} & \\multicolumn{2}{c}{\\bf Work-units} & Search & Work & Work & Public\\\\\n\t\t\\rowstyle{\\bfseries}\n\t\t& &  & Initial & Runtime & Traversal & Division & Sharing & Code \\\\[2pt] \\hline\n\t\t& & & & & & & & \\\\[-6pt] \n\t\t\\rowstyle{}\n\t\t\\textsc{ParWang}~ & 2005 & DM & Vertices & \\xmark & DFS & Static & \\xmark & \\xmark \\\\[2pt]\n\t\t\\textsc{DM-Grochow}~\t& 2008  & DM & Isoclasses & Isoclasses & DFS  & First-Fit & \\xmark & \\xmark \\\\[2pt]\n\t\t\\textsc{MPRF}~\t& 2009 & MapReduce  & Edges & Subgraphs & BFS  & Static & \\xmark & \\xmark  \\\\\n\t\t\\textsc{DM-ESU}~ & 2010 & DM   & Vertices & Subgraph-trees & DFS & Diagonal & M-W & \\xmark \\\\\n\t\t\\textsc{DM-Gtries}~ & 2010 & DM  & Vertices & Subgraph-trees  & DFS & Diagonal & W-W & \\xmark  \\\\\n\t\t\\textsc{SM-Gtries}~ & 2014 & SM  & Vertices & Subgraph-trees & DFS & Diagonal   & W-W &\\\\\n\t\t\\textsc{SM-FaSE}~ & 2014 & SM & Vertices & Subgraph-trees & DFS &  Diagonal & W-W & \\\\\n\t\t\\textsc{Subenum}~ & 2015 & SM & Edges & Subgraphs & DFS & First-Fit  & \\xmark & \\\\\n\t\t\\textsc{GPU-Orca}~ & 2015 & GPU & Vertices &  Subgraphs & BFS & Static & \\xmark & \\xmark\\\\\n\t\t\\textsc{Lin}~ & 2015 & GPU & Vertices & Subgraphs & BFS & Static & \\xmark & \\xmark\\\\ \n\t\t\\textsc{MRSUB}~ & 2015 & MapReduce & Edges & Subgraphs & BFS & Static & \\xmark & \\xmark\\\\\n\t\t\\textsc{PGD}~ & 2015 & SM  & Edges& \\xmark & DFS & Static & \\xmark & \\\\\n\t\t\\textsc{GPU-PGD}~ & 2016 & CPU+GPU & Edges & Subgraph-trees & BFS & First-Fit & W-W &  \\xmark \\\\\n\t\t\\textsc{Elenberg}~ & 2016 & DM & Vertices & Subgraphs & DFS & First-Fit & \\xmark & \\\\\n\t\t\\textsc{MR-Gtries}~ & 2017 & MapReduce & Vertices & Subgraph-trees & DFS & Timed & M-W & \\xmark\\\\\n\t\\end{tabular}\n\\end{table}", "cites": [4921], "cite_extract_rate": 0.05555555555555555, "origin_cites_number": 18, "insight_result": {"type": "comparative", "scores": {"synthesis": 3.5, "critical": 2.0, "abstraction": 3.0}, "insight_level": "medium", "analysis": "The section organizes and compares multiple parallel subgraph counting algorithms using a structured taxonomy, showing synthesis by grouping them based on shared characteristics. However, it lacks in-depth critical evaluation of the cited works, such as discussing their relative merits or limitations. Some abstraction is evident in the classification framework, but broader conceptual patterns or principles are not explicitly identified."}}
{"id": "18c5decb-090f-448d-9684-7eb9bf36e215", "title": "Historical Overview", "level": "subsection", "subsections": [], "parent_id": "cb91ac12-7c2c-4505-99a9-7274208a2c96", "prefix_titles": [["title", "A Survey on Subgraph Counting: Concepts, Algorithms and Applications to Network Motifs and Graphlets"], ["section", "Parallel Strategies"], ["subsection", "Historical Overview"]], "content": "\\label{sec:par_hist}\nOne key aspect necessary to achieve a scalable parallel computation is finding a balanced work division (i.e., splitting work-units \\emph{evenly} between workers -- parallel processors/threads). A naive possibility for subgraph counting is to assign $\\frac{|V(G)|}{|P|}$ nodes from network $G$ to each worker $p \\in P$. This egalitarian division is a poor choice since two nodes induce very different search spaces\n; for instance, $hub$-like nodes induce many more subgraph occurrences than nearly-isolated nodes. Instead of performing an egalitarian division, \\citeAutRef{wang2005parallel} discriminate nodes by their degree and distribute them among workers, the idea being that each worker gets roughly the same amount of \\textit{hard} and \\textit{easy} work-units. Despite achieving a more balanced division than the naive version, there is still no guarantee that the node-degree is sufficient to determine the actual complexity of the work-unit. Distributing work immediately (without runtime adjustments) is called a \\textbf{static division}. Wang et al. did not assess scalability in~, but they showed that their parallel algorithm was faster than \\textsc{Mfinder}~ in an E. Coli transcriptional regulation network. Since their method was not named, we refer to it as \\textsc{ParWang} henceforth. \n\\iffalse\nThe first approach targeting \\underline{multicore machines} was by \\textbf{Schreiber and Schw\\\"obbermeyer (FPF/MAVisto)}  and, similar to Wang et al.~, it was a static division method. They reported \\textcolor{red}{speed-ups of $\\approx$4-5x using a 8-core machine on ten different metabolic which were more significant when bigger subgraphs were counted (5 or 6 nodes)}.\nBoth  and  parallelized \\underline{network-centric} sequential algorithms.\\fi \n The first parallel strategy with a \\textbf{single-subgraph-search} algorithm at its core, namely \\textsc{Grochow}~, was by \\citeAutRef{schatz2008parallel}. Since the algorithm was not named, and it targets a \\textbf{distributed memory (DM)} architecture (i.e., parallel cluster), we refer to it as \\textsc{DM-Grochow}. In order to distribute query subgraphs (also called \\textbf{isoclasses}) among workers they employed two strategies: naive and \\textbf{first-fit}. The naive strategy is similar to \\textsc{ParWang}'s. In the first-fit model, each slave processor requests a subgraph type (or \\textbf{isoclass}) from the master and enumerates all occurrences of that type (e.g., cliques, stars, chains). This division is \\textbf{dynamic}, as opposed to static, but it is not balanced since different isoclasses induce very different search trees. For instance, in sparse networks $k$-cliques are faster to compute than $k$-chains. Using 64 cores, Schatz et al. obtained $\\approx$10-15x speedups over the sequential version on a yeast PPI network. They also tried another novel approach by partitioning the network instead of partitioning the subgraph-set. However, finding adequate partitions for subgraph counting is a very hard problem due to partition overlaps and subgraphs traversing different partitions, and no speedup was obtained using this strategy. We should note that parallel graph partitioning remains an active research problem to this day~, but is out of the scope of this work.\n All parallel algorithms mentioned so far traverse occurrences in a \\textbf{depth-first (DFS)} fashion, since doing so avoids having to store intermediate states. By contrast, \\citeAutRef{liu2009mapreduce} use a \\textbf{breadth-first search (BFS)} where, at each step, all subgraph occurrences found in the previous one are expanded by one node. Their algorithm, \\textsc{MPRF}, is implemented following a \\textbf{MapReduce} model~ which is intrinsically a BFS-like framework. In MPRF, mappers extend size $k$ occurrences to size $k+1$ and reducers remove repeated occurrences. At each BFS-level, \\textsc{MPRF} divides work-units evenly among workers. We still consider this to be a static division since no adjustments are made in runtime. Thus, in our terminology, static divisions can be performed only once (at the start of computation in DFS-like algorithms) or multiple times (once per level in BFS-like algorithms). Overhead caused by reading and writing to files reduces \\textsc{MRPF}'s efficiency, but the authors report speedups of $\\approx7x$ on a 48-node cluster, when compared to the execution on a single-processor. \n DFS-based algorithms discussed so far either perform a complete work-division right at the beginning (\\textsc{ParWang}), or they perform a partial work-division at the beginning and then workers request work when idle (\\textsc{DM-Grochow}). In both cases, a worker has to finish a work-unit before proceeding a new one. Therefore, it is possible that a worker gets stuck processing a very computationally heavy work-unit while all the others are idle. This has to do with work-unit granularity: work-units at the top of the DFS search space have high (coarse) granularity since the algorithm has to explore a large search space. BFS-based algorithms mitigate this problem because work-units are much more fine grained (usually a worker only extends his work-unit(s) by one node). The work by \\citeAutRef{ribeiro2010parallelesu} was the first to implement \\textbf{work sharing} during parallel subgraph counting, alleviating the problem of coarse work-unit granularity of DFS-based subgraph counting algorithms. Workers have a splitting threshold that dictates how likely it is to, instead of fully processing a work-unit, putting part of it in a global work queue. A work-unit is divided using \\textbf{diagonal work splitting} which gathers unprocessed nodes at level $k$ (i.e., nodes that are reached by expanding the current work-unit) and recursively goes up in the search tree, also gathering unprocessed nodes of level $k-i$, $i < k$, until reaching level $1$. This process results in a set of finer-grained work-units that induces a more balanced search space than static and first-fit divisions. In  Ribeiro et al. use \\textsc{ESU} as their core enumeration algorithm and propose a\n \\textbf{master-worker (M-W)} architecture where a master-node manages a work-queue and distributes its work-units among slave workers. This strategy, \\textsc{DM-ESU}, was the first to achieve near-linear speedups ($\\approx$128x on a 128-node cluster) on a set of heterogeneous network. A subsequent version~ used \\textsc{GTries} as their base algorithm and implemented a \\textbf{worker-worker (W-W)} architecture where workers perform work stealing. \\textsc{DM-Gtries} improves upon \\textsc{DM-ESU }by using a faster enumeration algorithm (\\textsc{GTries}) and having all workers perform subgraph enumeration (without wasting a node in work queue management). Similar implementations (based on W-W sharing and diagonal splitting) of \\textsc{GTries} and \\textsc{FASE}  were also developed for \\textbf{shared memory (SM) environments}, which achieved near-linear speedups in a 64-core machine~. The main advantages of SM implementations is that work sharing is faster (since no message passing is necessary) and SM architectures (such as multicores) are a commodity while DM architectures (such as a cluster) are not.\n Instead of developing efficient work sharing strategies, \\citeAutRef{shahrivari2015fast} try to avoid the unbalanced computation induced by vertice-based work-unit division. \\textsc{Subenum} is an adaptation of \\textsc{ESU} which uses edges as starting work-units, achieving near-linear speedup ($\\approx$10x on a 12-core machine). Using edges as starting work-units is also more suitable for the MapReduce model since edges are finer-grained work-units than vertices. In a follow-up work~, Shahrivari and Jalili propose a MapReduce algorithm, \\textsc{MRSUB}, which greatly improves upon~, reporting a speedup of $\\approx34$x on a 40-core machine. Like \\textsc{Subenum}, \\textsc{MRSUB} does not support work sharing between workers. A MapReduce algorithm with work sharing was put forward by \\citeAutRef{ahmad2017scalable}, henceforth called \\textsc{MR-Gtries}. Using work sharing with \\textbf{timed redistribution} (i.e., after a certain time, every worker stops and work is fully redistributed), they report a speedup of $\\approx26$x on a 32-core machine. While \\textsc{MRSUB} and \\textsc{MR-GTries} efficiency is comparable ($\\approx80\\%$), the latter has a much faster sequential algorithm at its core; therefore, in terms of absolute runtime, \\textsc{MR-Gtries} is the fastest MapReduce subgraph counting algorithm that we know of.\n Graphics processing units (\\textbf{GPUs}) are processors specialized in image generation, but numerous general purpose tasks have been adapted to them~. GPUs are appealing due to their large number of cores, reaching hundreds or thousands of parallel threads whereas commodity multicores typically have no more than a dozen. However, algorithms that rely on graph traversal are not best suited for the GPU framework due to branching code, non-coalesced memory accesses and  coarse work-unit granularity~. \\textbf{Milinkovi\\'c et al.}~ were one of the firsts to follow a GPU approach (\\textsc{GPU-Orca}), with limited success. \\citeAutRef{lin2015network} put forward a GPU algorithm (henceforth refereed to as \\textsc{Lin} since it was unnamed) mostly targeted at network motif discovery but also with some emphasis on efficient subgraph enumeration. \\textsc{Lin} avoids duplicate in a similar fashion to ESU  and auxiliary arrays are used to mitigate uncoalesced memory accesses. A BFS-style traversal is used (extending each subgraph 1 node at a time) to better balance work-units among threads. They compare \\textsc{Lin} running on a 2496-core GPU (Tesla K20) against parallel CPU algorithms and report a speedup of $\\approx$10x to a 6-core execution of the fastest CPU algorithm, \\textsc{DM-GTries}. \n \\citeAut{rossi2016leveraging} proposed the first algorithm that \\textbf{combines multiple GPUs and CPUs}~. Their method dynamically distributes work between CPUs and GPUs, where unbalanced computation is given to the CPU whereas GPUs compute the more regular work-units. Since their method was not named, we refer to it as \\textsc{GPU-PGD}. Their hybrid CPU-GPU version achieves speedups of $\\approx 20$x to $\\approx 200$x when compared to sequential \\textsc{PGD}, depending largely on the network. As mentioned in Section~\\ref{sec:exact}, \\textsc{PGD} is one of the fastest methods for sequential subgraph counting. As such, \\textsc{GPU-PGD} is the fastest subgraph counting algorithm currently available as far as we know. However, \\textsc{GPU-PGD} is limited to 4-node subgraphs, while \\textsc{DM-GTries} is the fastest general approach.", "cites": [4923, 4922], "cite_extract_rate": 0.1, "origin_cites_number": 20, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.5, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section effectively synthesizes information from multiple cited papers by integrating different parallel strategies and highlighting their design choices and trade-offs. It provides critical evaluations, such as the limitations of static versus dynamic division, and explains why certain approaches succeed or fail. The section abstracts these methods into broader concepts like work-unit granularity, static/dynamic division, and DFS/BFS paradigms, offering a structured and insightful historical framework."}}
{"id": "c7aaa7cd-25f9-43d6-9e9c-3f14e99f02ff", "title": "Distributed Memory (DM)", "level": "subsubsection", "subsections": [], "parent_id": "42c7320c-fdda-4e88-bc26-85d4eff62e8a", "prefix_titles": [["title", "A Survey on Subgraph Counting: Concepts, Algorithms and Applications to Network Motifs and Graphlets"], ["section", "Parallel Strategies"], ["subsection", "Platform"], ["subsubsection", "Distributed Memory (DM)"]], "content": "A parallel cluster offers the opportunity to use multiple (heterogenous) machines to speedup computation. Clusters can have hundreds of processors and therefore, if speedup is linear, computation time is reduced from weeks to just a few hours. For work sharing to be efficiently performed on DM architectures one can either have a master-node mediating work sharing~ or have workers directly steal work from each other~. Usually DM approaches are implemented directly using MPI~ but higher level software, such as GraphLab, can also be used~. DM has the drawback of workers having to send messages through the network, making network bandwidth a bottleneck.", "cites": [4921], "cite_extract_rate": 0.14285714285714285, "origin_cites_number": 7, "insight_result": {"type": "descriptive", "scores": {"synthesis": 1.5, "critical": 1.5, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section provides a basic description of distributed memory (DM) platforms for parallel subgraph counting, mentioning general concepts like master-node mediation, work stealing, and the use of MPI or GraphLab. However, it only briefly references one paper without integrating or connecting it to broader themes or other works. There is minimal synthesis, no critical evaluation of the cited work, and only superficial abstraction of DM's role in subgraph counting."}}
{"id": "fb2e3707-8ad5-4a45-bc05-b2dfba905397", "title": "Subgraphs", "level": "subsubsection", "subsections": [], "parent_id": "d46b0766-44c7-4528-b032-3f000eb4b78f", "prefix_titles": [["title", "A Survey on Subgraph Counting: Concepts, Algorithms and Applications to Network Motifs and Graphlets"], ["section", "Parallel Strategies"], ["subsection", "Work-units"], ["subsubsection", "Subgraphs"]], "content": "At the start of computation, only vertices and edges from the network are known. As the $k$-subgraph counting process proceeds, subgraphs of sizes $k-i, i < k$ are found. Thus, the work-units divided among threads can be these intermediate states (incomplete subgraphs). Some BFS-based algorithms~ begin with either edges or vertices as initial work-units and, at the end of each BFS-level, intermediate subgraphs are found and divided among workers. DFS-based methods expand each subgraph work-unit by one node until they reach a $k$-subgraph~.", "cites": [4921], "cite_extract_rate": 0.2, "origin_cites_number": 5, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 1.5, "abstraction": 1.5}, "insight_level": "low", "analysis": "The section provides a brief description of how work-units can be structured around subgraphs in parallel algorithms but offers minimal synthesis by only referencing one paper and not connecting it to broader themes or other methods. There is no critical evaluation or comparison of approaches, nor is there abstraction to highlight general principles or trends in the literature. The content remains largely factual and lacks deeper analytical or conceptual insight."}}
{"id": "e591bc46-2d34-4438-8762-73dea928c130", "title": "Static", "level": "subsubsection", "subsections": [], "parent_id": "7776fb24-158e-4cac-92d6-377837b1f310", "prefix_titles": [["title", "A Survey on Subgraph Counting: Concepts, Algorithms and Applications to Network Motifs and Graphlets"], ["section", "Parallel Strategies"], ["subsection", "Work Division"], ["subsubsection", "Static"]], "content": "The simplest form of work division is to produce an initial distribution of work-units and proceed with the parallel computation, without ever spending time dividing work during runtime. Trying to obtain an estimation of the work beforehand~ is valuable but limited: if the estimation is done quickly but is not very precise (such as using node-degrees or clustering coefficients to estimate work-unit difficulty) little guarantees are offered that the work division is balanced, and obtaining a very precise estimation is as computationally expensive as doing subgraph enumeration itself. Following a BFS approach~ helps balancing out the work-units and a static work division at each BFS-level is usually sufficient to obtain good results. However, those strategies have limitations as discussed in Section~\\ref{sec:bfs}. Some analytic works, which do not rely on explicit subgraph enumeration, do not need advanced work division strategies because their algorithm is almost embarrassingly parallel~.", "cites": [4924], "cite_extract_rate": 0.16666666666666666, "origin_cites_number": 6, "insight_result": {"type": "analytical", "scores": {"synthesis": 2.5, "critical": 3.0, "abstraction": 2.5}, "insight_level": "medium", "analysis": "The section provides an analytical overview of static work-division strategies, mentioning their pros and cons and referencing the computational trade-offs in estimating work-unit difficulty. While it connects to the concept of approximate counting from the cited paper, it does not deeply synthesize multiple sources or develop a novel framework. The critique of estimation accuracy and limitations of BFS-based strategies is present but not extensive."}}
