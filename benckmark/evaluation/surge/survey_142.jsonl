{"id": "6499795f-6609-4387-9877-c3a8e89edd87", "title": "Data Collection Challenges", "level": "section", "subsections": [], "parent_id": "a7f574da-775c-407d-b71a-3750f04bf536", "prefix_titles": [["title", "A Survey of Machine Learning Methods and Challenges for Windows Malware Classification"], ["section", "Data Collection Challenges"]], "content": "\\label{sec:data}\nAs with many applications, the first task to building a machine learning model is to obtain data that accurately represents the distribution of binaries that will be observed. It is indeed well known that obtaining more and better labeled data is one of the most effective ways to improve the accuracy of a machine learning system . However, by its very nature the potential scope of what a binary can do is unbounded. There is no way for us to randomly sample from the binaries that may exist in the world, and we have no way to measure how much of the \"space\" of binaries we have covered with any given dataset. \nBeyond the unbounded scope, the malware domain poses a number of unique challenges to data collection. This makes it almost impossible to perform canonical best practices, such as having multiple labelers per file and judging inter-labeler agreement . \nWhen obtaining data, it is often the case that malware is the easiest to get. Not only are there websites dedicated to collecting malware sent in by volunteers , but it is not unusual for a researcher to obtain their own malware specimens through the use of honeypots . A honeypot is a system connected to the Internet that intentionally tries to get infected by malware, often by leaving open security holes and foregoing standard protections. At the same time, both of these sources of malware can have data quality issues. \nHoneypots will have data biased toward what that system is capable of collecting, as malware may require interaction from the honeypot through specific applications in order to successfully infect a machine .  That is, a malware sample's infection vector may rely on a specific version of Firefox or Chrome to be running, and it may not be possible to account for all possible application interactions. Malware may also attempt to detect that a potential target is in fact a honeypot, and avoid infection to defer its detection . The issues that bias what malware is collected by honeypots are also likely to impact the quality of larger malware repositories, as users may run honeypots and submit their catches to these larger collections. Malware repositories will also have a self-selection bias from those who are willing to share their malware and take the time to do so. \nBenign data, or \"goodware\", has proven to be even more challenging to physically obtain than malware. This is in part because malware actively attempts to infect new hosts, whereas benign applications do not generally spread prolifically. As far as we are aware, no work has been done to quantify the diversity or collection of benign samples, or how to best obtain representative benign data. Most works take the easiest avenue of data collection, which is to simply collect the binaries found on an installation of Microsoft Windows. This tactic can lead to extreme over-fitting, where models literally learn to find the string \"Microsoft Windows\" to make a determination . \nThe population of binaries from Windows share too much of a common base to \nbe useful for training more general models\nInstead, the model learns to classify everything that does not come from Microsoft as malware . This bias is strong enough that even using only a subset of the information will still lead to over-fitting . This issue is particularly wide spread, and occurs in almost all cited papers in this survey. The significant exception to this are papers produced by corporate entities that have private data they use to develop anti-virus software. When this goodware bias issue is combined with the fact that there is no standard data-set for the task of malware detection, it is almost impossible to compare the results from different papers when different datasets are used. In addition, prior work using benign samples from clean Microsoft installations may significantly over-estimate the accuracy of their methods.\nOnly recently has effort been made to address this lack of a standard dataset for malware detection.  \\textcite{Anderson2018} released the EMBER dataset, which contains features extracted from 1.1 million benign and malicious binaries. EMBER is the first standardized corpus that has been released for malware detection. Their work has taken important steps toward reproducible science and a shared benchmark, but more work is still needed. By the author's own admission, the method of its labeling makes it an \"easy\" corpus. If users want to create new features from the raw binaries, they have to obtain the binaries themselves independently --- as the authors are unable to share the raw files due to copyright concerns. Information regarding malware family is also not present in the original version. A 2018 version of the Ember corpus (released in 2019, so that labels would be of higher confidence) has attempted to rectify a number of these issues by using more challenging data and malware family information.  \nOnce data has been obtained, labeling the data must follow (when labels do not come \"for free\" as they do with honeypots). The issue of labeling malware into families, or determining if an unknown binary is or is not malware, is labor intensive and requires significant domain knowledge and training. This is in contrast to many current machine learning domains, like image classification, where labeling can often be done by individuals with no special expertise and with minimal time. For example, an expert analyst can often take around 10 hours to characterize a malicious binary . This observation of the expense to understand what a file does is not unique, with a recent survey reporting hours to weeks of time, with participants ranging from 3-21 years experience .This effort makes manually labeling large corpora impractical.\nFor an entirely expert-labeled corpus for malware family classification, the largest public corpus we are aware of was developed by \\textcite{Upchurch2015}. They grouped 85 malware samples by functional similarity into a total of 8 groups. \nFor benign vs malicious labeling, many have attempted to circumvent this issue through the use of anti-virus (AV) products. One popular strategy is to upload the binaries to websites such as \\textit{VirusTotal}, which will run several dozen AV products against each binary, and return individual results. If more than 30\\% of the AVs claim a file is malicious, it is assumed malicious. \nIf none of the AVs say it is malware, it is assumed benign. Any specimen that tests between these two levels (at least one but less than 30\\% of the products say it's malicious) is then discarded from the experiment . We note there is nothing particularly special about choosing 30\\% as the threshold, and many works have used different rules. Others have used $\\geq4$ AV hits as a splitting point between malicious and benign , or left the issue unspecified .\nA recent study by \\textcite{251586} of different thresholding strategies found that using a threshold of $\\leq 15$ as the decision point between benign and malicious is a reasonable compromise to varying factors. This includes the fact that 1) AV decisions fluctuate over time, stabilizing after several months. 2) The false positive rate of AV engines in not trivial for novel files, 3) the false positive rate on packed benign files can be significantly higher, and 3) many AV engines have correlated answers and some appear to alter their own decisions based on the results of other AV engines over time. We note that these results regarding the use of VirusTotal labels are only for a benign vs malicious determination, and an equally thorough study of family labeling using VirusTotal has not yet been presented. \nWhile this selection is easy to perform, the labels will be intrinsically biased to what the AV products already recognize. More importantly, binaries marked by only a few AV products as malicious are likely to be the most important and challenging examples. This middle ground will consist of either benign programs which look malicious for some reason (false positives), or malicious binaries that are not easy to detect (false negatives). Removing such examples will artificially inflate the measured accuracy, as only the easiest samples are kept. Removing such difficult to label points will also prevent the model from observing the border regions of the space between benign and malicious. The aforementioned EMBER dataset uses this style of labeling, and hence the \"easy\" designation . \nThis AV-bias issue also hampers effective model evaluation, as we are skewing the data and thus the evaluation to an easier distribution of benign and malicious samples. This causes an artificially large accuracy by any of the metrics we will discuss later in \\autoref{sec:evaluation}. \nOnly recently have some of these AV biases been categorized and described. \\textcite{Botacin2020} has shown that the detection rate of AV products may vary by country (i.e., is this malware global, or country specific, in its proliferation), executable type (e.g., COM files vs. DLL), and family type (e.g., ransomware vs trojans). These biases will naturally be embedded into any model and evaluation built from labels that are AV produced. Further, using older files to try and maximize confidence is not a guaranteed workaround, since AV engines will have label regressions over time, where they stop detecting sufficiently old files as malicious . \nWe also note that the subscription service to VirusTotal allows for downloading the original files based on their hash values. This is how users can get the raw version of the EMBER dataset, or create their own preliminary datasets. However, the subscription to VirusTotal is not cheap (even with academic discounts), and may be beyond the budget of smaller research groups or those just getting into this space. As such it represents an unfortunate barrier to entry, especially since VirusTotal is widely adopted within the industry. \nWhen the desired labels are for malware families, the use of AV outputs becomes even more problematic. \nThe family\nlabels provided by AVs are not standardized and different AV products will often disagree on labels or type . While more advanced methods exist than simple thresholding (e.g., 3/5 of AVs say the label is \"Conficker\") for determining benignity  and malware family , the use of many AV products remains the only scalable method to obtain labels. High quality family labels require manual analysis, which as noted before, requires days-to-weeks of effort. Worse still, malware authors have historically copied/stolen code from one-another, which can make determining a specific family (and the related problem of attribution) even more difficult . \nBeyond the issue of collecting data, there is also the fact that binaries exhibit \\textit{concept drift}, meaning the population as a whole changes over time. This is true of both benign and malicious binaries, as changes will percolate through the population as the Windows API changes, code generation changes with newer compilers, libraries fall in and out of favor, and other factors. It then becomes important to investigate the performance of a classification system as change occurs , which is not widely explored. The distribution of malware in particular drifts at a faster rate, as malware authors attempt to modify their code to avoid detection. For example, \\textcite{Rajab2011} performed an extensive study of web based malware on Google's Safe Browsing infrastructure. Over four years they saw an increase in malware that relied on social engineering, \na short lifespan for the use of most exploits documented by Common Vulnerabilities and Exposures (CVEs), and an increase in attempts at \"IP cloaking\" to obscure their source. The fast evolution of malware is a result of an \\textit{adversarial} scenario, and only further complicates the development of a long term solution .", "cites": [7862, 7863, 3859, 7861], "cite_extract_rate": 0.15384615384615385, "origin_cites_number": 26, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 4.0, "abstraction": 3.5}, "insight_level": "high", "analysis": "The section demonstrates strong synthesis by integrating the challenges of data collection in malware classification, drawing from multiple cited papers to build a coherent narrative around data bias and labeling issues. It offers critical analysis by evaluating the limitations of common data sources (e.g., honeypots, VirusTotal) and highlighting how these affect reproducibility and model generalization. While it identifies broader patterns in data bias and labeling challenges, it could elevate abstraction by explicitly framing these as systematic issues across the field rather than focusing on specific datasets."}}
{"id": "04f27465-874b-4dcf-89bf-7b9e4c0edd3b", "title": "Dynamic Analysis Features", "level": "subsection", "subsections": [], "parent_id": "1b2cb9c3-b5c8-43c3-b9fb-d2e18198f2f2", "prefix_titles": [["title", "A Survey of Machine Learning Methods and Challenges for Windows Malware Classification"], ["section", "Features for Binaries"], ["subsection", "Dynamic Analysis Features"]], "content": "\\label{sec:dynamic_features}\nThere are a number of common feature types to extract from dynamic analysis. For example, an early type of dynamic analysis was to modify the linker in the operating system to wrap each function call to the OS or other libraries with a special prologue and epilogue . In doing so the functions called could be tracked in the order of their occurrence and one could obtain a sequence of \\textit{API or function calls}. Such trackings of API calls can be used in many ways, and is often interpreted as a sequential ordering or as a directed graph .  Special tracking can be added for common tasks, such as registry edits, files created or deleted, mutex operations, and TCP/IP calls . These are all common tasks or operations that malware might perform, so recording extra information (such as method arguments) can be beneficial to analysis. Ultimately, there are many ways to combine the API functions called and the operations performed, with many works using one of or both options, and tracking different subsets of actions. These approaches are often called \"behavior based\", and make up a large portion of the dynamic features used. Directly related to tracking of API calls is tracking \\textit{system calls}.  For our purposes, we define a system call as a service provided by the Windows kernel, and (usually) accessed via an entry point in {\\tt Ntdll.dll}.  \n\nThere are several hundred of these functions, and they are often called by the APIs Microsoft provides, but less often by user code.  In fact, use of functions in Ntdll.dll by user code is regarded as a malware indicator . \nOne advantage of tracking system calls, rather than all calls to the Windows API, is that the set of system calls tends to remain stable from one version of Windows to another, for the sake of compatibility.\nThe same technology that allows for API call traces can also be used to track changes to the state of the system. Such \\textit{system changes} may include the registry edits and files created, as well as processes that started or ended, and other various configurable settings within the OS . System changes may also be obtained from system logs , which can be used as a convenient feature source with minimal overhead (since the system was going to collect such logs anyway) or for retroactively detecting malware and determining the time of infection. \nThough not as popular, more granular information can be extracted as well. It is  possible to record the sequence of assembly instructions as they run . Though this approach in particular can require additional feature selection and processing, as the amount of data can grow quickly and the length of program execution may be unbounded. Another option is to track the results of various performance and hardware counters that are present in modern CPUs as well as process related counters tracked by the OS  . These could include the number of memory pages being allocated or swapped, voluntary and forced context switches, cache hits and misses, and other various fields. The intuition being that the performance behavior of malware will be distinct from benign applications due to the different nature of their operation. \nAnother less frequently used approach is to monitor the network traffic and content that a binary may produce . Many different malware applications make use of command-and-control servers (\nthe existence or location of which may be obfuscated) to direct the actions of infected hosts, making it a potentially informative behavior. \nUse of the local network is also one of the most common ways for malware to self proliferate. \nWhile the population of malware that does not use the Internet or any local network may be small, it may also be one of the more interesting and important ones to classify correctly. \nThe methods discussed in this section\nmake up the majority of features that are extracted via dynamic analysis. While the set of options may seem simple, the systems to capture them represent their own significant engineering efforts. Many such systems have been developed over time, and we refer the reader to  for a survey of the numerous systems for dynamic analysis and their relative pros and cons. The focus of this work will remain not on the method of collection, but what is collected and the challenges that are faced in doing so.", "cites": [7863, 7864], "cite_extract_rate": 0.1111111111111111, "origin_cites_number": 18, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.5, "critical": 2.0, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section describes several types of dynamic analysis features used in malware classification, such as API calls, system calls, system changes, and network traffic. While it references two cited papers, it does so minimally and without substantial integration or synthesis of their contributions. The analysis remains largely descriptive and lacks critical evaluation or abstraction to broader principles."}}
{"id": "75935c13-30d3-41d0-a052-caa9cb5a6bb8", "title": "Static Analysis Features", "level": "subsection", "subsections": [], "parent_id": "1b2cb9c3-b5c8-43c3-b9fb-d2e18198f2f2", "prefix_titles": [["title", "A Survey of Machine Learning Methods and Challenges for Windows Malware Classification"], ["section", "Features for Binaries"], ["subsection", "Static Analysis Features"]], "content": "\\label{sec:static_features}\nBy its very nature, static analysis greatly reduces the scope of features options to consider for classification. One common choice is to use the raw-bytes themselves as features . A subset of the raw-byte approach is simply to search for and extract what appear to be ASCII strings . This approach assumes the least amount of knowledge and is widely applied to other file types because of its ease of application. Another approach is to instead compute a windowed entropy over the raw bytes, mapping each file to a entropy sequence . Regardless of how processed, these approaches have an attractive simplicity at the cost of ignoring relevant properties. For example, while the raw bytes may be processed as one long linear sequence, the locality within a binary is non-linear. Different portions will relate to others through pointers in the storage format as well as various local and long jumps in the assembly. It is also common to build histograms from this information to reduce it to a fixed length format . \nUsing more domain knowledge, it is also popular to parse the PE-Header  for relevant information, extracting the fields and imports and encoding them as numeric and categorical features . Being able to process the PE-Header is also important for finding and disassembling the binary code, which is one of the more popular feature types to use  in static analysis. As mentioned in \\autoref{sec:dynamic_features}, assembly sequences can be used in dynamic analysis as well. The difference then becomes what assembly sequences appear in the file and overall structure, versus the sequence of instructions actually run . In each case one may observe sequences not seen by the other. The dynamic version may not run all of the code present, and the static version may not find obfuscated instructions. \nThe extraction of PE-Header disassembly from static analysis are more readily available, and provided by many open-source projects. For the PE-Header, there are projects like PortEx , pefile\\footnote{\\url{https://github.com/erocarrera/pefile}}, and this functionality is even built-into the Go language runtime\\footnote{\\url{https://golang.org/pkg/debug/pe/}}.  For disassembly, relevant projects include Capstone\\footnote{\\url{http://www.capstone-engine.org/}}, Xori\\footnote{\\url{https://github.com/endgameinc/xori}}, Distorm\\footnote{\\url{https://github.com/gdabah/distorm}}, BeaEngine\\footnote{\\url{https://github.com/BeaEngine/beaengine}}, and others. \nMany different disassemblers have become available in part because disassembling a binary is non-trivial, especially when malware may attempt to create obscure and obfuscated byte code that attempts to thwart disassembly. Each of the many options available have different pros and cons in terms of run-time, accuracy, supported architectures, and other issues. \nOnce a binary is successfully disassembled (which requires the PE Header), it is also possible to resolve API function calls from the assembly using the Import Address Table . The IAT stores the functions the library wishes to load as well as the virtual address at which the function will be stored. Then any \\mintinline{nasm}{jump} or \\mintinline{nasm}{call} function's arguments can be converted to the canonical target function. This allows us to not only use the imported functions and APIs as features in a fixed-length feature vector (function present / absent), but also as a sequence or graph of API call order. \nFinally, the most knowledge-intensive and time-consuming option is to consult malware analysts on what information to look for, and attempt to automatically extract said information . Such approaches may obtain a distinct advantage from expert opinion, but will require additional work to update due to concept drift as malware authors adjust their code to avoid detection.", "cites": [7862, 3859], "cite_extract_rate": 0.11764705882352941, "origin_cites_number": 17, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.5, "critical": 3.0, "abstraction": 3.0}, "insight_level": "medium", "analysis": "The section synthesizes information from the cited papers by highlighting the role of PE headers and disassembly in static analysis, aligning with the methods described in Paper 1 and 2. It offers some critical evaluation by noting the limitations of raw-byte approaches and the challenges of disassembling obfuscated code. While it identifies patterns such as the trade-off between simplicity and effectiveness, it does not fully abstract to higher-level principles or systematically compare the cited works."}}
{"id": "4bd0fbac-f89f-4afa-8760-3935da5d13cb", "title": "Contextual Features", "level": "subsection", "subsections": [], "parent_id": "1b2cb9c3-b5c8-43c3-b9fb-d2e18198f2f2", "prefix_titles": [["title", "A Survey of Machine Learning Methods and Challenges for Windows Malware Classification"], ["section", "Features for Binaries"], ["subsection", "Contextual Features"]], "content": "A third type of features are what we will call \\textit{contextual} features. These are features that are not properties of the malicious binary itself, but come from the context of how the malware may exist or be distributed. The use of contextual features is less common in research, but has been reported to be highly successful in practice.  Such systems are generally graph-based in their approach. \nFor example \\textcite{Chau2011} used information about the \"reputation\" of the machines at which an executable file was found to make a determination about maliciousness, without looking at the content of the file itself.  Others have followed this same strategy, and attempt to more precisely define the relations between files to improve results , and to merge both relations and file dependent features . \nBeyond measuring reputation of machines, the reputation of the domain name or IP address from which a file was downloaded can also be used to classify the downloaded binary as malicious if the source address has low reputation. This, as well as counter-measures, were discussed by \\textcite{Rajab2011}. Others have created more elaborate graphs based on how and from where the file was downloaded, including the benign applications (e.g., Internet Explorer) that are also involved in the process . \nIn a similar theme, \\textcite{export:193769} looked at making classifications for files that are found in the same container (e.g., a zip or rar file). This approach is based on the hypothesis that if any file found in a container is malicious, all are more likely to be malicious. A similar approach has recently been proposed to leverage the file name of the malware itself, rather than its contents, to predict maliciousness . While not sufficient on its own, it may be useful in conjunction with other features  or in investigative/prioritization situations where the whole file may not be available (e.g., file path was stored in a log, but the file itself has since been deleted) .", "cites": [7865], "cite_extract_rate": 0.2, "origin_cites_number": 5, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.3, "critical": 2.7, "abstraction": 3.0}, "insight_level": "medium", "analysis": "The section synthesizes a few cited works into a coherent discussion on contextual features, highlighting their practical success and graph-based approaches. While it provides some abstraction by identifying broader themes (e.g., using file container or source reputation), it lacks deeper critical evaluation of the methods' limitations or comparative analysis between them. The discussion is insightful but stops short of offering a novel framework or in-depth critique."}}
{"id": "054cb479-2135-490d-b767-73335ad11477", "title": "N-Grams", "level": "subsection", "subsections": ["24311e66-6e8d-48d4-938d-af10efa13c45"], "parent_id": "59237794-fe56-453e-972e-177721b4aefb", "prefix_titles": [["title", "A Survey of Machine Learning Methods and Challenges for Windows Malware Classification"], ["section", "Machine Learning Methods"], ["subsection", "N-Grams"]], "content": "\\label{sec:ngrams}\nThe first item we discuss is not a learning algorithm, but a method of constructing features. N-Grams are a \"bread and butter\" tool for creating feature vectors from sequence information, though capture very little sequential information (and hence are included in this section). Despite this, n-grams have been widely used in malware classification, starting with the work of  that connected the methods being used with those in the domain of Natural Language Processing (NLP). Since then, n-grams have been one of the most popular feature processing methods for malware classification, and have been used for processing bytes, assembly, and API calls  into bag-of-words type models. To give a more concrete example of this process, the byte sequence \\textit{0xDEADBEEF} would have the 2-grams \\textit{DEAD}, \\textit{ADBE}, and \\textit{BEEF}. At training time all possible 2-grams would be counted, and each 2-gram found would map to an index in a high-dimensional feature vector. The feature vector for \\textit{0xDEADBEEF} would have 3 non-zero values, the specific values determined by some feature weighting scheme such as TF-IDF or Okapi , though a binary present/absent value is popular as well.\nThere exists a particular desire to use larger values of $n$ for malware classification due to the limited semantic meaning contained within only 6 or so bytes or instructions. To give this context, a 6-byte-gram is not large enough to capture a whole instruction 2.4\\% of the time . This is due to the variable length encoding of the x86 instruction set, and a valid x86 instruction can be up to 15 bytes in length. Similarly, an assembly 6-gram is often not sufficient to cover the behavior of a larger function. A simple function can compile to dozens of instructions, let alone more complicated functions which may easily be hundreds to thousands of instructions in length. \nWhile large values of $n$ are desirable, they are also computationally demanding. \nAs $n$ increases, the number of possible n-grams grows exponentially. Counting and tracking these itself is expensive, and feature selection is required before deploying. As such, the use of $n > 6$ has historically been rare. Some work has been done to speedup  the collection of n-grams by approximately selecting the top-$k$ most frequent n-grams as an initial feature selection process . This is based on the observation that n-grams tend to follow a power-law distribution, and that useful predictive features tend to have a minimum frequency . Later work developed this into a probabilistic algorithm for selecting the top-$k$ $n$-grams in a faster manner with fixed memory cost, testing values of $n=8192$ . This study found that $n \\geq 64$ was surprisingly useful, and had the benefit that a malware analyst could reverse engineering the meaning of a large $n$-gram to better understand what the model had learned. Their work showed that predictive performance was maximized around $n=8$, and that $n$-gram features had a surprisingly long shelf life, still being effective in detecting benign/malicious software up to 3-years newer than the training data.", "cites": [7866], "cite_extract_rate": 0.14285714285714285, "origin_cites_number": 7, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.5, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section effectively synthesizes the concept of n-grams across the broader NLP and malware classification domains, integrating the cited paper to explain trends and challenges in using large n-grams. It provides critical analysis by discussing the trade-offs between n-gram size and computational cost, and the limitations of small n-grams in capturing meaningful instructions. The section abstracts these ideas to highlight broader patterns, such as the power-law distribution of n-gram frequencies and the potential for interpreability in malware analysis."}}
{"id": "7e9b7142-ae72-44c1-95b5-ceaacaed609e", "title": "Kernel Methods", "level": "subsection", "subsections": [], "parent_id": "59237794-fe56-453e-972e-177721b4aefb", "prefix_titles": [["title", "A Survey of Machine Learning Methods and Challenges for Windows Malware Classification"], ["section", "Machine Learning Methods"], ["subsection", "Kernel Methods"]], "content": "\\label{sec:kernel_methods}\nKernel methods are an extension of the linear methods discussed in \\autoref{sec:linear}. Most commonly used with Support Vector Machines (SVMs) using a kernel trick $K$, the objective function is given in \\eqref{eq:svm_kernel}.  We note that for SVMs the regularization penalty is usually expressed with the term $C$, where larger values indicate less regularization. These forms are equivalent where $C =  1 / (2 \\lambda N)$. The kernel-trick is used to project the original data-set into a different space. A linear solution is found in this new space, which may be non-linear in the original space. \n\\begin{equation} \\label{eq:svm_kernel}  \n\\sum_{i=1}^N \\max( 0, 1- y_i K(w, x_i)) + \\lambda \\norm{w}^2_2\n\\end{equation}\nA valid kernel $K$ represents the inner product in this new feature space, but does not require us to explicitly form it\\footnote{The kernel trick is usually more formally explained as a Reproducing kernel Hilbert space (RKHS). We avoid it to reduce the mathematical background needed for this review}. This allows us to obtain classifiers that are non-linear in the original feature space (and thus potentially achieve a higher accuracy). We can always pick the linear kernel \\eqref{eq:linear_kernel}, which results in a linear model. Practically, two of the more common choices are the polynomial \\eqref{eq:poly_kernel} and Radial Basis Function (RBF) \\eqref{eq:rbf_kernel} kernels. The polynomial kernel is particularly helpful to illustrate the intuition behind the kernel-trick, as we can easily compute $(\\alpha + \\beta)^{10}$ with two operations, an addition and an exponentiation. This is computing the inner product in the polynomial space explicitly, but avoids actually expanding the polynomial. If were were to explicitly form the feature space first by expanding the polynomial, we would end up performing 36 exponentiations, 10 additions, and 38 multiplications. \n\\begin{subnumcases}{K(a, b) =} \\label{eq:linear_kernel}\n                    a^T b  & \\text{Linear}\\\\\n                    \\label{eq:poly_kernel}\n                    (a^T b + c)^p & \\text{Polynomial} \\\\\n                    \\label{eq:rbf_kernel}\n                    \\exp\\left(-\\gamma \\norm{a-b}^2\\right) & \\text{RBF}\n\\end{subnumcases}\nThe price for this flexibility is generally computational, as solving the kernelized version can take $O(N^3)$ time and $O(N^2)$ memory. On top of that, a parameter search must be done for the values (such as $\\gamma$) used in the kernel. This is in addition to the regularization penalty $C$. Most malware data-sets being used are on the order of 40,000 samples or less, which is still in the range of available tools like LIBSVM . More advanced techniques that do not attempt to obtain the exact solution also exist, allowing the use of kernel methods to larger data-sets . \nOne of the challenges with the malware domain is the multiplicity of feature options and potential representations. For most machine learning techniques it is necessary to reduce these down to a single feature vector of fixed length for each data-point. This often results in an over-simplification for the malware domain. The use of more sophisticated kernels to alleviate this problem is a yet unexplored possibility. For example, one challenge is that the PE format specifies many different section types, the most common being sections for imports, exports, binary code, and data. However any of these section types may occur in a binary with any multiplicity\\footnote{up-to a hard limit on the number of sections specified by the PE format} (e.g., one could have five different executable sections). The standard approach, if differentiating between sections, is to operate as if all instances of a section type were a part of one section. Instead, one could use a kernel that matches sets of feature vectors , allowing the model to learn from these directly. \nKernels can also be defined directly over strings , which could be useful for comparing the function names defined within an executable or in handling unusual data content, such as URLs that can be found within malware . To handle the function graphs that may be generated from dynamic analysis, kernels over graphs may also be defined  and has seem some small amount of use for malware classification . Furthermore, the composition of multiple kernels via additions and multiplications also forms a new and valid kernel. This would provide a direct method to incorporate multiple modalities of information into one classifier. For example, we could combine a kernel over graphs on API call sequences, a linear kernel for assembly n-gram features, and a kernel over strings found in the file into one larger kernel. However these options with kernels are largely unexplored for the malware classification problem.", "cites": [8330], "cite_extract_rate": 0.09090909090909091, "origin_cites_number": 11, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.5, "critical": 3.0, "abstraction": 3.5}, "insight_level": "medium", "analysis": "The section provides an analytical overview of kernel methods in the context of malware classification. It synthesizes key concepts from the cited paper (e.g., graph kernels) and explains how they could be applied to malware data, such as API call sequences or function names. It also identifies limitations of current practices and suggests unexplored possibilities, such as using set-based or multi-kernel approaches, but does not deeply compare or critique the cited methods."}}
{"id": "467770ad-d910-4697-a8cd-d2dc0bb833e0", "title": "Decision Trees", "level": "subsection", "subsections": [], "parent_id": "59237794-fe56-453e-972e-177721b4aefb", "prefix_titles": [["title", "A Survey of Machine Learning Methods and Challenges for Windows Malware Classification"], ["section", "Machine Learning Methods"], ["subsection", "Decision Trees"]], "content": "Methods based on Decision Trees have been popular in machine learning, and a number of variants and extensions to them exist. The two most popular base decision tree algorithms are C4.5  and CART . A number of desirable properties have resulted in their widespread use among many domains, making them some of the most widely used algorithms in general . In particular, decision trees are able to handle both categorical and numeric features simultaneously, are invariant to shifts or re-scaling of numeric features, can handle missing values at training and test time, are fast to apply at test time, and often obtain competitive accuracies while requiring minimal parameter tuning. \nAll of these properties can be highly relevant to malware classification, where a mix of numerical and categorical features may be common, and there are often real-time requirements for deployment on user machines. Missing values can be a common issue as well, as obfuscations performed by the malware may prevent successful extraction of a given feature. For these reasons many researchers have used decision tree based methods for malware classification . They are easy to apply, provided as a standard tool in most machine learning libraries across several languages  and with many stand-alone tools dedicated to more powerful extensions . \n\\textcite{Kolter:2006:LDC:1248547.1248646} used boosted decision trees in their seminal byte n-gramming paper. Boosting is one of many ensemble methods that work to improve the accuracy of decision trees by intelligently creating a collection of multiple trees, where each tree specializes to a different subset of the data. While they chose the AdaBoost algorithm because it performed best on their data, \\author{Kolter:2006:LDC:1248547.1248646} were able to utilize the interpretability of decision trees to gain insights to their model. An example of how one would be able to read a decision tree is given in \\autoref{fig:decision_tree_example}. \n\\begin{figure}[ht]\n\\centering\n\\adjustbox{max width=\\linewidth}{\n\\forestset{\n    .style={\n        for tree={\n            base=bottom,\n            child anchor=north,\n            align=center,\n            s sep+=1cm,\n    straight edge/.style={\n        edge path={\\noexpand\\path[\\forestoption{edge},thick,-{Latex}] \n        (!u.parent anchor) -- (.child anchor);}\n    },\n    if n children={0}\n        {tier=word, draw, thick, rectangle}\n        {draw, rectangle, thick, aspect=2},\n    if n=1{\n        edge path={\\noexpand\\path[\\forestoption{edge},thick,-{Latex}] \n        (!u.parent anchor) -| (.child anchor) node[pos=.2, above] {Y};}\n        }{\n        edge path={\\noexpand\\path[\\forestoption{edge},thick,-{Latex}] \n        (!u.parent anchor) -| (.child anchor) node[pos=.2, above] {N};}\n        }\n        }\n    }\n}\n\\begin{forest} \n[Certificate table's size $\\geq 2 \\cdot 10^4$ bytes\n    [File size $\\geq 10^6$\n        [Malware] \n        [Benign] \n    ]   \n    [is DLL?\n        [is 64bit?\n            [Benign] \n            [Malware] \n        ]   \n        [Malware] \n    ]   \n] \n\\end{forest}\n}\n\\caption{A hypothetical decision tree. }\n\\label{fig:decision_tree_example}\n\\end{figure}\n\\textcite{raff2017peheader} used the Random Forests  and Extra Random Trees  ensembles to naturally handle the many disparate value types found within the PE-Header. Values from the header can be binary variables, multi-label variables, and numeric values with varying sizes and scales. For example, some values in the header will give the byte offset to another part of the binary, which could be anywhere from a few hundred to millions of bytes away. Most algorithms would have difficulty learning from this value range, and it can be difficult to normalize effectively. \\author{raff2017peheader} also exploited the tree based approaches to obtain ranked feature importance scores , another method by which one can glean information about what a decision tree has learned. \nSome have worked on developing enhanced ensembling methods for decision trees to improve malware classification accuracy . Even when there is no reason to use a tree based approach in particular, many malware classification works still include them as one of many models to try . \nThe widespread success of decision trees has made them a valuable tool inside and outside the domain of malware classification. This has lead to a large literature of decision tree techniques to tackle various problems, many of which may be applicable to malware classification. For example, the popular AdaBoost algorithm often overfits in the presence of significant labeling errors. An extension known as Modest AdaBoost is more robust to this issue, and may lead to improvements  in generalization. Another possibility is to use decision trees to deal with concept drift. While malware datasets with date-first-seen labels are not publicly available\\footnote{Such information can be obtained from the paid-for API of VirusTotal}, there already exists a literature of decision tree methods designed to work with changing data streams . This also relates to how the accuracy of a malware classification system should be evaluated, which we will discuss further in \\autoref{sec:evaluation}.", "cites": [7867, 7861, 7144], "cite_extract_rate": 0.11538461538461539, "origin_cites_number": 26, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.0, "abstraction": 3.5}, "insight_level": "medium", "analysis": "The section effectively synthesizes the cited papers by connecting their use of decision trees in the context of malware classification, highlighting how their features and ensemble techniques address domain-specific challenges. It provides some critical analysis, particularly regarding limitations like overfitting with labeling errors and the need for real-time performance. While it identifies broader principles (e.g., handling mixed data types, feature importance), it stops short of offering a novel or meta-level framework."}}
{"id": "a1823433-68a8-4a19-86fc-4fb1893cca34", "title": "Neural Networks", "level": "subsection", "subsections": [], "parent_id": "59237794-fe56-453e-972e-177721b4aefb", "prefix_titles": [["title", "A Survey of Machine Learning Methods and Challenges for Windows Malware Classification"], ["section", "Machine Learning Methods"], ["subsection", "Neural Networks"]], "content": "\\label{sec:neural_nets}\nNeural Networks have seen a recent resurgence in the machine learning community. Though older literature often referred to the technique for classification as Multi-Layer Perceptrons, newer work has placed an emphasis on the depth of trained networks and is often referred to as Deep Learning. We will provide a brief overview of neural networks, and refer the reader to \\textcite{Goodfellow-et-al-2016-Book} for a more thorough introduction to modern architectures, activations, and training methods. \nNeural networks get their name from their original inspiration in mimicking the connections of neurons in the brain (though the interpretation is often taken too literally). A neuron is connected to multiple real valued inputs by a set of synaptic weights, corresponding to real-valued multipliers. An activation function $f(x)$ is used to produce the output of the neuron, where the input is the weighted sum of every input connected to that neuron. Generally the initial features fed into a network are called the input layer, and a set of neurons that produce our desired outputs form the output layer, from which a loss is derived (such as cross-entropy, or mean squared error). In-between is some number of hidden layers, where we specify the number of neurons, connectivity, and activations for each layer. The classic approach is to connect every neuron in one layer to every neuron in the preceding layer to form a fully connected network. A diagram of this arrangement is presented in \\autoref{fig:fully_connected_nn}. \n\\begin{figure}[ht] \n\\centering\n\\begin{neuralnetwork}[height=5,toprow=true]\n\t\t\\newcommand{\\nodetextclear}[2]{}\n\t\t\\newcommand{\\nodetextx}[2]{$x_#2$}\n        \\newcommand{\\nodetextha}[2]{$h^1_#2$}\n        \\newcommand{\\nodetexthb}[2]{$h^2_#2$}\n\t\t\\newcommand{\\nodetexty}[2]{$y_#2$}\n\t\t\\inputlayer[count=3, bias=true, biaspos=top row, title=Input\\\\layer, text=\\nodetextx]\n\t\t\\hiddenlayer[count=3, bias=true, biaspos=top row, title=Hidden\\\\layer, text=\\nodetextha] \\linklayers\n        \\hiddenlayer[count=4, bias=true, biaspos=top row, title=Hidden\\\\layer, text=\\nodetexthb] \\linklayers\n\t\t\\outputlayer[count=1, bias=false,biaspos=top row, title=Output\\\\layer, text=\\nodetexty] \\linklayers\n\t\\end{neuralnetwork}\n    \\caption{Diagram of a simple 1-layer neural network. {\\color{green} Green} nodes are input features. {\\color{yellow}Yellow} nodes are for the bias variable. {\\color{blue} Blue} nodes are hidden layers. {\\color{red} Red} nodes are the output layer.}\n    \\label{fig:fully_connected_nn}\n\\end{figure}\nThe weights for such a network are learned through an algorithm known as back-propagation , which is performing gradient decent on the function created by the neuron graph. The view of neural networks as a large function graph has become increasingly popular, and allows for fast development using Automatic Differentiation. The user specifies the functions used by the network, and the software automatically computes the gradients with respect to any weight in the network. This has helped to fuel the resurging neural network literature and is a feature supported by many deep learning frameworks . \nThe fundamental strategy enabled by such an approach is that the user should avoid feature engineering, and instead alter the network architecture to the needs of the problem. This works as neural networks have been found to learn their own complex feature hierarchies and representations from raw data alone . This ability has allowed neural networks to become the state of the art in both speech processing~ and image classification~, significantly outperforming prior approaches. \nWhile many works in malware classification have made use of neural networks , they are often based on dated approaches to neural network construction. Advances in optimization algorithms (gradient descent), activation functions,  architecture design, and regularization have dramatically changed the \"best practices\" of neural networks while also improving their performance. \nOne of the first effective applications of a modern neural network style was by \\textcite{Saxe2015a}, who used a private corpus to obtain reasonable accuracies.  Their work performed the feature engineering manually by processing a combination  of entropy, string, and PE header features. While their model performed well, it was not compared with any other machine learning algorithms, making it difficult to determine the benefits of neural networks in this particular application. The work of \\textcite{Saxe2015a} is also notable for its model evaluation, which we will discuss further in \\autoref{sec:evaluation}. \n\\textcite{raff2017peheader} also looked at using a neural network, but instead presented it with raw byte information and did no feature engineering. Their work provided initial evidence that neural networks can reproduce the same feature learning on raw bytes, but was limited to a relatively small (and fixed size) subset of the PE header. \nAs \\textcite{raff2017peheader} noted, the behavior and locality within malware is markedly different from signal and image processing tasks. Malware lacks the rigid scope and especially locality properties these other fields enjoy. As an example, it is easy to see how in an image the correlation between a pixel and its neighbors is relatively consistent throughout any image. But for a binary jumps and function calls can directly connect disparate regions, causing correlations between potentially arbitrary locations. No work has yet been done on determine what kinds of architectures can learn best from this type of locality complexity. \nAnother interesting application of modern neural network design is by \\textcite{Huang:2016:MMN:2976956.2976984}. Their system looked at System-call like features extracted via dynamic analysis, reducing the feature set by applying domain knowledge about the relationship function calls. Their architecture was modified to perform both malware detection (benign or malicious) and family classification (with 100 malware families) simultaneously. The jointly trained model resulted in a relative improvement of 26\\% over a model trained to do only malware detection on the same data. This shows the potential for intelligent architecture design choices to provide real gains in accuracy. This is also a method to enable more data use for training, as it is easier to get more malware data labeled with malware family labels than it is to get more benign data. The portion of the network trained to predict malware family can then be trained with this additional data, without biasing the malware detection portion of the network due to class imbalance.", "cites": [7157], "cite_extract_rate": 0.08333333333333333, "origin_cites_number": 12, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.5, "critical": 3.5, "abstraction": 3.0}, "insight_level": "medium", "analysis": "The section provides a clear overview of neural networks and situates cited works (Saxe2015a, Raff2017, Huang2016) within the broader context of their design and application in malware classification. It synthesizes these works to highlight trends such as the shift from manual feature engineering and the potential of joint training. The section also offers critical observations, such as the lack of comparison with other ML methods in Saxe2015a and the challenges of locality in malware data. While it identifies some patterns, it does not rise to a meta-level abstraction or propose a novel framework."}}
{"id": "26902f76-dad6-4b96-bfbb-2c01dc363dea", "title": "Machine Learning Over Sequences", "level": "section", "subsections": ["7929449a-e9cd-4932-8c84-1a06b42160fa", "af1937fa-3422-48c0-9790-0d38f1428070", "f73139a7-e2f9-485a-ba17-91e0493b8bfd", "e33131f0-fda7-402a-8b00-723e9b6b93b5", "a05e77d0-0898-49e6-9b3f-de244aadd5b4"], "parent_id": "a7f574da-775c-407d-b71a-3750f04bf536", "prefix_titles": [["title", "A Survey of Machine Learning Methods and Challenges for Windows Malware Classification"], ["section", "Machine Learning Over Sequences"]], "content": "\\label{sec:ml_seq}\nMany of the feature types we have discussed, such as assembly instructions, can be more accurately described as a sequence of events or values. Using n-grams to convert them to fixed length feature vectors allows us to use the wider breadth of models discussed in \\autoref{sec:ml_methods}, at the cost of ignoring most of the sequential nature intrinsic to the data. \nIn this section we will review a number of techniques that are designed specifically for processing sequences, some of which will work directly on the sequence level, while others may attempt to create fixed-length representations more intelligently. In the latter case, the primary difference compared to the n-gram approaches discussed in \\autoref{sec:ngrams} is that n-grams only capture a very small amount of local sequence information. Approaches in this section will more generally capture larger amounts of the sequential structure in the data. \nSome of the methods we will talk about face unique challenges regarding sequence length. For example, assembly sequences from binaries can be hundreds of thousands of steps in length or more, which significantly outpaces the longest sequences in other domains. While byte and assembly sequences are obviously the longest, potentially millions of steps long, higher level events and features extracted via dynamic analysis can easy reach hundreds of thousands of steps in length . These sequences are far longer than what machine learning is normally applied to, meaning the tools to tackle this problems are often lacking. For example, the longest sequence length we are aware of for neural networks outside of malware is in audio generation. Here the WaveNet architecture was applied to a sequence length of 16,000 steps . This was an order of magnitude larger than what others had achieved, yet is still an order of magnitude smaller than the sequences in the malware space.", "cites": [4722], "cite_extract_rate": 0.5, "origin_cites_number": 2, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.5, "critical": 3.0, "abstraction": 3.5}, "insight_level": "medium", "analysis": "The section provides an analytical overview of sequence-based machine learning for malware classification, contrasting n-gram methods with more advanced approaches. It integrates the cited paper on WaveNet to highlight the relative novelty of handling long sequences in other domains, but its critique of the limitations in the malware domain is not deeply elaborated. The abstraction level is moderate as it generalizes the issue of sequence length and connects it to broader machine learning challenges."}}
{"id": "b142a634-6331-4c83-98a3-00b6aed8951e", "title": "Normalized Compression Distance", "level": "subsubsection", "subsections": [], "parent_id": "af1937fa-3422-48c0-9790-0d38f1428070", "prefix_titles": [["title", "A Survey of Machine Learning Methods and Challenges for Windows Malware Classification"], ["section", "Machine Learning Over Sequences"], ["subsection", "Byte Similarity Measures"], ["subsubsection", "Normalized Compression Distance"]], "content": "\\label{sec:ncd}\nThe Normalized Compression Distance (NCD)   is a distance function based on the ability of a compression algorithm to compress two sequences to their smallest possible size. The NCD distance is defined in \\eqref{eq:ncd}, where $C$ is a function that returns the compressed length of an input, and $ab$ represents the joining of sequences $a$ and $b$ (normally done by simple concatenation). Given an oracle that can perform perfect compression, the NCD is a valid distance metric. This oracle cannot exist, and so NCD must be approximated using algorithms such as LZMA. Because NCD works based on compression, it can be applied to a wide variety of features and has become quite popular, especially for discovering malware families and relationships. It has been used successfully on raw bytes  and on behavior sequences from dynamic analysis . \n\\begin{equation}\\label{eq:ncd}\n\\text{NCD}(a,b) = \\frac{C\\left(ab\\right)-\\min\\left(C(a), C(b)\\right)}{\\max\\left(C(a), C(b)\\right)}\n\\end{equation}\nThe flexibility of NCD, in that it can be applied to anything encodable as a sequence of bytes, makes it a powerful tool given the multiple different features we may wish to extract. NCD has also seen considerable use for malware detection due to its accuracy, which improves with the quality of the compression algorithm used. Yet the limits of existing compression algorithms also mean that NCD has difficulty in the face of long sequences , causing the distance metric to break down. Attempts to improve NCD have been made by changing how the concatenation $ab$ \nis done in practice , but room for improvement still exists. When sequences are short enough that NCD works well, a yet unexplored possibility is to use it with some of the kernels discussed in \\autoref{sec:kernel_methods}. A simple merging would be to replace the Euclidean distance in the RBF kernel with the result of NCD, producing $K(a, b) = \\exp\\left(-\\gamma \\cdot \\text{NCD}(a, b)^2\\right)$.", "cites": [7868], "cite_extract_rate": 0.2, "origin_cites_number": 5, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.0, "critical": 3.5, "abstraction": 3.0}, "insight_level": "medium", "analysis": "The section provides a clear explanation of NCD and incorporates insights from the cited paper on its limitations with large malware files. It critically assesses the theoretical assumptions and practical constraints of NCD. While it connects the concept to broader applications in malware classification, the synthesis and abstraction remain moderate, focusing on a single paper and not building a novel framework or deeper meta-level insights."}}
{"id": "a2b32a75-2799-4775-bc9d-bd53eb69f8bc", "title": "Lempel-Ziv Jaccard Distance", "level": "subsubsection", "subsections": [], "parent_id": "af1937fa-3422-48c0-9790-0d38f1428070", "prefix_titles": [["title", "A Survey of Machine Learning Methods and Challenges for Windows Malware Classification"], ["section", "Machine Learning Over Sequences"], ["subsection", "Byte Similarity Measures"], ["subsubsection", "Lempel-Ziv Jaccard Distance"]], "content": "\\label{sec:lzjd}\nInspired by the successes and background of NCD, the Lempel-Ziv Jaccard Distance (LZJD) has been developed for malware classification . It draws from the observation that the compression algorithms that tend to work best in this domain make use of the Lempel-Ziv dictionary encoding scheme, and that the compressed output itself is never used. Instead LZJD creates the compression dictionary, and then measures the similarity of binaries using the Jaccard distance \\eqref{eq:jaccard_sim} between the dictionaries. \n\\begin{equation}\\label{eq:jaccard_sim}\nJ(A, B) = \\frac{|A \\cap B |}{|A \\cup B|}\n\\end{equation}\nThis alone was shown to be more accurate for nearest-neighbor classification of malware, and can be made nearly three orders of magnitude faster than NCD through the use of min-hashing, thus alleviating the runtime cost of NCD. In addition to being faster, LZJD retains the distance metric properties lost by NCD. The use of the Jaccard similarity / distance also means that it is a valid kernel, and can be directly  applied to the methods discussed in \\autoref{sec:kernel_methods}. \n\\textcite{raff_shwel} developed a method of converting LZJD's dictionary into a fixed length feature vector using a technique known as the \"hashing trick\" . More interesting is their observation that the compression dictionary is sensitive to byte ordering, and single byte changes can cause large changes to the dictionary. They exploited this weakness to develop an over-sampling technique for tackling class imbalance, an issue we will discuss further in \\autoref{sec:class_imbalance}. This was later refined to require less hyper-parameter tuning for easier use .\nLZJD represents an approach of applying the intuition of NCD to a specific compression algorithm, the Lempel Ziv approach. Another approach along this theme is the Burrows Wheeler Markov Distance (BWMD), which again applies the intuition of NCD to the Burrows Wheeler compression algorithm . The Burrows Wheeler method is not as effective a compression approach as Lempel Ziv, and is reflected in BWMD not being quite as accurate as LZJD in nearest neighbor search. The benefit from BWMD comes from it producing a euclidean feature vector, rather than a a digest like LZJD does. This makes BWMD compatible with a wider class of ML algorithms, which showed how BWMD could produce better clustering and orders of magnitude faster search by leveraging more appropriate algorithms that require euclidean feature vectors .", "cites": [7867, 7868], "cite_extract_rate": 0.25, "origin_cites_number": 8, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.5, "abstraction": 3.5}, "insight_level": "medium", "analysis": "The section effectively synthesizes information from the cited papers by connecting the concept of NCD with the practical implementation of LZJD, and contrasts it with BWMD. It critically analyzes the limitations of NCD and highlights the advantages of LZJD, such as accuracy, runtime efficiency, and compatibility with kernel methods. The section also abstracts by identifying broader patterns in the use of compression-based similarity measures and their implications for malware classification."}}
{"id": "f73139a7-e2f9-485a-ba17-91e0493b8bfd", "title": "Convolutional and Recurrent Neural Networks", "level": "subsection", "subsections": [], "parent_id": "26902f76-dad6-4b96-bfbb-2c01dc363dea", "prefix_titles": [["title", "A Survey of Machine Learning Methods and Challenges for Windows Malware Classification"], ["section", "Machine Learning Over Sequences"], ["subsection", "Convolutional and Recurrent Neural Networks"]], "content": "\\label{sec:rnn}\nAs we discussed in \\autoref{sec:neural_nets}, neural networks have become popular algorithms and can be viewed as a graph defining a large and potentially complicated function. This flexibility allows them to be extended to sequence tasks by replicating the same network for every step in the sequence. This is often referred to as \"weight sharing\", and leads to the idea of the Convolution Neural Network (CNN). \nThe success of CNNs in both image and signal processing has been long recognized . \nCNNs embed a strong prior into the network architecture that exploits the temporal/spatial locality of these problems. The convolution operator essentially learns a neuron with a limited receptive field, and re-uses this neuron in multiple locations. Thus a neuron that learns to detect edges can be reused for each part of the image, since edges can occur just about anywhere in an image. This property is not a perfect fit for malware sequence problems, and it remains to be seen if they will be useful despite the structural mismatch. CNNs may be a better fit at higher levels of abstraction, and have been applied to system call traces . We also note that on their own, convolutions do not completely handle the variable length problem that comes with the malware domain. \nOne common method of dealing with variable length sequences is to further extend the weight sharing idea, by adding a set of connections from one time step to the next, using the previous timestep's activations as a summary of everything previously seen. This high-level idea gives rise to Recurrent Neural Networks (RNNs), and we refer the reader to \\textcite{Lipton2015} for a deeper introduction to the history and use of RNNs. We note that the CNN and RNN encode different priors about the nature of sequences, and can be used together in the same large architecture, or be kept disjoint. We will again refer the reader to \\textcite{Goodfellow-et-al-2016-Book} for a broader background on neural networks. Below we will give only \nhigh-level details pertinent to models used in malware classification literature. \nNaive construction of a RNN often leads to difficulties with both vanishing and exploding gradients , making the training process difficult. One older solution to this problem is the Echo State Network (ESN) . The ESN circumvents the RNN learning difficulty by selecting the recurrent weights via a stochastic process, so that no learning of the recurrent portion is needed. This may also be interpreted as a stochastic process by which we convert varying length sequences to fixed length feature vectors, after which any of the techniques discussed in \\autoref{sec:ml_methods} may be applied. The parameters that control the stochastic process can be adjusted to sample different types of ESNs, and cross validation can be used to select the hyper-parameters that worked best. This simple strategy has worked well for many problems, and can be applied to a number of different types of learning scenarios . The ESN has been used by \\textcite{export:249072} to process a set of high-level events, including API calls, for malware classification and found the ESNs to have an accuracy rate almost twice as high as an n-gram based approach. \n\\tikzstyle{decision} = [diamond, draw, text width=4.5em, text badly centered, node distance=3cm, inner sep=0pt]\n\\tikzstyle{input} = [rectangle, text width=3.5em, text centered, rounded corners, minimum height=2em]\n\\tikzstyle{hidden_layer} = [circle, draw, text centered, minimum height=2em]\n\\tikzstyle{line} = [draw, -latex']\n\\tikzstyle{embed} = [circle, fill=blue!20, text centered, minimum height=2em]\n\\begin{figure}[ht]\n    \\centering\n    \\begin{subfigure}[b]{0.48\\textwidth}\n\t    \\centering\n        \\resizebox{1.0\\linewidth}{!}{\n        \\caption{A 2-layer RNN}\n        \\label{fig:rnn}\n    \\end{subfigure}\n    \\hfill\n    \\begin{subfigure}[b]{0.48\\textwidth}\n\t    \\centering\n        \\resizebox{1.0\\linewidth}{!}{\n        \\caption{A 2-layer bi-directional RNN}\n        \\label{fig:rnn_bidir}\n    \\end{subfigure}\n    \\caption{Two simpler RNN architectures for classifying a sequence. In each case the rows of the diagram represent the same neuron being applied on inputs at different time steps. The input includes the bottom up input (previous layer) as well as the previous time step (which is implicitly zero when not present).}\n    \\label{fig:rnn_examples}\n\\end{figure}\nIn the Deep Learning literature the Long Short Term Memory (LSTM) unit  has also helped to overcome a number of difficulties in training the recurrent connections themselves, especially in combination with recent advances in gradient-based training and weight initialization. Training works by extending back-propagation \"through time\" , which amounts to unrolling the sequence of input and output transitions over the course of the sequence (i.e., weight sharing across time). This produces a directed acyclic graph, on which normal back-propagation can be applied. Two examples of this are given in \\autoref{fig:rnn_examples}, where the neurons in each column all share the same weights. Back-propagation can then be done normally on this unrolled architecture, and the shared weights will be updated based on the average gradient for each time the shared weight was used. This also means that any of the architecture types discussed in \\autoref{sec:neural_nets} can be used with RNNs, either before, after, or in-between recurrent stages, and trained jointly with the rest of the network. \n\\textcite{Kolosnjaji2016} have exploited the flexibility of neural networks to combine LSTMs with CNNs for malware classification based on API call sequences. The architecture combination allows the CNNs to learn to recognize small groupings of co-occurring API calls, and the LSTM portion allows the information from multiple co-occurrences to be captured through the whole call trace to inform a decision, and were found to out-perform HMMs by 14 to 42 percentage points. Similar work was done by \\textcite{Tobiyama2016}. \nUsing just LSTMs, \\textcite{raff2017peheader} instead looked at byte sequences and were able to show that LSTMs could learn to process the bytes of the PE header sequentially to arrive at accurate classifications. They also used an \\textit{attention mechanism} to show that the LSTM learned to find the same features as a domain knowledge approach learned to use when the features were manually extracted. The purpose of an attention mechanism is to mimic the human ability to focus on only what is important, and ignore or down-weight extraneous information. This has become a tool often used in Machine Translation, and offers a more interpretable component to a neural network. \nCNNs to process the raw bytes of a file where first introduced by \\textcite{MalConv}, which treated the raw bytes of a executable file as a 2 million byte long sequence. Their work found that many of the best practices for building neural networks for image, signal, and natural language processing did not carry over to learning from raw bytes. Notably this required using a shallower and wider network (rather than deep and narrow), and the abandonment of layer normalization techniques like Batch-Norm. \\textcite{Krcal2018} expanded this work on their own corpus, but also compared with analyst-derived features used by Avast for their AV product. In doing so they found the approach was competitive with their classical AV, but that combining the features learned by the CNN with those their analysts developed had the best accuracy. This indicates that the CNN approach is learning to detect features that were overlooked by the expert analysts. Otherwise the features would be redundant, and their combination should have no impact. \nThe ability of CNNs and RNNs to handle variable length sequences makes them an attractive tool for malware classification, however they have yet to receive significant application to that task. Part of this is likely due to the added computational burden they bring. Regular neural network algorithms often require the use of GPUs to train for days at a time. RNNs exacerbate this situation with more computations and a reduction in the parallelism of the problem, making it challenging to scale out training across multiple nodes. It is also difficult to train RNNs for sequences longer than a few thousand time steps, which is easily exceeded by call traces, byte sequences, and entropy measurements. It is likely that intelligent combinations of RNNs with other architectures or advancements in training efficiency will be needed before wide use is seen.", "cites": [71], "cite_extract_rate": 0.1111111111111111, "origin_cites_number": 9, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.8, "critical": 3.5, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section synthesizes multiple papers into a coherent narrative about the application of CNNs and RNNs for malware classification, particularly emphasizing architectural differences and domain-specific adaptations. It provides critical evaluation by noting structural mismatches and training challenges, and highlights comparative performance improvements from hybrid architectures. The abstraction is strong, as it generalizes the role of these models in sequence learning and identifies broader implications such as the potential of CNNs to discover overlooked features."}}
{"id": "1d750f01-3d36-431b-97fb-143a02e7aaba", "title": "Evaluating Over Time", "level": "subsection", "subsections": [], "parent_id": "3405c014-2398-4841-90d3-9f3b8ffaa4a1", "prefix_titles": [["title", "A Survey of Machine Learning Methods and Challenges for Windows Malware Classification"], ["section", "Evaluation and Metrics"], ["subsection", "Evaluating Over Time"]], "content": "It is also important to evaluate a system based on the longevity of the model's utility. That is to say, we may desire a model that is more robust to concept drift, perhaps at some cost in terms of another metric. This would be important for any system that in some way has limited Internet connectivity, making it expensive (or impossible) to update the model over time. This does not necessarily prevent malware from trying to infect the device when online, or from someone with physical access attempting to install malware on the device. In this case the model needs to be robust to malware over longer periods of time to thwart such efforts until an update of the model can be completed. In our view, \\textcite{Saxe2015a} is one of the more important attempts at performing such an evaluation. They used the compile date provided in the PE header to split the dataset into before and after July 31st, 2014. Under this scenario their malware detection rate dropped from 95.2\\% to 67.7\\% for a fixed false positive rate of 0.1\\%. \nThis dramatic drop shows the importance of considering time in evaluations, which is not a common practice. One issue is that the compile date in the PE header is easily modified, and so malware authors can alter the value seen. File first-seen date may be a usable alternative source for this information, but is necessarily less precise. Performing evaluations split in time like this also requires significant data from a wide breadth of time. This exacerbates the need for good benign data mentioned in \\autoref{sec:data}. Not addressed in \\textcite{Saxe2015a}, but also worth considering, is evaluating the performance on the test set as a function of time --- which would allow one to more precisely characterize the longevity of generalizing information. \nThe EMBER dataset follows this evaluation protocol, with date-first-seen information provided by an external source rather than the time stamp of the file . This avoids the problems caused if the malware lies about its creation date, but has less precision. Valuable information could be obtained by doing a comparative study between these different types of date information, seeing how well they correlate, and how the choice impacts results. \nThere are still many important questions related to a malware model's performance over time that have not been answered. Most notably, for how long is a model effective? What are the important factors to a model's longevity (i.e., is data or the model type more or less important)? How old can training data be before it becomes uninformative or even detrimental to training? Presuming that such a threshold for training data exists, do benign and malicious data have a different  \"shelf-life\" in terms of utility for training?", "cites": [7861], "cite_extract_rate": 1.0, "origin_cites_number": 1, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 4.0, "abstraction": 4.0}, "insight_level": "high", "analysis": "The section provides a clear analytical perspective on the importance of time-based evaluation in malware classification, using the work of Saxe et al. and the EMBER dataset to build a broader argument about model longevity and concept drift. It not only integrates these sources but also critically assesses their limitations and suggests potential research directions. The discussion generalizes beyond the cited papers to address fundamental questions about the temporal dynamics of malware data and model effectiveness."}}
{"id": "2e2debe0-2660-480f-b9d7-0cb00422b419", "title": "Learning with Class Imbalance", "level": "subsection", "subsections": [], "parent_id": "ede9e8e3-a18a-4470-ae7f-81df41703fed", "prefix_titles": [["title", "A Survey of Machine Learning Methods and Challenges for Windows Malware Classification"], ["section", "Future Research Potential"], ["subsection", "Learning with Class Imbalance"]], "content": "\\label{sec:class_imbalance}\nMost machine learning algorithms presume equally balanced classes  at training time, and thus also at testing time. Learning from imbalanced classes can naturally cause the algorithm to favor the more numerous class, but also be detrimental in failing to learn how to properly separate the classes. Class imbalance is a common problem in the malware domain , which makes it especially important to consider the evaluation metric used for both malware detection and family classification (as mentioned in \\autoref{sec:mal_detection} and \\autoref{sec:mal_family_classification}). \nOne way to tackle such imbalance problems is to over-sample the infrequent classes or under-sample the more populous ones. These approaches are common, but can be out-performed by a more intelligent over-sampling or under-sampling process. Indeed there is an existing literature for such methods focusing on both approaches, which have seen almost no application to the malware problem. Exploring their applicability to this domain and how such methods may be adapted for the difficulties of sequence and graph based features is, as far as we are aware, an open problem area. \nOversampling the minority class is an intuitively desirable approach, as it allows us to use the larger amount of of majority class data --- and thus more data to train on overall. However, naive oversampling can lead to overfitting . One technique to do this more intelligently is to interpolate new datums from the training distribution, and a popular algorithm SMOTE takes this approach and has many variants as well . This also assumes a natural fixed length feature vector, and that interpolated instances are intrinsically meaningful. This may not be the case for all malware features, and may not be readily possible for sequence or graph based approaches to malware classification. \nUnder-sampling is often done intrinsically for malware detection, where the ratio of malicious to benign samples available is large. While less intuitively desirable than oversampling, smarter approaches for this exist as well. One approach is to train multiple models, with different subsets of the majority class used in each model, allowing for the creation of an ensemble. Other techniques also attempt to more intelligently select the sub-samples. \nWe are aware of relatively little work that explores the problems of class imbalance in this space. \\textcite{Moskovitch2009a} investigated training set proportion's impact on differing test-set proportions, but worked under the assumption that malware will make up 10\\% of seen files in a network stream, and in later work simply set the training ratio equal to this ratio .\n\\textcite{raff_shwel} looked at developing an algorithm specific oversampling technique, evaluating on an assumption of equal class ratio. \nIt is generally thought that malware will make the minority of samples in deployment,  which is supported by a large study on over 100 million machines which found that the number of benign singletons outnumbers malicious ones at a ratio of 80:1 . However, they also found that this ratio changed over time. We think further study is warranted to determine how applicable this rule of thumb is. Do all institutions share the same ratio of benign to malicious, or would certain institutions or individual users who are targets for malware authors have lower ratios? Similarly, do different types of equipment (e.g., desktop computer, router, or mobile device) see differing ratios of malware? How do these rates change with geographical area? Lastly, we suspect there are a number of niche professions with special needs that will see differing distributions. For example, cyber crime investigators inspecting a recovered hard drive may expect to see a much higher ratio of malware given their targeted goals.", "cites": [8392], "cite_extract_rate": 0.0625, "origin_cites_number": 16, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.0, "critical": 3.5, "abstraction": 3.5}, "insight_level": "medium", "analysis": "The section provides an analytical overview of class imbalance in malware classification, integrating general oversampling and undersampling techniques from the literature while highlighting their limited application to the domain. It critically points out limitations of naive oversampling and the need for adaptation to sequence and graph-based features. While not offering a novel framework, it identifies broader research questions and contextual factors (e.g., institution, device type, geography) that could influence class distribution, showing reasonable abstraction."}}
{"id": "807b774d-f86e-428e-8013-f3e18a748cd9", "title": "Malware, Natural Language Processing, and Reports ", "level": "subsection", "subsections": [], "parent_id": "ede9e8e3-a18a-4470-ae7f-81df41703fed", "prefix_titles": [["title", "A Survey of Machine Learning Methods and Challenges for Windows Malware Classification"], ["section", "Future Research Potential"], ["subsection", "Malware, Natural Language Processing, and Reports "]], "content": "A common task for malware analysts is to generate reports of their findings, which are shared with other security processionals to make them aware of new threats, and how to identify the malware, and other valuable information. These documents may be in any format, and may contain a variety of detail labels. Little work has been done on this data, mostly consisting of performing a variety of NLP tasks on the reports themselves \n. \nIn reality, the reports represent one mode of a multi-model data tuple, the textual report of behavior and unique identifies, and the unstructured binary executable(s) that are the subject of the report. A regular occurrence is a new malware family being discovered, and these reports may serve as a source of additional information that could be used to detect novel malware families with limited labeled examples. Other possibilities include work in generating these reports from the malware itself, following inspiration from the automated statistician work . This could aid in both developing/adapting models more quickly, as well as disseminating information faster. A variety of possibilities exist at this unique intersection of malware detection and NLP that have yet to be explored.", "cites": [7869, 7871, 7870], "cite_extract_rate": 0.42857142857142855, "origin_cites_number": 7, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.0, "critical": 2.5, "abstraction": 3.5}, "insight_level": "medium", "analysis": "The section synthesizes the cited papers by identifying a potential synergy between malware analysis and NLP, particularly through the use of automated report generation inspired by the 'automatic statistician' concept. While it offers some abstraction by framing reports as part of a multi-modal data tuple and suggests broader implications for malware detection, it lacks deeper critical analysis of the papers limitations or specific evaluations of their applicability to the malware domain. The integration of ideas is coherent but not particularly novel."}}
