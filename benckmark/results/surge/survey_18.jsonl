{"id": "8b3dfa22-17fe-43f3-9b59-5e3997956f90", "title": "Introduction", "level": "section", "subsections": [], "parent_id": "9409a959-d9a0-482f-ae90-dcda4156e238", "prefix_titles": [["title", " A Survey on Theorem Provers in Formal Methods"], ["section", "Introduction"]], "content": "\\label{s1}}\nRecent developments and evolution in Information and Communication Technology (ICT) have made computing systems more and more complex. \nThe criteria that how much we can rely on these systems is based on their correctness. \nBugs or any loopholes in the system lead to severe risks that endanger \nhuman safety or financial loss. In recent times, bugs ratio has \nincreased due to the complex designs of the modern systems under market pressure and user requirements.\nThe efforts and cost required to correct bugs increases as the gap widens between their introduction and detection.\nTable \\ref{Ta1}, taken from , shows the relative costs to fix bugs that are introduced in the requirements\nphase. A bug introduced in a particular stage of a system development is relatively cheap to fix if also detected in that stage.\nIt becomes more hard and expensive to fix a bug that is introduced in one stage and detected in the other stage.\nFor safety-critical systems, the impact of bugs can be so large as to make a fix effectively mandatory.\\vspace{-3mm}\n\\begin{table}[!ht]\n \\caption{Cost to fix a bug introduced in requirements phase}\\vspace{-2mm}\n \\centering\n\\scalebox{0.8}{\n  \\begin{tabular}{ | c | c | }\n    \\hline\n    {\\bf Bug Found at Stage} & {\\bf Relative Cost to Fix} \\\\ \\hline\n     Requirements & 1 (definition) \\\\ \\hline\n    Architecture & 3 \\\\ \\hline\n    Design & 5-10 \\\\\\hline\n    System Test & 10 \\\\\\hline\n   Post-Release & 10-100\\\\\\hline\n     \\end{tabular}}\n     \\label{Ta1}\n  \\end{table}\\vspace{-2mm}\nTesting and verification techniques are used in the system test phase to empirically check their correctness. \nIn testing, a system is tested against the software/hardware \nrequirements . Similarly, simulation provides virtual environments for any real events. \nHowever, there are some inherent limitations of these techniques. A program can be only tested \nagainst the functional requirements of the system, which may be not refined and may contain ambiguities that leads to inadequate testing. \nExhaustive testing of systems is not possible. Moreover, the time and budget constraints may affect the testing process. \nSimulations are also based on assumptions and does not always cover all the aspects of the system . \nFurthermore, both testing and simulation can not be used efficiently for analyzing the continuous or hybrid systems. According to \n: ``Program testing is an effective way to find errors, but it does not guarantee the absence of errors''.\nOn the other hand, formal methods formally verify the system correctness. \nFormal methods are ``mathematical-based techniques that are used in the modeling, analysis and verification of both the software and hardware \nsystems'' . Formal methods allow the early introduction of models in the development life-cycle, against which the system\ncan be proved by using appropriate mathematics.\nAs mathematics is involved in the modeling and analysis, 100\\% accuracy is guaranteed .  But why we need \nformal methods in place of other well-known, widely acceptable and easy to use techniques such as testing and simulation? \nTo answer this question, we first provide a few examples where testing and simulation failed.\nAir France Flight 447 crashed in June 2009, which resulted into hundred of casualties. During investigation, it was found that the probe \nsensors were unable to measure the accurate speed of the plane, which provides the automatic disengagement of autopilot. Similarly, \nin August 2005, Malaysian Airbus 124 landed unexpectedly 18 minutes after taking off due to a fault in its air data inertial \nreference unit. There are two accelerators that control the airspeed of the flight, but one of them failed,  which resulted into a sudden \nrapid climbing and passed almost 4000 feet higher than expected without any warning. After investigation, it came to know that on \nthe failure of the first accelerator, the second one used the falsy data of former due to input anomaly in the software. The probe, which laid hidden \nfor a decade, was not found in testing because the designer had never assumed that such an event might occur . In June \n2009, Metro Train in Washington crashed and as a result, the operator of the train and 80 other people got injured severely. The cause of this \nincident \nwas the design anomaly in the safety signal system. The safety system sent a green signal to the upcoming station, while the track was not empty. \nSimilarly, other examples are failure of the London Ambulance Service's computer added dispatch system , Therac 25 , Anaesthetic \nequipment and the respiration monitoring device  which resulted into the  casualties and financial losses. All listed accidents could have\nbeen avoided if the design of the systems were analyzed mathematically.\nFormal methods techniques in contrast to testing permit the exhaustive investigation and reveals those bugs which are missed by testing methods. \nActual requirements of the system in such techniques are \ntranslated into formal specifications which are mathematically verified and elaborate the actual behavior of the system in real scenarios. \nTwo most popular formal verification methods are \\texttt{model checking}\nand  \\texttt{theorem proving}. \nIn  model checking, a finite model of the system is developed first, whose state space \nis then explored by the model checker to examine whether a desired property is satisfied in the model or not . Model checking is \nautomatic, fast, effective and it can be used to check the partial specification of the system. However, model checkers \nstill face the {\\em state-space explosion problem} . Model state space grows infinitely large with increase in the \ntotal number of variables and components used and the number of distinct values assigned to these variables . \nTheorem proving on the other hand, can be used to handle infinite systems. In theorem proving, systems are defined and specified by users in an\nappropriate mathematical logic. Important/critical properties of the system are verified by {\\em theorem provers}. \nTheorem prover checks that whether a statement (goal) can be derived from a logical set of statements (axiom/hypothesis). It can \nmodel and verify any system that can be defined with the help of mathematical logics.\nIt is akin to Computer Algebra System (CAS) because both are used for symbolic computation. However, theorem provers have some advantages \nover CAS such as: flexibility in logic expressiveness, clear expression and more rigor. Theorem provers can be further categorized into \ntwo main types: Automated Theorem Provers (ATPs) and Interactive Theorem Provers (ITPs). ATPs deal with the development of automated computer \nprograms to prove the goals . In contrast, ITPs involve human \ninteraction with computer in the process of proof searching and development. That is why ITPs are also known as {\\em proof-assistants}. \nDue to practical limitations in pure automation, interactive proving is the suitable way \nfor the formalization of ``most non trivial theorems in mathematics or computer system correctness'' .\nTheorem provers have been used successfully in various domains such as biomedical , \ngame theory , machine learning , economy , computer science , \nartificial intelligence  and self-adaptive systems .  \nNote that the terms theorem provers and\nmechanical reasoning systems are used interchangeably in this paper.\nWe believe that a comprehensive review on mechanical reasoning systems is strongly needed. People having little knowledge about them\ngenerally think that all the systems based on mathematics have similar nature. However, it is not the case. Each system has different \nfunctionality and it is not an easy task to select which system should be used for the formalization efforts. \nTheorem provers are diverse in nature and the\nmain aim of this work is to demonstrate how different they are. Moreover, the goal is to provide a proper guidance to new \nresearchers in formal verification. In order to substantiate our work, a questionnaire has been designed \nfor the evaluation of theorem provers. The questionnaire is then filled by \nthe developers and active researchers of theorem provers. Mechanical reasoning systems are investigated for the following parameters:\n\\begin{itemize}\n\\item Mathematical logic used in the system,\n\\item Implementation language of the system,\n\\item System type,\n\\item Platform-support in the system,\n\\item System category, whether it belongs to ATP or ITP,\n\\item Truth value of the system (binary/fuzzy),\n\\item Calculus (deductive/inductive) of the system,\n\\item Set (ZF/fuzzy) theoretic support in the system,\n\\item Programming paradigm of the system,\n\\item User Interface (UI) of the system,\n\\item Scalability of the system,\n\\item Distributed/multi-threaded,\n\\item Integrated development environment (IDE) support,\n\\item Library support in the the system,\n\\item Whether the system satisfy the de Bruijn criterion, and \n\\item Whether the system satisfy the Poincar{\\'e} principle of automation.\n\\end{itemize}\nPrimarily, this survey is a collection of tables and figures that illustrates various aspects of theorem provers. We \nreceived replies from experts/developers of 16 theorem provers. Another 27 theorem provers characteristics are investigated through \nonline databases and research articles. \nWe also report the top scientists who have proved maximum number of theorems in provers \nand top provers in which most number of mathematical theorems are proved till now. ATP that performed best at CADE ATP \nsystem competition (CASC) are also discussed. CASC is a yearly competition for the first-order logic fully ATPs. Moreover, aforementioned \nparameters are used to compare the provers and to present their main characteristics and differences. Finally, their applications \nare discussed along-with the existing recent work and the potential application/problems, where they can be used. \nThe rest of the survey is structured as follows: An overview on the historical background of theorem provers in\nthe light of logical frameworks  is provided in Section \\ref{s2}. Related work is also discussed. Section \\ref{s3} elaborates the research \nmethodology that is based on \nthe systematic literature review in software engineering. Section \\ref{s4} presents the results of the questionnaire, where answers of \nthe experts and developers are presented. In Section \\ref{s5}, top scientist that proved most of the theorems and top provers in which \nmaximum number of theorems are proved till now are listed. ATP that performed best at CASC competition are also listed. Finally, theorem \nprovers are compared for aforementioned criteria. The strengths, in-depth analysis of the differences among \nthe existing theorem provers and their application areas are discussed in Section \\ref{SAFD}, along-with the future research directions. \nThe survey concludes with some remarks in Section \\ref{s6}.", "cites": [16, 7174], "cite_extract_rate": 0.09090909090909091, "origin_cites_number": 22, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 2.0, "abstraction": 2.0}, "insight_level": "low", "analysis": "The introduction provides a general overview of theorem provers and their importance in formal methods, with some context on the limitations of testing and simulation. It mentions two cited papers but does not deeply synthesize or integrate their content into a broader narrative. The section is primarily descriptive and lacks critical evaluation or abstraction to higher-level principles."}}
{"id": "a174bb81-0b23-4cbe-bbd6-70e2b57ca92e", "title": "Related Work", "level": "subsection", "subsections": [], "parent_id": "1b85b9fd-1b10-424f-869d-f4d806e469fe", "prefix_titles": [["title", " A Survey on Theorem Provers in Formal Methods"], ["section", "Background"], ["subsection", "Related Work"]], "content": "Our survey on mechanical reasoning systems is certainly not the first one. \nSome work is done in the past on the survey and detailed discussion and comparison on theorem  provers \n. \nA detailed description of proof-assistants and their theoretical foundations is given in  along-with the comparison for nine theorem provers.\nHowever, their comparison results take only one and a half pages. \n17 theorem provers are compared in  for three parameters: (i) library size of each prover, (ii) strength of \nthe logic used in the prover, and (iii) level of automation in each prover. \nSimilarly,  surveyed Coq, PVS, Mizar, ProofPower-Hol, HOL4, Isabelle/HOL and HOL Light for formally analyzing the  \nreal time systems. They also investigated the extended standard libraries \nthat play main role in proof automations: C-CoRN/MathClasses for Coq, ACL2(r) for ACL2 \nand the NASA PVS library. The application of theorem provers in economics is discussed in , with the focus on two domains: \nsocial choice theory and auction theory. \nIn literature, other comparisons between provers can be found. However, in most of those works, only two systems are compared generally. \nSuch works include the comparisons between HOL and PVS ,\nHOL and Isabelle , NuPRL and Nqthm , Coq and HOL , HOL and ALF  and Isabelle/HOL and Coq . Some works have also been done on how to adapt the proofs to different systems . \nIn , Reentrant Readers Writers problem is first modeled in UPPAAL model checker and found a possible\ndeadlock scenario. They further converted the UPPAAL model and analyzed the model in PVS and checked the PVS model for arbitrary number of \nprocesses. Moreover, SPIN model checker is used in  for modeling and analysis of \nReentrant Reader Writers problem.\nPromela model is converted to PVS specification and the correctness of the model was then verified.", "cites": [16], "cite_extract_rate": 0.045454545454545456, "origin_cites_number": 22, "insight_result": {"type": "descriptive", "scores": {"synthesis": 2.0, "critical": 2.0, "abstraction": 2.0}, "insight_level": "low", "analysis": "The section provides a basic listing of related works and their comparisons but lacks deeper synthesis of ideas or themes across the cited papers. It mentions the number of provers compared and some specific libraries or domains studied, but does not connect these findings into a broader narrative. There is minimal critical evaluation or abstraction beyond the individual works."}}
{"id": "3533a895-366e-4651-8d65-8519fe18523b", "title": "ITPs", "level": "subsection", "subsections": [], "parent_id": "a039e28c-2700-4a8b-bd24-c8b8405fda8b", "prefix_titles": [["title", " A Survey on Theorem Provers in Formal Methods"], ["section", "Strengths, Analysis, Applications and Future Directions"], ["subsection", "ITPs"]], "content": "ACL2 main strengths are: state-of-the-art prover heuristics, robust engineering and extensive hyperlinked documentation. \nAmong all ITPs, ACl2 uses FOL instead of higher-order logics. Only two ITPs, Isabelle and ACl2 offer parallel proof checking facility. \nACl2 also supports program extraction (also called code generation) by translating the specification in ACL2 language to Common Lisp. Theories can also be developed and\nexecuted in ACL2 as it is built around a real programming language. Users can not construct inductive types, but powerful built-in induction scheme in ACl2 allows users \nto define their own recursive functions. The inference engine is based on the waterfall design of Nqthm prover .\nACL2 has been used extensively to verify hardware and software designs at AMD, Centaur, Oracle, Intel, IBM and to prove separation \nkernel properties at Rockwell Collins . Moreover, ACL2 is also used successfully in processor modeling , \ndigital systems , programming languages , asynchronous circuits  and \nconcurrency . ACl2(ml)  uses machine learning to facilitate users in the proof process.\nIn past, some work has been done in integrating SAT solvers into ACL2 . \nHowever, it has generated new issues because of their support for a wide range of domains including real numbers and uninterpreted \nfunctions. The $x86isa$ library   in ACL2 offers a formal model for reasoning about $x86$ machine-code programs. \nAdding several features to current $x86isa$ library such as exceptions, interrupts handling and extending I/O capabilities will enable \nus to reason about real system codes. \nAtelier B offers a framework that automatically prove and review user added mathematical proof rules. \nProof obligations in Atelier B contain traceability information that helps in locating modeling errors\nand model editor allows the navigation of models and operations . B-method allows one to develop many models of the same system \nwith the refinement technique. However, one is required to explain the B model while proving theorems and the proof obligation generator may generates small \nproof obligations that need to be discharged.\nAtelier B is used in the development of safety-critical systems  and communication protocol .\nMoreover, B-method is also used successfully in the development of safety-critical parts in \ntwo railway projects  and byte code verifier of the Java card . \nMain strength of Metamath is that it uses the minimum possible framework that is required to express mathematics and their proofs. \nUnlike most ITPs, \nno assumption is made by the Metamath's verification engine about the underlying logic and the main verification algorithm is very simple (essentially nothing more\nthan substitution of variables expression, enhanced with checking for conflicts in distinct variables). \nWeaker logics such as quantum or intuitionistic can be handled in Metamath with different sets of axioms. \nProofs in Metamath are generally very long, but the proofs are completely transparent and Metamath database contains over 30,000 human readable formal proofs.\nIn the proof development process, users prove a theorem/lemma interactively within the program, which is then written to the source by the program.\nA definition is provided in  for models of Metamath style formal systems, which are demonstrated on propositional\ncalculus examples. \nFrom mathematical foundations, Hilbert space and quantum logic is developed in Metamath, which are used in the verification of some\nnew results in these fields. Metamath is used in the formalization of Dirichlet's theorem and Selberg's proof \nof the prime number theorem . \nAn algorithm is presented in  that converts HOL Light proofs into Metamath.\nTwelf strengths are representing deductive systems with side conditions and judgments with contexts. It offers an environment for experimenting with encodings \nand to verify their meta-theoretic properties. It also provides a module system for the organization of large developments. \nTwelf implements the {\\em $\\lambda$Prolog}  and its logic is very close to the Edinburgh Logical Framework (LF) . \nTwelf specifications can be executed through a search procedure, which means that it  can also be used as a logical programming language.\nTwelf is used in proving the safety of standard ML programming \nlanguage , in typed assembly language system , in foundational Proof Carrying-Code system ,\nin cut-elimination proofs for classical and intuitionistic logic , for specifying and validating logic\nmorphisms  and construction of a safety policy for the IA-32 architecture .\nMain features of Agda is the interactive construction of programs and proofs with meta-variables and place-holders. \nUnlike other ITPs that work with {\\em proof-scripts}, Agda acts as a structure editor, providing support for term construction. \nUsers can edit the {\\em proof-object} by focusing on a hole and executing one of the operations (tactics) that is applied to that hole. It is the only ITP that offers a \nfunctional programming language with dependent types.\nMoreover, strictly positive inductive and inductive-recursive data types are supported in Agda.\nEmacs interface for Agda allows the incremental development of programs .\nAgda is used to formally verify railway interlocking systems , web client application development ,\nfully certified merge sort , hardware description and verification , \nformalizing Type-Logical Grammars , Curry programs verification  and formalization of Valiant's Algorithm .\nIn , automated theorem prover Waldmeister  is integrated in Agda to facilitate the proof automation. \nSimilarly, another tool is proposed in  for automated theorem proving in Agda.\nMizar received popularity because of its huge repository of formalized mathematical knowledge, \nwhich has been used in developing AI/ATP methods to solve conjectures in mathematics . \nOver the years, the syntax of Mizar is improved, simplified and the Mizar language now contains\na rich set of logical quantifiers and connectives.\nThe evolution of Mizar in first 30 years is presented in . \nIn Mizar, proofs are written in a declarative way and proofs are developed according to the rules of the Ja\\`{s}kowski style of\nnatural deduction . This characteristics influenced other systems to build similar kind of proof\nlayers on top of several other systems, such as the Mizar mode for HOL , the Isar language for Isabelle , \nMizar-Light for HOL-Light  and the declarative proof language (DPL) for Coq . \nMizar does not support the Poincar{\\'e} principle, yet it has some automated deduction and a set of tactics that are very user-friendly. \nThe main unique feature is that the {\\em proof-script} is close to an ordinary proof in mathematics.\nApart from large MML, Mizar is used in the development of rigorous mathematics, in hardware/software verification and in mathematical education .\nSome recent work in Mizar includes the formalization of Pell's equation , Nominative Algorithmic Algebra \nand formalization of bounded functions for cryptology . \nA suite of AI/ATP system is developed on Mizar library in  that contains approximately 58000 theorems. \n14 strongest methods that executed in parallel proved 40.6\\% of the theorems.\nMoreover, an independent certification mechanism is developed in Mizar that is based on Isabelle framework . \nIn , Mizar environment is also emulated inside the Isabelle.\nHOL was build upon the Cambridge LCF approach  that is now referred to as HOL/88 with the purpose of hardware verification. It has influenced the \ndevelopment of other famous ITPs such as Isabelle/HOL,\nHOL Zero, ProofPower and HOL Light. In HOL, the computations that involves recursion can become quite lengthy and complex when \nthey are converted to {\\em proof-objects}. Thus, the {\\em proof-objects} are not stored, only the {\\em proof-scripts}. \nThis is the reason why {\\em non-standard proof-objects} are used in HOL.\nUsers in HOL generally work inside the implementation language. As HOL is fully programmable, various other means of interacting \nwith HOL have also been developed. HOL Light is the most widely used provers of this family and it is probably the only prover that represents the \nLCF approach in its purest form. Its logic is based on simple type theory with polymorphic type variable. The terms in HOL Light are of simply typed \n$\\lambda-$calculus, \nwith just two primitive types: {\\em bool} (Booleans) and {\\em ind} (individuals). HOL has been used extensively for formal verification projects in industry.\nHOL provers are used widely in the formalization of mathematical theorems , hardware design ,\ncommunication protocols verification , programs  \nand control system analysis . \nSimilarly, HOL(y) Hammer offers machine learning based premise selection and automated reasoning both for HOL Light and HOL4 .\nRecent work in HOL includes the formalization of quaternions , linear analog circuits ,\nprocess algebra CCS  and metric spaces . A library for combinational circuits is developed in .\nMoreover, formalized Lambek calculus has been ported from Coq to HOL4 in  with some new theorems and improvements. \nA technique based on A* algorithm is presented in  to automate the selection process of \ntactics and tactic-sequences in HOL4.\nNuprl , which inspired the development of RedPRL, is a proof development system based on Computational\nType Theory. Nuprl has evolved significantly in years and now can handle those logics \nwhere inference rules can be declared in a sequent style. It follows the LCF approach and the type theory include less-common subtype, \nvery-dependent function types and type constructors of quotient type. Type checking in Nuprl is undecidable as subtypes can be defined with arbitrary types. \nWhereas in PVS, an algorithm for type-checking automates all simpler type checking tasks. Moreover, the computation language is untyped and judgments are also not \ndecidable because the Poincar{\\'e} principle is assumed not only for {\\em intensional equality} but also for {\\em extensional equality}. Users can interact\nwith Nuprl only through structural editors where proofs can be edited and viewed as proof trees.\nNuprl is used in mathematics formalization and hundred of theorems are proved in the system . \nNuprl is also used in protocol verification , hardware and software specification and \nverification , reasoning about functional programs , design of reliable\nnetworks , and the development of demonstrably correct distributed systems .\nSome work on the integration of Nuprl with other systems is done in the past. \nIn , PVS is integrated in Nuprl to enables users to access PVS from the Nuprl environment. \nA new semantics is provided in  to embed the logic of the HOL prover inside Nuprl.\nSimilarly, Nuprl's meta-theory is formalized in Coq , which is later used in the Nuprl proof for the validity of Brouwer's Bar \nInduction principle .\nCoq also follows the LCF approach and probably the most developed ITP after HOL Light. \nThe logic used in Coq is very expressive that can define rich mathematical objects. \nMoreover, Coq has the ability to explicitly manipulate {\\em proof-objects} from {\\em proof-scripts}, \nwhich makes the integrity of the syetm dependent on the\ncorrectness of the type-checking algorithm. As Coq is based on constructive foundations, it has two basic meta-types (also called sorts): {\\em Prop} (as a type of \nlogical propositions) and {\\em Set} (as a type of other types (eg., Booleans, naturals, subsets, etc) .\nThis allows Coq to distinguish between terms that represent proofs and terms that represent programs.\nA program extractor can also be used to synthesize and extract verified programs (in OCaml, Haskell or Scheme) from their formal specifications . \nCoq uses two languages for proofs: {\\em Gallina} (a pure functional programming language) for writing specification and {\\em LTac} (a procedural language)\nfor the proof process manipulation.\nMain success stories of the system are formalization of fully certified C-compiler , \ndisjoint-set data structure , formalization of two way finite automata , multiplier circuit \nformalization  and coordination language . Main mathematical formalizations done in Coq include the formalization of \nFeit-Thompson theorem , four-color theorem , three gap theorem , real analysis  and \ntheory of algebra . \nA new approach in Coq is presented in  that directly generates provably-safe C code.\nRecently, Coq is used in the formal verification of dynamical systems , password quality checkers , \nsecurity protocol , QWIRE quantum circuit language , complex data structure invariants , \ncomponent connectors  and the control function for the inverted pendulum .\nMoreover, a plug-in (called  SMTCoq) is developed in  to integrate external SMT solvers in Coq.\nAn IDE for integration of Coq projects into Eclipse is also developed in . \nCompared to other ITPs, PVS is based on classical simple type theory and is without {\\em proof-objects},\nwhich allows all kinds of rewriting for numeric as well as symbolic equalities. \nIt offers theory interpretation, dependent types, predicate sub-typing, powerful decision procedures, Latex \nsupport for specifications and proofs, and is user-friendly due to highly expressive specification language and powerful built-in automated deduction. It is also\nintegrated with other outside systems such as a BDD-based model checker and also serves as a back-end verification tool for computer algebra and code \nverification systems . \nDuring proof construction, PVS builds a graphical proof tree in which remaining proof obligations are at the leaves of tree.\nEach node in the tree represents a sequence and each branch is considered as a (sub) proof \ngoal that is followed from its off-spring branch with the help of a proof step.\nPVS prover is based on \\emph{sequent calculus} where each proof goal is a \\emph{sequent} consisting of a sequence of formulas\ncalled \\emph{antecedents} and a sequence of formulas called {\\em consequents}. The type system of PVS is not algorithmically decidable and theorem proving may be \nrequired to establish the type-consistency of a PVS specification. Theorems that need to be proved are called type-correctness conditions (TCCs). \nPVS is used in hardware and software verification , concurrency problems verification , \nfile systems verification , control systems , cryptographic protocol ,\nmicroprocessor verification , real time systems , formalization of integral calculus \n and medical devices .\nSome recent work in PVS includes the specification of multi-window user interface , formalization of component connectors , \nanalysis of distributed cognition systems , genetic algorithms operators  and cloud services .  \nPVS along with its libraries is translated to the OMDoc/MMT framework in . The proposed translation \nprovides a universal representation format for theorem prover libraries.\nSimilarly, PVS is allowed in  to export proof certificates that can be verified externally.\nMoreover, denotational semantics for Answer Set Programming (ASP) is encoded in  and fundamental \nproperties of ASP are proved with PVS theorem prover. \nSome of the differences between top ten famous proof-assistants are listed in Table \\ref{itpcom}. \n\\begin{table}[!ht]\n \\centering\n \\begin{threeparttable}\n  \\caption{Comparison of proof-assistants}\\label{itpcom}\\vspace*{-2mm}\n  \\begin{tabular}{|c|c|c|c|c|c|c|c|}\n    \\hline\n    {\\bf ITPs} & {\\bf rel} & {\\bf T} & {\\bf dep. T} & {\\bf dec. T}& {\\bf state. $\\mathbb{R}$} & {\\bf rpif} & {\\bf LLib} \\\\ \\hline\n     ACL2 & - & - & - & - & + & + & +\\\\ \\hline\n     Isabelle & ++ & + & - & + & + & + & + \\\\ \\hline\n     Metamath & + & - & - & - & + & + & + \\\\ \\hline\n     Twelf & + & + & + & + & - & - & - \\\\ \\hline\n     Agda & +++ & + & + & + & - & - & + \\\\ \\hline\n     Mizar & + & + & + & + & + & + & + \\\\ \\hline\n     HOL & ++ & + & - & + & + & - & + \\\\ \\hline\n     Nuprl & ++ & + & + & - & - & - & - \\\\ \\hline\n     Coq & + & + & + & + & + & - & +\\\\ \\hline\n     PVS & - & + & + & - & + & - & + \\\\ \\hline    \n     \\end{tabular}\n\\begin{tablenotes}\n \\item {\\bf rel}: reliability, {\\bf T}: typed, {\\bf dep. T}: dependent type, {\\bf dec. T}: decidable type, {\\bf state. $\\mathbb{R}$}: statement about $\\mathbb{R}$, \n {\\bf rpif}: readable proof input files, {\\bf LLib}: large library\n\\end{tablenotes}\n\\end{threeparttable}\n\\end{table}", "cites": [7177, 18, 8311, 7180, 7178, 7175, 7179, 17, 9088, 7176], "cite_extract_rate": 0.08264462809917356, "origin_cites_number": 121, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.2, "critical": 3.5, "abstraction": 3.8}, "insight_level": "high", "analysis": "The section effectively synthesizes information from multiple cited papers to discuss the strengths, applications, and technical features of various ITPs. It provides critical insights, such as the limitations of proof obligation generators in Atelier B or the complexity of recursion in HOL. The discussion moves beyond individual tools to highlight broader patterns, such as the use of declarative proof styles or the integration of AI/ATP systems."}}
{"id": "0d771572-8600-42ae-acc2-a3123d3ab133", "title": "ATPs", "level": "subsection", "subsections": [], "parent_id": "a039e28c-2700-4a8b-bd24-c8b8405fda8b", "prefix_titles": [["title", " A Survey on Theorem Provers in Formal Methods"], ["section", "Strengths, Analysis, Applications and Future Directions"], ["subsection", "ATPs"]], "content": "Isabelle is built around a relatively small core that implements many theories as classical FOL, constructive type theory, intuitionistic \nnatural deduction and ZFC. Its meta-logic is based on the fragment of intuitionistic simple type theory \nthat includes basic types as functional types. Whereas the terms are of typed $\\lambda$-calculus. Only the type {\\em prop} (proposition) is defined by the meta-logic \nand the formulas are terms of type {\\em prop}. The meta-logic supports implication, the universal quantification and equality, and the inference rule is \nprovided in natural-deduction style . For proofs, Isabelle combines HOL for writing specification and Isar as the language to describe procedures for proofs \nmanipulation. Isabelle/HOL  is the most widely used system nowadays.  \nIsabelle offers a rich infrastructure for high-level proof schemes. During theory development, both structured and unstructured proofs can be mixed freely. \nIt is important to state that both HOL and Isabelle use {\\em non-standard proof-objects} in the form of tactics for equational reasoning. \nThis makes formalization relatively easy in both systems but it has the disadvantage that the {\\em proof-objects} can not be used to see the proof details. \nIn principal, both systems can be modified for {\\em proof-objects} creation and storing.\nHP used Isabelle in the design and analysis of the HP 9000 line of servers' Runway bus . \nThe \\emph{L4.verified project} at NICTA used Isabelle to prove the \nfunctional correctness of \\emph{seL4} micro-kernel . Moreover, Isabelle is successfully used in security protocols' \ncorrectness , formalization of Java programming language , Java virtual machine code soundness and \ncompleteness , property verification of programming \nlanguage semantics .\nA list of research projects that uses Isabelle can be found at: \\url{isabelle.in.tum.de/community/projects}.\nRecent works in Isabelle include the verification of Ethereum smart contract bytecode , \n imperative programs asymptotic time complexity verification  and formalization of Akra-Bazzi method ,\ndeep learning theoretical foundations , Green's theorem  and \nMarkov chains and Markov decision processes with discrete time and \ndiscrete state-spaces .\nFrom last 15 years, E theorem prover is constantly participating at CASC in more than one category (winnrer in SLH divison in CASC-27 (2019)). \nThe semantics of E is purely decelrative and internal unique features are: shared terms with cached rewriting, folding feature vector \nindexing and fingerprint indexing. Unique features that are visible to the users are advanced and highly flexible search heuristics.\nE main strengths are the generation of {\\em proof-objects}, the automatic problem analysis and the support for the TPTP standrad for answers .\n\\emph{E} is successfully used in the reasoning of large ontologies , software verification \nand certification . One of the main limitations in ATP is the lack of mechanism that allows proofs to guide the proof \nsearch for a new conjecture. In this regard, E is extended in  with various new clause selection strategies. These strategies\nare based on similarity of a clause with the conjecture. The use of watchlists (also known as hint list) in large E \ntheories is explored in , to improve the proof process automation.\nEscher Verifier (the successor of Perfect Developer ) is based on the Verified Design-by-Contract Paradigm  inspired from \nHoare logic and weakest precondition. It performs static analysis and formal verification of \nC programs by checking the out-of-bounds array indexing, arithmetic overflow, null-pointer de-referencing and other undefined behavior in the program. \nIt extends the C language with additional keywords and constructs that are required in programs specifications expression and to give strength to the \nC type system . Term rewriting and FOL based theorem prover is implemented for the verification purpose. \nThe unique feature of the tool is that it provides hints for the cases when the provers is unable to verify the code automatically . \nEscher verifier is used in the verification of C programs , compilers  and \nformal analysis of web applications .\nVampire  is an ATP for FOL, based on equational superposition calculus and is one of the best ATPs at CASC. \nUnique features of Vampire include the generation of interpolants and implementation of a limited resource strategy (LRS). \nMoreover, symbol elimination is also implemented in Vampire that is used to automatically find first-order program properties.\nIt has a special mode for working with very large knowledge bases and can answer queries to them according to TPTP standars. On a multi-core system, Vampire can perform\nseveral proof attempts in parallel .\nThe strength of ATPs such as Vampire, E and SPASS in proving theorems from MML is presented in .\nSome work on adding arithmetic to Vampire is done in .\nVampire is used in  to automate the soundness proofs of type systems.  \nVampire is also used for program analysis and in proving properties of loops with arrays .\nCheap SAT solvers such as Avatar  plays an important role in the success of Vampire.\nIn general, Vampire is well-suited in the domain of type soundness proofs. However, the use of Vampire \nrelies heavily on the size of the chosen axiom set and on the concrete form of individual axioms.\nProver9 , the successor of the Otter prover, is a resolution based automated prover for equational logic and FOL. \nMain strength of Prover9 is that it is paired with Mace4. Users gives formulas and Prover9 attempts to find a proof. \nIf proof is not find then Mace4 looks for a counter-example. Similalry, Prooftrans can be used to transform Prover9 proofs into more detailed proofs, \nsimplify the justifications, re-number and expand proof steps, produce them in XML format, generate hints to guide subsequent searches and produces proofs for \ninput to proof checkers such as IVY. \nProver9 is used in the analysis of cryptographic-key Assignment schemes , verification of Alloy specification language \n and access control policies . Moreover some tasks in combinatorics on words  and\ngeometric procedure  is  also formalized in Prover9, along with proofs of theorems in Tarskian geometry .\nSimilarly, iProver  is based on an instantiation framework for FOL called Inst-Gen .\nFirst order reasoning is combined with ground reasoning in iProver with the help of SAT solver called MiniSat . \nMain strengths of iProver are: reasoning with large theories, a predicate elimination procedure as a preprocessing technique, \nEPR-based k-induction with counterexample, model representation with first order definitions in term algebra and \nproof extraction for resolution as well as instantiation. More details on iProver and other ATPs can be found in Appendix \\ref{A1}.\nTable \\ref{diff6} compares the famous ATPs that perform best at CASC for some features. SonTPTP (Systems on TPTP) is an online interface for ATPs. It can be \nused by the users to run the ATP on TPTP (thousand problems for theorem provers) library or their own problems in the TPTP language . \nIt is important to point out that MaLARea  is not an ATP. It is a simple metasystem that combines several ATPs (E, SPASS, Vampire, etc) \nwith a machine learning based component (SNoW system).  MaLARea interleaves the ATPs by first running them (in cycles) on problems, followed by machine learning \nfrom successful proofs. The learned information is then used to limit the set of axioms provided to ATPs in the next cycle. In CASC-J9 (2018), \nMaLARea comes first in the LTB division. \n\\begin{table}[!ht]\n \\centering\n \\begin{threeparttable}\n  \\caption{Comparison of famous ATPs}\\label{diff6}\n  \\begin{tabular}{|c|c|c|c|c|c|}\n    \\hline\n    {\\bf } & {\\bf Type} & {\\bf ILang} & {\\bf Lib} & {\\bf SS} & {\\bf Web service}\\\\ \\hline\n     E & SB-FOP & C & - & + & SonTPTP\\\\ \\hline\n     Vampire & SB-FOP & C++ & + & - & SonTPTP\\\\ \\hline    \n     Prover9/Otter & RB-FOP & C & + & - & SonTPTP\\\\ \\hline     \n     SPASS & SB-FOP & Java/C & - & + & SonTPTP\\\\ \\hline \n     Satallax & TB-HOP  & OCaml & - & + & SonTPTP \\\\ \\hline \n     iProver & IB-FOP & OCaml & - & + & SonTPTP \\\\ \\hline \n     LEO-II & RB-HOP & OCaml & + & + & SonTPTP \\\\ \\hline \n     MaLARea & MS-ATP & Perl & + & - & - \\\\ \\hline \n     \\end{tabular}\n\\begin{tablenotes}\n\\item \n{\\bf SS}: standalone system, {\\bf FOP}: first-order prover \n {\\bf SB-FOP}: super-position-based FOP, {\\bf RB-FOP}: resolution-based FOP, {\\bf TB-FOP}: tableau-based FOP, {\\bf TB-HOP}: tableau-based higher-order prover, \n {\\bf IB-FOP}: instantaition-based FOP, {\\bf RB-HOP}: resolution-based HOP, {\\bf SonTPTP}: systems on TPTP. {\\bf MS-ATP}: metasystem for ATP\n\\end{tablenotes}\n\\end{threeparttable}\n\\end{table}\nATPs can be integrated (through hammers ) with ITPs for the proof automation in interactive proof development process. \nHammers use ATPs to automatically find the proofs for user defined proof goals.\nThey combine the learning from previous proofs with translation of the goals to the logics of ATPs and reconstruction of the successfully found\nproofs for the goals. Similarly, the SAT/SMT solvers can be used in ITPs by first translating and passing the goals to the fragment supported by a SAT/SMT solver. \nThe SAT/SMT solver then solve the translated goal without human intervention and guidance. Table \\ref{diff7} lists some of the hammers and SAT/SMT solvers that \nare developed and integrated with ITPs. Waldmeister  is integrated with \nAgda in , but no SAT/SMT solvers is yet integrated with Agda. Moreover, PVS employs the Yices SMT solver as an oracle , \nbut not integrated with any ATPs yet.\nSome new theorem provers that aims to fill the gap between interactive and automated theorem proving such as Lean  \n offers APIs to access features of SMT solvers (CVC4, Z3) and ATPs.\n\\begin{table}[!ht]\n \\centering\n  \\caption{ATPs and SAT/SMT solvers for ITPs}\\label{diff7}\n \\begin{tabular}{|c|c|c|}\n    \\hline\n    {\\bf ITP} & {\\bf Hammers} & {\\bf SAT/SMT solvers} \\\\ \\hline\n     Isabelle/HOL & Sledgehammer  & Yices in Isabelle/HOL  \\\\ \\hline\n     HOL Light/HOL4 & HOLyHammer  & SMT solvers for HOL4  \\\\ \\hline\n     Mizar & MizAR  & MiniSAT for Mizar  \\\\ \\hline\n     Coq & Hammer for Coq  & SMTCoq \\\\\\hline\n     ACL2 & ATPs for ACL2  & Smtlink for ACL2 \\\\\\hline\n     \\end{tabular}\n\\end{table}\\vspace*{-2mm}", "cites": [7181, 7182, 7185, 7175, 7183, 7184], "cite_extract_rate": 0.09836065573770492, "origin_cites_number": 61, "insight_result": {"type": "analytical", "scores": {"synthesis": 4.0, "critical": 3.5, "abstraction": 3.0}, "insight_level": "medium", "analysis": "The section synthesizes information from multiple cited papers to provide a coherent narrative about the capabilities, strengths, and application areas of various ATPs. It critically evaluates some limitations, such as the difficulty in inspecting proof objects and the dependence on axiom sets, and discusses improvements like clause selection strategies and watchlists. However, while it identifies some patterns (e.g., reliance on clause selection for proof efficiency), it does not fully abstract these into overarching principles or frameworks."}}
{"id": "951a3765-c38c-47e0-8a12-84315e17fac8", "title": "Some Future Directions", "level": "subsection", "subsections": [], "parent_id": "a039e28c-2700-4a8b-bd24-c8b8405fda8b", "prefix_titles": [["title", " A Survey on Theorem Provers in Formal Methods"], ["section", "Strengths, Analysis, Applications and Future Directions"], ["subsection", "Some Future Directions"]], "content": "Active research activity is going on in both ITPs and ATPs. \nDespite the great progress in last three decades, general purpose FOL based theorem provers are still unable to directly \ndetermine the satisfiability of a first-order formula. \nSMT problem deals with whether a formula written in first-order is satisfiable in some logical theory. \nOne of the famous theorem prover for SMT problem is CVC4 . \nSMT solvers may not terminate on some problems due to undecidability of FOL.\nIn such cases, users would like to know the reason why the solver failed. \nDeveloping tools for SMT solvers which allows developers and users in helping the system to finish some proofs is an\ninteresting research area.\nCurrently, most of the SMT solvers display ``unknown'' when they are unable in proving the unsatisfiability of \nquantified formulas . Main research direction in SMT solvers is to enable them to return counter models \nin case they fail to prove the unsatisfiability of quantified formulas that ranges from integers and inductive datatypes to free sorts. Popular SMT solvers (CVC4, Yices, Z3 etc) generally work in a sequential manner. One another research area is to parallelize SMT solving to better utilize the capability of hardware in multi-core systems. \nPZ3  (the parallel solver for Z3) is one example for this kind of parallelization.\nAnother important area is the development of tools that can integrate SMT solvers in ITPs \nto increase the level of automation by offering safe tactics/strategies for solving proof goals automatically with the help of\nexternal solvers. SMT solvers for ITPs listed in the preceding Table \\ref{diff7} are some example of this. \nOne of the main challenge in ATPs is reasoning with large ontologies, which are becoming more dominant\nas large knowledge bases. Some techniques used for reasoning with large theories are based \non methods for different axiom selection . \nMachine learning is also used for axiom selection where previous knowledge is used to prove a \nconjecture . \nFramework for abstract refinement, where the axioms selection and reasoning phases are interleaved, can \nalso be used in reasoning of large ontologies, as shown recently in  .\nTheorem provers have the limitations that it is not fast enough, the logic is inconvenient as a scripting\nlanguage and majority of theorem provers do not support graphics and visualization tools. Similarly, ITPs requires\nheavy interactions between a user and the proof-assistant, which consumes a lot of time. \nIDE's in theorem provers , especially in ITPs, can substantially facilitate the creation of large proofs. \nHowever, very few of them are equipped with full-fledged IDE's.\nSome future work in this direction includes: (i) making the provers fast and efficient, and (ii) development of IDE's and integration\nof IDE's in different provers. This will make these tools more acceptable in industrial sector. \nSimilarly, in ITPs, users make use of tactics that reduces a goal to simpler and smaller sub-goals. \nAnother interesting area is the development of strategies/tactics by using\ntactic languages, such as HITAC  and Ltac  which will allow users \nto elaborate proof strategies and combine tactics.\nITPs also lack the inter-operability among proof-assistants and other related tools, which means that tool support cannot be easily shared between ITPs. \nTranslation of ITPs to a universal format is needed to overcome the duplication efforts\nin the development of systems, their libraries and supporting periphery tools. Similarly,\nsome work  is done on integrating the model checking with theorem provers. \nHowever, integrating model checking with theorem proving is more difficult as it involves \nthe mapping of models and mathematics involved in the analysis of the systems. \nThe vision of QED manifesto is to develop a universal, computer-based database for all mathematical knowledge that is formalized\nin logic and is supported by proofs that can be validated mechanically.\nAs shown in previous sections, theorem provers are diverse in nature with radically different foundations. \nOn one hand, using various provers offers a diverse experience, which helps to better understand\nthe strengths and weaknesses of provers. However, on the other hand, the effort and overhead needed to learn even one prover \neffectively makes researchers to stick to using just one system. This results in duplication of similar work. \nA way of sharing the work and knowledge among provers would not be just appealing but it would also make \nprovers more powerful and practical. One feasible approach is to import theorems from one prover to another.\nTheorems between different systems are transported by translating the libraries between systems, as done in .\nThe main challenge in sharing theorems is to ensure a meaningful semantic match between the provers, meaning that logic, definitions, types and\ntreatment of functions, etc. in provers are compatible with each other.\nIsabelle's sledgehammer  describes the way for integrating different automation tools.\nHowever, sledgehammer has number of limitations, such as unsound translation, primitive relevance filter and low performance on \nhigher-order problems. Integrating ITPs with ATPs still requires a lot of research into approaches of interfacing. One\nof the main challenge is a sound and reliable translation among different languages and logics.\nSimilarly, other main concern is the interpretation of ATP outputs back into ITP environment.\nITPs does have a large corpora of computer-understandable reasoning knowledge  in the form of libraries. \nThese corpora can play an important role in artificial intelligence based methods, such as concept matching, structure formation\nand theory exploration. \nThe ongoing fast progress in machine learning and data mining made it possible to use\nthese learning techniques on such corpora in guiding the proof search process, in proof automation and in developing proof tactics/strategies, as indicated in\nrecent works . \nSuch machine learning systems can also be combined with ATPs on the large ITPs libraries to develop an artificial intelligence based feedback loops.\nAnother interesting area is to use evolutionary algorithms  in ITPs to find and evolve proofs. Till now,\neffective search mechanisms for formal proofs are lacking and we believe that\nevolutionary algorithms are more suitable for this task due to their suitability to solve search and optimization problems.\nMoreover, investigating evolutionary/heuristic algorithms (as the program (proof) generator) and ITPs (as the proof verifier) to automatically find \nformal proofs for new conjectures is also worth pursuing. Some initial work can be found in , where a GA is used with the Coq to automatically \nfind formal proofs for theorems. \nA single tool based on machine learning is developed in  that can be used for every ITP on one condition: \nboth the language and its corresponding library are available in a universal format, so that they can be easily put into the common selection \nalgorithm. However, the universal format is generally infeasible and expensive for many applications. \nThe reason is that it is very hard to built a universal format that can offer a good trade-off between universality\nand simplicity. Even if such a universal format is available, the implementation of library export into the universal format is laborious. \nOne of the such universal format for formal knowledge is the OMDoc/MMT framework , which has been used\nto translate Mizar , HOL Light  and PVS  libraries into OMDoc/MMT framework . \nTheir work has made the libraries becomes accessible to a wide range of OMDoc-based tools. \nIt would be interesting to translate other famous ITPs logics and libraries to OMDoc/MMT framework for formal mathematics and knowledge management.\nAlso, translation of ITPs to one universal format will make the machine learning based premise selection to provers much easier.\nMoreover, with flexible alignments  between the libraries, the developers of different provers can be guided in the \napproximate translation of contents across libraries and in reuse notations, such as to show one prover \ncontent in a form that looks familiar to other prover users.", "cites": [7182, 19, 20, 7174], "cite_extract_rate": 0.125, "origin_cites_number": 32, "insight_result": {"type": "analytical", "scores": {"synthesis": 3.5, "critical": 3.0, "abstraction": 3.5}, "insight_level": "medium", "analysis": "The section provides an analytical overview of future directions in theorem proving, incorporating insights from the cited papers on machine learning, evolutionary algorithms, and semantic translation. While it integrates concepts from multiple sources, the synthesis is somewhat fragmented and lacks a novel, overarching framework. The critical evaluation is present but limited, with some mention of limitations (e.g., unsound translation in Sledgehammer), though deeper analysis is not consistently applied. The section does attempt abstraction by discussing broader themes such as automation, interoperability, and AI-based proof strategies."}}
